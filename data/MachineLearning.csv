created_utc,score,domain,id,title,ups,downs,num_comments,permalink,selftext,link_flair_text,over_18,thumbnail,subreddit_id,edited,link_flair_css_class,author_flair_css_class,is_self,name,url,distinguished
1375240426.0,139,self.MachineLearning,1jeawf,Machine Learning Books,156,17,36,http://www.reddit.com/r/MachineLearning/comments/1jeawf/machine_learning_books/,"I have been collecting machine learning books over the past couple months.  It seems that machine learning professors are good about posting free legal pdfs of their work.  I hope they are useful to you.  I saw a couple of these books posted individually, but not many of them and not all in one place, so I decided to post. 

Machine Learning

[Elements of Statistical Learning. Hastie, Tibshirani, Friedman ] (http://www-stat.stanford.edu/~tibs/ElemStatLearn/printings/ESLII_print10.pdf)

[All of Statistics. Larry Wasserman](http://www.ucl.ac.uk/~rmjbale/Stat/wasserman2.pdf)


[Machine Learning and Bayesian Reasoning. David Barber ](http://web4.cs.ucl.ac.uk/staff/D.Barber/textbook/090310.pdf)

[Gaussian Processes for Machine Learning. Rasmussen and Williams](http://www.gaussianprocess.org/gpml/chapters/RW.pdf)

[Information Theory, Inference, and Learning Algorithms. David MacKay ] (http://www.cs.toronto.edu/~mackay/itprnn/book.pdf)

[Introduction to Machine Learning. Smola and Vishwanathan](http://alex.smola.org/drafts/thebook.pdf)

[A Probabilistic Theory of Pattern Recognition.  Devroye, Gyorfi, Lugosi.](http://www.szit.bme.hu/%7Egyorfi/pbook.pdf)

[Introduction to Information Retrieval. Manning, Rhagavan, Shutze](http://nlp.stanford.edu/IR-book/pdf/irbookprint.pdf)

[Forecasting: principles and practice. Hyndman, Athanasopoulos. (Online Book) ] (http://otexts.com/fpp/)

Probability / Stats

[Introduction to statistical thought. Lavine ](https://www.math.umass.edu/%7Elavine/Book/book.pdf)

[Basic Probability Theory. Robert Ash](http://www.math.uiuc.edu/~r-ash/BPT/BPT.pdf)

[Introduction to probability. Grinstead and Snell](http://math.dartmouth.edu/~prob/prob/prob.pdf)

[Principle of Uncertainty. Kadane](http://uncertainty.stat.cmu.edu/wp-content/uploads/2011/05/principles-of-uncertainty.pdf)

Linear Algebra / Optimization

[Linear Algebra, Theory, and Applications. Kuttler](https://math.byu.edu/~klkuttle/Linearalgebra.pdf)

[Linear Algebra Done Wrong. Treil](http://www.math.brown.edu/~treil/papers/LADW/LADW.pdf)

[Applied Numerical Computing. Vandenberghe](http://www.seas.ucla.edu/~vandenbe/103/reader.pdf)

[Applied Numerical Linear Algebra.  James Demmel](http://uqu.edu.sa/files2/tiny_mce/plugins/filemanager/files/4281667/hamdy/hamdy1/cgfvnv/hamdy2/h1/h2/h3/h4/h5/h6/Applied%20Numerical%20Linear%20.pdf)

[Convex Optimization. Boyd and Vandenberghe](http://www.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf)

Genetic Algorithms

[ A Field Guide to Genetic Programming. Poli, Langdon, McPhee.](http://dces.essex.ac.uk/staff/rpoli/gp-field-guide/A_Field_Guide_to_Genetic_Programming.pdf)

[Evolved To Win. Sipper](http://www.lulu.com/ie/en/shop/moshe-sipper/evolved-to-win/ebook/product-18719826.html)

[Essentials of Metaheuristics.  Luke](http://cs.gmu.edu/%7Esean/book/metaheuristics/Essentials.pdf) 


Edit: added books listed in comments. added probability, LA, and GA sections",,False,self,t5_2r3gv,1375317761.0,,,True,t3_1jeawf,http://www.reddit.com/r/MachineLearning/comments/1jeawf/machine_learning_books/,
1324928707.0,129,cs.cmu.edu,nre76,We are the 99%.,153,24,7,http://www.reddit.com/r/MachineLearning/comments/nre76/we_are_the_99/,,,False,http://f.thumbs.redditmedia.com/oSMHyr5B0tJS4-KY.jpg,t5_2r3gv,False,,,False,t3_nre76,http://www.cs.cmu.edu/~bsettles/assets/svm.jpg,
1359245549.0,129,peekaboo-vision.blogspot.de,17cbuz, Machine Learning Cheat Sheet (for scikit-learn),148,19,20,http://www.reddit.com/r/MachineLearning/comments/17cbuz/machine_learning_cheat_sheet_for_scikitlearn/,,,False,http://f.thumbs.redditmedia.com/-CqSzm_oV7AWmB-S.jpg,t5_2r3gv,False,,,False,t3_17cbuz,http://peekaboo-vision.blogspot.de/2013/01/machine-learning-cheat-sheet-for-scikit.html,
1367089102.0,117,self.MachineLearning,1d899i,"Google have this week been granted a very broad patent on using Machine Learning on phones. I have an app that does exactly this, published before they filed their application. What do?",137,20,46,http://www.reddit.com/r/MachineLearning/comments/1d899i/google_have_this_week_been_granted_a_very_broad/,"[My app uses machine learning to predict people you are likely to call](https://play.google.com/store/apps/details?id=in.lipik.ai_dial), as a way of enhancing the phone dialer.

[Google's shiny new patent](http://www.google.com/patents/US8429103) gives them the exclusive right to use machine learning on phones (claim 1). Amongst other things, they claim it can be used to predict people you are likely to call (claim 9).

I know about not being evil etc, but this is such a broad patent - and not really novel. I am struggling to understand how a non-evil researcher/engineer would have written the application (I never considered my app to contain anything patentable) - they have essentially claimed rights to the use of machine learning services on phones. So, nobody can make an adaptive app for and phone platform, if Google objects!

I know about the rational for defensive patenting, but still, they have claimed an invention where none exists (they do not have any demonstrated products using this yet - and even if they did, it would not really be invention), and they have subjected all AI implementers to seek their consent before developing!

I am not in America, but my app is on app store. I am wondering what would be the best course of action to take? Ideally, I'd like to show my app as very obvious prior art, and get them to donate the patent to EFF or something.

**Edit**: [I am not that concerned about getting sued, etc. More astonished at the breadth of this patent](/r/MachineLearning/comments/1d899i/google_have_this_week_been_granted_a_very_broad/c9nxvmr).",,False,self,t5_2r3gv,1367100629.0,,,True,t3_1d899i,http://www.reddit.com/r/MachineLearning/comments/1d899i/google_have_this_week_been_granted_a_very_broad/,
1351490136.0,114,fora.tv,129gsx,Peter Norvig reveals new developments by Google in hierarchical learning. Singularity Summit 2012,120,6,8,http://www.reddit.com/r/MachineLearning/comments/129gsx/peter_norvig_reveals_new_developments_by_google/,,,False,http://c.thumbs.redditmedia.com/VP4MXqVgFCHZcsRD.jpg,t5_2r3gv,False,,,False,t3_129gsx,http://fora.tv/2012/10/14/Peter_Norvig_Channeling_the_Flood_of_Data,
1365084662.0,111,oneweirdkerneltrick.com,1bnt2u,Find a separating hyperplane with this One Weird Trick...,144,33,21,http://www.reddit.com/r/MachineLearning/comments/1bnt2u/find_a_separating_hyperplane_with_this_one_weird/,,,False,http://e.thumbs.redditmedia.com/CWF0SxpOIHcUJjMd.jpg,t5_2r3gv,False,,,False,t3_1bnt2u,http://www.oneweirdkerneltrick.com/#,
1367436024.0,96,jbhuang0604.blogspot.se,1di07a,Miss Korea 2013 Contestants Face Morphing,131,35,5,http://www.reddit.com/r/MachineLearning/comments/1di07a/miss_korea_2013_contestants_face_morphing/,,,False,http://f.thumbs.redditmedia.com/MXA47-k6WUoSJDfS.jpg,t5_2r3gv,False,,,False,t3_1di07a,http://jbhuang0604.blogspot.se/2013/04/miss-korea-2013-contestants-face.html,
1321464607.0,92,thenextweb.com,mekrb,This Guy Broke Jeopardy’s All-Time Record… Using ML Techniques To Train Himself,100,8,19,http://www.reddit.com/r/MachineLearning/comments/mekrb/this_guy_broke_jeopardys_alltime_record_using_ml/,,,False,default,t5_2r3gv,False,,,False,t3_mekrb,http://thenextweb.com/shareables/2011/11/16/mind-blown-this-guy-broke-jeopardys-all-time-record-with-an-app/,
1334562132.0,88,techdirt.com,sc3m7,Why Netflix Never Implemented The Algorithm That Won The Netflix $1 Million Challenge | Techdirt,97,9,10,http://www.reddit.com/r/MachineLearning/comments/sc3m7/why_netflix_never_implemented_the_algorithm_that/,,,False,http://e.thumbs.redditmedia.com/CAULtMe51OvDqbgd.jpg,t5_2r3gv,False,,,False,t3_sc3m7,http://www.techdirt.com/blog/innovation/articles/20120409/03412518422/why-netflix-never-implemented-algorithm-that-won-netflix-1-million-challenge.shtml,
1342808337.0,84,twitter.com,wvvwj,"""Is this Bayesian? You know I'm a strict Bayesian, right?""",100,16,12,http://www.reddit.com/r/MachineLearning/comments/wvvwj/is_this_bayesian_you_know_im_a_strict_bayesian/,,,False,http://f.thumbs.redditmedia.com/zKQnxC6xfQ9ogq0_.jpg,t5_2r3gv,False,,,False,t3_wvvwj,https://twitter.com/ML_Hipster,
1376435950.0,84,youtube.com,1kb977,"Andrew Ng: Deep Learning, Self-Taught Learning and Unsupervised Feature Learning",98,14,21,http://www.reddit.com/r/MachineLearning/comments/1kb977/andrew_ng_deep_learning_selftaught_learning_and/,,,False,http://f.thumbs.redditmedia.com/AVv6OW45ZYYWUDd_.jpg,t5_2r3gv,False,,,False,t3_1kb977,https://www.youtube.com/watch?v=n1ViNeWhC24,
1289233823.0,87,self.MachineLearning,e2yzo,"We are the Dataists; we love statistics, machine learning, visualization, and all things data.  How can we help you?",105,18,83,http://www.reddit.com/r/MachineLearning/comments/e2yzo/we_are_the_dataists_we_love_statistics_machine/,"A few months ago, a group of likeminded folks in New York and the San Francisco Bay area decided it was time to start a blog about data, and we can up with [the Dataists](http://www.dataists.com).

Since then we thought about a taxonomy of [data science](http://www.dataists.com/2010/09/a-taxonomy-of-data-science/), [careful statistical computing](http://www.dataists.com/2010/09/careful-statistical-computing-part-1/), [what data visualization should do](http://www.dataists.com/2010/10/what-data-visualization-should-do-simple-small-truth/), and even started a [predictive analytics contest for the R community](http://www.dataists.com/2010/10/using-data-tools-to-find-data-tools-the-yo-dawg-of-data-hacking/).

Many of our posts have been featured here at /r/MachineLearning, so  the moderators thought it would be fun to run a community Q&amp;A.  So, how can we help you?",,False,self,t5_2r3gv,False,,,True,t3_e2yzo,http://www.reddit.com/r/MachineLearning/comments/e2yzo/we_are_the_dataists_we_love_statistics_machine/,
1363136738.0,83,plus.google.com,1a6pb4,Geoffrey Hinton joining Google,93,10,25,http://www.reddit.com/r/MachineLearning/comments/1a6pb4/geoffrey_hinton_joining_google/,,,False,http://f.thumbs.redditmedia.com/EIRpvg8xc4FxsN1G.jpg,t5_2r3gv,False,,,False,t3_1a6pb4,https://plus.google.com/u/0/102889418997957626067/posts/GWe4AscQdS7,
1343284698.0,84,tor.com,x6f00,Norvig vs. Chomsky and the Fight for the Future of AI,96,12,17,http://www.reddit.com/r/MachineLearning/comments/x6f00/norvig_vs_chomsky_and_the_fight_for_the_future_of/,,,False,http://a.thumbs.redditmedia.com/d0H0i-dLTXWk_dyl.jpg,t5_2r3gv,False,,,False,t3_x6f00,http://www.tor.com/blogs/2011/06/norvig-vs-chomsky-and-the-fight-for-the-future-of-ai,
1335889619.0,84,code.google.com,t1o4k,Ceres Solver: Google's large scale nonlinear least squares solver open sourced,89,5,22,http://www.reddit.com/r/MachineLearning/comments/t1o4k/ceres_solver_googles_large_scale_nonlinear_least/,,,False,default,t5_2r3gv,False,,,False,t3_t1o4k,http://code.google.com/p/ceres-solver/,
1360780925.0,80,fastml.com,18gjdz,The secret of the big guys: K-means clustering + a linear model = good results,96,16,18,http://www.reddit.com/r/MachineLearning/comments/18gjdz/the_secret_of_the_big_guys_kmeans_clustering_a/,,,False,http://a.thumbs.redditmedia.com/p86vszMb1C-VR9WZ.jpg,t5_2r3gv,False,,,False,t3_18gjdz,http://fastml.com/the-secret-of-the-big-guys/,
1344796097.0,78,youtube.com,y3owr,What makes Paris look like Paris?,86,8,4,http://www.reddit.com/r/MachineLearning/comments/y3owr/what_makes_paris_look_like_paris/,,,False,http://e.thumbs.redditmedia.com/n47C0iysQjidTlQ4.jpg,t5_2r3gv,False,,,False,t3_y3owr,http://www.youtube.com/watch?v=s5-30NKSwo8,
1306762125.0,76,mldemos.epfl.ch,hngqr,Visualization of Machine Learning algorithms,82,6,23,http://www.reddit.com/r/MachineLearning/comments/hngqr/visualization_of_machine_learning_algorithms/,,,False,http://thumbs.reddit.com/t3_hngqr.png,t5_2r3gv,False,,,False,t3_hngqr,http://mldemos.epfl.ch/,
1367326507.0,76,numenta.org,1deofm,Numenta will open source their core algorithms,87,11,34,http://www.reddit.com/r/MachineLearning/comments/1deofm/numenta_will_open_source_their_core_algorithms/,,,False,http://e.thumbs.redditmedia.com/xJm-P0UrICk8SXV4.jpg,t5_2r3gv,False,,,False,t3_1deofm,http://numenta.org,
1372422801.0,74,self.MachineLearning,1h8svj,"Can anyone explain the recent unsupervised learning ""breakthrough"" by Yoshua Bengio?",82,8,32,http://www.reddit.com/r/MachineLearning/comments/1h8svj/can_anyone_explain_the_recent_unsupervised/,"I only just read about it [here](http://www.wired.com/wiredenterprise/2013/06/yoshua-bengio/). What exactly did he come up with that's new, and what can it do that's different?",,False,self,t5_2r3gv,False,,,True,t3_1h8svj,http://www.reddit.com/r/MachineLearning/comments/1h8svj/can_anyone_explain_the_recent_unsupervised/,
1289672991.0,71,self.MachineLearning,e5nzm,Some professors and grad students have offered to do a r/ML Q&amp;A next week on combining the Mechanical Turk crowdsourcing tool with ML. Vote up if you want to talk to them or down if you don't,83,12,13,http://www.reddit.com/r/MachineLearning/comments/e5nzm/some_professors_and_grad_students_have_offered_to/,,,False,self,t5_2r3gv,False,,,True,t3_e5nzm,http://www.reddit.com/r/MachineLearning/comments/e5nzm/some_professors_and_grad_students_have_offered_to/,
1365499835.0,69,youtube.com,1bzawc,A really gentle introduction to Hidden Markov Models.,81,12,3,http://www.reddit.com/r/MachineLearning/comments/1bzawc/a_really_gentle_introduction_to_hidden_markov/,,,False,http://f.thumbs.redditmedia.com/-lnHyAsJnTzVTGPq.jpg,t5_2r3gv,False,,,False,t3_1bzawc,http://www.youtube.com/watch?v=jY2E6ExLxaw,
1349587875.0,68,jeremykun.wordpress.com,112snv,"Eigenfaces, linear algebra for face recognition: a well done tutorial with proofs and pictures.",82,14,1,http://www.reddit.com/r/MachineLearning/comments/112snv/eigenfaces_linear_algebra_for_face_recognition_a/,,,False,http://b.thumbs.redditmedia.com/ayd7yAzzmr_-tID7.jpg,t5_2r3gv,False,,,False,t3_112snv,http://jeremykun.wordpress.com/2011/07/27/eigenfaces/,
1352308731.0,69,swampland.time.com,12t0k6,Inside the Secret World of the Data Crunchers Who Helped Obama Win,77,8,28,http://www.reddit.com/r/MachineLearning/comments/12t0k6/inside_the_secret_world_of_the_data_crunchers_who/,,,False,http://d.thumbs.redditmedia.com/m5946FX2vTwhYzU-.jpg,t5_2r3gv,False,,,False,t3_12t0k6,http://swampland.time.com/2012/11/07/inside-the-secret-world-of-quants-and-data-crunchers-who-helped-obama-win/,
1358375834.0,71,techtalks.tv,16pnlc,Andrew Ng Talk on Deep Learning,83,12,12,http://www.reddit.com/r/MachineLearning/comments/16pnlc/andrew_ng_talk_on_deep_learning/,,,False,default,t5_2r3gv,False,,,False,t3_16pnlc,http://techtalks.tv/talks/machine-learning-and-ai-via-brain-simulations/57862/,
1323912778.0,65,youtube.com,nd5vo,Well taught and extensive machine learning video series in a format a bit like Khan Academy,70,5,4,http://www.reddit.com/r/MachineLearning/comments/nd5vo/well_taught_and_extensive_machine_learning_video/,,,False,http://c.thumbs.redditmedia.com/sajHQbTl-nmtdOwh.jpg,t5_2r3gv,False,,,False,t3_nd5vo,http://www.youtube.com/playlist?list=PLD0F06AA0D2E8FFBA&amp;feature=plcp,
1364406360.0,65,yelp.com,1b4ekh,Yelp has released a new academic dataset,78,13,6,http://www.reddit.com/r/MachineLearning/comments/1b4ekh/yelp_has_released_a_new_academic_dataset/,,,False,default,t5_2r3gv,False,,,False,t3_1b4ekh,http://www.yelp.com/dataset_challenge,
1306509605.0,67,norvig.com,hlk9x,Norvig on Chomsky and the Two Cultures of Statistical Learning,75,8,14,http://www.reddit.com/r/MachineLearning/comments/hlk9x/norvig_on_chomsky_and_the_two_cultures_of/,,,False,http://thumbs.reddit.com/t3_hlk9x.png,t5_2r3gv,False,,,False,t3_hlk9x,http://norvig.com/chomsky.html,
1374408821.0,64,techtalks.tv,1iqwnt,Videos of all the talks of ICML 2013 are now available,72,8,10,http://www.reddit.com/r/MachineLearning/comments/1iqwnt/videos_of_all_the_talks_of_icml_2013_are_now/,,,False,http://e.thumbs.redditmedia.com/sgkHVkvzAFfl65vj.jpg,t5_2r3gv,False,,,False,t3_1iqwnt,http://techtalks.tv/icml/2013/,
1370278388.0,62,numenta.org,1fl96e,Introducing the Numenta Platform for Intelligent Computing (NuPIC),83,21,29,http://www.reddit.com/r/MachineLearning/comments/1fl96e/introducing_the_numenta_platform_for_intelligent/,,,False,http://a.thumbs.redditmedia.com/vH5V8smbwg_qhoer.jpg,t5_2r3gv,False,,,False,t3_1fl96e,http://numenta.org/news/2013/06/03/introducing-nupic.html,
1292287473.0,61,puremango.co.uk,elbqx,"Genetic Algorithm for ""Hello World"". In JavaScript.",68,7,17,http://www.reddit.com/r/MachineLearning/comments/elbqx/genetic_algorithm_for_hello_world_in_javascript/,,,False,http://thumbs.reddit.com/t3_elbqx.png,t5_2r3gv,False,,,False,t3_elbqx,http://www.puremango.co.uk/2010/12/genetic-algorithm-for-hello-world/,
1376299907.0,64,autonlab.org,1k74we,Andrew Moore's slides on Bayesian classifiers — the most accessible (yet mathematically rigorous) introduction to the topic I have ever read.,75,11,6,http://www.reddit.com/r/MachineLearning/comments/1k74we/andrew_moores_slides_on_bayesian_classifiers_the/,,,False,default,t5_2r3gv,False,,,False,t3_1k74we,http://www.autonlab.org/tutorials/prob18.pdf,
1367597485.0,62,fastml.com,1dmj90,Deep learning made easy,68,6,6,http://www.reddit.com/r/MachineLearning/comments/1dmj90/deep_learning_made_easy/,,,False,http://e.thumbs.redditmedia.com/3Vv7OMrQnz8l2H3R.jpg,t5_2r3gv,False,,,False,t3_1dmj90,http://fastml.com/deep-learning-made-easy/,
1358458790.0,63,137.189.35.203,16rxn0,"ML for Reddit: 10,000 images of cats",79,16,8,http://www.reddit.com/r/MachineLearning/comments/16rxn0/ml_for_reddit_10000_images_of_cats/,,,False,http://d.thumbs.redditmedia.com/BB_qHbPoPmx56L09.jpg,t5_2r3gv,False,,,False,t3_16rxn0,http://137.189.35.203/WebUI/CatDatabase/catData.html,
1366694060.0,63,self.MachineLearning,1cx2l8,Anyone else doing Andrew Ng's Coursera course on machine learning?,71,8,35,http://www.reddit.com/r/MachineLearning/comments/1cx2l8/anyone_else_doing_andrew_ngs_coursera_course_on/,"The class started today. You can sign up [here](https://www.coursera.org/course/ml) (it is free). /r/mlclass has been a sort of subreddit/study group for it in the past, it seems, and I assume it could fill that purpose again this time around. Anyway, I signed up for it and I'm pretty stoked for it. :D",,False,self,t5_2r3gv,False,,,True,t3_1cx2l8,http://www.reddit.com/r/MachineLearning/comments/1cx2l8/anyone_else_doing_andrew_ngs_coursera_course_on/,
1355435161.0,59,abstrusegoose.com,14t2aj,Cat!,81,22,16,http://www.reddit.com/r/MachineLearning/comments/14t2aj/cat/,,,False,http://f.thumbs.redditmedia.com/fvfekSmn7EJP-P6e.jpg,t5_2r3gv,False,,,False,t3_14t2aj,http://abstrusegoose.com/496,
1341547808.0,60,work.caltech.edu,w43hp,Introduction to Machine Learning Lectures: from Caltech Prof. Yaser S. Abu-Mostafa,66,6,2,http://www.reddit.com/r/MachineLearning/comments/w43hp/introduction_to_machine_learning_lectures_from/,,,False,http://d.thumbs.redditmedia.com/-ihRQ7cWIQCoBPL9.jpg,t5_2r3gv,False,,,False,t3_w43hp,http://work.caltech.edu/library/,
1301693003.0,59,engadget.com,ggpch,[impressive] Zdenek Kalal's object tracking algorithm learns on the fly,68,9,12,http://www.reddit.com/r/MachineLearning/comments/ggpch/impressive_zdenek_kalals_object_tracking/,,,False,default,t5_2r3gv,False,,,False,t3_ggpch,http://www.engadget.com/2011/03/31/zdenek-kalals-object-tracking-algorithm-learns-on-the-fly-like/,
1337564332.0,58,mewo2.github.com,twt9g,Markov Chain Monte Carlo and the Eurovision Song Contest,61,3,5,http://www.reddit.com/r/MachineLearning/comments/twt9g/markov_chain_monte_carlo_and_the_eurovision_song/,,,False,http://b.thumbs.redditmedia.com/rYuqPysmv-uFQmtI.jpg,t5_2r3gv,False,,,False,t3_twt9g,http://mewo2.github.com/nerdery/2012/05/20/ive-got-eurosong-fever-ted/,
1288847635.0,60,geekosystem.com,e10o1,"The graph of breakups over the course of the year, as culled from over 10,000 Facebook status updates by data-minded supersleuth David McCandless.",69,9,8,http://www.reddit.com/r/MachineLearning/comments/e10o1/the_graph_of_breakups_over_the_course_of_the_year/,,,False,http://thumbs.reddit.com/t3_e10o1.png,t5_2r3gv,False,,,False,t3_e10o1,http://www.geekosystem.com/facebook-breakup-graph/,
1367537885.0,60,youtube.com,1dl2qq,Advanced Machine Learning with scikit-learn (156:42) [x-post /r/python],69,9,2,http://www.reddit.com/r/MachineLearning/comments/1dl2qq/advanced_machine_learning_with_scikitlearn_15642/,,,False,http://d.thumbs.redditmedia.com/UVcUpUEbxF12GHfE.jpg,t5_2r3gv,False,,,False,t3_1dl2qq,http://www.youtube.com/watch?v=iFkRt3BCctg,
1366353212.0,57,blog.bigml.com,1cnysg,A New Way to Visualize Decision Trees,69,12,5,http://www.reddit.com/r/MachineLearning/comments/1cnysg/a_new_way_to_visualize_decision_trees/,,,False,http://c.thumbs.redditmedia.com/rBKY2KfznPn0m5ab.jpg,t5_2r3gv,False,,,False,t3_1cnysg,http://blog.bigml.com/2013/04/19/a-new-way-to-visualize-decision-trees/,
1329415323.0,59,nytimes.com,psksj,"How Companies Learn Your Secrets -- “If we wanted to figure out if a customer is pregnant, even if she didn’t want us to know, can you do that? ”",64,5,9,http://www.reddit.com/r/MachineLearning/comments/psksj/how_companies_learn_your_secrets_if_we_wanted_to/,,,False,default,t5_2r3gv,False,,,False,t3_psksj,http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html,
1343757356.0,56,blog.echen.me,xgk72,Edge Prediction in a Social Graph: Edwin Chen's Solution to Facebook's User Recommendation Contest,60,4,0,http://www.reddit.com/r/MachineLearning/comments/xgk72/edge_prediction_in_a_social_graph_edwin_chens/,,,False,http://e.thumbs.redditmedia.com/DA_LYs4T6FjAGJ9p.jpg,t5_2r3gv,False,,,False,t3_xgk72,http://blog.echen.me/2012/07/31/edge-prediction-in-a-social-graph-my-solution-to-facebooks-user-recommendation-contest-on-kaggle/,
1374713356.0,59,newfolder.github.io,1izuqf,A Quick Guide to SVMs for Scientists &amp; Engineers,64,5,4,http://www.reddit.com/r/MachineLearning/comments/1izuqf/a_quick_guide_to_svms_for_scientists_engineers/,,,False,http://e.thumbs.redditmedia.com/2UUk1st1-eWQkVmL.jpg,t5_2r3gv,False,,,False,t3_1izuqf,http://newfolder.github.io/blog/2013/07/24/using-svms/,
1344661914.0,58,i.stanford.edu,y1bcz,Mining of Massive Datasets: Free E-Book from Stanford prof,64,6,3,http://www.reddit.com/r/MachineLearning/comments/y1bcz/mining_of_massive_datasets_free_ebook_from/,,,False,http://a.thumbs.redditmedia.com/5hF70KFNhpilpjgB.jpg,t5_2r3gv,False,,,False,t3_y1bcz,http://i.stanford.edu/~ullman/mmds.html,
1335199904.0,56,coursera.org,sodu1,Stanford's ML class for Spring 2012 is now live for anyone interested.,57,1,10,http://www.reddit.com/r/MachineLearning/comments/sodu1/stanfords_ml_class_for_spring_2012_is_now_live/,,,False,default,t5_2r3gv,False,,,False,t3_sodu1,https://www.coursera.org/course/ml,
1304582274.0,56,eferm.com,h4oc5,Machine Learning cheat sheet ,68,12,11,http://www.reddit.com/r/MachineLearning/comments/h4oc5/machine_learning_cheat_sheet/,,,False,http://thumbs.reddit.com/t3_h4oc5.png,t5_2r3gv,False,,,False,t3_h4oc5,http://eferm.com/machine-learning-cheat-sheet,
1279792557.0,53,informationweek.com,cseh1,Memphis uses predictive analytics to cut crime by 31%,58,5,7,http://www.reddit.com/r/MachineLearning/comments/cseh1/memphis_uses_predictive_analytics_to_cut_crime_by/,,,False,default,t5_2r3gv,False,,,False,t3_cseh1,http://www.informationweek.com/news/business_intelligence/analytics/showArticle.jhtml?articleID=226100087,
1353104745.0,57,snikolov.wordpress.com,13blz2,Early detection of Twitter trends explained,63,6,27,http://www.reddit.com/r/MachineLearning/comments/13blz2/early_detection_of_twitter_trends_explained/,,,False,http://f.thumbs.redditmedia.com/qvgneJt3kibzRYu5.jpg,t5_2r3gv,False,,,False,t3_13blz2,http://snikolov.wordpress.com/2012/11/14/early-detection-of-twitter-trends/,
1326160131.0,56,holehouse.org,oa633,Complete notes of Stanford machine learning course,63,7,3,http://www.reddit.com/r/MachineLearning/comments/oa633/complete_notes_of_stanford_machine_learning_course/,,,False,default,t5_2r3gv,False,,,False,t3_oa633,http://holehouse.org/mlclass/,
1313460832.0,55,ml-class.org,jk0on,"Machine Learning Class, this coming Fall 2011, by Andrew Ng",60,5,12,http://www.reddit.com/r/MachineLearning/comments/jk0on/machine_learning_class_this_coming_fall_2011_by/,,,False,http://thumbs.reddit.com/t3_jk0on.png,t5_2r3gv,False,,,False,t3_jk0on,http://ml-class.org/,
1376149222.0,54,self.MachineLearning,1k3c6z,Struggling to learn Machine Learning on my own,66,12,36,http://www.reddit.com/r/MachineLearning/comments/1k3c6z/struggling_to_learn_machine_learning_on_my_own/,"I'm studying Machine Learning on my own, but with some difficulties. I tried many books on Machine Learning but it wasn't easy to find the right one.

Bishop's ""Pattern Recognition and Machine Learning"" is a very hard read. In my opinion, the problem is not the material but the exposition. Many derivations are left to the reader and there are too many ""it's trivial to see"", ""it can be readily seen"" and ""after some straightforward algebra"". In the end, I gave up.

""The Elements of Statistical Learning"" (Hastie et al.) suffers from the same problems. Moreover, some explanations I couldn't follow because they referred to concepts I wasn't familiar with. All these books claim that you just need to know some calculus, probability and linear algebra, but that's a lie. Bishop even tries to teach you basic probability, suggesting that his book can be read by one who doesn't know probability, which is absurd.

The lessons by Andrew Ng are easy to follow but they're not very deep. They show you a collection of techniques but they don't provide the theory that should guide you in using these techniques. Also, many techniques are presented in their simplest form.
The lectures by Tom Mitchell are also very easy to follow but I think he oversimplifies things. By the way, he says that after taking his course one can do research and read papers without problems. I wish it was that easy.

The same material can be presented at very different levels and I found out that there is a noticeable gap between elementary texts and lessons, and advanced ones. I was looking for something advanced but at the same time accessible. In my opinion, a text can be advanced and at the same time introductory. Introductory should mean that no prior knowledge of the topic is assumed. Many books claim to be introductory but they're not. Some explanations are so cryptic that only one with a prior exposure to the material would benefit from them.

Finally, I found the right book for me: Pattern Classification (Duda, Hart, Stork, 2ed.). The book doesn't shy away from advanced material and the explanations are great. Finally, a book that I can study on my own without having to rely on somebody else for additional explanations!

What's your experience with Machine Learning books, textbooks and lectures?",,False,self,t5_2r3gv,False,,,True,t3_1k3c6z,http://www.reddit.com/r/MachineLearning/comments/1k3c6z/struggling_to_learn_machine_learning_on_my_own/,
1375101532.0,56,peekaboo-vision.blogspot.de,1j9toa,Peekaboo: Scikit-learn 0.14 release candidate,65,9,18,http://www.reddit.com/r/MachineLearning/comments/1j9toa/peekaboo_scikitlearn_014_release_candidate/,,,False,http://d.thumbs.redditmedia.com/j449NrE6NvMk5B5i.jpg,t5_2r3gv,False,,,False,t3_1j9toa,http://peekaboo-vision.blogspot.de/2013/07/scikit-learn-sprint-and-014-release.html,
1354527300.0,51,richardminerich.com,146zlq,"My Education in Machine Learning via Cousera, A Review So Far",62,11,16,http://www.reddit.com/r/MachineLearning/comments/146zlq/my_education_in_machine_learning_via_cousera_a/,,,False,default,t5_2r3gv,False,,,False,t3_146zlq,http://richardminerich.com/2012/12/my-education-in-machine-learning-via-cousera/,
1331821677.0,54,amturing.acm.org,qxsrb,Judea Pearl wins Turing Award,57,3,3,http://www.reddit.com/r/MachineLearning/comments/qxsrb/judea_pearl_wins_turing_award/,,,False,http://b.thumbs.redditmedia.com/p_98MqONO1Kpj127.jpg,t5_2r3gv,False,,,False,t3_qxsrb,http://amturing.acm.org/award_winners/pearl_2658896.cfm,
1361888081.0,53,arxiv.org,199c6c,"Efficient Estimation of Word Representations in Vector Space -- vec(""King"") - vec(""Man"") + vec(""Woman"") ~= vec(""Queen"")",59,6,2,http://www.reddit.com/r/MachineLearning/comments/199c6c/efficient_estimation_of_word_representations_in/,,,False,default,t5_2r3gv,False,,,False,t3_199c6c,http://arxiv.org/pdf/1301.3781v1.pdf,
1352072624.0,54,cs.uvm.edu,12mxy7,"Top 10 algorithms in data mining: outdated, but a good starting point for newcomers to the field",62,8,4,http://www.reddit.com/r/MachineLearning/comments/12mxy7/top_10_algorithms_in_data_mining_outdated_but_a/,,,False,default,t5_2r3gv,False,,,False,t3_12mxy7,http://www.cs.uvm.edu/~icdm/algorithms/10Algorithms-08.pdf,
1343348919.0,53,blog.david-andrzejewski.com,x7yek,Practical machine learning tricks from the KDD 2011 best industry paper,55,2,3,http://www.reddit.com/r/MachineLearning/comments/x7yek/practical_machine_learning_tricks_from_the_kdd/,,,False,default,t5_2r3gv,False,,,False,t3_x7yek,http://blog.david-andrzejewski.com/machine-learning/practical-machine-learning-tricks-from-the-kdd-2011-best-industry-paper/,
1371807062.0,48,eferm.com,1gsazq,Machine learning - cheat sheet,63,15,5,http://www.reddit.com/r/MachineLearning/comments/1gsazq/machine_learning_cheat_sheet/,,,False,http://d.thumbs.redditmedia.com/ZCJv1Pydm-74ziWc.jpg,t5_2r3gv,False,,,False,t3_1gsazq,http://eferm.com/machine-learning-cheat-sheet/,
1368717813.0,55,googleresearch.blogspot.com,1ege1k,Google launches quantum artificial intelligence lab!,68,13,17,http://www.reddit.com/r/MachineLearning/comments/1ege1k/google_launches_quantum_artificial_intelligence/,,,False,default,t5_2r3gv,False,,,False,t3_1ege1k,http://googleresearch.blogspot.com/2013/05/launching-quantum-artificial.html,
1358544643.0,53,yann.lecun.com,16u8rm,Yann LeCun's proposal for a new peer review system.,58,5,25,http://www.reddit.com/r/MachineLearning/comments/16u8rm/yann_lecuns_proposal_for_a_new_peer_review_system/,,,False,http://b.thumbs.redditmedia.com/sosH0Pn8SecKhfRy.jpg,t5_2r3gv,False,,,False,t3_16u8rm,http://yann.lecun.com/ex/pamphlets/publishing-models.html,
1355733561.0,50,conductrics.com,14ziao,A List of Data Science and Machine Learning Resources [x-post Hacker News],55,5,3,http://www.reddit.com/r/MachineLearning/comments/14ziao/a_list_of_data_science_and_machine_learning/,,,False,http://c.thumbs.redditmedia.com/h_OVgCPkpPBirYzJ.jpg,t5_2r3gv,False,,,False,t3_14ziao,http://conductrics.com/data-science-resources/,
1330191631.0,54,pennyauctionwatch.com,q5m9m,Penny Auction Scam Uncovered By PhD Students,61,7,7,http://www.reddit.com/r/MachineLearning/comments/q5m9m/penny_auction_scam_uncovered_by_phd_students/,,,False,http://b.thumbs.redditmedia.com/EY_qzdmrhdWmZq87.jpg,t5_2r3gv,False,,,False,t3_q5m9m,http://www.pennyauctionwatch.com/2012/02/arrowoutlet-scam-exposed-penny-auctions/,
1255539062.0,52,www-stat.stanford.edu,9u0ot,"The Elements of Statistical Learning (Hastie, Tibshirani and Friedman) is now available as free PDF
	
",53,1,6,http://www.reddit.com/r/MachineLearning/comments/9u0ot/the_elements_of_statistical_learning_hastie/,,,False,default,t5_2r3gv,False,,,False,t3_9u0ot,http://www-stat.stanford.edu/~tibs/ElemStatLearn/,
1370850985.0,47,youtube.com,1g18a6,Geoff Hinton - Recent Developments in Deep Learning,61,14,14,http://www.reddit.com/r/MachineLearning/comments/1g18a6/geoff_hinton_recent_developments_in_deep_learning/,,,False,http://d.thumbs.redditmedia.com/nDLE5A52idp7Jg-u.jpg,t5_2r3gv,False,,,False,t3_1g18a6,http://www.youtube.com/watch?v=vShMxxqtDDs,
1351877771.0,52,blog.kaggle.com,12iuri,How deep learning on GPUs wins datamining contest without feature engineering,56,4,11,http://www.reddit.com/r/MachineLearning/comments/12iuri/how_deep_learning_on_gpus_wins_datamining_contest/,,,False,default,t5_2r3gv,False,,,False,t3_12iuri,http://blog.kaggle.com/2012/11/01/deep-learning-how-i-did-it-merck-1st-place-interview/,
1354093999.0,53,deeplearning.net,13xd4r,Deep Learning Reading List,57,4,2,http://www.reddit.com/r/MachineLearning/comments/13xd4r/deep_learning_reading_list/,,,False,default,t5_2r3gv,False,,,False,t3_13xd4r,http://deeplearning.net/reading-list/,
1309001974.0,52,youtube.com,i8uuc,Andrew Ng : Unsupervised Feature Learning and Deep Learning [VID],55,3,7,http://www.reddit.com/r/MachineLearning/comments/i8uuc/andrew_ng_unsupervised_feature_learning_and_deep/,,,False,http://thumbs.reddit.com/t3_i8uuc.png,t5_2r3gv,False,,,False,t3_i8uuc,http://www.youtube.com/watch?v=ZmNOAtZIgIk,
1275043947.0,47,engadget.com,c907j,"Autonomous quadrocopter flies through windows, straight into our hearts (video) -- Engadget",50,3,6,http://www.reddit.com/r/MachineLearning/comments/c907j/autonomous_quadrocopter_flies_through_windows/,,,False,http://thumbs.reddit.com/t3_c907j.png,t5_2r3gv,False,,,False,t3_c907j,http://www.engadget.com/2010/05/28/autonomous-quadrocopter-flies-through-windows-straight-into-our/,
1369326316.0,49,appliedpredictivemodeling.com,1ewswv,new predictive modeling book,59,10,21,http://www.reddit.com/r/MachineLearning/comments/1ewswv/new_predictive_modeling_book/,,,False,http://c.thumbs.redditmedia.com/-BdAeNg5W0JJpvj8.jpg,t5_2r3gv,False,,,False,t3_1ewswv,http://appliedpredictivemodeling.com/,
1352940511.0,46,vimeo.com,137nlk,Why do scientists continue supporting the Kaggle model? Kaggle = scientists exploited.,59,13,68,http://www.reddit.com/r/MachineLearning/comments/137nlk/why_do_scientists_continue_supporting_the_kaggle/,,,False,http://a.thumbs.redditmedia.com/bXOo4yEIkoJvQrLN.jpg,t5_2r3gv,False,,,False,t3_137nlk,http://vimeo.com/53095017,
1316202832.0,50,singularityhub.com,khzlx,Lawyers Object As Computer Program Does Job Better  | Singularity Hub,57,7,0,http://www.reddit.com/r/MachineLearning/comments/khzlx/lawyers_object_as_computer_program_does_job/,,,False,http://thumbs.reddit.com/t3_khzlx.png,t5_2r3gv,False,,,False,t3_khzlx,http://singularityhub.com/2011/07/04/lawyers-object-as-computer-program-does-job-better/,
1299406581.0,46,puremango.co.uk,fycjp,Fun Genetic Algorithm Examples,52,6,8,http://www.reddit.com/r/MachineLearning/comments/fycjp/fun_genetic_algorithm_examples/,,,False,default,t5_2r3gv,False,,,False,t3_fycjp,http://www.puremango.co.uk/2011/03/genetic-algorithm-examples/,
1277983240.0,48,metaoptimize.com,ckw5k,Stackoverflow for Machine Learning and Natural Language Processing,53,5,7,http://www.reddit.com/r/MachineLearning/comments/ckw5k/stackoverflow_for_machine_learning_and_natural/,,,False,default,t5_2r3gv,False,,,False,t3_ckw5k,http://metaoptimize.com/qa,
1372647623.0,49,techtalks.tv,1heiol,Geoff Hinton on his new approach to deep neural networks: DREDNETs,52,3,8,http://www.reddit.com/r/MachineLearning/comments/1heiol/geoff_hinton_on_his_new_approach_to_deep_neural/,,,False,default,t5_2r3gv,False,,,False,t3_1heiol,http://techtalks.tv/talks/drednets/58115/,
1362530831.0,46,github.com,19qs1t,"Generalized! Long Short-Term Memory neural networks (Python code, link to original paper in readme)",57,11,24,http://www.reddit.com/r/MachineLearning/comments/19qs1t/generalized_long_shortterm_memory_neural_networks/,,,False,http://d.thumbs.redditmedia.com/26UFzohlcDUGTLl-.jpg,t5_2r3gv,False,,,False,t3_19qs1t,https://github.com/MrMormon/lstm-g,
1345165070.0,47,guidetodatamining.com,ycnxi,"Great, free intro to data mining &amp; machine learning",59,12,2,http://www.reddit.com/r/MachineLearning/comments/ycnxi/great_free_intro_to_data_mining_machine_learning/,,,False,http://e.thumbs.redditmedia.com/XPYna7-9tttqFgKp.jpg,t5_2r3gv,False,,,False,t3_ycnxi,http://guidetodatamining.com/,
1339540878.0,49,quora.com,uyr6p,"How big is the largest feedforward neural network ever trained, and what for? - Quora",58,9,15,http://www.reddit.com/r/MachineLearning/comments/uyr6p/how_big_is_the_largest_feedforward_neural_network/,,,False,http://b.thumbs.redditmedia.com/2Q_DYW3w3Vf0TvNa.jpg,t5_2r3gv,False,,,False,t3_uyr6p,http://www.quora.com/How-big-is-the-largest-feedforward-neural-network-ever-trained-and-what-for,
1325621446.0,43,hunch.net,o1h2a,Clever and unintentional ways to overfit a data set,48,5,0,http://www.reddit.com/r/MachineLearning/comments/o1h2a/clever_and_unintentional_ways_to_overfit_a_data/,,,False,default,t5_2r3gv,False,,,False,t3_o1h2a,http://hunch.net/?p=22,
1310496325.0,50,hunch.net,innmq,Neural Networks Making A Comeback? ICML Says Yes?,53,3,15,http://www.reddit.com/r/MachineLearning/comments/innmq/neural_networks_making_a_comeback_icml_says_yes/,,,False,default,t5_2r3gv,False,,,False,t3_innmq,http://hunch.net/?p=1852,
1362654172.0,45,webgl-ann-experiment.appspot.com,19u8j4,Experimental Visualization of Artificial Neural Network with WebGL by Markus Sprunck .  This is a terrific example of a neural network.  The visualization clearly shows the relationships between the different layers.  I have a few articles on machine learning @ http://www.refactorthis.net ,56,11,7,http://www.reddit.com/r/MachineLearning/comments/19u8j4/experimental_visualization_of_artificial_neural/,,,False,default,t5_2r3gv,False,,,False,t3_19u8j4,http://webgl-ann-experiment.appspot.com/,
1346181370.0,44,youtube.com,yz5tx,"Brains, Sex, and Machine Learning: Geoffrey Hinton introduces ""dropout"" technique for training neural nets",53,9,85,http://www.reddit.com/r/MachineLearning/comments/yz5tx/brains_sex_and_machine_learning_geoffrey_hinton/,,,False,http://b.thumbs.redditmedia.com/F0r3kpMo_BSw3VBg.jpg,t5_2r3gv,False,,,False,t3_yz5tx,http://www.youtube.com/watch?v=DleXA5ADG78&amp;feature=youtube_gdata,
1329771422.0,44,33bits.org,pya0m,Writing de-anonymizer achieves 80% accuracy with 50% recall on 2.4m posts from 100k blogs,52,8,14,http://www.reddit.com/r/MachineLearning/comments/pya0m/writing_deanonymizer_achieves_80_accuracy_with_50/,,,False,http://c.thumbs.redditmedia.com/6DUIqjAb6rdIOnwt.jpg,t5_2r3gv,False,,,False,t3_pya0m,http://33bits.org/2012/02/20/is-writing-style-sufficient-to-deanonymize-material-posted-online/,
1324518984.0,46,self.MachineLearning,nm1d4,Show r/ML: Classifying New Posts into Subreddits,52,6,2,http://www.reddit.com/r/MachineLearning/comments/nm1d4/show_rml_classifying_new_posts_into_subreddits/,"Hi r/ML - I just finished a class in Applied Machine Learning, for which I was required to implement an open-ended project that would use some of the things taught to us during the quarter. Inspired by [this article](http://blog.notdot.net/2010/06/Trying-out-the-new-Prediction-API), I decided to build a system which could learn to predict the intended subreddit for a given post. Although I initially wanted to use dimensionality reduction techniques like PCA or LDA, it turned out that they offered little marginal benefit to warrant the added computational complexity. In the end, I decided to train independent supervised classifiers for the post's title text and its domain, and combined the two probability estimates for each subreddit to arrive at a holistic score for the post. I experimented with several types of classifier models (logistic regression, stochastic gradient descent, and naive bayes), and used the one-vs-all approach  to generalize the first two model types to handle more than two subreddits. Unfortunately, I did not have as much time as I hoped to explore the various avenues of this project (partially because I spent too long playing around with PCA and LDA, partially because I ended up spending more time than I wanted to on other classes), but I still feel I managed to get some decent results (which were comparable with the Prediction API results). 

You can read my [project report](http://dl.dropbox.com/u/700763/229a_project.pdf) for more details about the exact implementation. Although it lacks any real figures because of the class-imposed 5 page limit, you can see some sample results in [this table](http://dl.dropbox.com/u/700763/table.pdf). You can also see the title text classifier features with the highest coefficients for each subreddit in [this table](http://dl.dropbox.com/u/700763/words.pdf), which can be thought of as the strongest indicators that a post should belong in that respective subreddit. Finally, you can see the code that I wrote for this project on [github](https://github.com/smoreinis/classificator), which also contains a data directory with a script to scrape new posts from Reddit (inspired by the same post from Nick Johnson) and some sample data for people to play around with.

Code Miscellany: This code was written in python, and uses the numpy, scipy, simplejson, Stemmer, sklearn packages (and in fact was based on an sklearn tutorial on classifying newsgroup articles). The extract.py file handles the conversion of a JSON file full of posts into a feature dictionary, while models.py handles the actual supervised classification models provided by sklearn (as well as using CV grid search to find optimal parameters, and the CombinedClassifier which provides overall score posts). The gold.py file runs the whole thing - give it json files as arguments, and it should spit out the results for each type of sklearn classifier, which include a confusion matrix, overall F1-score, and a classification report like seen above. Finally, you can use the --topFeatures flag to print the highest coefficients (as seen above), but only if you are classifying on title text only (which is the way the code is set up now). To change it to classify posts based on title text and domain, change default value of combine to True on line 153 in models.py, comment out lines 173 an 178 in gold.py, and uncomment lines 174 and 177 (this is one of those things I'd have refactored to be prettier if I had the time, but hopefully it's not too confusing).

I hope this can be of use to some of you - it seems there are several people trying to build recommendation systems for posts, so maybe this can provide at least a little insight into how much information can be gained from a post's title and domain. Although all posts are currently uniformly weighted when training the supervised classifiers, changing this weighting (to either reflect the post's number of upvotes, or some personalized ranking) could also yield some interesting results and potentially make the model's results even better. Let me know if there are any questions!",,False,self,t5_2r3gv,True,,,True,t3_nm1d4,http://www.reddit.com/r/MachineLearning/comments/nm1d4/show_rml_classifying_new_posts_into_subreddits/,
1274306776.0,48,code.google.com,c62ym,Google Prediction API - Google Code,52,4,6,http://www.reddit.com/r/MachineLearning/comments/c62ym/google_prediction_api_google_code/,,,False,default,t5_2r3gv,False,,,False,t3_c62ym,http://code.google.com/apis/predict/,
1358173122.0,46,shop.oreilly.com,16juw2,What does /r/MachineLearning think of the book Machine Learning for hackers? Is it a good book to get my feet wet or should I look at something else?,55,9,54,http://www.reddit.com/r/MachineLearning/comments/16juw2/what_does_rmachinelearning_think_of_the_book/,,,False,http://f.thumbs.redditmedia.com/e-7IKUL7z34MVS-G.jpg,t5_2r3gv,False,,,False,t3_16juw2,http://shop.oreilly.com/product/0636920018483.do,
1353770768.0,47,nytimes.com,13prya,Scientists See Promise in Deep-Learning Programs,57,10,8,http://www.reddit.com/r/MachineLearning/comments/13prya/scientists_see_promise_in_deeplearning_programs/,,,False,http://c.thumbs.redditmedia.com/I6u_exUFc8zfAUiP.jpg,t5_2r3gv,False,,,False,t3_13prya,http://www.nytimes.com/2012/11/24/science/scientists-see-advances-in-deep-learning-a-part-of-artificial-intelligence.html,
1337924226.0,42,mewo2.github.com,u42iy,"Final Eurovision predictions, and what to watch for in the voting",52,10,0,http://www.reddit.com/r/MachineLearning/comments/u42iy/final_eurovision_predictions_and_what_to_watch/,,,False,http://d.thumbs.redditmedia.com/wAy8KoETS4jiW2UQ.jpg,t5_2r3gv,False,,,False,t3_u42iy,http://mewo2.github.com/nerdery/2012/05/24/eurovision-statistics-final-predictions/,
1308129723.0,45,alex.smola.org,i06a0,Book draft: Introduction To Machine Learning (by Smola &amp; Vishwanathan) [PDF],47,2,9,http://www.reddit.com/r/MachineLearning/comments/i06a0/book_draft_introduction_to_machine_learning_by/,,,False,default,t5_2r3gv,False,,,False,t3_i06a0,http://alex.smola.org/drafts/thebook.pdf,
1368408067.0,43,amazon.com,1e7tj7,Best Selling Big Data Book Free on Amazon right now!,70,27,34,http://www.reddit.com/r/MachineLearning/comments/1e7tj7/best_selling_big_data_book_free_on_amazon_right/,,,False,http://a.thumbs.redditmedia.com/JinjyL-qKwCXlTUx.jpg,t5_2r3gv,False,,,False,t3_1e7tj7,http://www.amazon.com/Secrets-Big-Data-Revolution-ebook/dp/B00CLSW0RA/ref=sr_1_13?ie=UTF8&amp;qid=1367858662&amp;sr=8-13&amp;keywords=big+data+revolution,
1342108153.0,43,nlp.stanford.edu,wg2g4,Deep Learning Tutorial for NLP,48,5,2,http://www.reddit.com/r/MachineLearning/comments/wg2g4/deep_learning_tutorial_for_nlp/,,,False,default,t5_2r3gv,False,,,False,t3_wg2g4,http://nlp.stanford.edu/~socherr/SocherBengioManning-DeepLearning-ACL2012-20120707-NoMargin.pdf,
1341284405.0,41,technologyreview.com,vyjtp,L.A. Cops Embrace Crime-Predicting Algorithm - Technology Review,49,8,11,http://www.reddit.com/r/MachineLearning/comments/vyjtp/la_cops_embrace_crimepredicting_algorithm/,,,False,http://c.thumbs.redditmedia.com/DWmEC_XH3uldXhkb.jpg,t5_2r3gv,False,,,False,t3_vyjtp,http://www.technologyreview.com/news/428354/la-cops-embrace-crime-predicting-algorithm/,
1310324287.0,41,web4.cs.ucl.ac.uk,ilr8w,Bayesian Reasoning and Machine Learning free ebook,45,4,6,http://www.reddit.com/r/MachineLearning/comments/ilr8w/bayesian_reasoning_and_machine_learning_free_ebook/,,,False,http://thumbs.reddit.com/t3_ilr8w.png,t5_2r3gv,False,,,False,t3_ilr8w,http://web4.cs.ucl.ac.uk/staff/D.Barber/pmwiki/pmwiki.php?n=Main.Textbook,
1306447893.0,43,blogs.forbes.com,hl0k8,IBM’s Watson Now A Second-Year Med Student,48,5,8,http://www.reddit.com/r/MachineLearning/comments/hl0k8/ibms_watson_now_a_secondyear_med_student/,,,False,http://thumbs.reddit.com/t3_hl0k8.png,t5_2r3gv,False,,,False,t3_hl0k8,http://blogs.forbes.com/bruceupbin/2011/05/25/ibms-watson-now-a-second-year-med-student/,
1272186353.0,42,docs.google.com,bvs9o,Top 10 Algorithms in Data Mining,50,8,10,http://www.reddit.com/r/MachineLearning/comments/bvs9o/top_10_algorithms_in_data_mining/,,,False,default,t5_2r3gv,False,,,False,t3_bvs9o,https://docs.google.com/viewer?url=http%3A%2F%2Fwww.cs.uvm.edu%2F~icdm%2Falgorithms%2F10Algorithms-08.pdf,
1371961476.0,44,spark-project.org,1gw65d,"Spark, up to 100x faster than Hadoop MapReduce.",52,8,10,http://www.reddit.com/r/MachineLearning/comments/1gw65d/spark_up_to_100x_faster_than_hadoop_mapreduce/,,,False,default,t5_2r3gv,False,,,False,t3_1gw65d,http://spark-project.org/,
1371882741.0,43,home.comcast.net,1guf3c,Cool gallery of learned decision boundaries of various classification algorithms run against synthetic datasets,46,3,10,http://www.reddit.com/r/MachineLearning/comments/1guf3c/cool_gallery_of_learned_decision_boundaries_of/,,,False,default,t5_2r3gv,False,,,False,t3_1guf3c,http://home.comcast.net/~tom.fawcett/public_html/ML-gallery/pages/,
1371657882.0,40,class.coursera.org,1gnuig,"Coursera's Discrete Optimization class starts today delves into CSP,LP,LS problems.",50,10,6,http://www.reddit.com/r/MachineLearning/comments/1gnuig/courseras_discrete_optimization_class_starts/,,,False,http://d.thumbs.redditmedia.com/r-cyl8H1eT-eJ5lo.jpg,t5_2r3gv,False,,,False,t3_1gnuig,https://class.coursera.org/optimization-001/class/index,
1344279303.0,45,gibiansky.com,xs232,Machine Learning: Neural Networks,46,1,14,http://www.reddit.com/r/MachineLearning/comments/xs232/machine_learning_neural_networks/,,,False,http://f.thumbs.redditmedia.com/uBSK-cqzgax2bDnG.jpg,t5_2r3gv,False,,,False,t3_xs232,http://www.gibiansky.com/2012/08/machine-learning-neural-networks.html,
1341581015.0,41,gregorypark.org,w4lop,Kaggle Post-Mortem: Psychopathy Prediction Blowout,47,6,8,http://www.reddit.com/r/MachineLearning/comments/w4lop/kaggle_postmortem_psychopathy_prediction_blowout/,,,False,http://b.thumbs.redditmedia.com/4fhoO70sI9prXWO7.jpg,t5_2r3gv,False,,,False,t3_w4lop,http://www.gregorypark.org/?p=359,
1333375287.0,46,techtalks.tv,rpi10,Google's keynote on doing machine learning using quantum computing. Non-convex NP-hard optimization problems are solved within hunderds of milliseconds. The lecture starts at 30:28.,52,6,4,http://www.reddit.com/r/MachineLearning/comments/rpi10/googles_keynote_on_doing_machine_learning_using/,,,False,http://c.thumbs.redditmedia.com/qz9OGmUQJSfslx2P.jpg,t5_2r3gv,False,,,False,t3_rpi10,http://techtalks.tv/talks/54457/,
1331759996.0,43,work.caltech.edu,qwr8o,Learning From Data - Online Course from Caltech,43,0,5,http://www.reddit.com/r/MachineLearning/comments/qwr8o/learning_from_data_online_course_from_caltech/,,,False,http://a.thumbs.redditmedia.com/2ftdRNxGFpT-5DPH.jpg,t5_2r3gv,False,,,False,t3_qwr8o,http://work.caltech.edu/telecourse.html,
1321545171.0,41,self.MachineLearning,mfrfc,More courses from Stanford,43,2,17,http://www.reddit.com/r/MachineLearning/comments/mfrfc/more_courses_from_stanford/,"Link to [Probabilistic Graphical Models](http://www.pgm-class.org/) - starting Jan.  More courses at the bottom of the page (ML, NLP, Game Theory, et al).",,False,self,t5_2r3gv,False,,,True,t3_mfrfc,http://www.reddit.com/r/MachineLearning/comments/mfrfc/more_courses_from_stanford/,
1320519389.0,47,cs.cmu.edu,m1m7m,"Graduate course on Machine Learning at CMU from 
Tom Mitchell.",51,4,3,http://www.reddit.com/r/MachineLearning/comments/m1m7m/graduate_course_on_machine_learning_at_cmu_from/,,,False,http://d.thumbs.redditmedia.com/4-aFtNHKTd27AMXQ.jpg,t5_2r3gv,False,,,False,t3_m1m7m,http://www.cs.cmu.edu/~tom/10701_sp11/lectures.shtml,
1316728361.0,43,youtube.com,kod8e,A new set of awesome intro lectures on machine learning,49,6,1,http://www.reddit.com/r/MachineLearning/comments/kod8e/a_new_set_of_awesome_intro_lectures_on_machine/,,,False,default,t5_2r3gv,False,,,False,t3_kod8e,http://www.youtube.com/user/mathematicalmonk#p/c/D0F06AA0D2E8FFBA/26/LcbwmT1OAKo,
1294334104.0,45,static.googleusercontent.com,exc77,The Learning Behind Gmail Priority Inbox (pdf),48,3,6,http://www.reddit.com/r/MachineLearning/comments/exc77/the_learning_behind_gmail_priority_inbox_pdf/,,,False,default,t5_2r3gv,False,,,False,t3_exc77,http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36955.pdf,
1285065325.0,41,self.MachineLearning,dgs8w,"I am the founder of Kaggle, a platform for machine learning competitions. Happy to answer any questions",52,11,33,http://www.reddit.com/r/MachineLearning/comments/dgs8w/i_am_the_founder_of_kaggle_a_platform_for_machine/,"For those who haven't come across the platform before (http://kaggle.com), companies and researchers post their problems and have data scientists from all over the world compete to produce the most accurate models. 

Crowdsourcing data modelling is particularly effective because there are an infinite number of approaches that applied to any problem. By opening up a problem to a wide audience, the competition host quickly gets to the best that can be done given the inherent noise and richness of a dataset",,False,self,t5_2r3gv,False,,,True,t3_dgs8w,http://www.reddit.com/r/MachineLearning/comments/dgs8w/i_am_the_founder_of_kaggle_a_platform_for_machine/,
1375902919.0,39,self.MachineLearning,1jwie8,Online evolutionary robotics course (crossposted to /r/artificial and /r/robotics),55,16,12,http://www.reddit.com/r/MachineLearning/comments/1jwie8/online_evolutionary_robotics_course_crossposted/,"Hello redditors, I'm Josh Bongard, a robotics professor at the University of Vermont.

We have just launched 'Ludobots', an online evolutionary robotics course. After you've completed all 10 assignments, you can work with us -- and your fellow users -- on research projects, or even create a project of your own. Depending on your contribution, you could end up as a co-author on a research paper.

Any feedback on the course is welcome. Additionally, I'll be doing an AMA at 4pm EST today to answer questions about the site, the field of robotics, and anything else you'd like to ask.

http://www.uvm.edu/~ludobots/index.php/Discover/Discover",,False,self,t5_2r3gv,False,,,True,t3_1jwie8,http://www.reddit.com/r/MachineLearning/comments/1jwie8/online_evolutionary_robotics_course_crossposted/,
1374339213.0,38,self.MachineLearning,1ip9y4,Matrix Calculus for Machine Learning,53,15,8,http://www.reddit.com/r/MachineLearning/comments/1ip9y4/matrix_calculus_for_machine_learning/,"In the last two weeks I studied Matrix Calculus, i.e. the set of rules and methods for differentiating functions involving vectors and matrices. It wasn't easy to make sense of the various methods. Not so many books cover this important topic and the book by Magnus and Neudecker is too long for someone who wants to get up to speed in a short time.
I wrote an article about what I learned about this topic. It should provide a brief but self-contained and practical introduction to Matrix Calculus useful for Machine Learning.
Please let me know if something is unclear or if you have any questions about the article and the topic.

edit: I'm going to add some examples of how to compute Hessian matrices as well.

[link!](http://easymachinelearning.tumblr.com/post/55967954817/matrix-calculus)",,False,self,t5_2r3gv,1374405654.0,,,True,t3_1ip9y4,http://www.reddit.com/r/MachineLearning/comments/1ip9y4/matrix_calculus_for_machine_learning/,
1371527481.0,41,stanford.edu,1gkbfs,Deep Learning With Commodity Off-The-Shelf High Performance Computing [pdf],45,4,2,http://www.reddit.com/r/MachineLearning/comments/1gkbfs/deep_learning_with_commodity_offtheshelf_high/,,,False,default,t5_2r3gv,False,,,False,t3_1gkbfs,http://stanford.edu/~acoates/papers/CoatesHuvalWangWuNgCatanzaro_icml2013.pdf,
1370872871.0,40,kieranhealy.org,1g1m0h,Using Metadata to find Paul Revere,51,11,4,http://www.reddit.com/r/MachineLearning/comments/1g1m0h/using_metadata_to_find_paul_revere/,,,False,http://b.thumbs.redditmedia.com/IfCGDCyv7uBPeOOy.jpg,t5_2r3gv,False,,,False,t3_1g1m0h,http://kieranhealy.org/blog/archives/2013/06/09/using-metadata-to-find-paul-revere/,
1365559660.0,40,cs.cmu.edu,1c19j4,Learning to play Super Mario [x-post from /r/compsci],50,10,7,http://www.reddit.com/r/MachineLearning/comments/1c19j4/learning_to_play_super_mario_xpost_from_rcompsci/,,,False,default,t5_2r3gv,False,,,False,t3_1c19j4,http://www.cs.cmu.edu/~tom7/mario/,
1340488311.0,44,americanscientist.org,vhyq6,The Manifest Destiny of Artificial Intelligence,51,7,13,http://www.reddit.com/r/MachineLearning/comments/vhyq6/the_manifest_destiny_of_artificial_intelligence/,,,False,http://c.thumbs.redditmedia.com/uwZ-kj0_w6jAPeCJ.jpg,t5_2r3gv,False,,,False,t3_vhyq6,"http://www.americanscientist.org/issues/id.15837,y.2012,no.4,content.true,page.1,css.print/issue.aspx",
1336094313.0,43,blog.bigml.com,t63d7,Machine Learning in Python Has Never Been Easier,58,15,24,http://www.reddit.com/r/MachineLearning/comments/t63d7/machine_learning_in_python_has_never_been_easier/,,,False,http://b.thumbs.redditmedia.com/nwDMpiJcyOAhbG2g.jpg,t5_2r3gv,False,,,False,t3_t63d7,http://blog.bigml.com/2012/05/04/machine-learning-in-python-has-never-been-easier/,
1248881818.0,46,academicearth.org,95o9l,Introduction to Machine Learning (20 Lectures) – Stanford [AE],48,2,6,http://www.reddit.com/r/MachineLearning/comments/95o9l/introduction_to_machine_learning_20_lectures/,,,False,http://thumbs.reddit.com/t3_95o9l.png,t5_2r3gv,False,,,False,t3_95o9l,http://academicearth.org/courses/machine-learning,
1366680172.0,43,scribd.com,1cwla8,Really excited to share this - Using Neural Networks and 'luck' to predict who will win in the NHL,49,6,50,http://www.reddit.com/r/MachineLearning/comments/1cwla8/really_excited_to_share_this_using_neural/,,,False,http://b.thumbs.redditmedia.com/jIDd0k4TuuxhY__U.jpg,t5_2r3gv,False,,,False,t3_1cwla8,http://www.scribd.com/doc/137463732/Forcasting-NHL-Success,
1360689233.0,40,gigaom.com,18dwog,Researchers say AI prescribes better treatment than doctors,50,10,16,http://www.reddit.com/r/MachineLearning/comments/18dwog/researchers_say_ai_prescribes_better_treatment/,,,False,http://d.thumbs.redditmedia.com/h5NOsWj7o1uUb02E.jpg,t5_2r3gv,False,,,False,t3_18dwog,http://gigaom.com/2013/02/11/researchers-say-ai-prescribes-better-treatment-than-doctors/,
1349282308.0,43,quora.com,10vrpj,Statistical analysis on twitter data: differences between NYC and SF,51,8,8,http://www.reddit.com/r/MachineLearning/comments/10vrpj/statistical_analysis_on_twitter_data_differences/,,,False,http://a.thumbs.redditmedia.com/abceWj1DqURHOoxT.jpg,t5_2r3gv,False,,,False,t3_10vrpj,http://www.quora.com/Comparing-Cities/What-cultural-differences-exist-between-New-York-and-Silicon-Valley,
1349067681.0,41,normaldeviate.wordpress.com,10qxgz,The remarkable k-means++,48,7,6,http://www.reddit.com/r/MachineLearning/comments/10qxgz/the_remarkable_kmeans/,,,False,http://d.thumbs.redditmedia.com/N_XlesLJr_RMRIy3.jpg,t5_2r3gv,False,,,False,t3_10qxgz,http://normaldeviate.wordpress.com/2012/09/30/the-remarkable-k-means/,
1347827591.0,43,self.MachineLearning,zzir6,What is your favorite Machine Learning lecture on YouTube?,46,3,11,http://www.reddit.com/r/MachineLearning/comments/zzir6/what_is_your_favorite_machine_learning_lecture_on/,"I'll start.  I really enjoyed [Brains, Sex, and Machine Learning](http://www.youtube.com/watch?v=DleXA5ADG78) by Geoffrey Hinton.

I'm limiting it to YouTube for the selfish reason that I like to be able to download lectures so that I can watch them on TV :-)",,False,self,t5_2r3gv,False,,,True,t3_zzir6,http://www.reddit.com/r/MachineLearning/comments/zzir6/what_is_your_favorite_machine_learning_lecture_on/,
1339088435.0,40,youtube.com,uq0jx,"TIL howto Moneyball :-) build a Classifier to predict labels . [Practical Machine Learning in Python, intro to toolkits]
",44,4,3,http://www.reddit.com/r/MachineLearning/comments/uq0jx/til_howto_moneyball_build_a_classifier_to_predict/,,,False,http://c.thumbs.redditmedia.com/OChFjPGKELWXPUsz.jpg,t5_2r3gv,False,,,False,t3_uq0jx,http://www.youtube.com/watch?v=__s45TTXxps,
1308192496.0,43,self.MachineLearning,i0vol,Is there a top machine learning hangout on the web?,48,5,12,http://www.reddit.com/r/MachineLearning/comments/i0vol/is_there_a_top_machine_learning_hangout_on_the_web/,"like some place where most serious lads/lasses hang out? #machinelearning on irc isnt really happening, #R is ok too, reddit is good, but i wonder, am i missing a party somewhere?

Edit: metaoptimize is fantastic, thank you!",,False,self,t5_2r3gv,True,,,True,t3_i0vol,http://www.reddit.com/r/MachineLearning/comments/i0vol/is_there_a_top_machine_learning_hangout_on_the_web/,
1307561415.0,45,archive.org,huves,"Twitter dataset - 200 million rows, 13 million users, 2gb compressed, get it while it's hot. (/r/datasets repost)",48,3,20,http://www.reddit.com/r/MachineLearning/comments/huves/twitter_dataset_200_million_rows_13_million_users/,,,False,http://thumbs.reddit.com/t3_huves.png,t5_2r3gv,False,,,False,t3_huves,http://www.archive.org/details/2011-06-calufa-twitter-sql,
1376536548.0,42,code.google.com,1ke9w3,word2vec - Google research tool for computing vector representations of words.,47,5,9,http://www.reddit.com/r/MachineLearning/comments/1ke9w3/word2vec_google_research_tool_for_computing/,,,False,default,t5_2r3gv,False,,,False,t3_1ke9w3,https://code.google.com/p/word2vec/,
1370350210.0,39,arxiv.org,1fncmj,Deep Learning using Support Vector Machines,45,6,10,http://www.reddit.com/r/MachineLearning/comments/1fncmj/deep_learning_using_support_vector_machines/,,,False,default,t5_2r3gv,False,,,False,t3_1fncmj,http://arxiv.org/abs/1306.0239,
1357537036.0,40,richardweiss.org,163snp,Restricted Boltzmann Machines in Python - A simple introduction.,44,4,3,http://www.reddit.com/r/MachineLearning/comments/163snp/restricted_boltzmann_machines_in_python_a_simple/,,,False,default,t5_2r3gv,False,,,False,t3_163snp,http://richardweiss.org/blog/?p=35,
1331066016.0,40,coursera.org,qkmd0,Stanford NLP class is live!,40,0,7,http://www.reddit.com/r/MachineLearning/comments/qkmd0/stanford_nlp_class_is_live/,,,False,default,t5_2r3gv,False,,,False,t3_qkmd0,https://www.coursera.org/nlp/class,
1317085161.0,38,ml-class.org,kseyi,"Stanford's online Machine Learning class now open 
for enrollment (ml-class.org)",42,4,12,http://www.reddit.com/r/MachineLearning/comments/kseyi/stanfords_online_machine_learning_class_now_open/,,,False,http://thumbs.reddit.com/t3_kseyi.png,t5_2r3gv,False,,,False,t3_kseyi,http://www.ml-class.org/course/auth/welcome,
1313531907.0,39,ml-class.com,jkx7u,Introduction to Machine Learning - Online Class taught by Andrew Ng - Starting Oct 10,43,4,0,http://www.reddit.com/r/MachineLearning/comments/jkx7u/introduction_to_machine_learning_online_class/,,,False,http://thumbs.reddit.com/t3_jkx7u.png,t5_2r3gv,False,,,False,t3_jkx7u,http://www.ml-class.com/,
1305481862.0,41,video.google.com,hbxvk,"Patrick Winston Lectures on ""Neural Nets, Back Propagation, Support Vector Machines""",42,1,4,http://www.reddit.com/r/MachineLearning/comments/hbxvk/patrick_winston_lectures_on_neural_nets_back/,,,False,default,t5_2r3gv,False,,,False,t3_hbxvk,http://video.google.com/videoplay?docid=-4677773923428923202#,
1295602813.0,44,mldata.org,f6e0h,Machine learning dataset repository,45,1,5,http://www.reddit.com/r/MachineLearning/comments/f6e0h/machine_learning_dataset_repository/,,,False,default,t5_2r3gv,False,,,False,t3_f6e0h,http://mldata.org/,
1268053923.0,42,deeplearning.net,banhb,"Deep Learning tutorial: learn to build complex neural networks (convolutional, autoencoders, RBMs) on the GPU in python with theano",44,2,20,http://www.reddit.com/r/MachineLearning/comments/banhb/deep_learning_tutorial_learn_to_build_complex/,,,False,default,t5_2r3gv,False,,,False,t3_banhb,http://deeplearning.net/tutorial,
1375849378.0,36,isse.sourceforge.net,1jv2d0,"Adobe, CCRMA and Stanford release sound separation software based on machine learning.",40,4,3,http://www.reddit.com/r/MachineLearning/comments/1jv2d0/adobe_ccrma_and_stanford_release_sound_separation/,,,False,default,t5_2r3gv,False,,,False,t3_1jv2d0,http://isse.sourceforge.net/index.html,
1375624646.0,38,self.MachineLearning,1joh9v,Can someone explain Kernel Trick intuitively?,51,13,23,http://www.reddit.com/r/MachineLearning/comments/1joh9v/can_someone_explain_kernel_trick_intuitively/,,,False,self,t5_2r3gv,False,,,True,t3_1joh9v,http://www.reddit.com/r/MachineLearning/comments/1joh9v/can_someone_explain_kernel_trick_intuitively/,
1363900522.0,40,blog.smellthedata.com,1ara1l,"March Madness, Gaussian Processes, and Bayesian Optimization",51,11,9,http://www.reddit.com/r/MachineLearning/comments/1ara1l/march_madness_gaussian_processes_and_bayesian/,,,False,http://b.thumbs.redditmedia.com/7F823HoWRk6LCac1.jpg,t5_2r3gv,False,,,False,t3_1ara1l,http://blog.smellthedata.com/2013/03/now-that-march-madness-is-officially.html,
1338571042.0,35,stevehanov.ca,ufv6e,20 lines of code that will beat A/B testing every time using an epsilon-greedy strategy,44,9,7,http://www.reddit.com/r/MachineLearning/comments/ufv6e/20_lines_of_code_that_will_beat_ab_testing_every/,,,False,http://d.thumbs.redditmedia.com/Cy4d6ezY8ZYTm3Bi.jpg,t5_2r3gv,False,,,False,t3_ufv6e,http://stevehanov.ca/blog/index.php?id=132,
1370273585.0,35,izbicki.me,1fl361,Haskell's HLearn library cross-validates more than 400x faster than Weka due to new monoid based algorithm,50,15,21,http://www.reddit.com/r/MachineLearning/comments/1fl361/haskells_hlearn_library_crossvalidates_more_than/,,,False,http://f.thumbs.redditmedia.com/zSubgY6CA5z-Qwi_.jpg,t5_2r3gv,False,,,False,t3_1fl361,http://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka,
1366993987.0,36,coursera.org,1d5ukv,Don't forget that UW's Introduction to Data Science (Coursera) starts 5/1. An excellent concurrent complement to Andrew Ng's ML class.,42,6,12,http://www.reddit.com/r/MachineLearning/comments/1d5ukv/dont_forget_that_uws_introduction_to_data_science/,,,False,http://d.thumbs.redditmedia.com/r-cyl8H1eT-eJ5lo.jpg,t5_2r3gv,False,,,False,t3_1d5ukv,https://www.coursera.org/course/datasci,
1352797343.0,38,self.MachineLearning,1345b3,Compiling a list of awesome ML papers,42,4,10,http://www.reddit.com/r/MachineLearning/comments/1345b3/compiling_a_list_of_awesome_ml_papers/,"I thought it would be cool to collect a list of some really awesome (maybe even a few ""lay person"" accesable) research papers on the topic of ML. I wanted to open it up to the /r/MachineLearning community and see what papers you found really interesting. Here are two I thought were pretty interesting:

[Quantitative Analysis of Culture Using Millions of Digitized Books](http://www.sciencemag.org/content/331/6014/176.full.pdf)

and 

[Building High-level Features Using Large Scale Unsupervised Learning](http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/pubs/archive/38115.pdf)",,False,self,t5_2r3gv,False,,,True,t3_1345b3,http://www.reddit.com/r/MachineLearning/comments/1345b3/compiling_a_list_of_awesome_ml_papers/,
1337761610.0,38,mewo2.github.com,u0r0c,An update on Eurovision,44,6,1,http://www.reddit.com/r/MachineLearning/comments/u0r0c/an_update_on_eurovision/,,,False,http://c.thumbs.redditmedia.com/_3z7hCdPF_Xiddd2.jpg,t5_2r3gv,False,,,False,t3_u0r0c,http://mewo2.github.com/nerdery/2012/05/23/eurovision-statistics-post-semifinal-update/,
1294951224.0,36,engadget.com,f1s0n,IBM Supercomputer Watson owns humans at Jeopardy [video].,42,6,14,http://www.reddit.com/r/MachineLearning/comments/f1s0n/ibm_supercomputer_watson_owns_humans_at_jeopardy/,,,False,http://thumbs.reddit.com/t3_f1s0n.png,t5_2r3gv,False,,,False,t3_f1s0n,http://www.engadget.com/2011/01/13/ibms-watson-supercomputer-destroys-all-humans-in-jeopardy-pract/,
1371080644.0,34,googleresearch.blogspot.com,1g8ddd,Details emerge of the algorithm used in Google's photo search,44,10,5,http://www.reddit.com/r/MachineLearning/comments/1g8ddd/details_emerge_of_the_algorithm_used_in_googles/,,,False,http://c.thumbs.redditmedia.com/SYvqncWmKPjkTE0b.jpg,t5_2r3gv,False,,,False,t3_1g8ddd,http://googleresearch.blogspot.com/2013/06/improving-photo-search-step-across.html,
1359137398.0,37,mlss.tuebingen.mpg.de,179m95,2013 Machine Learning Summer School Announced,47,10,8,http://www.reddit.com/r/MachineLearning/comments/179m95/2013_machine_learning_summer_school_announced/,,,False,http://a.thumbs.redditmedia.com/v1yimDHQeiu1K7j0.jpg,t5_2r3gv,False,,,False,t3_179m95,http://mlss.tuebingen.mpg.de,
1306170633.0,39,self.MachineLearning,hi63q,Advice on industry jobs for PHD's in Machine Learning..,48,9,51,http://www.reddit.com/r/MachineLearning/comments/hi63q/advice_on_industry_jobs_for_phds_in_machine/,"Hi. I'm about to start a PHD in the fall in computer science focusing on Machine Learning and Information Extraction. I am aware that faculty positions are hard to come by and may not be the best fit for me in the future, and I was wondering what the industry jobs prospects are there for people trained in Machine Learning at the advanced graduate level. 

The program I am accepted into is a well ranked one and has some famous professors in the field I can work with. 

If you have one of these sorts of jobs I would like to know the following:

* Do you regret the time taken to get your PHD?
* Are you happy with your salary?
* Do you find the work stimulating?
* Do you find this sort of work isolating (Could someone who defines themselves as an extrovert work in your job)?
* Is there an ability to move up and progress at your job or is it dead end?

Thanks in advance.",,False,self,t5_2r3gv,False,,,True,t3_hi63q,http://www.reddit.com/r/MachineLearning/comments/hi63q/advice_on_industry_jobs_for_phds_in_machine/,
1296581386.0,39,matrixcookbook.com,fd6za,The Matrix Cookbook: A free mathematical desktop reference on matrices,40,1,1,http://www.reddit.com/r/MachineLearning/comments/fd6za/the_matrix_cookbook_a_free_mathematical_desktop/,,,False,http://thumbs.reddit.com/t3_fd6za.png,t5_2r3gv,False,,,False,t3_fd6za,http://matrixcookbook.com/,
1294431925.0,33,self.MachineLearning,ey3fp,Machine Learning scared my potential employer,43,10,32,http://www.reddit.com/r/MachineLearning/comments/ey3fp/machine_learning_scared_my_potential_employer/,"I interviewed with a major marketing company who asked me to improve their public-facing website's ability to predict ""hot"" stories based on the tweets containing the story URL.

I got all excited in the interview and started telling the manager there how I could use machine learning algorithms to automatically predict which stories would be successful based on the rate of tweets about the story.

When I started describing what machine learning was, the manager interviewing me reacted as if I was describing some magical voodoo. He said things like ""that won't scale"" even though I was only describing running an SVM on a small amount of training data.

They just want to predict simple stuff, but the more I try to clarify what machine learning is, the more skeptical the manager is getting. I think he thinks I'm trying to sell him some sort of snake oil.

Has anyone else ever experienced this where an employer is scared off because they don't understand what machine learning/information retrieval is and what it can do for them?",,False,self,t5_2r3gv,False,,,True,t3_ey3fp,http://www.reddit.com/r/MachineLearning/comments/ey3fp/machine_learning_scared_my_potential_employer/,
1270237257.0,36,youtube.com,blr0g,Recent Developments in Deep Learning (Geoff Hinton),39,3,13,http://www.reddit.com/r/MachineLearning/comments/blr0g/recent_developments_in_deep_learning_geoff_hinton/,,,False,http://thumbs.reddit.com/t3_blr0g.png,t5_2r3gv,False,,,False,t3_blr0g,http://www.youtube.com/watch?v=VdIURAu1-aU,
1250172702.0,40,youtube.com,9aain,"Complete Machine Learning course taught by Andrew Ng
on Youtube.",44,4,6,http://www.reddit.com/r/MachineLearning/comments/9aain/complete_machine_learning_course_taught_by_andrew/,,,False,http://thumbs.reddit.com/t3_9aain.png,t5_2r3gv,False,,,False,t3_9aain,http://www.youtube.com/view_play_list?p=A89DCFA6ADACE599,
1249330338.0,35,self.MachineLearning,976pe,Ask MachineLearning: What do you consider to be the most exciting/innovative ideas in machine learning right now?,41,6,16,http://www.reddit.com/r/MachineLearning/comments/976pe/ask_machinelearning_what_do_you_consider_to_be/,"As someone who is very intrigued by machine learning (although not very experienced) I am interested in finding out what you guys think are the ""hot"" areas of research.",,False,self,t5_2r3gv,False,,,True,t3_976pe,http://www.reddit.com/r/MachineLearning/comments/976pe/ask_machinelearning_what_do_you_consider_to_be/,
1365738294.0,37,blog.zipfianacademy.com,1c6oc4,A Practical Intro to Data Science,47,10,8,http://www.reddit.com/r/MachineLearning/comments/1c6oc4/a_practical_intro_to_data_science/,,,False,default,t5_2r3gv,False,,,False,t3_1c6oc4,http://blog.zipfianacademy.com/post/46864003608/a-practical-intro-to-data-science,
1364338567.0,39,instant.ly,1b2n0d,Some friends from Stanford are doing a machine learning project on humor. Finding hidden structure in kinds of humor. Give us one more datapoint! :),42,3,22,http://www.reddit.com/r/MachineLearning/comments/1b2n0d/some_friends_from_stanford_are_doing_a_machine/,,,False,default,t5_2r3gv,False,,,False,t3_1b2n0d,http://www.instant.ly/s/t8ZRF,
1364324678.0,37,youtube.com,1b245u,"Have you guys seen mathematicalmonk's Machine Learning series? I'm learning about decision trees right now, and he makes random forests sound easy!",46,9,3,http://www.reddit.com/r/MachineLearning/comments/1b245u/have_you_guys_seen_mathematicalmonks_machine/,,,False,default,t5_2r3gv,False,,,False,t3_1b245u,http://www.youtube.com/playlist?list=PLD0F06AA0D2E8FFBA,
1364297159.0,38,youtube.com,1b1alt,'Open Problems in Machine Translation' by Prof Philipp Koehn,41,3,1,http://www.reddit.com/r/MachineLearning/comments/1b1alt/open_problems_in_machine_translation_by_prof/,,,False,http://c.thumbs.redditmedia.com/halOHrHce-q05c_h.jpg,t5_2r3gv,False,,,False,t3_1b1alt,http://www.youtube.com/watch?v=6UVgFjJeFGY,
1363105103.0,36,youtu.be,1a5j65,Jeff Hawkins gives a talk at Google - Building Brains to Understand the World's Data,43,7,6,http://www.reddit.com/r/MachineLearning/comments/1a5j65/jeff_hawkins_gives_a_talk_at_google_building/,,,False,http://d.thumbs.redditmedia.com/fYXYpKUGH3n5USKi.jpg,t5_2r3gv,False,,,False,t3_1a5j65,http://youtu.be/4y43qwS8fl4,
1361982175.0,37,vimeo.com,19c0lb,Music recommendations at Spotify - Machine Learning (x/post from r/spotify),40,3,10,http://www.reddit.com/r/MachineLearning/comments/19c0lb/music_recommendations_at_spotify_machine_learning/,,,False,http://a.thumbs.redditmedia.com/lSuOWuZVM4Emezaf.jpg,t5_2r3gv,False,,,False,t3_19c0lb,http://vimeo.com/57900625,
1357362189.0,37,self.MachineLearning,15zrpp,Please explain Support Vector Machines (SVM) like I am a 5 year old. ,47,10,34,http://www.reddit.com/r/MachineLearning/comments/15zrpp/please_explain_support_vector_machines_svm_like_i/,,,False,self,t5_2r3gv,False,,,True,t3_15zrpp,http://www.reddit.com/r/MachineLearning/comments/15zrpp/please_explain_support_vector_machines_svm_like_i/,
1355611321.0,38,en.wikipedia.org,14wwx1,Moravec's_paradox - Evolution based explanation on why perceptual tasks are hard and cognitive ones are easy,51,13,2,http://www.reddit.com/r/MachineLearning/comments/14wwx1/moravecs_paradox_evolution_based_explanation_on/,,,False,default,t5_2r3gv,False,,,False,t3_14wwx1,http://en.wikipedia.org/wiki/Moravec's_paradox,
1348761346.0,32,homes.cs.washington.edu,10kg4s,"A few useful things to know about machine learning (CACM article, pdf)",38,6,4,http://www.reddit.com/r/MachineLearning/comments/10kg4s/a_few_useful_things_to_know_about_machine/,,,False,default,t5_2r3gv,False,,,False,t3_10kg4s,http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf,
1344614779.0,36,highlyscalable.wordpress.com,y02ue,"MapReduce Patterns, Algorithms, and Use Cases",46,10,1,http://www.reddit.com/r/MachineLearning/comments/y02ue/mapreduce_patterns_algorithms_and_use_cases/,,,False,http://c.thumbs.redditmedia.com/6_-ELhuMb8SYoEXh.jpg,t5_2r3gv,False,,,False,t3_y02ue,http://highlyscalable.wordpress.com/2012/02/01/mapreduce-patterns/,
1330009862.0,32,blog.printf.net,q2jtu,Computers are very good at the game of Go,43,11,19,http://www.reddit.com/r/MachineLearning/comments/q2jtu/computers_are_very_good_at_the_game_of_go/,,,False,http://d.thumbs.redditmedia.com/_ux9AXhFYQeXlrd-.jpg,t5_2r3gv,False,,,False,t3_q2jtu,http://blog.printf.net/articles/2012/02/23/computers-are-very-good-at-the-game-of-go,
1323096658.0,36,self.MachineLearning,n14ov,Explain Conditional Random Fields like I'm stupid?,44,8,11,http://www.reddit.com/r/MachineLearning/comments/n14ov/explain_conditional_random_fields_like_im_stupid/,"I have been reading about CRFs and nothing is seeming to click.  Can somebody give me a general idea of what CRFs are doing, persay?  I understand HMMs, and people often relate them in the literature but I don't understand the relationship.  

Why are CRFs undirected?  When would you use CRFs over HMMs?  What extra power do they provide?  Thanks!",,False,self,t5_2r3gv,False,,,True,t3_n14ov,http://www.reddit.com/r/MachineLearning/comments/n14ov/explain_conditional_random_fields_like_im_stupid/,
1298541159.0,35,ibm.com,frpjb,"How to build your own ""Watson Jr."" in your basement",41,6,0,http://www.reddit.com/r/MachineLearning/comments/frpjb/how_to_build_your_own_watson_jr_in_your_basement/,,,False,default,t5_2r3gv,False,,,False,t3_frpjb,https://www.ibm.com/developerworks/mydeveloperworks/blogs/InsideSystemStorage/entry/ibm_watson_how_to_build_your_own_watson_jr_in_your_basement7?lang=en,
1293885160.0,34,matpalm.com,euivi,my list of cool machine learning books,42,8,8,http://www.reddit.com/r/MachineLearning/comments/euivi/my_list_of_cool_machine_learning_books/,,,False,http://thumbs.reddit.com/t3_euivi.png,t5_2r3gv,False,,,False,t3_euivi,http://matpalm.com/blog/2010/08/06/my-list-of-cool-machine-learning-books/,
1283268974.0,36,en.wikibooks.org,d7qws,Wikibook : Data Mining Algorithms in R,41,5,6,http://www.reddit.com/r/MachineLearning/comments/d7qws/wikibook_data_mining_algorithms_in_r/,,,False,default,t5_2r3gv,False,,,False,t3_d7qws,http://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R,
1281000939.0,37,readwriteweb.com,cxna7,"Google CEO Schmidt: ""People Aren't Ready for the Technology Revolution""",42,5,10,http://www.reddit.com/r/MachineLearning/comments/cxna7/google_ceo_schmidt_people_arent_ready_for_the/,,,False,http://thumbs.reddit.com/t3_cxna7.png,t5_2r3gv,False,,,False,t3_cxna7,http://www.readwriteweb.com/archives/google_ceo_schmidt_people_arent_ready_for_the_tech.php,
1372782827.0,35,guardian.co.uk,1hi7da,How algorithms rule the world: the ubiquity of machine-learning,47,12,4,http://www.reddit.com/r/MachineLearning/comments/1hi7da/how_algorithms_rule_the_world_the_ubiquity_of/,,,False,http://c.thumbs.redditmedia.com/XeEnkExENBYXGUtn.jpg,t5_2r3gv,False,,,False,t3_1hi7da,http://www.guardian.co.uk/science/2013/jul/01/how-algorithms-rule-world-nsa,
1367759346.0,38,anand.typepad.com,1dq9wu,Are Machine-Learned Models Prone to Catastrophic Errors?,42,4,7,http://www.reddit.com/r/MachineLearning/comments/1dq9wu/are_machinelearned_models_prone_to_catastrophic/,,,False,default,t5_2r3gv,False,,,False,t3_1dq9wu,http://anand.typepad.com/datawocky/2008/05/are-human-experts-less-prone-to-catastrophic-errors-than-machine-learned-models.html?buffer_share=5d610&amp;utm_source=buffer&amp;utm_medium=twitter&amp;utm_campaign=Buffer%253A%252BSeanTAllen%252Bon%252Btwitter,
1356940666.0,37,arxiv.org,15prv8,Interesting article by Gelman &amp; Shalizi about foundations of Bayesian inference.,44,7,4,http://www.reddit.com/r/MachineLearning/comments/15prv8/interesting_article_by_gelman_shalizi_about/,,,False,default,t5_2r3gv,False,,,False,t3_15prv8,http://arxiv.org/pdf/1006.3868v4.pdf,
1320569432.0,33,jmlr.csail.mit.edu,m296s,"Scikit-learn, Machine Learning in Python - ""This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language""",38,5,5,http://www.reddit.com/r/MachineLearning/comments/m296s/scikitlearn_machine_learning_in_python_this/,,,False,default,t5_2r3gv,False,,,False,t3_m296s,http://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html,
1319724298.0,38,self.MachineLearning,lqycl,Kaggle screws up and the HHP,40,2,15,http://www.reddit.com/r/MachineLearning/comments/lqycl/kaggle_screws_up_and_the_hhp/,"Looks like Kaggle doesn't randomize the order of their training data.  Ouch.

http://www.kaggle.com/forums/t/980/wikipedia-participation-challenge-an-unfortunate-ending

On another topic, the Heritage Health Prize.  Who thinks they'll make the .4 benchmark in the end and pay out the 3M?  Right now they're at .455 :

http://www.heritagehealthprize.com/c/hhp/Leaderboard

I remember that with the Netflix prize it took a year or so to eek out that last 1 percent of performance.  They've got over 10 percent more to go here.

Edit:  Looks like Kaggle isn't interested in learning from this mistake.  They moved the original post to an old competition forum.  It's a shame because its a cool site, but they can't be making friends on the participant side with this bizarre behavior.",,False,self,t5_2r3gv,True,,,True,t3_lqycl,http://www.reddit.com/r/MachineLearning/comments/lqycl/kaggle_screws_up_and_the_hhp/,
1289448100.0,36,google-opensource.blogspot.com,e4eq0,"Announcing Google Refine - tool for working with messy data sets, including cleaning up inconsistencies, transforming formats &amp; extending data from external web services or databases. ",37,1,5,http://www.reddit.com/r/MachineLearning/comments/e4eq0/announcing_google_refine_tool_for_working_with/,,,False,default,t5_2r3gv,False,,,False,t3_e4eq0,http://google-opensource.blogspot.com/2010/11/announcing-google-refine-20-power-tool.html,
1270831625.0,34,thearling.com,boqf9,An Overview of Data Mining Techniques,38,4,-1,http://www.reddit.com/r/MachineLearning/comments/boqf9/an_overview_of_data_mining_techniques/,,,False,http://thumbs.reddit.com/t3_boqf9.png,t5_2r3gv,False,,,False,t3_boqf9,http://www.thearling.com/text/dmtechniques/dmtechniques.htm,
1268686967.0,33,33bits.org,bdrkw,An open letter to Netflix from the authors of the de-anonymization paper,38,5,4,http://www.reddit.com/r/MachineLearning/comments/bdrkw/an_open_letter_to_netflix_from_the_authors_of_the/,,,False,default,t5_2r3gv,False,,,False,t3_bdrkw,http://33bits.org/2010/03/15/open-letter-to-netflix/,
1266746641.0,34,freespace.virgin.net,b4m41,My ever on-going AI project: Neuropilot,41,7,11,http://www.reddit.com/r/MachineLearning/comments/b4m41/my_ever_ongoing_ai_project_neuropilot/,,,False,http://thumbs.reddit.com/t3_b4m41.png,t5_2r3gv,False,,,False,t3_b4m41,http://freespace.virgin.net/michael.fairbank/neuropilot/index.html,
1375994971.0,35,zinkov.com,1jzbvt,Stop using Plate Notation,46,11,16,http://www.reddit.com/r/MachineLearning/comments/1jzbvt/stop_using_plate_notation/,,,False,http://e.thumbs.redditmedia.com/o5bkU-waLZNEL5Up.jpg,t5_2r3gv,False,,,False,t3_1jzbvt,http://zinkov.com/posts/2013-07-28-stop-using-plates/,
1373820181.0,34,videolectures.net,1ia6fi,Group Theory and Machine Learning by Risi Kondor,38,4,3,http://www.reddit.com/r/MachineLearning/comments/1ia6fi/group_theory_and_machine_learning_by_risi_kondor/,,,False,default,t5_2r3gv,False,,,False,t3_1ia6fi,http://videolectures.net/mlcued08_kondor_gtm/,
1366326361.0,33,research.google.com,1cn29p,"Fast, Accurate Detection of 100,000 Object Classes on a Single Machine",40,7,4,http://www.reddit.com/r/MachineLearning/comments/1cn29p/fast_accurate_detection_of_100000_object_classes/,,,False,default,t5_2r3gv,False,,,False,t3_1cn29p,http://research.google.com/pubs/pub40814.html,
1365649348.0,33,blog.echen.me,1c40lc,Two ways of finding k in k-means,41,8,7,http://www.reddit.com/r/MachineLearning/comments/1c40lc/two_ways_of_finding_k_in_kmeans/,,,False,http://a.thumbs.redditmedia.com/Tss-5tPCLHp5Ww1r.jpg,t5_2r3gv,False,,,False,t3_1c40lc,http://blog.echen.me/2011/03/19/counting-clusters/,
1364583080.0,31,arxiv.org,1b99ye,Awesome paper on learning to recognize images of cats without any cat images as training data using word embeddings and image data for similar objects,42,11,3,http://www.reddit.com/r/MachineLearning/comments/1b99ye/awesome_paper_on_learning_to_recognize_images_of/,,,False,default,t5_2r3gv,False,,,False,t3_1b99ye,http://arxiv.org/pdf/1301.3666v2.pdf,
1360387178.0,32,wired.com,186gex,Big Data can produce Big Errors.,42,10,16,http://www.reddit.com/r/MachineLearning/comments/186gex/big_data_can_produce_big_errors/,,,False,http://b.thumbs.redditmedia.com/O0V2bc1NqX5SXbVy.jpg,t5_2r3gv,False,,,False,t3_186gex,http://www.wired.com/opinion/2013/02/big-data-means-big-errors-people/,
1342974981.0,38,blog.explainmydata.com,wyyg8,Lessons in Python performance learned from big ML tasks,42,4,0,http://www.reddit.com/r/MachineLearning/comments/wyyg8/lessons_in_python_performance_learned_from_big_ml/,,,False,default,t5_2r3gv,False,,,False,t3_wyyg8,http://blog.explainmydata.com/2012/07/expensive-lessons-in-python-performance.html,
1339270337.0,35,self.MachineLearning,utjdl,My Kaggle rank is leveling out. Advice?,39,4,19,http://www.reddit.com/r/MachineLearning/comments/utjdl/my_kaggle_rank_is_leveling_out_advice/,"Hi ML, I've been competing in several Kaggle competitions. I can get in the top 10-20%, but after that my rank stagnates. My template workflow is to process the data(derive every variable I can come up with), partition the data into k-folds or k-stratified-folds, (optionally or separately) perform feature selection, throw every algorithm appropriate from sklearn/scipy/theano-scripts into my model class then bag the models. I do grid-searching on the hyper-parameters for algorithms that perform poorly. I try to keep my individual model fitting time to under 12 hours on my 8-core workstation. I can usually eek out a little more if I run add models ran with more of the features to my bag.

I have a good understanding of many of the algorithms that sklearn implements, but I don't have the foggiest clue how this knowledge could help me except in something like diagnosing stochastic gradient descent. I've implemented a couple(slower and less pretty) versions of them. I've worked through Elements of Statistical Learning. I've well-versed in hypothesis testing and visualizing data(my job). I don't know where to go from here. I thought I was pretty good at building models, but I am humbled by the leaderboard.

Where do I go from here? What books do I read? What software/languages do I learn? I'm fine with logarithmic returns on my effort, but I don't know where to find them.",,False,self,t5_2r3gv,False,,,True,t3_utjdl,http://www.reddit.com/r/MachineLearning/comments/utjdl/my_kaggle_rank_is_leveling_out_advice/,
1332076644.0,34,reddit.com,r1zjm,Attempt #2: Want to help reddit build a recommender? -- A public dump of voting data that our users have donated for research : redditdev,36,2,9,http://www.reddit.com/r/MachineLearning/comments/r1zjm/attempt_2_want_to_help_reddit_build_a_recommender/,,,False,default,t5_2r3gv,False,,,False,t3_r1zjm,http://www.reddit.com/r/redditdev/comments/dtg4j/want_to_help_reddit_build_a_recommender_a_public/,
1323702800.0,36,matpalm.com,n9p12,"A nice, readable article on semi supervised naive bayes",37,1,16,http://www.reddit.com/r/MachineLearning/comments/n9p12/a_nice_readable_article_on_semi_supervised_naive/,,,False,default,t5_2r3gv,False,,,False,t3_n9p12,http://matpalm.com/semi_supervised_naive_bayes/semi_supervised_bayes.html,
1320831307.0,34,blog.jackadam.net,m5y4l,How Dark Sky Works: Neural Networks and Computer Vision,45,11,3,http://www.reddit.com/r/MachineLearning/comments/m5y4l/how_dark_sky_works_neural_networks_and_computer/,,,False,http://a.thumbs.redditmedia.com/iFe9bpzLDc9XOL_x.jpg,t5_2r3gv,False,,,False,t3_m5y4l,http://blog.jackadam.net/2011/how-dark-sky-works/,
1319556364.0,31,quora.com,loh00,Is there any summary of top models for the Netflix prize?,35,4,2,http://www.reddit.com/r/MachineLearning/comments/loh00/is_there_any_summary_of_top_models_for_the/,,,False,http://thumbs.reddit.com/t3_loh00.png,t5_2r3gv,False,,,False,t3_loh00,"http://www.quora.com/Netflix-Prize/Is-there-any-summary-of-top-models-for-the-Netflix-prize?__snids__=27459564,27458419",
1310726934.0,36,mlg.ucd.ie,iqbcc,"Graph and Network Analysis. Tutorial, datasets and code",37,1,1,http://www.reddit.com/r/MachineLearning/comments/iqbcc/graph_and_network_analysis_tutorial_datasets_and/,,,False,default,t5_2r3gv,False,,,False,t3_iqbcc,http://mlg.ucd.ie/summer,
1374882313.0,33,self.MachineLearning,1j4prp,"Let's learn R together! Kaggle's ""Titanic"" competition.",45,12,17,http://www.reddit.com/r/MachineLearning/comments/1j4prp/lets_learn_r_together_kaggles_titanic_competition/,"Kaggle currently has a ""knowledge"" competition going where you are given some basic demographic information about passengers and are asked to use this information to predict whether or not they survived the disaster.

Here's a link to the competition: http://www.kaggle.com/c/titanic-gettingStarted

This is a great learning problem because the data set is relatively simple, with some missing values thrown in, and just enough noise to make things interesting.

I'm just learning R and here's what I propose: If you're interested in honing your R skills (or are just learning predictive modeling) we try to tackle this problem together. In this thread we will post our R models--with plenty of comments explaining what each line of code does and why we chose to do it. In addition, we'll post our scores so everyone can see how successful our models are. To start things off, I'll post a comment with my best scoring randomForest model.

Since this is a learning thread, if you don't understand something about any code that's posted, just ask! R has a slight learning curve and everyone has to start somewhere.",,False,self,t5_2r3gv,False,,,True,t3_1j4prp,http://www.reddit.com/r/MachineLearning/comments/1j4prp/lets_learn_r_together_kaggles_titanic_competition/,
1374070754.0,35,georgemdallas.wordpress.com,1ihj29,Machine Learning: Under the hood. Blog post explains the principles of machine learning in layman terms. Simple and clear,52,17,13,http://www.reddit.com/r/MachineLearning/comments/1ihj29/machine_learning_under_the_hood_blog_post/,,,False,http://e.thumbs.redditmedia.com/gJ0RRMTlqx6sLmaL.jpg,t5_2r3gv,False,,,False,t3_1ihj29,http://georgemdallas.wordpress.com/2013/06/11/big-data-data-mining-and-machine-learning-under-the-hood/,
1372961111.0,33,self.MachineLearning,1hn9gf,A series of blog posts about biclustering,40,7,8,http://www.reddit.com/r/MachineLearning/comments/1hn9gf/a_series_of_blog_posts_about_biclustering/,"
This summer I am implementing biclustering algorithms for the [scikit-learn](http://scikit-learn.org/stable/) machine learning library and blogging about my progress. I thought some people on /r/MachineLearning might find them useful.

So far I have written two articles:

1. [An introduction to biclustering](http://www.kemaleren.com/an-introduction-to-biclustering.html)

2. [Spectral biclustering, part 1](http://www.kemaleren.com/spectral-biclustering-part-1.html)
",,False,self,t5_2r3gv,False,,,True,t3_1hn9gf,http://www.reddit.com/r/MachineLearning/comments/1hn9gf/a_series_of_blog_posts_about_biclustering/,
1371404292.0,32,self.MachineLearning,1ggp3s,are Genetic Algorithms anymore than an academic exercise?,46,14,47,http://www.reddit.com/r/MachineLearning/comments/1ggp3s/are_genetic_algorithms_anymore_than_an_academic/,I come across a lot of criticism of genetic algorithms (typically in the direction of overfitting).  I'm just wondering what the /r/ML folks think of GAs.  Are they useful in the real world?  Do they look good on your CV?,,False,self,t5_2r3gv,False,,,True,t3_1ggp3s,http://www.reddit.com/r/MachineLearning/comments/1ggp3s/are_genetic_algorithms_anymore_than_an_academic/,
1368309886.0,32,self.MachineLearning,1e5ftb,Starting a machine learning job ...,37,5,29,http://www.reddit.com/r/MachineLearning/comments/1e5ftb/starting_a_machine_learning_job/,"I just graduated with a B.S. in CS and managed to snag an entry-level machine learning position at a pretty well known company in the Bay Area.

I'm incredibly nervous for a number of reasons but mainly because I feel like I lack the machine learning knowledge to really contribute. My only experience is a class in college and also the coursera ML class that I'm currently taking. Furthermore, the position was originally meant for a MS/PhD. I can't shake the feeling that I'm ""not good enough"".
 
I mainly would like to know what I should expect from an entry-level machine learning position? What would be the best way to prepare? Best ways to review ML material? Any tools/skills that every person working in ML should be familiar with? How do I overcome this lack of confidence?

Sorry if this post seems more suited for /r/cscareerquestions - I felt like I'd get more specific advice here.",,False,self,t5_2r3gv,False,,,True,t3_1e5ftb,http://www.reddit.com/r/MachineLearning/comments/1e5ftb/starting_a_machine_learning_job/,
1367860672.0,31,self.MachineLearning,1dswo0,"Trying to find papers about Similarity Metrics (Cosine, Euclidean, Pearson, Covariance, Manhattan)",38,7,8,http://www.reddit.com/r/MachineLearning/comments/1dswo0/trying_to_find_papers_about_similarity_metrics/,"I'm doing research involving recommendation systems using collaborative filtering and I'm trying to find papers that talk about the performance of these similarity metrics: Cosine, Euclidean, Pearson, Covariance, and Manhattan. I was also trying to find papers that talk about blending the metrics together to improve performance.",,False,self,t5_2r3gv,False,,,True,t3_1dswo0,http://www.reddit.com/r/MachineLearning/comments/1dswo0/trying_to_find_papers_about_similarity_metrics/,
1361656825.0,36,arxiv.org,193lhb,MaxOut - new deep architecture using dropout and max units sets new records on a few data sets,38,2,1,http://www.reddit.com/r/MachineLearning/comments/193lhb/maxout_new_deep_architecture_using_dropout_and/,,,False,default,t5_2r3gv,False,,,False,t3_193lhb,http://arxiv.org/pdf/1302.4389v3,
1357942325.0,36,cs229.stanford.edu,16ejb7,Final project reports from 2012 Stanford Machine Learning class ,42,6,12,http://www.reddit.com/r/MachineLearning/comments/16ejb7/final_project_reports_from_2012_stanford_machine/,,,False,default,t5_2r3gv,False,,,False,t3_16ejb7,http://cs229.stanford.edu/projects2012.html,
1357325616.0,34,mlsurveys.com,15yopa,"r/MachineLearning, help me build a comprehensive list of Machine Learning survey papers",43,9,5,http://www.reddit.com/r/MachineLearning/comments/15yopa/rmachinelearning_help_me_build_a_comprehensive/,,,False,http://b.thumbs.redditmedia.com/kDgz-7sV1qLMhAcg.jpg,t5_2r3gv,False,,,False,t3_15yopa,http://www.mlsurveys.com/,
1353896815.0,33,newyorker.com,13sgvq,Is “Deep Learning” a Revolution in Artificial Intelligence? : The New Yorker,49,16,8,http://www.reddit.com/r/MachineLearning/comments/13sgvq/is_deep_learning_a_revolution_in_artificial/,,,False,http://c.thumbs.redditmedia.com/b6fYl8H0t90Cd0Jz.jpg,t5_2r3gv,False,,,False,t3_13sgvq,http://www.newyorker.com/online/blogs/newsdesk/2012/11/is-deep-learning-a-revolution-in-artificial-intelligence.html,
1351182873.0,33,kaggle.com,122m4r,Massive ML Project that will land you a job at facebook,43,10,32,http://www.reddit.com/r/MachineLearning/comments/122m4r/massive_ml_project_that_will_land_you_a_job_at/,,,False,http://d.thumbs.redditmedia.com/dwpbJQhIaetNbyWo.jpg,t5_2r3gv,False,,,False,t3_122m4r,https://www.kaggle.com/c/facebook-ii/,
1338152969.0,33,mewo2.github.com,u7qc2,"Eurovision statistics: post-game analysis, and an apology to the people of Malta",38,5,2,http://www.reddit.com/r/MachineLearning/comments/u7qc2/eurovision_statistics_postgame_analysis_and_an/,,,False,http://b.thumbs.redditmedia.com/LDC620TGcigogAGy.jpg,t5_2r3gv,False,,,False,t3_u7qc2,http://mewo2.github.com/nerdery/2012/05/27/eurovision-statistics-after-the-final/,
1336161614.0,34,nymag.com,t7cfh,New York recently became the nation's first federal court to explicitly approve the use of predictive coding,36,2,12,http://www.reddit.com/r/MachineLearning/comments/t7cfh/new_york_recently_became_the_nations_first/,,,False,http://c.thumbs.redditmedia.com/TK4sFy5gnZKexVi2.jpg,t5_2r3gv,False,,,False,t3_t7cfh,http://nymag.com/daily/intel/2012/03/new-technology-may-spell-doom-for-new-lawyers.html,
1322599438.0,33,self.MachineLearning,mtrcg,"Genetic Algorithm for generating ""music"" - Followup",37,4,7,http://www.reddit.com/r/MachineLearning/comments/mtrcg/genetic_algorithm_for_generating_music_followup/,"I [posted](http://www.reddit.com/r/MachineLearning/comments/mmz3r/genetic_algorithm_for_generating_music/) about a week ago asking for advice on creating a genetic algorithm. I wanted to thank those who replied, and share the results of my coding. 

The code is currently here: [GEN-OLM](http://github.com/bobschriver/GEN-OLM)

Many people expressed concern about the fitness I would choose. I ended up looking for a few long-period cycles in the results, as well as large variation between values. I hoped this would create a more complicated and dynamic sound, which it mostly does.

I'm currently having an issue where some high fitness sentences generated from my program result in completely boring music, and haven't quite figured out how to solve it, but it still produces other high fitness sentences which are interesting.

A few that I've picked out so far for being particularly interesting are these, which look much different than anything I've made by hand.

( t * ( t ^ ( ( t &gt;&gt; 7 ) / 7 ) ) )
( t * ( ( 5 - t ) &gt;&gt; ( t ^ ( t - 9 ) ) ) )

Feel free to play around with the program and modify as you please, and you can test the sentences it generates [here](http://wurstcaptures.untergrund.net/music/)

Once again, thanks for all your advice and help, enjoy!",,False,self,t5_2r3gv,False,,,True,t3_mtrcg,http://www.reddit.com/r/MachineLearning/comments/mtrcg/genetic_algorithm_for_generating_music_followup/,
1314779292.0,35,m.theatlantic.com,k00b2,Man vs. Machine on Wall Street: How Computers Beat the Market,38,3,2,http://www.reddit.com/r/MachineLearning/comments/k00b2/man_vs_machine_on_wall_street_how_computers_beat/,,,False,default,t5_2r3gv,False,,,False,t3_k00b2,http://m.theatlantic.com/business/print/2011/03/man-vs-machine-on-wall-street-how-computers-beat-the-market/73120/,
1312434730.0,32,r-bloggers.com,j8ikg,How Google makes online advertising more effective using R,34,2,0,http://www.reddit.com/r/MachineLearning/comments/j8ikg/how_google_makes_online_advertising_more/,,,False,default,t5_2r3gv,False,,,False,t3_j8ikg,http://www.r-bloggers.com/how-google-uses-r-to-make-online-advertising-more-effective/,
1306263848.0,33,self.MachineLearning,hj4cx,Classic papers in Machine Learning?,37,4,22,http://www.reddit.com/r/MachineLearning/comments/hj4cx/classic_papers_in_machine_learning/,"I am trying to get into machine learning, and one thing that has been helpful to me in other fields has been reading some of the ""classic"" papers in the field. I don't have a mentor for machine learning to ask, so I turn to you guys. What are some of the ""classic"" machine learning papers that helped establish the field?",,False,self,t5_2r3gv,False,,,True,t3_hj4cx,http://www.reddit.com/r/MachineLearning/comments/hj4cx/classic_papers_in_machine_learning/,
1290553525.0,34,kaggle.com,easib,"$10,000 on offer for a competition to build an algorithm that predicts commute times on a Sydney freeway",38,4,14,http://www.reddit.com/r/MachineLearning/comments/easib/10000_on_offer_for_a_competition_to_build_an/,,,False,http://thumbs.reddit.com/t3_easib.png,t5_2r3gv,False,,,False,t3_easib,http://kaggle.com/RTA,
1285716270.0,33,metaoptimize.com,dk8hs,Good Freely Available Textbooks on Machine Learning ,33,0,2,http://www.reddit.com/r/MachineLearning/comments/dk8hs/good_freely_available_textbooks_on_machine/,,,False,default,t5_2r3gv,False,,,False,t3_dk8hs,http://metaoptimize.com/qa/questions/186/,
1271955269.0,34,reddit.com,bupfu,"Reddit releases CSV dump of voting data - ML, think you can do something fun with it?",39,5,2,http://www.reddit.com/r/MachineLearning/comments/bupfu/reddit_releases_csv_dump_of_voting_data_ml_think/,,,False,default,t5_2r3gv,False,,,False,t3_bupfu,http://www.reddit.com/r/redditdev/comments/bubhl/csv_dump_of_reddit_voting_data/,
1263320386.0,33,self.MachineLearning,aor5z,Stanford Machine Learning (CS229) - Who wants to work through this together?,35,2,20,http://www.reddit.com/r/MachineLearning/comments/aor5z/stanford_machine_learning_cs229_who_wants_to_work/,"I'm loving the course so far. I'm about 1/4 of the way done. I think it's really valuable knowledge so I'm going through every detail and developing a deep understanding. 

I'm hungry for real problems to solve, for real projects. It's exciting to see there are plenty of them I can engage on online.

However, learning and exploring potential projects is much more fun, productive and efficient when done in a group.

We could work through this course together. We now have a CrunchCourse page! We can start using the forum http://www.crunchcourse.com/class/stanford-cs229-machine-learning/2010/jan/

Lecture materials and videos: [Stanford CS229 Machine Learning](http://see.stanford.edu/see/courseinfo.aspx?coll=348ca38a-3a6d-4052-937d-cb017338d7b1)

Summary of the course:
This course provides a broad introduction to machine learning and statistical pattern recognition. Topics include: supervised learning (generative/discriminative learning, parametric/non-parametric learning, neural networks, support vector machines); unsupervised learning (clustering, dimensionality reduction, kernel methods); learning theory (bias/variance tradeoffs; VC theory; large margins); reinforcement learning and adaptive control. The course will also discuss recent applications of machine learning, such as to robotic control, data mining, autonomous navigation, bioinformatics, speech recognition, and text and web data processing.",,False,self,t5_2r3gv,True,,,True,t3_aor5z,http://www.reddit.com/r/MachineLearning/comments/aor5z/stanford_machine_learning_cs229_who_wants_to_work/,
1373892293.0,28,self.MachineLearning,1ic408,Self study machine learning?,42,14,40,http://www.reddit.com/r/MachineLearning/comments/1ic408/self_study_machine_learning/,"I haven't done any serious math in quite a long time and I wanted to know what resources would you recommend to raise my rusty math skills to the appropriate level for machine learning and genetic programming?

I hope to re-learn mathematics the proper way instead of memorizing steps to solve a problem.

Thanks for your time.",,False,self,t5_2r3gv,False,,,True,t3_1ic408,http://www.reddit.com/r/MachineLearning/comments/1ic408/self_study_machine_learning/,
1373065624.0,31,youtube.com,1hpvl1,NASA neural networks regain control in the case of aviation control failure. Interesting application.,44,13,6,http://www.reddit.com/r/MachineLearning/comments/1hpvl1/nasa_neural_networks_regain_control_in_the_case/,,,False,http://d.thumbs.redditmedia.com/Ha5qHUzcdABSltb9.jpg,t5_2r3gv,False,,,False,t3_1hpvl1,https://www.youtube.com/watch?v=aObBHXsc_iw,
1369083000.0,31,self.MachineLearning,1epuhv,I coded a tiny optimization framework in C++11 over the weekend. It contains a genetic algorithm and a neural network with classic backpropagation (project is on github).,41,10,7,http://www.reddit.com/r/MachineLearning/comments/1epuhv/i_coded_a_tiny_optimization_framework_in_c11_over/,"Hello everyone,

As mentiond in the title, the project contains implementations for a neural network, a genetic algorithm, some statistics functions (mean, variance, covariance, pearson's R2) and a linear scaling method for shifting data. 

I haven't paid much attention to design yet (lost a lot of time reading about rprop and levenberg-marquardt methods for ann training - hopefully they will be implemented soon), but the code is fairly simple so maybe it'll be useful to anyone looking for some code samples. 

The repo is here: https://github.com/bburlacu/meta

Feedback or suggestions (even algorithm requests) would be appreciated. Thanks :)",,False,self,t5_2r3gv,False,,,True,t3_1epuhv,http://www.reddit.com/r/MachineLearning/comments/1epuhv/i_coded_a_tiny_optimization_framework_in_c11_over/,
1364737488.0,32,self.MachineLearning,1bcv89,Textbook on sale!,44,12,27,http://www.reddit.com/r/MachineLearning/comments/1bcv89/textbook_on_sale/,"Hey guys, I don't know if you really allow this sort of thing, but as a person who is always trying to not borrow textbooks from others when they are particularly good, I just found out that the ML book I've been wanting to properly own is on super sale on Amazon. Like, the MSRP is $90, it usually retails for $80, and Amazon (proper, not a secondary retailer) is selling new copies for $35! HOLY CRAP!

[Here's the link](http://www.amazon.com/Machine-Learning-Probabilistic-Perspective-Computation/dp/0262018020/ref=sr_1_1?ie=UTF8&amp;qid=1364737373&amp;sr=8-1&amp;keywords=Machine+Learning%3A+A+Probabilistic+Perspective) -- Machine Learning, a Probabilistic Perspective (Murphy).",,False,self,t5_2r3gv,False,,,True,t3_1bcv89,http://www.reddit.com/r/MachineLearning/comments/1bcv89/textbook_on_sale/,
1364003486.0,32,blog.thegrandlocus.com,1au4bu,Identify the author of a text,40,8,6,http://www.reddit.com/r/MachineLearning/comments/1au4bu/identify_the_author_of_a_text/,,,False,http://c.thumbs.redditmedia.com/4SuVqCEMZThCoSEh.jpg,t5_2r3gv,False,,,False,t3_1au4bu,http://blog.thegrandlocus.com/2013/03/one-shade-of-authorship-attribution,
1360079583.0,34,camdp.com,17xqhf,How to win the Showdown on the Price is Right.,42,8,5,http://www.reddit.com/r/MachineLearning/comments/17xqhf/how_to_win_the_showdown_on_the_price_is_right/,,,False,default,t5_2r3gv,False,,,False,t3_17xqhf,http://camdp.com/blogs/how-solve-price-rights-showdown,
1352911804.0,34,self.MachineLearning,136rne,Best R tutorial/book for Machine Learning,38,4,18,http://www.reddit.com/r/MachineLearning/comments/136rne/best_r_tutorialbook_for_machine_learning/,"I am in a ML and Data mining class right now and we are encouraged to use R for our assignments and projects. I've been using Weka with my supervisor.

I have a decent coding background but I wasn't able to understand the syntax of R so I need to find a good tutorial or book to help me learn, probably from the near begining. 

In our first assignment we were supposed to use RWeka and DMwR libraries but even after seeing the solution I still don't understand the code and syntax.

For our project we are to be pre-processing lots of text (which I could easily do in python) and then do ML on it to improve the classification rate. Since it is imbalanced data (10-90) I know I need to deal with stuff such as the area under the curve (which I can't do in Weka).

So please recomend me a good tutorial or book I can get to help me learn the syntax for R that touches upon ML related tasks.

Thanks

",,False,self,t5_2r3gv,False,,,True,t3_136rne,http://www.reddit.com/r/MachineLearning/comments/136rne/best_r_tutorialbook_for_machine_learning/,
1348150021.0,34,online.wsj.com,106xdc,"Xerox now leaves all hiring for its 48,700 call-center jobs to software ",39,5,10,http://www.reddit.com/r/MachineLearning/comments/106xdc/xerox_now_leaves_all_hiring_for_its_48700/,,,False,http://d.thumbs.redditmedia.com/HkLwgBUXKH-VZukc.jpg,t5_2r3gv,False,,,False,t3_106xdc,http://online.wsj.com/article/SB10000872396390443890304578006252019616768.html,
1346753925.0,32,self.MachineLearning,zbv6d,Looking for an open source machine learning project,39,7,39,http://www.reddit.com/r/MachineLearning/comments/zbv6d/looking_for_an_open_source_machine_learning/,"I'm a senior software engineer for a big European corporation. I've got master's degree in machine learning, specialised in classification and semi-supervised learning. I haven't put this knowledge to use in almost three years now, except for solving some simple clustering problems. I'd really appreciate any suggestions of open source projects that I could contribute to. I just want to keep my skills sharp. Since I don't get any challenging tasks at work (I slack off), I'd rather spend this time doing something useful.

I have a slight preference for Java projects because I used to work with WEKA a lot. But I can learn a new language too.

Sorry for using throwaway, some of my colleagues are redditors, I'm pretty sure sure they don't browse r/MachineLearning, but I don't want to take any chances.",,False,self,t5_2r3gv,False,,,True,t3_zbv6d,http://www.reddit.com/r/MachineLearning/comments/zbv6d/looking_for_an_open_source_machine_learning/,
1345422653.0,31,arxiv.org,yhwuh,Rapid Feature Learning with Stacked Linear Denoisers (deep learning in seconds!),38,7,13,http://www.reddit.com/r/MachineLearning/comments/yhwuh/rapid_feature_learning_with_stacked_linear/,,,False,default,t5_2r3gv,False,,,False,t3_yhwuh,http://arxiv.org/abs/1105.0972,
1343742448.0,34,self.MachineLearning,xg5e6,Ok. What exactly is 'deep learning'?,38,4,24,http://www.reddit.com/r/MachineLearning/comments/xg5e6/ok_what_exactly_is_deep_learning/,"Hello all, 

I have done some ML, and being somewhat plugged into the scene, I keep hearing about deep learning this and deep learning that. 

For all the blogs/articles/soundbites I come across however, I cannot seem to come across just what *exactly* deep learning is. Its starting to sound like a buzz word unfortunately, but maybe there is some gold in the ruff. 

So, what is deep learning precisely? What will it help us do differently, and how? If you feel you can couch it in terms of supervised/unsupervised learning, all the better, with the constraint that the explanation still be precise, clear, and intuitive. 

Thanks! :-)",,False,self,t5_2r3gv,False,,,True,t3_xg5e6,http://www.reddit.com/r/MachineLearning/comments/xg5e6/ok_what_exactly_is_deep_learning/,
1341688624.0,34,aimusings.wordpress.com,w6sv5,A Quick Sentiment Analysis Experiment: Vorpal Wabbit vs state of the art results,36,2,7,http://www.reddit.com/r/MachineLearning/comments/w6sv5/a_quick_sentiment_analysis_experiment_vorpal/,,,False,http://d.thumbs.redditmedia.com/N_XlesLJr_RMRIy3.jpg,t5_2r3gv,False,,,False,t3_w6sv5,http://aimusings.wordpress.com/2012/07/06/a-quick-sentiment-analysis-experiment/,
1341463984.0,30,self.MachineLearning,w2aus,I am working to fight child slavery by doing statistical analysis and I would like your help.,42,12,20,http://www.reddit.com/r/MachineLearning/comments/w2aus/i_am_working_to_fight_child_slavery_by_doing/,"Let me say upfront that this is the early stages of this project and there is no money involved. If this goes well I might write a paper about it (though I have no idea where I would submit it).

Here is the basic premise of the problem: 

**Lots of young girls are used as sex slaves/prostitutes in the US. If we examine the ad space of young prostitutes can we help them?**

More details:

Their pimps advertise the girls in many cities all across the country. The pimps might have girls in several cities or move girls between several cities. 

These ads appear online in a variety of publications. These ads often come with telephone numbers and photographs.

The question:

If we scrapped ads from these websites what sort of useful analysis could we do?

So far this is what I have thought of:

Do cluster analysis on the text of the ads to see which ads were posted by the same person. Essentially this is an unsupervised learning algorthm being applied to the data of the ads (photo, text, date/time of posting, location, phone number). It was suggested that I use an [LDE](http://en.wikipedia.org/wiki/Latent_Dirichlet_allocation).  Additionally, there is no need to actually decode the meaning of the ads at this time, but it could be interesting later.

Photo analysis to see which girls are operating in which cities. This has several different possible levels of success: Finding the same picture attached to different ads. Finding similar pictures, i.e., pictures that might have been taken in the same room. Finding the same girls in distinctly different pictures.

What help I would like from r/machinelearning:

How have problems like this been solved in the past. I imagine someone has done analysis on craigslist ads to similar effect, i.e., to find out which ads were posted by the same person. Probably in the name of fraud detection. Can someone point me to some papers on the topic? I am looking myself, but I wouldn't mind the help.
",,False,self,t5_2r3gv,False,,,True,t3_w2aus,http://www.reddit.com/r/MachineLearning/comments/w2aus/i_am_working_to_fight_child_slavery_by_doing/,
1321973207.0,33,self.MachineLearning,mlhas,ML interview questions,39,6,27,http://www.reddit.com/r/MachineLearning/comments/mlhas/ml_interview_questions/,"What questions would you ask a candidate, for a job that required applying machine learning, to test their skills?",,False,self,t5_2r3gv,False,,,True,t3_mlhas,http://www.reddit.com/r/MachineLearning/comments/mlhas/ml_interview_questions/,
1320342467.0,29,bits.blogs.nytimes.com,lz7tw,Kaggle Receives $11 Million in Venture Funding,34,5,0,http://www.reddit.com/r/MachineLearning/comments/lz7tw/kaggle_receives_11_million_in_venture_funding/,,,False,http://b.thumbs.redditmedia.com/nF8UqtcpJLZ8jJJy.jpg,t5_2r3gv,False,,,False,t3_lz7tw,http://bits.blogs.nytimes.com/2011/11/03/a-site-for-data-scientists-to-prove-their-skills-and-make-money/,
1319637098.0,34,reddit.com,lpoc3,Want to help reddit build a subreddit recommender? -- A public dump of voting data that our users have donated for research [x-post from /r/redditdev],43,9,8,http://www.reddit.com/r/MachineLearning/comments/lpoc3/want_to_help_reddit_build_a_subreddit_recommender/,,,False,default,t5_2r3gv,False,,,False,t3_lpoc3,http://www.reddit.com/r/redditdev/comments/lowwf/attempt_2_want_to_help_reddit_build_a_recommender/,
1293481933.0,31,wired.com,es769,The A.I. Revolution Is On,41,10,8,http://www.reddit.com/r/MachineLearning/comments/es769/the_ai_revolution_is_on/,,,False,http://thumbs.reddit.com/t3_es769.png,t5_2r3gv,False,,,False,t3_es769,http://www.wired.com/magazine/2010/12/ff_ai_essay_airevolution/,
1292560334.0,32,behind-the-enemy-lines.blogspot.com,en87x,Mechanical Turk: Now with 40.92% spam.,34,2,9,http://www.reddit.com/r/MachineLearning/comments/en87x/mechanical_turk_now_with_4092_spam/,,,False,http://thumbs.reddit.com/t3_en87x.png,t5_2r3gv,False,,,False,t3_en87x,http://behind-the-enemy-lines.blogspot.com/2010/12/mechanical-turk-now-with-4092-spam.html,
1289151984.0,34,news.cs.cmu.edu,e2joo,"NELL – a computer system that, over time, is 
teaching itself to read and understand the web. (has 
a twitter feed of its results, even)",37,3,3,http://www.reddit.com/r/MachineLearning/comments/e2joo/nell_a_computer_system_that_over_time_is_teaching/,,,False,http://thumbs.reddit.com/t3_e2joo.png,t5_2r3gv,False,,,False,t3_e2joo,http://news.cs.cmu.edu/article.php?a=1974,
1264030664.0,32,blog.okcupid.com,as4q1,What profile pictures are attractive?,35,3,3,http://www.reddit.com/r/MachineLearning/comments/as4q1/what_profile_pictures_are_attractive/,,,False,http://thumbs.reddit.com/t3_as4q1.png,t5_2r3gv,False,,,False,t3_as4q1,http://blog.okcupid.com/index.php/2010/01/20/the-4-big-myths-of-profile-pictures/,
1249536729.0,34,nytimes.com,97ztu,"""For Today’s Graduate, Just One 
Word: Statistics"" - NYTIMES.com",37,3,2,http://www.reddit.com/r/MachineLearning/comments/97ztu/for_todays_graduate_just_one_word_statistics/,,,False,default,t5_2r3gv,False,,,False,t3_97ztu,http://www.nytimes.com/2009/08/06/technology/06stats.html?_r=1&amp;hp,
1369959611.0,32,dlib.net,1fdfom,dlib C++ Library v18.2 released. Lots of state-of-the-art Machine Learning algorithms and other useful tools meant for use on real world problems.,43,11,16,http://www.reddit.com/r/MachineLearning/comments/1fdfom/dlib_c_library_v182_released_lots_of/,,,False,default,t5_2r3gv,False,,,False,t3_1fdfom,http://dlib.net/ml.html,
1359750916.0,31,cilvr.cs.nyu.edu,17pqa3,First video/slides from John Langford and Yann LeCun's large scale ML class,36,5,3,http://www.reddit.com/r/MachineLearning/comments/17pqa3/first_videoslides_from_john_langford_and_yann/,,,False,default,t5_2r3gv,False,,,False,t3_17pqa3,http://cilvr.cs.nyu.edu/doku.php?id=courses:bigdata:slides:start,
1346170787.0,32,self.MachineLearning,yyu8s,Project ideas for software developers with an interest in machine learning,37,5,29,http://www.reddit.com/r/MachineLearning/comments/yyu8s/project_ideas_for_software_developers_with_an/,"A little background: BS degrees in Mathematics and Computer Science, and am a reasonably experienced software developer. I spend most of my free time writing software or doing math.

I have recently been going through the Coursera Machine Learning course and have found the subject to be really awesome. I have found a few nice data sets that I have been playing around with, and have started diving into a textbook (Pattern Recognition and Machine Learning by Bishop). It is going to take me a long time to get through it, though.

In the meantime, does anyone have any ideas for projects that could use novice-level skills in machine learning but also have a large software development component? It seems like there is only a small portion of ""data scientists"" that have significant software development experiences, so I am hoping that there is some interesting low-hanging fruit here.",,False,self,t5_2r3gv,False,,,True,t3_yyu8s,http://www.reddit.com/r/MachineLearning/comments/yyu8s/project_ideas_for_software_developers_with_an/,
1336787442.0,31,scikit-learn.org,tj3io,Support Vector Machines,40,9,5,http://www.reddit.com/r/MachineLearning/comments/tj3io/support_vector_machines/,,,False,http://d.thumbs.redditmedia.com/acTZH9j2fLYEkI43.jpg,t5_2r3gv,False,,,False,t3_tj3io,http://scikit-learn.org/0.10/modules/svm.html,
1329080448.0,30,nytimes.com,pmgae,Big Data’s Impact in the World - NYTimes,34,4,1,http://www.reddit.com/r/MachineLearning/comments/pmgae/big_datas_impact_in_the_world_nytimes/,,,False,default,t5_2r3gv,False,,,False,t3_pmgae,http://www.nytimes.com/2012/02/12/sunday-review/big-datas-impact-in-the-world.html,
1322614932.0,30,self.MachineLearning,mu2ly,Is a PhD worth it in machine learning?,35,5,38,http://www.reddit.com/r/MachineLearning/comments/mu2ly/is_a_phd_worth_it_in_machine_learning/,"I'm in a graduate program in statistics right now, and have dabbled in machine learning and data mining for a while. I'm currently getting my master's, and I'm trying to decide if it's worth it to get a Ph.D if this is the field I want to get into.

What is your experience with the MS/PhD requirements for ML/DM jobs? Is a master's or master's + experience equivalent to a phd for most jobs? Most research jobs? And are most ML/DM jobs research oriented or not?

Is having a degree in statistics, instead of CS, a hindrance?
Can a strong statistical background make up for a less strong CS background?

Lastly, what skills are most valuable for work in machine learning, or what skills are too often overlooked?",,False,self,t5_2r3gv,False,,,True,t3_mu2ly,http://www.reddit.com/r/MachineLearning/comments/mu2ly/is_a_phd_worth_it_in_machine_learning/,
1322504288.0,31,self.MachineLearning,ms8gh,"A general PSA to the new recruits to the subreddit from the ML-CLASS: Your toolbox contains a few new hammers, but not every problem is a nail",49,18,7,http://www.reddit.com/r/MachineLearning/comments/ms8gh/a_general_psa_to_the_new_recruits_to_the/,"I've seen several posts recently that appear to be solutions searching for a problem. Posts along the lines of ""Is this problem suitable for me to apply this new technique I learned?""

I understand that you all are looking for ways to apply your new skills, and you absolutely should. If you don't practice your new knowledge, you're likely to forget it. Unfortunately though, walking around with a hammer in search of a nail is generally a bad way to go about it. You need to review available problems and consider possible solutions independent of the tools you'd prefer to exercise. 

I'm sorry I don't have any resources to offer. My general suggestions for getting some practice are to poke around on [Kaggle](http://www.kaggle.com/), or pick up a ML textbook and work through some exercises. Maybe find a problem that has already been solved by a technique you want to practice and try figuring out how to do it yourself.

A general warning: try not to be like that guy in your office who just figured out how to make pretty graphs in excel and is looking for excuses to plot anything he can as a 3D bubble chart. It just doesn't work that way.",,False,self,t5_2r3gv,False,,,True,t3_ms8gh,http://www.reddit.com/r/MachineLearning/comments/ms8gh/a_general_psa_to_the_new_recruits_to_the/,
1306087631.0,29,imgur.com,hhfct,My relationship with statistical learning theory...,57,28,10,http://www.reddit.com/r/MachineLearning/comments/hhfct/my_relationship_with_statistical_learning_theory/,,,False,http://thumbs.reddit.com/t3_hhfct.png,t5_2r3gv,False,,,False,t3_hhfct,http://imgur.com/R9FeI,
1279897390.0,32,vimeo.com,cswey,A Robot that Flip Pancakes using Reinforcement Learning.,34,2,7,http://www.reddit.com/r/MachineLearning/comments/cswey/a_robot_that_flip_pancakes_using_reinforcement/,,,False,http://thumbs.reddit.com/t3_cswey.png,t5_2r3gv,False,,,False,t3_cswey,http://vimeo.com/13387420,
1252860004.0,32,blog.smellthedata.com,9k4gk,"A recommendation algorithm using probabilistic matrix factorization, with full Python implementation.",34,2,3,http://www.reddit.com/r/MachineLearning/comments/9k4gk/a_recommendation_algorithm_using_probabilistic/,,,False,http://thumbs.reddit.com/t3_9k4gk.png,t5_2r3gv,False,,,False,t3_9k4gk,http://blog.smellthedata.com/2009/06/netflix-prize-tribute-recommendation.html,
1375753429.0,30,self.MachineLearning,1js67c,How do you organize your machine-learning pipeline?,38,8,16,http://www.reddit.com/r/MachineLearning/comments/1js67c/how_do_you_organize_your_machinelearning_pipeline/,"I was wondering about the way people organize their machine learning projects. Specifically, it is very common to have a pipeline starting with data in some sort of database, which is fed through several sequential algorithms (an example taken from Andrew Ng's course - we start with raw images, then extract locations of digits which appear in them, then feed these to a digit-recognizer).

1. Where do you store intermediary results? 
2. How do you store your trained classifiers?
3. How do you store the results of different parameterizations or hyper-parametrizations of your algorithms? (for example, assuming that one layer is perfect so that we can see how that affects the final output)


Thanks!",,False,self,t5_2r3gv,False,,,True,t3_1js67c,http://www.reddit.com/r/MachineLearning/comments/1js67c/how_do_you_organize_your_machinelearning_pipeline/,
1373713606.0,33,youtube.com,1i7ocx,Marvin Minsky Calls the Turing Test a Joke and criticizes the use of the Turing Test as an identifier of artificial intelligence,47,14,21,http://www.reddit.com/r/MachineLearning/comments/1i7ocx/marvin_minsky_calls_the_turing_test_a_joke_and/,,,False,http://b.thumbs.redditmedia.com/DHXpP8p9FTMX3awa.jpg,t5_2r3gv,False,,,False,t3_1i7ocx,http://www.youtube.com/watch?feature=player_embedded&amp;v=3PdxQbOvAlI#at=60,
1371912777.0,27,area51.stackexchange.com,1guvgf,Support the Machine Learning StackExchange (currently in Area51 at 87% required commitment),43,16,20,http://www.reddit.com/r/MachineLearning/comments/1guvgf/support_the_machine_learning_stackexchange/,,,False,default,t5_2r3gv,False,,,False,t3_1guvgf,http://area51.stackexchange.com/proposals/41738/machine-learning,
1371385211.0,33,pauloortins.com,1gg8qp,Resources to become a Machine Learning Ninja,53,20,5,http://www.reddit.com/r/MachineLearning/comments/1gg8qp/resources_to_become_a_machine_learning_ninja/,,,False,default,t5_2r3gv,False,,,False,t3_1gg8qp,http://pauloortins.com/resources-to-become-a-ninja-machine-learning/,
1370577712.0,34,machinedlearnings.com,1fuazg,How to be effective as an ML developer: Productivity is about not waiting,41,7,6,http://www.reddit.com/r/MachineLearning/comments/1fuazg/how_to_be_effective_as_an_ml_developer/,,,False,default,t5_2r3gv,False,,,False,t3_1fuazg,http://www.machinedlearnings.com/2013/06/productivity-is-about-not-waiting.html,
1367405220.0,28,machinedlearnings.com,1dh33i,Machined Learnings: Learning is easier than optimization,34,6,5,http://www.reddit.com/r/MachineLearning/comments/1dh33i/machined_learnings_learning_is_easier_than/,,,False,default,t5_2r3gv,False,,,False,t3_1dh33i,http://www.machinedlearnings.com/2013/04/learning-is-easier-than-optimization.html,
1362155309.0,27,kkjkok.blogspot.com,19gw0q,Introduction to Machine Learning: Gaussian Parameter Estimation (xpost r/DSP),32,5,10,http://www.reddit.com/r/MachineLearning/comments/19gw0q/introduction_to_machine_learning_gaussian/,,,False,http://d.thumbs.redditmedia.com/swZ2OAZtSzOYk-2-.jpg,t5_2r3gv,False,,,False,t3_19gw0q,http://kkjkok.blogspot.com/2013/03/introduction-to-machine-learning-part-1.html,
1355853444.0,30,metaoptimize.com,1527nn,"MetaOptimize QA: The ""StackOverflow"" for Machine Learning",39,9,3,http://www.reddit.com/r/MachineLearning/comments/1527nn/metaoptimize_qa_the_stackoverflow_for_machine/,,,False,default,t5_2r3gv,False,,,False,t3_1527nn,http://metaoptimize.com/qa/questions/?sort=mostvoted,
1345039654.0,32,arkitus.com,y9f7s,Patterns for Research in Machine Learning,37,5,3,http://www.reddit.com/r/MachineLearning/comments/y9f7s/patterns_for_research_in_machine_learning/,,,False,default,t5_2r3gv,False,,,False,t3_y9f7s,http://arkitus.com/PRML/,
1344363516.0,32,alex.smola.org,xu2ku,SML: Scalable Machine Learning Course by Alex Smola,34,2,2,http://www.reddit.com/r/MachineLearning/comments/xu2ku/sml_scalable_machine_learning_course_by_alex_smola/,,,False,default,t5_2r3gv,False,,,False,t3_xu2ku,http://alex.smola.org/teaching/berkeley2012/index.html,
1339681139.0,31,arxiv.org,v1mbw,[PDF] No More Pesky Learning Rates,34,3,7,http://www.reddit.com/r/MachineLearning/comments/v1mbw/pdf_no_more_pesky_learning_rates/,,,False,default,t5_2r3gv,False,,,False,t3_v1mbw,http://arxiv.org/pdf/1206.1106v1.pdf,
1306078358.0,29,chem-eng.utoronto.ca,hhchh,An IInteresting Visual tree Map for introducing Data Mining.,35,6,3,http://www.reddit.com/r/MachineLearning/comments/hhchh/an_iinteresting_visual_tree_map_for_introducing/,,,False,http://thumbs.reddit.com/t3_hhchh.png,t5_2r3gv,False,,,False,t3_hhchh,http://chem-eng.utoronto.ca/~datamining/dmc/data_mining_map.htm,
1305898824.0,28,self.MachineLearning,hfvb6,Bayesian Networks with Python tutorial,33,5,9,http://www.reddit.com/r/MachineLearning/comments/hfvb6/bayesian_networks_with_python_tutorial/,"I'm trying to learn how to implement bayesian networks in python. I've read most of the theory on them and the math but I still have a gap in my knowledge between theory and usage.

For this I'd like to do some exercise programs or tutorials on the subject. I've noticed the preffered toolbox is MOCAPY but the documentation is quite old and I can find no examples.

Searching for tutorials gives me nothing but theory. Does anyone have any good step by step tutorials for Bayesian networks in python?",,False,self,t5_2r3gv,False,,,True,t3_hfvb6,http://www.reddit.com/r/MachineLearning/comments/hfvb6/bayesian_networks_with_python_tutorial/,
1302605230.0,28,alex.smola.org,go4g6,"A huge, up to date tutorial about using graphical models for web-scale applications, by Alex Smola. Starts out fairly basic, but gets pretty deep. [Warning: 300 page PDF]",33,5,3,http://www.reddit.com/r/MachineLearning/comments/go4g6/a_huge_up_to_date_tutorial_about_using_graphical/,,,False,default,t5_2r3gv,False,,,False,t3_go4g6,http://alex.smola.org/drafts/www11-1.pdf,
1297327124.0,32,arxiv.org,fin4q,"High-Performance Neural Networks for Visual Object Classification (Top performance on Cifar10, Mnist, Norb w/o unsupervised but lots of GPU)",32,0,6,http://www.reddit.com/r/MachineLearning/comments/fin4q/highperformance_neural_networks_for_visual_object/,,,False,default,t5_2r3gv,False,,,False,t3_fin4q,http://arxiv.org/abs/1102.0183,
1296220700.0,30,turingfilm.com,fapg3,The Genius of Alan Turing (in development feature length documentary),33,3,2,http://www.reddit.com/r/MachineLearning/comments/fapg3/the_genius_of_alan_turing_in_development_feature/,,,False,http://thumbs.reddit.com/t3_fapg3.png,t5_2r3gv,False,,,False,t3_fapg3,http://www.turingfilm.com/,
1293559373.0,30,youtube.com,esn1d,The Joy of Stats (from Gapminder so this should stay up),31,1,2,http://www.reddit.com/r/MachineLearning/comments/esn1d/the_joy_of_stats_from_gapminder_so_this_should/,,,False,http://thumbs.reddit.com/t3_esn1d.png,t5_2r3gv,False,,,False,t3_esn1d,http://www.youtube.com/watch?v=oOOmqHzkkOo,
1291817363.0,31,radar.oreilly.com,eia89,"Five data blogs you should read (Data geekery, visualization and journalism)",32,1,0,http://www.reddit.com/r/MachineLearning/comments/eia89/five_data_blogs_you_should_read_data_geekery/,,,False,http://thumbs.reddit.com/t3_eia89.png,t5_2r3gv,False,,,False,t3_eia89,http://radar.oreilly.com/2010/12/5-data-blogs-you-should-read.html,
1287843667.0,30,research.google.com,dvbge,Publications by Googlers in Artificial Intelligence and Data Mining,31,1,1,http://www.reddit.com/r/MachineLearning/comments/dvbge/publications_by_googlers_in_artificial/,,,False,default,t5_2r3gv,False,,,False,t3_dvbge,http://research.google.com/pubs/ArtificialIntelligenceandDataMining.html,
1252097736.0,30,youtube.com,9hfbl,"Peter Norvig on ""Innovations in AI and Search"". [VID]",32,2,0,http://www.reddit.com/r/MachineLearning/comments/9hfbl/peter_norvig_on_innovations_in_ai_and_search_vid/,,,False,http://thumbs.reddit.com/t3_9hfbl.png,t5_2r3gv,False,,,False,t3_9hfbl,http://www.youtube.com/watch?v=HT540VrCDwg,
1375607514.0,31,self.MachineLearning,1jo953,"With Hinton's DREDNETs, what happened to semi-supervised density modeling?",32,1,17,http://www.reddit.com/r/MachineLearning/comments/1jo953/with_hintons_drednets_what_happened_to/,"I've been trying to wrap my head around the Deep Learning scene for a while now, but I'm merely an enthusiast and get a little lost in the details once in a while. 
 
Following the literature over the last few years, it seemed like deep methods like RBMs etc. had a way of leveraging unlabeled data for e.g. a classification task, which is otherwise a task involving labeled data. As far as I understood, pre-training made the network generatively model the data, and when coupled to your classification task (via backpropagating using the labels) this would outperform methods that learnt through the labels alone. 

Then Hinton recently gave his formula for DREDNET, a deep network with rectified linear units and dropout, which seems to be a return to form for supervised neural networks. 

My question, then, is: where does this leave semi-supervised models, particularly Bengio's Deep Generative Stochastic Networks? (Important enough to get a Wired article yet the only benchmark I can find is MNIST) ",,False,self,t5_2r3gv,False,,,True,t3_1jo953,http://www.reddit.com/r/MachineLearning/comments/1jo953/with_hintons_drednets_what_happened_to/,
1374019418.0,25,self.MachineLearning,1ig8jm,What is the simplest to implement (from scratch) yet reasonably effective supervised learning algorithm?,32,7,54,http://www.reddit.com/r/MachineLearning/comments/1ig8jm/what_is_the_simplest_to_implement_from_scratch/,,,False,self,t5_2r3gv,False,,,True,t3_1ig8jm,http://www.reddit.com/r/MachineLearning/comments/1ig8jm/what_is_the_simplest_to_implement_from_scratch/,
1370965549.0,28,slideshare.net,1g4ku4,Slides: Machine Learning in R,39,11,0,http://www.reddit.com/r/MachineLearning/comments/1g4ku4/slides_machine_learning_in_r/,,,False,http://a.thumbs.redditmedia.com/a9Jkq9BJflsACdVZ.jpg,t5_2r3gv,False,,,False,t3_1g4ku4,http://www.slideshare.net/kerveros99/machine-learning-in-r,
1368508080.0,28,youtube.com,1eapy4,A friend of mine wrote his own neural network software. Check out this cool birdy,42,14,19,http://www.reddit.com/r/MachineLearning/comments/1eapy4/a_friend_of_mine_wrote_his_own_neural_network/,,,False,http://a.thumbs.redditmedia.com/YM-6IvwwGjL96a3l.jpg,t5_2r3gv,False,,,False,t3_1eapy4,http://www.youtube.com/watch?v=WF2tNSMtVb4,
1365809607.0,27,self.MachineLearning,1c8mx8,Three new machine learning competitions for ICML 2013,36,9,20,http://www.reddit.com/r/MachineLearning/comments/1c8mx8/three_new_machine_learning_competitions_for_icml/,"The tasks are interesting. I promise!

[The black box challenge](http://www.kaggle.com/c/challenges-in-representation-learning-the-black-box-learning-challenge)

[Multi-modal Learning](https://www.kaggle.com/c/challenges-in-representation-learning-multi-modal-learning)

[Learning facial expressions](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge)",,False,self,t5_2r3gv,False,,,True,t3_1c8mx8,http://www.reddit.com/r/MachineLearning/comments/1c8mx8/three_new_machine_learning_competitions_for_icml/,
1361217548.0,30,sumsar.net,18rp2g,Javascript MCMC demo (versus two-tailed t-test),34,4,10,http://www.reddit.com/r/MachineLearning/comments/18rp2g/javascript_mcmc_demo_versus_twotailed_ttest/,,,False,http://b.thumbs.redditmedia.com/7TyRDqjwzRHtD4js.jpg,t5_2r3gv,False,,,False,t3_18rp2g,http://www.sumsar.net/best_online/,
1357228003.0,27,stackoverflow.com,15w47e,Algorithm improvement for Coca-Cola recognition,37,10,7,http://www.reddit.com/r/MachineLearning/comments/15w47e/algorithm_improvement_for_cocacola_recognition/,,,False,default,t5_2r3gv,False,,,False,t3_15w47e,http://stackoverflow.com/questions/10168686/algorithm-improvement-for-coca-cola-can-shape-recognition,
1350542683.0,29,web4.cs.ucl.ac.uk,11ofk8,[PDF] Bayesian Reasoning and Machine Learning by David Barber,32,3,2,http://www.reddit.com/r/MachineLearning/comments/11ofk8/pdf_bayesian_reasoning_and_machine_learning_by/,,,False,default,t5_2r3gv,False,,,False,t3_11ofk8,http://web4.cs.ucl.ac.uk/staff/D.Barber/textbook/090310.pdf,
1350340008.0,29,zinkov.com,11jaud,Mini reviews of 10 popular books on Machine Learning,34,5,9,http://www.reddit.com/r/MachineLearning/comments/11jaud/mini_reviews_of_10_popular_books_on_machine/,,,False,http://d.thumbs.redditmedia.com/Zz0agAcZeyLtd_So.jpg,t5_2r3gv,False,,,False,t3_11jaud,http://zinkov.com/posts/2012-10-04-ml-book-reviews/,
1350006559.0,28,leonpalafox.com,11cdll,"I have the objective of creating the most comprehensive and intuitive ML book list to date, please suggest new titles.",36,8,20,http://www.reddit.com/r/MachineLearning/comments/11cdll/i_have_the_objective_of_creating_the_most/,,,False,http://d.thumbs.redditmedia.com/Zz0agAcZeyLtd_So.jpg,t5_2r3gv,False,,,False,t3_11cdll,http://www.leonpalafox.com/home/booklist,
1342141589.0,31,self.MachineLearning,wh2sb,Let's talk processes:  You're given a heaping pile of data.  You've constructed features.  What is your approach next?,39,8,14,http://www.reddit.com/r/MachineLearning/comments/wh2sb/lets_talk_processes_youre_given_a_heaping_pile_of/,"I feel that most people probably have a go-to approach when given new data that they want to perform classification on.  You've got a bunch of labeled data and features, what is your personal process for orienting yourself?",,False,self,t5_2r3gv,False,,,True,t3_wh2sb,http://www.reddit.com/r/MachineLearning/comments/wh2sb/lets_talk_processes_youre_given_a_heaping_pile_of/,
1336581275.0,30,rdatamining.com,tewbg,R and Data Mining: Examples and Case Studies,31,1,0,http://www.reddit.com/r/MachineLearning/comments/tewbg/r_and_data_mining_examples_and_case_studies/,,,False,default,t5_2r3gv,False,,,False,t3_tewbg,http://www.rdatamining.com/docs,
1335987639.0,28,blog.kaggle.com,t3rtn,Launch of the Kaggle Data Science Wiki,31,3,0,http://www.reddit.com/r/MachineLearning/comments/t3rtn/launch_of_the_kaggle_data_science_wiki/,,,False,default,t5_2r3gv,False,,,False,t3_t3rtn,http://blog.kaggle.com/2012/05/02/launch-of-the-kaggle-data-science-wiki/,
1334139014.0,29,highered.blogspot.com,s44p5,I tried to solve a puzzle using Eureqa. Here's the result...,32,3,12,http://www.reddit.com/r/MachineLearning/comments/s44p5/i_tried_to_solve_a_puzzle_using_eureqa_heres_the/,,,False,http://e.thumbs.redditmedia.com/E0-b1MP6j5JBc5yj.jpg,t5_2r3gv,False,,,False,t3_s44p5,http://highered.blogspot.com/2012/04/pattern-matching.html,
1314202545.0,28,quantombone.blogspot.com,jsznt,The vision hacker culture at Google,42,14,5,http://www.reddit.com/r/MachineLearning/comments/jsznt/the_vision_hacker_culture_at_google/,,,False,http://thumbs.reddit.com/t3_jsznt.png,t5_2r3gv,False,,,False,t3_jsznt,http://quantombone.blogspot.com/2011/08/vision-hacker-culture-at-google.html,
1305648353.0,29,hunch.net,hdg52,Research Directions for Machine Learning and Algorithms,29,0,0,http://www.reddit.com/r/MachineLearning/comments/hdg52/research_directions_for_machine_learning_and/,,,False,default,t5_2r3gv,False,,,False,t3_hdg52,http://hunch.net/?p=1822,
1299072492.0,30,kickstarter.com,fvrmb,The creator of the Creatures artificial life game series is looking for your help for a new game (r/artificial repost),32,2,2,http://www.reddit.com/r/MachineLearning/comments/fvrmb/the_creator_of_the_creatures_artificial_life_game/,,,False,http://thumbs.reddit.com/t3_fvrmb.png,t5_2r3gv,False,,,False,t3_fvrmb,http://www.kickstarter.com/projects/1508284443/grandroids-real-artificial-life-on-your-pc,
1297876676.0,30,ibmresearchnews.blogspot.com,fmku4,IBM Watson's wagering strategies ,31,1,8,http://www.reddit.com/r/MachineLearning/comments/fmku4/ibm_watsons_wagering_strategies/,,,False,http://thumbs.reddit.com/t3_fmku4.png,t5_2r3gv,False,,,False,t3_fmku4,http://ibmresearchnews.blogspot.com/2011/02/watsons-wagering-strategies.html,
1295474888.0,29,kaggle.com,f5dzs,Ford launches a challenge: build a classifier to determine whether or not drivers are alert,34,5,8,http://www.reddit.com/r/MachineLearning/comments/f5dzs/ford_launches_a_challenge_build_a_classifier_to/,,,False,http://thumbs.reddit.com/t3_f5dzs.png,t5_2r3gv,False,,,False,t3_f5dzs,http://www.kaggle.com/stayalert,
1280470962.0,29,forbes.com,cvdr8,High-Frequency Programmers Revolt Over Pay,31,2,21,http://www.reddit.com/r/MachineLearning/comments/cvdr8/highfrequency_programmers_revolt_over_pay/,,,False,default,t5_2r3gv,False,,,False,t3_cvdr8,http://www.forbes.com/2010/07/28/high-frequency-trading-personal-finance-programmer-pay.html,
1278268162.0,26,jdl.ac.cn,clxai,"How to get a PhD in AI. ""The Researcher's Bible""",35,9,4,http://www.reddit.com/r/MachineLearning/comments/clxai/how_to_get_a_phd_in_ai_the_researchers_bible/,,,False,default,t5_2r3gv,False,,,False,t3_clxai,http://www.jdl.ac.cn/how_to_research/doc/resbible.pdf,
1276212348.0,31,technologyreview.com,cdqnw,AI That Picks Stocks Better Than the Pros,37,6,16,http://www.reddit.com/r/MachineLearning/comments/cdqnw/ai_that_picks_stocks_better_than_the_pros/,,,False,http://thumbs.reddit.com/t3_cdqnw.png,t5_2r3gv,False,,,False,t3_cdqnw,http://www.technologyreview.com/blog/guest/25308/,
1275641594.0,29,youtube.com,cbch6,Lecture 1 | Machine Learning (Stanford),30,1,3,http://www.reddit.com/r/MachineLearning/comments/cbch6/lecture_1_machine_learning_stanford/,,,False,http://thumbs.reddit.com/t3_cbch6.png,t5_2r3gv,False,,,False,t3_cbch6,http://www.youtube.com/watch?v=UzxYlbK2c7E,
1270648501.0,31,youtube.com,bnn4u,TOWEL folding robot : The cutest robot on earth,38,7,4,http://www.reddit.com/r/MachineLearning/comments/bnn4u/towel_folding_robot_the_cutest_robot_on_earth/,,,False,http://thumbs.reddit.com/t3_bnn4u.png,t5_2r3gv,False,,,False,t3_bnn4u,http://www.youtube.com/watch?v=gy5g33S0Gzo,
1269290423.0,29,vimeo.com,bgrzk,Lecture on nonparametric models and other stuff by Peter Norvig (long video),31,2,3,http://www.reddit.com/r/MachineLearning/comments/bgrzk/lecture_on_nonparametric_models_and_other_stuff/,,,False,http://thumbs.reddit.com/t3_bgrzk.png,t5_2r3gv,False,,,False,t3_bgrzk,http://vimeo.com/4725365,
1258637506.0,30,mloss.org,a614v,PyBrain 0.3 -- swiss army knife for neural networking grew up a little,33,3,1,http://www.reddit.com/r/MachineLearning/comments/a614v/pybrain_03_swiss_army_knife_for_neural_networking/,,,False,http://thumbs.reddit.com/t3_a614v.png,t5_2r3gv,False,,,False,t3_a614v,http://mloss.org/software/view/156/,
1370480529.0,28,egtheory.wordpress.com,1frdjn,Machine learning and prediction without understanding,44,16,21,http://www.reddit.com/r/MachineLearning/comments/1frdjn/machine_learning_and_prediction_without/,,,False,http://a.thumbs.redditmedia.com/VPJkKLRcLTqmtuFl.jpg,t5_2r3gv,False,,,False,t3_1frdjn,http://egtheory.wordpress.com/2013/06/05/prediction-vs-understanding/,
1370195551.0,27,self.MachineLearning,1fj1ti,Ph. D necessary for ML jobs?,36,9,52,http://www.reddit.com/r/MachineLearning/comments/1fj1ti/ph_d_necessary_for_ml_jobs/,"I'm an undergrad majoring in CS, and I wanted to know if a Ph. D is necessary for machine learning/data mining jobs.
",,False,self,t5_2r3gv,False,,,True,t3_1fj1ti,http://www.reddit.com/r/MachineLearning/comments/1fj1ti/ph_d_necessary_for_ml_jobs/,
1361292795.0,28,cds.nyu.edu,18tqa4,NYU announces new Data Science department headed by Yann LeCun,35,7,24,http://www.reddit.com/r/MachineLearning/comments/18tqa4/nyu_announces_new_data_science_department_headed/,,,False,http://e.thumbs.redditmedia.com/QcF_JlfLES3fa2nX.jpg,t5_2r3gv,False,,,False,t3_18tqa4,http://cds.nyu.edu,
1358605296.0,28,self.MachineLearning,16vjhs,Question: pure math courses that are relevant to machine learning?,29,1,18,http://www.reddit.com/r/MachineLearning/comments/16vjhs/question_pure_math_courses_that_are_relevant_to/,"I am thinking about doing research on machine learning in the [very distant] future, and would like to know more about what math courses are relevant to the field.

I've just taken a course on **Probability and Stochastic Processes** (covered Markov Chains, but not Hidden Markov Model), and a **intro course on Real Analysis**, but I'm trying to plan out the rest of my classes. I have more analysis courses lined up (**Fourier Analysis**, **Complex Analysis**, **Real Analysis**), as well as **Algebra**, **Graph Theory** and hopefully **Probability Theory**. Which math courses are important or essential in studying machine learning, and which are less important?

Also, I will be taking a course on **Artificial Intelligence** next fall.

I know next to nothing about machine learning, and am trying to plan ahead while learning as much as I can in preparation. Thanks!",,False,self,t5_2r3gv,False,,,True,t3_16vjhs,http://www.reddit.com/r/MachineLearning/comments/16vjhs/question_pure_math_courses_that_are_relevant_to/,
1357435532.0,29,zinkov.com,161bti,Why Probabilistic Programming Matters,43,14,14,http://www.reddit.com/r/MachineLearning/comments/161bti/why_probabilistic_programming_matters/,,,False,default,t5_2r3gv,False,,,False,t3_161bti,http://zinkov.com/posts/2012-06-27-why-prob-programming-matters/,
1356904453.0,28,peekaboo-vision.blogspot.co.uk,15ov5d,Kernel Approximations for Efficient SVMs (from r/compsci),33,5,0,http://www.reddit.com/r/MachineLearning/comments/15ov5d/kernel_approximations_for_efficient_svms_from/,,,False,http://a.thumbs.redditmedia.com/Sq1H6Z9ybJNee-vx.jpg,t5_2r3gv,False,,,False,t3_15ov5d,http://peekaboo-vision.blogspot.co.uk/2012/12/kernel-approximations-for-efficient.html,
1354837593.0,28,streamhacker.com,14evef,NLTK + Scikit-Learn for Sentiment Classification,33,5,9,http://www.reddit.com/r/MachineLearning/comments/14evef/nltk_scikitlearn_for_sentiment_classification/,,,False,http://a.thumbs.redditmedia.com/hESGpHzGBW9w8kR6.jpg,t5_2r3gv,False,,,False,t3_14evef,http://streamhacker.com/2012/11/22/text-classification-sentiment-analysis-nltk-scikitlearn/,
1347739998.0,27,stats.stackexchange.com,zxu96,Big data from the viewpoint of statisticians -- interesting discussion at crossvalidated,33,6,0,http://www.reddit.com/r/MachineLearning/comments/zxu96/big_data_from_the_viewpoint_of_statisticians/,,,False,default,t5_2r3gv,False,,,False,t3_zxu96,http://stats.stackexchange.com/questions/35971/is-sampling-relevant-in-the-time-of-big-data,
1335796453.0,27,kaggle.com,szrk4,The Million Song Dataset Challenge - recommender system competition,37,10,5,http://www.reddit.com/r/MachineLearning/comments/szrk4/the_million_song_dataset_challenge_recommender/,,,False,default,t5_2r3gv,False,,,False,t3_szrk4,http://www.kaggle.com/c/msdchallenge,
1332854748.0,28,allendowney.blogspot.com,rft3d,The sunrise problem: a classic Bayes's theorem problem (from 1763).,32,4,0,http://www.reddit.com/r/MachineLearning/comments/rft3d/the_sunrise_problem_a_classic_bayess_theorem/,,,False,http://a.thumbs.redditmedia.com/5yewz-LdiBHPZyVl.jpg,t5_2r3gv,False,,,False,t3_rft3d,http://allendowney.blogspot.com/2012/03/sun-will-probably-come-out-tomorrow.html,
1330451583.0,28,deeplearning.stanford.edu,q9xsg,Stanford Unsupervised Feature Learning and Deep Learning Tutorial,32,4,8,http://www.reddit.com/r/MachineLearning/comments/q9xsg/stanford_unsupervised_feature_learning_and_deep/,,,False,default,t5_2r3gv,False,,,False,t3_q9xsg,http://deeplearning.stanford.edu/wiki/index.php/UFLDL_Tutorial,
1327179641.0,27,mpacula.com,oqlyh,AutoCorpus - natural language corpora from large public datasets,31,4,2,http://www.reddit.com/r/MachineLearning/comments/oqlyh/autocorpus_natural_language_corpora_from_large/,,,False,default,t5_2r3gv,False,,,False,t3_oqlyh,http://mpacula.com/autocorpus,
1313705377.0,26,newscientist.com,jn81g,Face recognition technology fails to find UK rioters,28,2,5,http://www.reddit.com/r/MachineLearning/comments/jn81g/face_recognition_technology_fails_to_find_uk/,,,False,http://thumbs.reddit.com/t3_jn81g.png,t5_2r3gv,False,,,False,t3_jn81g,http://www.newscientist.com/article/mg21128266.000,
1313665971.0,28,medicalxpress.com,jmmv8,Computational method predicts new uses for existing medicines,29,1,0,http://www.reddit.com/r/MachineLearning/comments/jmmv8/computational_method_predicts_new_uses_for/,,,False,http://thumbs.reddit.com/t3_jmmv8.png,t5_2r3gv,False,,,False,t3_jmmv8,http://medicalxpress.com/news/2011-08-method-medicines.html,
1311811331.0,30,techtalks.tv,j1nsn,TechTalks.TV : ICML 2011,31,1,0,http://www.reddit.com/r/MachineLearning/comments/j1nsn/techtalkstv_icml_2011/,,,False,http://thumbs.reddit.com/t3_j1nsn.png,t5_2r3gv,False,,,False,t3_j1nsn,http://techtalks.tv/icml/2011/,
1307770234.0,30,self.MachineLearning,hwyus,Learning ML after graduating,33,3,12,http://www.reddit.com/r/MachineLearning/comments/hwyus/learning_ml_after_graduating/,"There might be many like me - I want to pick up machine learning but I finished university 10 years ago. Of course there are great books and video courses online (I watch Stanford Machine Learning CS 229 with Andrew Ng) but being alone in front of this monumental field is difficult.

So I was wondering if there is a way to get personal tutoring. A student could probably do 99% of the work on his own with the videos and books, and ask for external help only for that last 1%. What is needed here is the ""coaching"" / ""question answering"" part more than the actual instruction part.

Do you think this could work? Any idea where to look for help?


Edit: Thank you for the links. Anyone willing to offer me (paid) tutoring over email and skype?",,False,self,t5_2r3gv,True,,,True,t3_hwyus,http://www.reddit.com/r/MachineLearning/comments/hwyus/learning_ml_after_graduating/,
1300476112.0,28,theatlantic.com,g6mu0,"A couple weeks ago, Huffington Post blogger Dan Mervish noted a funny trend: when Anne Hathaway was in the news, Warren Buffett's Berkshire Hathaway's shares went up. ",31,3,6,http://www.reddit.com/r/MachineLearning/comments/g6mu0/a_couple_weeks_ago_huffington_post_blogger_dan/,,,False,default,t5_2r3gv,False,,,False,t3_g6mu0,http://www.theatlantic.com/technology/archive/2011/03/does-anne-hathaway-news-drive-berkshire-hathaways-stock/72661/,
1299524111.0,26,self.MachineLearning,fz6tj,What are the 'hot topics' in MachineLearning right now?,31,5,24,http://www.reddit.com/r/MachineLearning/comments/fz6tj/what_are_the_hot_topics_in_machinelearning_right/,"I'm in my Masters now, and got the opportunity to write an essay/give a presentation about a 'hot topic' in Machine Learning.

I was thinking to give it on ""deep learning"", since that's a term I encountered quite some times recently, but have no idea about. What other new techniques or topics are worth looking into right now?
(Also, if you can point at 1-2 seminal papers about that topic, that'd be very awesome and helpful, as well)",,False,self,t5_2r3gv,False,,,True,t3_fz6tj,http://www.reddit.com/r/MachineLearning/comments/fz6tj/what_are_the_hot_topics_in_machinelearning_right/,
1298323274.0,28,kaggle.com,fpsvw,"Max Lin, of Google, on finishing second in the R package prediction challenge",29,1,0,http://www.reddit.com/r/MachineLearning/comments/fpsvw/max_lin_of_google_on_finishing_second_in_the_r/,,,False,http://thumbs.reddit.com/t3_fpsvw.png,t5_2r3gv,False,,,False,t3_fpsvw,http://www.kaggle.com/blog/2011/02/21/max-lin-on-finishing-second-in-the-r-challenge/,
1292580409.0,28,cs.gmu.edu,enc9t,Essentials of Metaheuristics,28,0,4,http://www.reddit.com/r/MachineLearning/comments/enc9t/essentials_of_metaheuristics/,,,False,http://thumbs.reddit.com/t3_enc9t.png,t5_2r3gv,False,,,False,t3_enc9t,http://www.cs.gmu.edu/~sean/book/metaheuristics/,
1292233388.0,29,kaggle.com,ekxt1,"Melbourne Uni is offering $5,000 for an algorithm to predict the outcome of grant applications",31,2,4,http://www.reddit.com/r/MachineLearning/comments/ekxt1/melbourne_uni_is_offering_5000_for_an_algorithm/,,,False,http://thumbs.reddit.com/t3_ekxt1.png,t5_2r3gv,False,,,False,t3_ekxt1,http://kaggle.com/unimelb,
1280696462.0,28,drewconway.com,cw66d,Benford’s Law Tests for Wikileaks Data,33,5,7,http://www.reddit.com/r/MachineLearning/comments/cw66d/benfords_law_tests_for_wikileaks_data/,,,False,http://thumbs.reddit.com/t3_cw66d.png,t5_2r3gv,False,,,False,t3_cw66d,http://www.drewconway.com/zia/?p=2234&amp;cpage=1#comment-4809,
1270576617.0,29,googleresearch.blogspot.com,bn8j9,Lessons learned developing a practical large scale machine learning system (Google Research),30,1,2,http://www.reddit.com/r/MachineLearning/comments/bn8j9/lessons_learned_developing_a_practical_large/,,,False,default,t5_2r3gv,False,,,False,t3_bn8j9,http://googleresearch.blogspot.com/2010/04/lessons-learned-developing-practical.html,
1268412158.0,28,gromgull.net,bclfh,The Machine Learning Algorithm with Capital A - three approaches that solve all your problems (disclaimer: my own post),32,4,13,http://www.reddit.com/r/MachineLearning/comments/bclfh/the_machine_learning_algorithm_with_capital_a/,,,False,http://thumbs.reddit.com/t3_bclfh.png,t5_2r3gv,False,,,False,t3_bclfh,http://gromgull.net/blog/2010/03/the-machine-learning-algorithm-with-capital-a/,
1263418695.0,27,nyulocal.com,apa1v,Machine Learning researcher Sam Roweis has died,28,1,4,http://www.reddit.com/r/MachineLearning/comments/apa1v/machine_learning_researcher_sam_roweis_has_died/,,,False,http://thumbs.reddit.com/t3_apa1v.png,t5_2r3gv,False,,,False,t3_apa1v,http://nyulocal.com/on-campus/2010/01/13/nyu-computer-science-professor-sam-roweis-jumps-to-death-in-washington-square-village/,
1254748593.0,28,self.MachineLearning,9qysk,"I'm a beginning machine learner. What fun can I 
have with a dataset of 150000+ song lyrics?",30,2,24,http://www.reddit.com/r/MachineLearning/comments/9qysk/im_a_beginning_machine_learner_what_fun_can_i/,"I'm starting a MsC in machine learning this christmas. [This post](http://www.reddit.com/r/compsci/comments/9q28l/simple_simhashing_my_favorite_trick/) described a simple clustering algorithm. It inspired me to implement it, using n-character substrings from the song lyrics as features to learn from. (I now understand that when the post said n-gram, it probably meant n _words_, not characters. Will try this too). 

I figure it would be fun to see if one could make a kind of recommendation engine for artists based on their lyrics alone. What else can I do with this data? Are there any other useful features I can pull out of the data? (If you think I really should be using a better algorithm, I'd like to know also!)

The results I've got so far have been somewhat useful, though my algorithm does for example think The Beatles are similar to N.W.A. ",,False,self,t5_2r3gv,False,,,True,t3_9qysk,http://www.reddit.com/r/MachineLearning/comments/9qysk/im_a_beginning_machine_learner_what_fun_can_i/,
1370118081.0,29,kurzweilai.net,1fhbeo,"New reinforcement algorithm that outperforms predecessors, with toolkit",34,5,2,http://www.reddit.com/r/MachineLearning/comments/1fhbeo/new_reinforcement_algorithm_that_outperforms/,,,False,http://d.thumbs.redditmedia.com/YThijJzGhV4qFy1c.jpg,t5_2r3gv,False,,,False,t3_1fhbeo,http://www.kurzweilai.net/how-computers-can-learn-better,
1369292099.0,28,byronknoll.blogspot.com,1ew2kj,Unlabeled Object Recognition in Google+,38,10,12,http://www.reddit.com/r/MachineLearning/comments/1ew2kj/unlabeled_object_recognition_in_google/,,,False,http://b.thumbs.redditmedia.com/gb9hk0u9RDfTPBPa.jpg,t5_2r3gv,False,,,False,t3_1ew2kj,http://byronknoll.blogspot.com/2013/05/unlabeled-object-recognition-in-google.html,
1367189894.0,27,camdp.com,1dashi,Machine Learning Counterexamples,35,8,8,http://www.reddit.com/r/MachineLearning/comments/1dashi/machine_learning_counterexamples/,,,False,default,t5_2r3gv,False,,,False,t3_1dashi,http://camdp.com/blogs/machine-learning-counter-examples-pt1,
1366205948.0,27,radar.oreilly.com,1cj4ov,TIL there's a probabilistic programming language called Church. Anyone here using it?,43,16,16,http://www.reddit.com/r/MachineLearning/comments/1cj4ov/til_theres_a_probabilistic_programming_language/,,,False,http://c.thumbs.redditmedia.com/OPMXkFI5LngyIsln.jpg,t5_2r3gv,False,,,False,t3_1cj4ov,http://radar.oreilly.com/2013/04/probabilistic-programming.html,
1358856422.0,28,docs.google.com,171utb,"Scikit-Learn user? Please fill in this survey! (also, 0.13 is out!)",35,7,1,http://www.reddit.com/r/MachineLearning/comments/171utb/scikitlearn_user_please_fill_in_this_survey_also/,,,False,default,t5_2r3gv,False,,,False,t3_171utb,https://docs.google.com/spreadsheet/viewform?formkey=dFdyeGNhMzlCRWZUdldpMEZlZ1B1YkE6MQ,
1354213040.0,24,gequest.com,1406i9,GE &amp; Kaggle announce $350k in prizes for two analytics quests: predicting flight delays and improving hospital operations ,38,14,10,http://www.reddit.com/r/MachineLearning/comments/1406i9/ge_kaggle_announce_350k_in_prizes_for_two/,,,False,default,t5_2r3gv,False,,,False,t3_1406i9,http://www.gequest.com/,
1350586497.0,28,mathbabe.org,11pbz4,Data science course notes on lecture by CTO of Hunch.com about recommendation engines and SVD,30,2,0,http://www.reddit.com/r/MachineLearning/comments/11pbz4/data_science_course_notes_on_lecture_by_cto_of/,,,False,http://f.thumbs.redditmedia.com/etPVaCgQBhv8P_WA.jpg,t5_2r3gv,False,,,False,t3_11pbz4,http://mathbabe.org/2012/10/18/columbia-data-science-course-week-7-hunch-com-recommendation-engines-svd-alternating-least-squares-convexity-filter-bubbles/,
1342812101.0,29,self.MachineLearning,wvzxr,From Mr. Deep Learning himself  :),33,4,0,http://www.reddit.com/r/MachineLearning/comments/wvzxr/from_mr_deep_learning_himself/,"https://www.coursera.org/course/neuralnets

Geoffrey Hinton's Neural Net class :)",,False,self,t5_2r3gv,False,,,True,t3_wvzxr,http://www.reddit.com/r/MachineLearning/comments/wvzxr/from_mr_deep_learning_himself/,
1341026037.0,26,github.com,vtt61,"ML evaluation metrics, in Python, R, Haskell, and MATLAB / Octave",31,5,0,http://www.reddit.com/r/MachineLearning/comments/vtt61/ml_evaluation_metrics_in_python_r_haskell_and/,,,False,http://e.thumbs.redditmedia.com/zxhoFLRPWCPcpwfF.jpg,t5_2r3gv,False,,,False,t3_vtt61,https://github.com/benhamner/Metrics,
1325871146.0,27,blog.echen.me,o5mjy,Introduction to Conditional Random Fields,33,6,0,http://www.reddit.com/r/MachineLearning/comments/o5mjy/introduction_to_conditional_random_fields/,,,False,http://d.thumbs.redditmedia.com/to55zxG51HghfXYo.jpg,t5_2r3gv,False,,,False,t3_o5mjy,http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/,
1322935617.0,27,hunch.net,myve3,"16 million features, 16 billion samples",29,2,0,http://www.reddit.com/r/MachineLearning/comments/myve3/16_million_features_16_billion_samples/,,,False,default,t5_2r3gv,False,,,False,t3_myve3,http://hunch.net/?p=2094,
1320256640.0,27,david-hu.com,lxx4k,Machine Learning Techniques in Khan Academy [xpost r/programming],31,4,3,http://www.reddit.com/r/MachineLearning/comments/lxx4k/machine_learning_techniques_in_khan_academy_xpost/,,,False,http://d.thumbs.redditmedia.com/ZqVW1VcFZfPP5FJQ.jpg,t5_2r3gv,False,,,False,t3_lxx4k,http://david-hu.com/2011/11/02/how-khan-academy-is-using-machine-learning-to-assess-student-mastery.html,
1312356779.0,28,valserb.wordpress.com,j7jdt,I tried to explain hidden markov models after learning them recently. Feel free to criticize or comment!,31,3,11,http://www.reddit.com/r/MachineLearning/comments/j7jdt/i_tried_to_explain_hidden_markov_models_after/,,,False,http://thumbs.reddit.com/t3_j7jdt.png,t5_2r3gv,False,,,False,t3_j7jdt,http://valserb.wordpress.com/2011/08/02/understanding-hidden-markov-models/,
1308856501.0,28,guardian.co.uk,i7exy,Data without borders: why I want to change the world,32,4,3,http://www.reddit.com/r/MachineLearning/comments/i7exy/data_without_borders_why_i_want_to_change_the/,,,False,default,t5_2r3gv,False,,,False,t3_i7exy,http://www.guardian.co.uk/news/datablog/2011/jun/23/data-without-borders-jake-porway,
1308356749.0,25,mlss2011.comp.nus.edu.sg,i2kxe,Machine Learning Summer School Slides,29,4,4,http://www.reddit.com/r/MachineLearning/comments/i2kxe/machine_learning_summer_school_slides/,,,False,default,t5_2r3gv,False,,,False,t3_i2kxe,http://mlss2011.comp.nus.edu.sg/index.php?n=Site.Slides,
1308323892.0,29,r-bloggers.com,i26m1,Engineering Data Analysis (with R and ggplot2) - Google Tech Talk,32,3,2,http://www.reddit.com/r/MachineLearning/comments/i26m1/engineering_data_analysis_with_r_and_ggplot2/,,,False,http://thumbs.reddit.com/t3_i26m1.png,t5_2r3gv,False,,,False,t3_i26m1,http://www.r-bloggers.com/engineering-data-analysis-with-r-and-ggplot2-%E2%80%93-a-google-tech-talk-given-by-hadley-wickham/,
1305994734.0,28,self.MachineLearning,hgqdv,I have a short internship doing data mining...and am getting overwhelmed,31,3,10,http://www.reddit.com/r/MachineLearning/comments/hgqdv/i_have_a_short_internship_doing_data_miningand_am/,"I'm a high school senior, and for my senior project I'm spending 3-4 weeks working at a company that does data mining. I've just finished my first week, and have:

* Read a bunch of online material to get an overview of data mining.

* Read several chapters from [*Data Mining* by Witten and Frank](http://www.amazon.com/Data-Mining-Practical-Techniques-Management/dp/0120884070/ref=sr_1_2?s=books&amp;ie=UTF8&amp;qid=1305991819&amp;sr=1-2).

* Played with WEKA, mostly to learn how to use it. (And sworn at the ARFF file format).

* Worked a bit with MS SQL Server and Excel PowerPivot.

* Installed Excel's Data Mining plugin.

There's a *lot* of data for the project, but I myself have downloaded and am working with six databases, each of which has approximately six million rows. It's about some pretty complex engines, and has several years' worth of readings from several dozen sensors. I think it's supposed to be tied to events (engine turns on, turns off, overheats, fails, etc.) but that column is blank.

Recently, I had the following conversation:

&gt;Me: I have all the software installed and more-or-less know how to use it. So...what am I supposed to be *doing*?

&gt;Boss: Oh, just play around with the databases and see what you learn.

&gt;Me: Well, I started doing that, but I feel like I can't really discover anything useful without having the readings tied to events...

&gt;Boss: No, there's a lot you can learn without the events.

&gt;Me: I mean, while learning WEKA I made really trivial observations, like, ""The temperature and pressure have a strong positive correlation"", but--

&gt;Boss: No, that's a good thing to know!

&gt;Me: Oh, well, um, okay.

For reference, here's a simplified version of the data I have:


Timestamp| SensorID  | Value | Unit
----------|----------|---     |
1/1/01 0:01| 1          | 478    | PSI
1/1/01 0:01| 2          | 50 | Ft/sec
1/1/01 0:01| 3          | 0 | 0=off; 1=on
1/1/01 3:23| 1          | 485 | PSI
1/1/01 3:23| 2          | 55 | Ft/sec
1/1/01 3:23| 3          | 1 | 0=off; 1=on


And here are my problems:

* I have a number of issues with actually manipulating the data into a useful form. I can figure it out eventually, it's just not streamlined at all. If you're interested, [here](http://pastebin.com/mj4epk8N)'s a description.

* I feel like I'm obsessing over stuff like my ARFF files just because I'm not actually sure what I'm going to do with them once they've actually been loaded into WEKA. It's also a much easier problem to solve, and tricks me into feeling productive when I do solve it.

* My boss told me to read up on Naive Bayesian classifiers, which I did, so I'm probably the most knowledgeable about how to classify stuff. However, as far as I know, I have no classes in which to put stuff (if I had the EventIDs, I'd imagine it'd be massively useful to be able to classify things into events...) I'm actually a bit unsure about what I *could* do...I guess I could make a model to predict the reading of one sensor based on the readings of the other--but when would that be useful? If you can get all but one reading, odds are you can get the last one too. I guess I could also try to predict stuff based on the previous readings (which would probably be useful, actually)...but without knowing if the engine is on or off or whatever, I'm guessing it wouldn't be as accurate as one would hope.

* Ooh, I guess I could discretize everything, and *then* I could classify stuff, right? Is this a good idea?

So I'm unclear about what my objective is, and I have only a shallow knowledge about how to achieve any objective I might have.

In case it's useful--I *do* know how to program (in Python, Java (I even have a Real Job doing Java development), and Lisp (I won prizes for a pretty cool genetic algorithm that generates AIs for games)), I took AP Statistics (which so far has not been remotely useful, unfortunately). I'm just quite clearly in very new territory (and don't get me wrong--I'm really happy to be learning new things. It's just pretty uncomfortable, too.)

So I'm sorry if this has been kinda long and unfocused. I'm just overwhelmed and am hoping that you guys will have some words of wisdom.

Thanks in advance.


---------------

TL; DR - I have a stack of data that I'm supposed to get information from. The data is readings from sensors on a large engine (and thus has the pressure, temperature, and other parameters from several different locations) taken periodically over the course of several years. There is no *specific* thing I'm trying to find out. I think it'd be useful to be able to take a set of readings and predict the next one, but that's just me--I could be wrong. Rather than blindly running promising-looking algorithms and seeing what happens, I'd like suggestions on what I should be looking for. I'd rather have an objective and then select a method based on it than do it the other way around.",,False,self,t5_2r3gv,True,,,True,t3_hgqdv,http://www.reddit.com/r/MachineLearning/comments/hgqdv/i_have_a_short_internship_doing_data_miningand_am/,
1300963989.0,25,self.MachineLearning,gaef5,So there was a link to JMLR posted yesterday...,32,7,31,http://www.reddit.com/r/MachineLearning/comments/gaef5/so_there_was_a_link_to_jmlr_posted_yesterday/,"Although I thought people would dismiss that submission as trivial since everyone already knows about it, I was surprised that some people said they never heard of it.  This is why I'm posting some ML conferences here in case some of you may not know about them.  This list is by no means complete, it's just my personal pick of the ""good"" conferences to follow if you're interested in ML.  So, here goes (I'm too lazy to actually put links):

* ICML
* NIPS
* UAI
* AISTATS
* COLT
* ACL, NAACL, EMNLP (they have pretty strong machine learning tracks)

Other, less ML related, but still possibly interesting conferences (by possibly interesting I mean that they get the odd ML paper that can be very interesting):

* KDD
* ICDM
* SIGIR
* VLDB
* COGSCI",,False,self,t5_2r3gv,False,,,True,t3_gaef5,http://www.reddit.com/r/MachineLearning/comments/gaef5/so_there_was_a_link_to_jmlr_posted_yesterday/,
1300888122.0,25,r-bloggers.com,g9p55,Screencast: How to successfully compete in data mining competitions (with R and Random forests),28,3,2,http://www.reddit.com/r/MachineLearning/comments/g9p55/screencast_how_to_successfully_compete_in_data/,,,False,default,t5_2r3gv,False,,,False,t3_g9p55,http://www.r-bloggers.com/getting-into-shape-for-the-sport-of-data-science-screencast-of-talk-by-jeremy-howard-at-melbourne-r-users,
1298770349.0,26,foundry.sandia.gov,ftgkt,"Sandia National Laboratory's open source machine learning library ""Cognitive Foundry""",28,2,1,http://www.reddit.com/r/MachineLearning/comments/ftgkt/sandia_national_laboratorys_open_source_machine/,,,False,default,t5_2r3gv,False,,,False,t3_ftgkt,http://foundry.sandia.gov/,
1296492938.0,27,gp-field-guide.org.uk,fcgs2,"Free E-Book: A Field Guide to Genetic Programming (by Riccardo Poli, William B. Langdon, Nicholas F. McPhee - 2008)",31,4,6,http://www.reddit.com/r/MachineLearning/comments/fcgs2/free_ebook_a_field_guide_to_genetic_programming/,,,False,http://thumbs.reddit.com/t3_fcgs2.png,t5_2r3gv,False,,,False,t3_fcgs2,http://www.gp-field-guide.org.uk/,
1292832135.0,26,ai.stackexchange.com,eoo2a,Tell /r/machinelearning:  The Artificial Intelligence community on StackExchange is now in public beta.,28,2,17,http://www.reddit.com/r/MachineLearning/comments/eoo2a/tell_rmachinelearning_the_artificial_intelligence/,,,False,default,t5_2r3gv,False,,,False,t3_eoo2a,http://ai.stackexchange.com/,
1291737045.0,27,statistik.mathematik.uni-wuerzburg.de,ehpah,A First Course on Time Series Analysis,29,2,0,http://www.reddit.com/r/MachineLearning/comments/ehpah/a_first_course_on_time_series_analysis/,,,False,default,t5_2r3gv,False,,,False,t3_ehpah,http://statistik.mathematik.uni-wuerzburg.de/timeseries/index.php?id=preamble,
1291563624.0,27,r-bloggers.com,egkgt,Genetic optimization for Trading Strategies using Rapidminer and R,31,4,4,http://www.reddit.com/r/MachineLearning/comments/egkgt/genetic_optimization_for_trading_strategies_using/,,,False,http://thumbs.reddit.com/t3_egkgt.png,t5_2r3gv,False,,,False,t3_egkgt,http://www.r-bloggers.com/genetic-optimization-for-trading-strategies-using-rapidminer-and-r,
1290548860.0,27,self.MachineLearning,ear4u,We are crowdsourcing researchers; we use amazon's mechanical turk to get people to do jobs computers cannot do. Please ask us about how machine learning can be combined with human computation. ,32,5,30,http://www.reddit.com/r/MachineLearning/comments/ear4u/we_are_crowdsourcing_researchers_we_use_amazons/,,,False,self,t5_2r3gv,False,,,True,t3_ear4u,http://www.reddit.com/r/MachineLearning/comments/ear4u/we_are_crowdsourcing_researchers_we_use_amazons/,moderator
1289509869.0,26,self.MachineLearning,e4sa5,What XOR looks like to a trained artificial neural network (repost from r/PICS),33,7,29,http://www.reddit.com/r/MachineLearning/comments/e4sa5/what_xor_looks_like_to_a_trained_artificial/,"[un-trained](http://imgur.com/Q6J7D.png) (weight matrix initialized to random numbers in [-1,1])

[trained](http://imgur.com/prYlg.png) (learning rate = 0.75, one iteration is one pass through the training data; in this case four input-output pairs)

**Context:** I just finished writing a pretty simple machine learning library targeted at recognizing features in images (right now the only learning algorithm in the lib is an ANN). As far as I know, the 'hello world' of multi-layer ANNs is learning XOR, since the problem of mapping the inputs to the outputs is not linearly separable for that data set.

To accomplish this, I set up a 3-layer ANN with 2 inputs, 3 hidden nodes, and 1 output (all non-output layers have bias nodes added automatically). Activation was accomplished using the generic sigmoid function. It took much less than a tenth of a second for the ANN to learn the data.

I was suddenly intrigued by what the output of the neural net would look like over its full trained domain, so dumped the numbers and generated the graph using **QtiPlot** (probably the best open-source data analysis &amp; plotting software I've ever seen). Result = fucking awesome and elegant, so I thought I'd share.

Edit: Note: the first graph is labeled incorrectly.",,False,self,t5_2r3gv,False,,,True,t3_e4sa5,http://www.reddit.com/r/MachineLearning/comments/e4sa5/what_xor_looks_like_to_a_trained_artificial/,
1287956570.0,27,web4.cs.ucl.ac.uk,dvs62,Really digging this book I stumbled upon by chance. [PDF],29,2,9,http://www.reddit.com/r/MachineLearning/comments/dvs62/really_digging_this_book_i_stumbled_upon_by/,,,False,default,t5_2r3gv,False,,,False,t3_dvs62,http://web4.cs.ucl.ac.uk/staff/D.Barber/courses/mlgm_epfl_book.pdf,
1286549971.0,28,videolectures.net,dokyb,Christopher Bishop's really good Introduction to Machine Learning and Bayesian Inference. [Video lecture],30,2,3,http://www.reddit.com/r/MachineLearning/comments/dokyb/christopher_bishops_really_good_introduction_to/,,,False,default,t5_2r3gv,False,,,False,t3_dokyb,http://videolectures.net/mlss09uk_bishop_ibi/,
1279219603.0,27,ocw.mit.edu,cpzqn,Lecture Notes from MIT's Machine Learning Course,29,2,0,http://www.reddit.com/r/MachineLearning/comments/cpzqn/lecture_notes_from_mits_machine_learning_course/,,,False,default,t5_2r3gv,False,,,False,t3_cpzqn,http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-867-machine-learning-fall-2006/lecture-notes/,
1273566106.0,29,kaggle.com,c2hpj,A new series about companies that rely on machine learning techniques,34,5,4,http://www.reddit.com/r/MachineLearning/comments/c2hpj/a_new_series_about_companies_that_rely_on_machine/,,,False,http://thumbs.reddit.com/t3_c2hpj.png,t5_2r3gv,False,,,False,t3_c2hpj,http://kaggle.com/blog/2010/05/11/data-inc-profiling-data-driven-companies/,
1264517768.0,27,puremango.co.uk,auchj,"Hey MLdit, I wrote a k-means clustering tutorial. Would appreciate feedback.",29,2,23,http://www.reddit.com/r/MachineLearning/comments/auchj/hey_mldit_i_wrote_a_kmeans_clustering_tutorial/,,,False,http://thumbs.reddit.com/t3_auchj.png,t5_2r3gv,False,,,False,t3_auchj,http://www.puremango.co.uk/2010/01/k-means-clustering-machine-learning/,
1264090445.0,27,self.MachineLearning,asfsh,"AskML: Best/fastest way to learn R (with ML/AI/Data Mining orientation) - book, course, anything? - thanks!",28,1,6,http://www.reddit.com/r/MachineLearning/comments/asfsh/askml_bestfastest_way_to_learn_r_with_mlaidata/,,,False,self,t5_2r3gv,False,,,True,t3_asfsh,http://www.reddit.com/r/MachineLearning/comments/asfsh/askml_bestfastest_way_to_learn_r_with_mlaidata/,
1374598764.0,24,self.MachineLearning,1iw7ab,"With so many off-the-shelf libraries and packages already implemented of ML algos, where does expertise come in?",27,3,19,http://www.reddit.com/r/MachineLearning/comments/1iw7ab/with_so_many_offtheshelf_libraries_and_packages/,"Besides knowing what, when, and where to apply technique X to your task

**edit:** thanks everyone. soopa helpful
",,False,self,t5_2r3gv,1374617971.0,,,True,t3_1iw7ab,http://www.reddit.com/r/MachineLearning/comments/1iw7ab/with_so_many_offtheshelf_libraries_and_packages/,
1371739164.0,26,blog.yhathq.com,1gq94z,Beer Recommender in R http://blog.yhathq.com/posts/recommender-system-in-r.html,33,7,5,http://www.reddit.com/r/MachineLearning/comments/1gq94z/beer_recommender_in_r/,,,False,default,t5_2r3gv,False,,,False,t3_1gq94z,http://blog.yhathq.com/posts/recommender-system-in-r.html,
1370439032.0,26,uni-goettingen.de,1fpwun,"Machine Learning for Computer Security: slides, videos and more!",34,8,8,http://www.reddit.com/r/MachineLearning/comments/1fpwun/machine_learning_for_computer_security_slides/,,,False,http://d.thumbs.redditmedia.com/JYgz8ZHl31KGAXp9.jpg,t5_2r3gv,False,,,False,t3_1fpwun,http://www.uni-goettingen.de/de/420811.html,
1368991807.0,26,code.google.com,1ena83,I made a classification program based on data compression,32,6,12,http://www.reddit.com/r/MachineLearning/comments/1ena83/i_made_a_classification_program_based_on_data/,,,False,default,t5_2r3gv,False,,,False,t3_1ena83,https://code.google.com/p/paqclass/,
1363308877.0,27,tastegenius.com,1abl2j,Just made a food recommendation website that uses machine learning,51,24,21,http://www.reddit.com/r/MachineLearning/comments/1abl2j/just_made_a_food_recommendation_website_that_uses/,,,False,http://d.thumbs.redditmedia.com/Shu57lGD1CCvCL9K.jpg,t5_2r3gv,False,,,False,t3_1abl2j,http://www.tastegenius.com/index.php,
1352484509.0,26,self.MachineLearning,12x96h,State of Machine Learning in the United States?  Are there industry employed ML practitioners in here or just enthusiasts and students? ,35,9,19,http://www.reddit.com/r/MachineLearning/comments/12x96h/state_of_machine_learning_in_the_united_states/,"I'm about to graduate with a PhD in machine learning in the US, and something's been bothering me and raising my curiosity.  I am subscribed to a bunch of the ML mailing lists, and these lists are where a large number of openings in the ML-related fields (both academic and commercial) are advertised.

Almost 95% of all the openings advertised are based in Europe, Canada, or China.  Other than the classic tech giants (Google, etc.) and Silicon Valley startups, what is the state of non-academic ML in the US?  I know that many firms, contractors, etc., are looking into applied ML to further their projects, but I don't see nearly the same amount of ""generalized"" applied research activity in the US as I do in other countries.

Is there the same level of activity here, just not as widely discussed?  Are any subscribers here actual commercial practitioners of ML techniques?",,False,self,t5_2r3gv,False,,,True,t3_12x96h,http://www.reddit.com/r/MachineLearning/comments/12x96h/state_of_machine_learning_in_the_united_states/,
1350308363.0,26,self.MachineLearning,11idgy,What data-mining/machine-learning software should I invest in learning?,29,3,45,http://www.reddit.com/r/MachineLearning/comments/11idgy/what_dataminingmachinelearning_software_should_i/,"At my job, I have years of customer, sales, and demographic data. I'd like to explore options for mining and visualizing this data. Who buys X product but not Y product? Are our products in discrete groups that tend to be purchased together but with little overlap? Does AB marketing message work in one county, while XY marketing message works better in another?

I want to become an expert in answering these kinds of questions. What software should I use for this? What software does, say, Nate Silver use for his computations? I'm willing to invest time and money to learn, but I don't know where to start.",,False,self,t5_2r3gv,1350327499.0,,,True,t3_11idgy,http://www.reddit.com/r/MachineLearning/comments/11idgy/what_dataminingmachinelearning_software_should_i/,
1345523540.0,24,scott.fortmann-roe.com,ykchf,Understanding the Bias-Variance Tradeoff: Nice Illustrations/description of bread and butter ML concept,29,5,4,http://www.reddit.com/r/MachineLearning/comments/ykchf/understanding_the_biasvariance_tradeoff_nice/,,,False,http://f.thumbs.redditmedia.com/G7b5W_aFGXUdJZ0k.jpg,t5_2r3gv,False,,,False,t3_ykchf,http://scott.fortmann-roe.com/docs/BiasVariance.html,
1344464087.0,27,self.MachineLearning,xwmdg,Any suggestions of recent (say at most ~5 years old) of ML papers that are (or you think should be) highly influential?,29,2,20,http://www.reddit.com/r/MachineLearning/comments/xwmdg/any_suggestions_of_recent_say_at_most_5_years_old/,"I'm feeling a bit like I've just been reading papers from my narrow interests and that of those around me but I'm looking to branch out.

It'd be awesome too if you'd say a bit about why you think the paper is/should be highly influential.",,False,self,t5_2r3gv,False,,,True,t3_xwmdg,http://www.reddit.com/r/MachineLearning/comments/xwmdg/any_suggestions_of_recent_say_at_most_5_years_old/,
1340365351.0,28,normaldeviate.wordpress.com,vfjub,What is the biggest open problem in statistics or machine learning?,33,5,17,http://www.reddit.com/r/MachineLearning/comments/vfjub/what_is_the_biggest_open_problem_in_statistics_or/,,,False,http://d.thumbs.redditmedia.com/N_XlesLJr_RMRIy3.jpg,t5_2r3gv,False,,,False,t3_vfjub,http://normaldeviate.wordpress.com/2012/06/21/90/,
1329687695.0,25,videolectures.net,pwve7,"Machine Learning and the Brain - The Neuroscience of Reinforcement Learning, a video lecture.",27,2,6,http://www.reddit.com/r/MachineLearning/comments/pwve7/machine_learning_and_the_brain_the_neuroscience/,,,False,default,t5_2r3gv,False,,,False,t3_pwve7,http://videolectures.net/icml09_niv_tnorl/,
1329251221.0,25,blog.stephenwolfram.com,ppkxg,Wolfram Blog: Launching a Democratization of Data Science,32,7,4,http://www.reddit.com/r/MachineLearning/comments/ppkxg/wolfram_blog_launching_a_democratization_of_data/,,,False,http://d.thumbs.redditmedia.com/5YaoU89MlfgHC2Ci.jpg,t5_2r3gv,False,,,False,t3_ppkxg,http://blog.stephenwolfram.com/2012/02/launching-a-democratization-of-data-science/,
1327061597.0,29,newscientist.com,oor1a,Neural network gets an idea of number without counting,35,6,16,http://www.reddit.com/r/MachineLearning/comments/oor1a/neural_network_gets_an_idea_of_number_without/,,,False,http://e.thumbs.redditmedia.com/uSPClo3cPY0DGKAp.jpg,t5_2r3gv,False,,,False,t3_oor1a,http://www.newscientist.com/mobile/article/mg21328484.200-neural-network-gets-an-idea-of-number-without-counting.html,
1319288814.0,27,blog.badlogic.se,lkysf,Feature learning (a summary of recent developments),31,4,23,http://www.reddit.com/r/MachineLearning/comments/lkysf/feature_learning_a_summary_of_recent_developments/,,,False,default,t5_2r3gv,False,,,False,t3_lkysf,http://blog.badlogic.se/?p=41,
1314058111.0,26,hunch.net,jr4pw,"Scaling Up Machine Learning, the Tutorial, KDD 2011",31,5,3,http://www.reddit.com/r/MachineLearning/comments/jr4pw/scaling_up_machine_learning_the_tutorial_kdd_2011/,,,False,default,t5_2r3gv,False,,,False,t3_jr4pw,http://hunch.net/~large_scale_survey/,
1313673312.0,25,nytimes.com,jmpcu,Sending the Police Before There’s a Crime,28,3,11,http://www.reddit.com/r/MachineLearning/comments/jmpcu/sending_the_police_before_theres_a_crime/,,,False,default,t5_2r3gv,False,,,False,t3_jmpcu,http://www.nytimes.com/2011/08/16/us/16police.html?_r=2,
1312760875.0,26,sfbay.craigslist.org,jbwba,Andrew Ng is looking for non programmers for an experimental course.,35,9,5,http://www.reddit.com/r/MachineLearning/comments/jbwba/andrew_ng_is_looking_for_non_programmers_for_an/,,,False,default,t5_2r3gv,False,,,False,t3_jbwba,http://sfbay.craigslist.org/pen/vol/2534889631.html,
1309587563.0,26,r-bloggers.com,ietyz,Predict future edit rates in Wikipedia - a new Kaggle competition for $5K,30,4,0,http://www.reddit.com/r/MachineLearning/comments/ietyz/predict_future_edit_rates_in_wikipedia_a_new/,,,False,default,t5_2r3gv,False,,,False,t3_ietyz,http://www.r-bloggers.com/wikipedia-for-kaggle-participants/,
1308579839.0,26,r-bloggers.com,i4c34,Calling R lovers to work together on “The R Programming wikibook”,28,2,9,http://www.reddit.com/r/MachineLearning/comments/i4c34/calling_r_lovers_to_work_together_on_the_r/,,,False,http://thumbs.reddit.com/t3_i4c34.png,t5_2r3gv,False,,,False,t3_i4c34,http://www.r-bloggers.com/calling-r-lovers-and-bloggers-%e2%80%93-to-work-together-on-%e2%80%9cthe-r-programming-wikibook%e2%80%9d/,
1307926971.0,25,ece.ucsb.edu,hy4ha,tutorial on hidden markov models and selected applications in speech recognition [PDF],29,4,12,http://www.reddit.com/r/MachineLearning/comments/hy4ha/tutorial_on_hidden_markov_models_and_selected/,,,False,default,t5_2r3gv,False,,,False,t3_hy4ha,http://www.ece.ucsb.edu/Faculty/Rabiner/ece259/Reprints/tutorial%20on%20hmm%20and%20applications.pdf,
1305388881.0,27,self.MachineLearning,hbaf9,machine learning for beginners ,32,5,21,http://www.reddit.com/r/MachineLearning/comments/hbaf9/machine_learning_for_beginners/,"I am more of a graphics guy , but recently I am picking up machine learning and I want to do it right.I will be dealing with tons of medical image data.
my  questions are as follows 
if i am doing machine learning in large scale what options for programming do i have?
i talked to a few people and got the following options 
1&gt;R 2&gt;matlab 3&gt;python
O kings of ML
what do you think is the way forward?",,False,self,t5_2r3gv,False,,,True,t3_hbaf9,http://www.reddit.com/r/MachineLearning/comments/hbaf9/machine_learning_for_beginners/,
1303717946.0,25,mlpy.fbk.eu,gwuuw,Machine Learning PYthon (mlpy) - A high-performance Python library for predictive modeling,28,3,9,http://www.reddit.com/r/MachineLearning/comments/gwuuw/machine_learning_python_mlpy_a_highperformance/,,,False,default,t5_2r3gv,False,,,False,t3_gwuuw,https://mlpy.fbk.eu/,
1303083828.0,26,self.MachineLearning,gsclp,"After leaving my laptop on overnight yet again to train several models, I got to thinking: is it possible to rent a powerful remote desktop computer, hosted on a server elsewhere?",37,11,14,http://www.reddit.com/r/MachineLearning/comments/gsclp/after_leaving_my_laptop_on_overnight_yet_again_to/,"This would be similar to the Amazon Cloud, but for personal use.  I tried renting server time at Amazon Web Services, but they seem to be focused entirely on web hosting, etc. I'm just looking to have a fully functional version of Windows/Linux hosted on a powerful server. I log into it and it behaves like a normal interactive desktop interface (with a bit of lag of course, since it's being processed elsewhere). But the upside is that it's so much more powerful since it's hosted on a very fast server elsewhere.

This would make my work so much easier... Does this exist anywhere? And my school does give me access to some very mediocre Linux servers, but I can only ssh in through putty and then I have to deal with a command line interface. I would really like to find a fully functional version of Windows/Linux that I can log into remotely.



EDIT:
thanks DimeShake! Looks like this is exactly what I was looking for:

http://blog.restbackup.com/how-to-use-amazon-ec2-as-your-desktop

I'll try it out when I have some time soon",,False,self,t5_2r3gv,True,,,True,t3_gsclp,http://www.reddit.com/r/MachineLearning/comments/gsclp/after_leaving_my_laptop_on_overnight_yet_again_to/,
1302765276.0,26,code.google.com,gpqob,"sofia-ml: Suite of Fast Incremental Algorithms for Machine Learning (incl. methods for learning classification and ranking models, using Pegasos SVM, SGD-SVM, ROMMA, Passive-Aggressive Perceptron, Perceptron with Margins, and Logistic Regression)",27,1,4,http://www.reddit.com/r/MachineLearning/comments/gpqob/sofiaml_suite_of_fast_incremental_algorithms_for/,,,False,default,t5_2r3gv,False,,,False,t3_gpqob,http://code.google.com/p/sofia-ml/,
1288585410.0,26,win-vector.com,dzcde,A Personal Perspective on Machine Learning,29,3,15,http://www.reddit.com/r/MachineLearning/comments/dzcde/a_personal_perspective_on_machine_learning/,,,False,http://thumbs.reddit.com/t3_dzcde.png,t5_2r3gv,False,,,False,t3_dzcde,http://www.win-vector.com/blog/2010/10/a-personal-perspective-on-machine-learning/,
1284386517.0,27,ai-contest.com,dd78k,Google AI Challenge has begun! (cross-post from just about everywhere - finally in it's rightful subreddit),28,1,4,http://www.reddit.com/r/MachineLearning/comments/dd78k/google_ai_challenge_has_begun_crosspost_from_just/,,,False,http://thumbs.reddit.com/t3_dd78k.png,t5_2r3gv,False,,,False,t3_dd78k,http://ai-contest.com/,
1282512899.0,26,quora.com,d46f8,Best data blogs,30,4,0,http://www.reddit.com/r/MachineLearning/comments/d46f8/best_data_blogs/,,,False,default,t5_2r3gv,False,,,False,t3_d46f8,http://www.quora.com/What-are-the-best-blogs-about-data/answer/Peter-Skomoroch,
1279327206.0,26,youtube.com,cqhvh,How the kernel trick allows SVMs to separate non-linearly separable classes.,28,2,5,http://www.reddit.com/r/MachineLearning/comments/cqhvh/how_the_kernel_trick_allows_svms_to_separate/,,,False,http://thumbs.reddit.com/t3_cqhvh.png,t5_2r3gv,False,,,False,t3_cqhvh,http://www.youtube.com/watch?v=3liCbRZPrZA,
1277053171.0,26,cs.berkeley.edu,ch1rp,"Practical Machine Learning course at Berkeley. Mike Jordan ""presents a broad overview of modern statistical machine learning from a practitioner's perspective""",29,3,4,http://www.reddit.com/r/MachineLearning/comments/ch1rp/practical_machine_learning_course_at_berkeley/,,,False,default,t5_2r3gv,False,,,False,t3_ch1rp,http://www.cs.berkeley.edu/~jordan/courses/294-fall09/,
1252588750.0,25,lingpipe-blog.com,9j68c,What is Bayesian statistical inference?,26,1,4,http://www.reddit.com/r/MachineLearning/comments/9j68c/what_is_bayesian_statistical_inference/,,,False,default,t5_2r3gv,False,,,False,t3_9j68c,http://lingpipe-blog.com/2009/09/09/what-is-bayesian-statistical-inference/,
1248960272.0,25,jmlr.csail.mit.edu,95zac,"JMLR provides ""high-quality scholarly 
articles in all areas of machine 
learning"" freely online.",30,5,0,http://www.reddit.com/r/MachineLearning/comments/95zac/jmlr_provides_highquality_scholarly_articles_in/,,,False,default,t5_2r3gv,False,,,False,t3_95zac,http://jmlr.csail.mit.edu/papers/,
1376593321.0,25,self.MachineLearning,1kfpsk,The MultiSkill Tennis Model: Estimating player skills on serve and return with dynamic Bayesian networks,27,2,6,http://www.reddit.com/r/MachineLearning/comments/1kfpsk/the_multiskill_tennis_model_estimating_player/,"To be presented at the Machine Learning Summer School in Tübingen (Germany), August 2013.

[The MultiSkill Tennis Model: Estimating player skills on serve and return with dynamic Bayesian networks](https://github.com/danielkorzekwa/tennis-player-compare/blob/master/doc/mlss2013/tennis_skills_poster.pdf?raw=true)",,False,self,t5_2r3gv,False,,,True,t3_1kfpsk,http://www.reddit.com/r/MachineLearning/comments/1kfpsk/the_multiskill_tennis_model_estimating_player/,
1376322961.0,26,videolectures.net,1k7o48,Learning Representations: Yann LeCun's Challenge to the Learning Theory community,28,2,1,http://www.reddit.com/r/MachineLearning/comments/1k7o48/learning_representations_yann_lecuns_challenge_to/,,,False,default,t5_2r3gv,False,,,False,t3_1k7o48,http://videolectures.net/colt2013_lecun_theory/,
1375809334.0,25,nhlnumbers.com,1jtmeo,Theoretical Limits in Machine Learning for the NHL,30,5,2,http://www.reddit.com/r/MachineLearning/comments/1jtmeo/theoretical_limits_in_machine_learning_for_the_nhl/,,,False,http://e.thumbs.redditmedia.com/b6glfFyyb83psZYX.jpg,t5_2r3gv,False,,,False,t3_1jtmeo,http://nhlnumbers.com/2013/8/6/theoretical-predictions-in-machine-learning-for-the-nhl-part-ii,
1371852075.0,26,dlib.net,1gtlps,dlib C++ Library v18.3 released. Now includes a Machine Learning algorithm selection flow chart and python interface,27,1,9,http://www.reddit.com/r/MachineLearning/comments/1gtlps/dlib_c_library_v183_released_now_includes_a/,,,False,http://a.thumbs.redditmedia.com/M9zcuQQiNaFknKyr.jpg,t5_2r3gv,False,,,False,t3_1gtlps,http://dlib.net/ml.html,
1365287416.0,27,camdp.com,1btja6,21st Century Problems: Multi-Armed Bandits,33,6,3,http://www.reddit.com/r/MachineLearning/comments/1btja6/21st_century_problems_multiarmed_bandits/,,,False,default,t5_2r3gv,False,,,False,t3_1btja6,http://camdp.com/blogs/multi-armed-bandits,
1357404639.0,24,en.wikibooks.org,160gpm,Ad Hoc Data Analysis From The Unix Command Line,30,6,6,http://www.reddit.com/r/MachineLearning/comments/160gpm/ad_hoc_data_analysis_from_the_unix_command_line/,,,False,default,t5_2r3gv,False,,,False,t3_160gpm,http://en.wikibooks.org/wiki/Ad_Hoc_Data_Analysis_From_The_Unix_Command_Line,
1349548888.0,23,self.MachineLearning,111vlv,Long-time programmer: Where to begin?,27,4,27,http://www.reddit.com/r/MachineLearning/comments/111vlv/longtime_programmer_where_to_begin/,"Preface: my apologies if this has already been asked on here (I searched for similar posts and couldn't find anything really tackling it).

I've been programming for a number of years and feel fairly confident in my understanding of essential comp sci, as well as being able to understand and implement various algorithms. I've had a passing interest in machine learning for quite some time but I can't seem to find a good place to start. I was looking through some of the stuff at *Quora* but nothing there feels like ""do this and you'll start to understand machine learning or at least know where to go.""

So what I'm looking for is:

* What books/websites/resources would you suggest for getting started?
* I've seen R being talked about a lot, should I learn to use it?
* I'm currently taking Calculus in college, should I learn any higher level math before continuing?",,False,self,t5_2r3gv,False,,,True,t3_111vlv,http://www.reddit.com/r/MachineLearning/comments/111vlv/longtime_programmer_where_to_begin/,
1347443887.0,26,self.MachineLearning,zrc82,[Please Don't Bite] I would like to know where to learn the basics,34,8,27,http://www.reddit.com/r/MachineLearning/comments/zrc82/please_dont_bite_i_would_like_to_know_where_to/,"Hi,

I'm a programmer for some time now, working in web and video games.
I have been fascinated by the things we can do with machine learning for a while and would like to know ""how to get my feet in"".

Is there any resources for noobs or whatever you could share ?

Thanks :)",,False,self,t5_2r3gv,False,,,True,t3_zrc82,http://www.reddit.com/r/MachineLearning/comments/zrc82/please_dont_bite_i_would_like_to_know_where_to/,
1343148207.0,25,self.MachineLearning,x2w0q,Convex Optimization - From Real-Time Embedded to Large-Scale Distributed - Stephen Boyd,27,2,5,http://www.reddit.com/r/MachineLearning/comments/x2w0q/convex_optimization_from_realtime_embedded_to/,"For people interested, this is an expanded version of the talk Stephen Boyd gave in KDD 2011

[Convex Optimization Lecture](http://www.multimedia.ethz.ch/speakers/ifa/boyd/?doi=10.3930/ETHZ/AV-1c085a1e-0b6e-4512-98ea-198db9f7b81e&amp;autostart=true)

He shows how convex optimization is related to machine learning, specifically Support Vector Machines.

Sorry I marked it nsfw, it was a mistake.
",,False,self,t5_2r3gv,1343150227.0,,,True,t3_x2w0q,http://www.reddit.com/r/MachineLearning/comments/x2w0q/convex_optimization_from_realtime_embedded_to/,
1342048515.0,25,youtube.com,wetra,Autonomous Race Car - I've been waiting for this!,31,6,6,http://www.reddit.com/r/MachineLearning/comments/wetra/autonomous_race_car_ive_been_waiting_for_this/,,,False,http://a.thumbs.redditmedia.com/s9_S8maVAmeyoT1l.jpg,t5_2r3gv,False,,,False,t3_wetra,http://www.youtube.com/watch?v=q1sk47FLAmg,
1335765882.0,27,online.wsj.com,szdlx,Talent crunch for machine learning and statistics skills,32,5,11,http://www.reddit.com/r/MachineLearning/comments/szdlx/talent_crunch_for_machine_learning_and_statistics/,,,False,http://a.thumbs.redditmedia.com/TW-mPg0ZUm5vhPA0.jpg,t5_2r3gv,False,,,False,t3_szdlx,http://online.wsj.com/article/SB10001424052702304723304577365700368073674.html,
1333116114.0,25,reddit.com,rkwvq,What is Support Vector Machine? : xpost from explainlikeimfive,30,5,7,http://www.reddit.com/r/MachineLearning/comments/rkwvq/what_is_support_vector_machine_xpost_from/,,,False,default,t5_2r3gv,False,,,False,t3_rkwvq,http://www.reddit.com/r/explainlikeimfive/comments/rkmjp/what_is_support_vector_machine/,
1316120421.0,25,economist.com,kgx1r,Game theory and predicting behavior,28,3,2,http://www.reddit.com/r/MachineLearning/comments/kgx1r/game_theory_and_predicting_behavior/,,,False,http://thumbs.reddit.com/t3_kgx1r.png,t5_2r3gv,False,,,False,t3_kgx1r,http://www.economist.com/node/21527025,
1312149825.0,27,people.few.eur.nl,j549q,"""How I won the Deloitte/FIDE Chess Rating Challenge""",28,1,2,http://www.reddit.com/r/MachineLearning/comments/j549q/how_i_won_the_deloittefide_chess_rating_challenge/,,,False,default,t5_2r3gv,False,,,False,t3_j549q,http://people.few.eur.nl/salimans/chess.html,
1302988295.0,26,businessweek.com,gro5b,Is social network analysis useless?,30,4,9,http://www.reddit.com/r/MachineLearning/comments/gro5b/is_social_network_analysis_useless/,,,False,default,t5_2r3gv,False,,,False,t3_gro5b,http://www.businessweek.com/magazine/content/11_17/b4225060960537.htm,
1296273583.0,25,heritagehealthprize.com,fb5oy,$3 million machine learning prize : develop a predictive algorithm which identifies patients who will be admitted to the hospital within six months,37,12,21,http://www.reddit.com/r/MachineLearning/comments/fb5oy/3_million_machine_learning_prize_develop_a/,,,False,http://thumbs.reddit.com/t3_fb5oy.png,t5_2r3gv,False,,,False,t3_fb5oy,http://www.heritagehealthprize.com/competition.php,
1295959179.0,25,ai.stanford.edu,f8o7r,The Quest for Artificial Intelligence ,26,1,4,http://www.reddit.com/r/MachineLearning/comments/f8o7r/the_quest_for_artificial_intelligence/,,,False,http://thumbs.reddit.com/t3_f8o7r.png,t5_2r3gv,False,,,False,t3_f8o7r,http://ai.stanford.edu/~nilsson/QAI/qai-webpage.html,
1294247481.0,25,i.imgur.com,ewopu,crossposted from r/funny [image],33,8,2,http://www.reddit.com/r/MachineLearning/comments/ewopu/crossposted_from_rfunny_image/,,,False,http://thumbs.reddit.com/t3_ewopu.png,t5_2r3gv,False,,,False,t3_ewopu,http://i.imgur.com/apAsm.png,
1276722737.0,25,nytimes.com,cfrhd,"IBM's new ""question-answering machine"" Watson",27,2,4,http://www.reddit.com/r/MachineLearning/comments/cfrhd/ibms_new_questionanswering_machine_watson/,,,False,http://thumbs.reddit.com/t3_cfrhd.png,t5_2r3gv,False,,,False,t3_cfrhd,http://www.nytimes.com/2010/06/20/magazine/20Computer-t.html?pagewanted=print,
1376243446.0,22,pystruct.github.io,1k5jtf,PyStruct 0.1 released! Structured prediction and learning in Python.,28,6,6,http://www.reddit.com/r/MachineLearning/comments/1k5jtf/pystruct_01_released_structured_prediction_and/,,,False,default,t5_2r3gv,False,,,False,t3_1k5jtf,http://pystruct.github.io,
1376173205.0,26,cs.uoi.gr,1k41k1,The Variational Approximation for Bayesian Inference: Life after the EM algorithm,28,2,2,http://www.reddit.com/r/MachineLearning/comments/1k41k1/the_variational_approximation_for_bayesian/,,,False,default,t5_2r3gv,False,,,False,t3_1k41k1,http://www.cs.uoi.gr/~arly/papers/SPM08.pdf,
1375397033.0,26,en.wikipedia.org,1jiz0j,Improve your Machine Learning with this one weird trick.,51,25,12,http://www.reddit.com/r/MachineLearning/comments/1jiz0j/improve_your_machine_learning_with_this_one_weird/,,,False,default,t5_2r3gv,False,,,False,t3_1jiz0j,http://en.wikipedia.org/wiki/Kernel_trick,
1372330978.0,24,egtheory.wordpress.com,1h66xr,Algorithmic philosophy: scientific inquiry as machine learning.,31,7,3,http://www.reddit.com/r/MachineLearning/comments/1h66xr/algorithmic_philosophy_scientific_inquiry_as/,,,False,http://a.thumbs.redditmedia.com/LpGwzf5ljQNHGr3Z.jpg,t5_2r3gv,False,,,False,t3_1h66xr,http://egtheory.wordpress.com/2013/06/26/algorithmic-philosophy/,
1371258396.0,24,quora.com,1gdis4,Bengio on the difficulties that one faces when starting working on Deep Learning,37,13,28,http://www.reddit.com/r/MachineLearning/comments/1gdis4/bengio_on_the_difficulties_that_one_faces_when/,,,False,http://c.thumbs.redditmedia.com/MHgRBHhnPmZqUl_t.jpg,t5_2r3gv,False,,,False,t3_1gdis4,http://www.quora.com/Deep-Learning/What-are-the-difficulties-that-one-might-face-when-starting-research-in-Deep-Learning?share=1,
1371145451.0,24,blog.bigml.com,1ga4h9,Matter over Mind in Machine Learning,36,12,0,http://www.reddit.com/r/MachineLearning/comments/1ga4h9/matter_over_mind_in_machine_learning/,,,False,http://e.thumbs.redditmedia.com/GXNnasbAeJP-D-0R.jpg,t5_2r3gv,False,,,False,t3_1ga4h9,http://blog.bigml.com/2013/06/13/matter-over-mind-in-machine-learning/,
1368088132.0,24,self.MachineLearning,1dzoim,A subreddit recommender with Machine Learning,26,2,18,http://www.reddit.com/r/MachineLearning/comments/1dzoim/a_subreddit_recommender_with_machine_learning/,"It is available as a [chrome extension](https://chrome.google.com/webstore/detail/preddit/epicmjpmnmjgbmahjcigppkenngbdjbd). Feedback by potential users and ML practitioners is appreciated!

Implementation details are available [here](https://xplr.com/a-subreddit-recommender-with-xplr/).",,False,self,t5_2r3gv,False,,,True,t3_1dzoim,http://www.reddit.com/r/MachineLearning/comments/1dzoim/a_subreddit_recommender_with_machine_learning/,
1367984191.0,23,blog.kaggle.com,1dwso1,Kaggle Q&amp;A With Job Salary Prediction First Prize Winner Vlad Mnih - another Kaggle win for deep neural nets and U Toronto students,33,10,4,http://www.reddit.com/r/MachineLearning/comments/1dwso1/kaggle_qa_with_job_salary_prediction_first_prize/,,,False,http://f.thumbs.redditmedia.com/NRqNDWIqjD3QZjfM.jpg,t5_2r3gv,False,,,False,t3_1dwso1,http://blog.kaggle.com/2013/05/06/qa-with-job-salary-prediction-first-prize-winner-vlad-mnih/,
1360873902.0,26,blog.thegrandlocus.com,18jb1q,Analyzing IMDB reviews,35,9,4,http://www.reddit.com/r/MachineLearning/comments/18jb1q/analyzing_imdb_reviews/,,,False,http://e.thumbs.redditmedia.com/q573UNAzbO5Urgw4.jpg,t5_2r3gv,False,,,False,t3_18jb1q,http://blog.thegrandlocus.com/2012/07/The-geometry-of-style,
1357188425.0,24,machinedlearnings.com,15vcxw,Nips 2012 trends,31,7,3,http://www.reddit.com/r/MachineLearning/comments/15vcxw/nips_2012_trends/,,,False,default,t5_2r3gv,False,,,False,t3_15vcxw,http://www.machinedlearnings.com/2013/01/nips-2012-trends.html,
1350389594.0,23,self.MachineLearning,11kegx,"Can somebody ""explain like I am 5"", to me the ""no free lunch theorem for supervised machine learning""?",30,7,45,http://www.reddit.com/r/MachineLearning/comments/11kegx/can_somebody_explain_like_i_am_5_to_me_the_no/,,,False,self,t5_2r3gv,False,,,True,t3_11kegx,http://www.reddit.com/r/MachineLearning/comments/11kegx/can_somebody_explain_like_i_am_5_to_me_the_no/,
1349307668.0,24,self.MachineLearning,10wkiu,"You're handed a 5 years worth of ecommerce data from a large site and asked to find ""actionable insights to improve the bottomline"" - what would you look for?",29,5,18,http://www.reddit.com/r/MachineLearning/comments/10wkiu/youre_handed_a_5_years_worth_of_ecommerce_data/,"I'm finding myself in similar corporate situations (this is a bit more general to make it interesting). Part of my work is to supply reports on sales and distribution numbers. Initially they were just interesting graphs, but since I 've got a background with some math and statistics I decided to learn data analysis with the goal of getting it to the level where I could apply it at work and turn it in to something more useful. At this point the biggest challenge is to know what to look for - knowing what to apply &amp; when to apply it. 

I'm interested in hearing how someone with experience would approach a problem like this, where you basically have access to all the data you need (You can assume millions of records and full purchase info), but very limited instructions. What kind of analysis would you run first and why did you decide to use it? I would love to learn more about the process of approaching a data analysis problem, but not sure where to look for learning that specifically. 
",,False,self,t5_2r3gv,False,,,True,t3_10wkiu,http://www.reddit.com/r/MachineLearning/comments/10wkiu/youre_handed_a_5_years_worth_of_ecommerce_data/,
1346529862.0,25,self.MachineLearning,z74p9,ML and the 10.000 hour rule,33,8,16,http://www.reddit.com/r/MachineLearning/comments/z74p9/ml_and_the_10000_hour_rule/,"OK so I'm going to share here something that has been bothering me.

I am a CS graduate and I just started my Masters in ML.
What I want to do is become, a really, really good ML scientist/expert/whatever.

Now, I am a big fan of ""practice makes perfect"", and the 10000 hour rule. What has been bothering me though is:

How does one ""practice"" in Machine Learning?

In other disciplines it's pretty straightforward.
If you want to become a good weight lifter, you lift.
If you want to become a great violin player, you practice violin.

How does one become ""better"" at Machine Learning though?",,False,self,t5_2r3gv,False,,,True,t3_z74p9,http://www.reddit.com/r/MachineLearning/comments/z74p9/ml_and_the_10000_hour_rule/,
1345580609.0,24,blog.stackoverflow.com,yljy9,Stack Exchange Machine Learning contest through Kaggle,34,10,8,http://www.reddit.com/r/MachineLearning/comments/yljy9/stack_exchange_machine_learning_contest_through/,,,False,http://a.thumbs.redditmedia.com/B_Pu37gA7ApZEdUB.jpg,t5_2r3gv,False,,,False,t3_yljy9,http://blog.stackoverflow.com/2012/08/stack-exchange-machine-learning-contest/,
1340865170.0,24,research.microsoft.com,vq9t1,Decision forests: Tree ensembles for everything!,28,4,12,http://www.reddit.com/r/MachineLearning/comments/vq9t1/decision_forests_tree_ensembles_for_everything/,,,False,default,t5_2r3gv,False,,,False,t3_vq9t1,http://research.microsoft.com/apps/pubs/default.aspx?id=155552,
1335121098.0,24,investuotojas.eu,smxrx,Machine learning for identification of cars,32,8,9,http://www.reddit.com/r/MachineLearning/comments/smxrx/machine_learning_for_identification_of_cars/,,,False,http://d.thumbs.redditmedia.com/KBC2bDFmWg-4ZYMK.jpg,t5_2r3gv,False,,,False,t3_smxrx,http://www.investuotojas.eu/2012/04/22/machine-learning-for-identification-of-cars/,
1331817114.0,24,allendowney.blogspot.com,qxpzt,Bayesian statistics tutorial: video from PyCon 2012,25,1,0,http://www.reddit.com/r/MachineLearning/comments/qxpzt/bayesian_statistics_tutorial_video_from_pycon_2012/,,,False,http://b.thumbs.redditmedia.com/dMwEMFBeZ3R6RA3C.jpg,t5_2r3gv,False,,,False,t3_qxpzt,http://allendowney.blogspot.com/2012/03/bayesian-statistics-made-simple.html,
1316246891.0,25,r-bloggers.com,kiivw,Datasets to Practice Your Data Mining,28,3,1,http://www.reddit.com/r/MachineLearning/comments/kiivw/datasets_to_practice_your_data_mining/,,,False,default,t5_2r3gv,False,,,False,t3_kiivw,http://www.r-bloggers.com/datasets-to-practice-your-data-mining/,
1315408625.0,23,sylvainzimmer.com,k7nlr,Building the largest Chess AI ever,27,4,4,http://www.reddit.com/r/MachineLearning/comments/k7nlr/building_the_largest_chess_ai_ever/,,,False,http://thumbs.reddit.com/t3_k7nlr.png,t5_2r3gv,False,,,False,t3_k7nlr,http://sylvainzimmer.com/2011/09/06/chessathome-building-largest-chess-ai/,
1311835896.0,26,bloomberg.com,j1ylx,2 Economists reckon that our current exponential model discounts the future /far/ too much (thinking about Reinforcement Learning).,28,2,6,http://www.reddit.com/r/MachineLearning/comments/j1ylx/2_economists_reckon_that_our_current_exponential/,,,False,default,t5_2r3gv,False,,,False,t3_j1ylx,http://www.bloomberg.com/news/2011-07-28/einstein-on-wall-street-time-money-continuum-commentary-by-mark-buchanan.html,
1310179937.0,24,seobythesea.com,iklvc,"ML Reddit, what do you make of this algorithm by Google? PHIL - Google's Second Most Important Algorithm",30,6,1,http://www.reddit.com/r/MachineLearning/comments/iklvc/ml_reddit_what_do_you_make_of_this_algorithm_by/,,,False,http://thumbs.reddit.com/t3_iklvc.png,t5_2r3gv,False,,,False,t3_iklvc,http://www.seobythesea.com/?p=6014,
1306341758.0,23,correlate.googlelabs.com,hjwb4,What search correlates with this one?,26,3,2,http://www.reddit.com/r/MachineLearning/comments/hjwb4/what_search_correlates_with_this_one/,,,False,default,t5_2r3gv,False,,,False,t3_hjwb4,http://correlate.googlelabs.com/,
1303824495.0,25,npr.org,gxr2b,Supreme Court Weighs Whether To Limit Data Mining,26,1,1,http://www.reddit.com/r/MachineLearning/comments/gxr2b/supreme_court_weighs_whether_to_limit_data_mining/,,,False,default,t5_2r3gv,False,,,False,t3_gxr2b,http://www.npr.org/2011/04/26/135703500/supreme-court-weighs-whether-to-limit-data-mining,
1301393038.0,26,i.imgur.com,gdtv3,Critique this visual taxonomy of pattern recognition methods,34,8,28,http://www.reddit.com/r/MachineLearning/comments/gdtv3/critique_this_visual_taxonomy_of_pattern/,,,False,http://thumbs.reddit.com/t3_gdtv3.png,t5_2r3gv,False,,,False,t3_gdtv3,http://i.imgur.com/E6jra.png,
1288838499.0,23,self.MachineLearning,e0yk6,Simple guide to support vector machines,28,5,12,http://www.reddit.com/r/MachineLearning/comments/e0yk6/simple_guide_to_support_vector_machines/,"Does anyone know of a sort of ""Support vector machines for dummies"" book or tutorial?",,False,self,t5_2r3gv,False,,,True,t3_e0yk6,http://www.reddit.com/r/MachineLearning/comments/e0yk6/simple_guide_to_support_vector_machines/,
1286201094.0,24,ai-contest.com,dmm20,So how many Redditors are doing the Google AI Challenge? What are your rankings at the moment?,29,5,7,http://www.reddit.com/r/MachineLearning/comments/dmm20/so_how_many_redditors_are_doing_the_google_ai/,,,False,default,t5_2r3gv,False,,,False,t3_dmm20,http://ai-contest.com/rankings.php,
1280469011.0,23,neverreadpassively.com,cvdfs,Book Idea: A machine learning workbook with a step-by-step solution to the Nextflix Prize,25,2,4,http://www.reddit.com/r/MachineLearning/comments/cvdfs/book_idea_a_machine_learning_workbook_with_a/,,,False,http://thumbs.reddit.com/t3_cvdfs.png,t5_2r3gv,False,,,False,t3_cvdfs,http://www.neverreadpassively.com/2010/07/book-idea-movies-by-numbers.html,
1268030713.0,24,self.MachineLearning,bajoa,Hey everyone I got accepted to grad school for machine learning!!!,35,11,20,http://www.reddit.com/r/MachineLearning/comments/bajoa/hey_everyone_i_got_accepted_to_grad_school_for/,"I will be attending University of Michigan and getting a PhD in Electrical Engineering. My focus is statistical signal processing and machine learning!

YAY! I am so excited!",,False,self,t5_2r3gv,False,,,True,t3_bajoa,http://www.reddit.com/r/MachineLearning/comments/bajoa/hey_everyone_i_got_accepted_to_grad_school_for/,
1263317988.0,25,books.google.com,aoqjw,"Peter Norvig's library (AI slant, obviously)",27,2,2,http://www.reddit.com/r/MachineLearning/comments/aoqjw/peter_norvigs_library_ai_slant_obviously/,,,False,http://thumbs.reddit.com/t3_aoqjw.png,t5_2r3gv,False,,,False,t3_aoqjw,http://books.google.com/books?uid=8640673873589796416&amp;as_coll=0&amp;rview=1,
1257283886.0,26,self.MachineLearning,a0mwd,"Dear Reddit Machine Learning, Is Jeff Hawkings, ""inventor"" of HTMs a Genius of a Rambling Egomaniac? ",30,4,27,http://www.reddit.com/r/MachineLearning/comments/a0mwd/dear_reddit_machine_learning_is_jeff_hawkings/,,,False,self,t5_2r3gv,False,,,True,t3_a0mwd,http://www.reddit.com/r/MachineLearning/comments/a0mwd/dear_reddit_machine_learning_is_jeff_hawkings/,
1374519268.0,22,self.MachineLearning,1itvru,Why use LDA over Perceptron?,25,3,21,http://www.reddit.com/r/MachineLearning/comments/1itvru/why_use_lda_over_perceptron/,"
Hey all, 

So I am very familiar with the percpetron, and I just recently learned about LDA. I get that it is an algorithm that finds the best hyperplane unto which to project your data for classification... however, I also understand that the perceptron does the same thing. 

So... why would someone elect to use LDA over the Perceptron? What advantages or disadvantages are there? I am trying to understand how all this fits together. Is it just another technique to so supervised learning?

Thanks. ",,False,self,t5_2r3gv,False,,,True,t3_1itvru,http://www.reddit.com/r/MachineLearning/comments/1itvru/why_use_lda_over_perceptron/,
1372285783.0,22,numenta.org,1h50kg,First NuPIC Hackathon Outcome,29,7,0,http://www.reddit.com/r/MachineLearning/comments/1h50kg/first_nupic_hackathon_outcome/,,,False,http://a.thumbs.redditmedia.com/vH5V8smbwg_qhoer.jpg,t5_2r3gv,False,,,False,t3_1h50kg,http://numenta.org/news/2013/06/25/hackathon-outcome.html,
1366564878.0,24,neurosurgery.washington.edu,1ct3r8,Read dreams with support vector machines,29,5,2,http://www.reddit.com/r/MachineLearning/comments/1ct3r8/read_dreams_with_support_vector_machines/,,,False,default,t5_2r3gv,False,,,False,t3_1ct3r8,http://neurosurgery.washington.edu/Lectures/science.1234330.full.pdf,
1359562470.0,22,washingtonpost.com,17kep5,Watson goes to college: IBM sends version of supercomputer to RPI to boost cognitive skills - The Washington Post,27,5,2,http://www.reddit.com/r/MachineLearning/comments/17kep5/watson_goes_to_college_ibm_sends_version_of/,,,False,default,t5_2r3gv,False,,,False,t3_17kep5,http://www.washingtonpost.com/business/watson-goes-to-college-ibm-sends-version-of-supercomputer-to-rpi-to-boost-cognitive-skills/2013/01/30/c7537234-6ab3-11e2-9a0b-db931670f35d_story.html,
1352749326.0,23,youtube.com,132t7y,Building Analytical Applications on Hadoop,29,6,1,http://www.reddit.com/r/MachineLearning/comments/132t7y/building_analytical_applications_on_hadoop/,,,False,http://e.thumbs.redditmedia.com/2vhA51jXHDlXDdgX.jpg,t5_2r3gv,False,,,False,t3_132t7y,http://www.youtube.com/watch?v=giXBP-wwYpw,
1351709820.0,25,self.MachineLearning,12evgi,Classification when 80% of my training set is of one class.,28,3,15,http://www.reddit.com/r/MachineLearning/comments/12evgi/classification_when_80_of_my_training_set_is_of/,"I'm new to ML but I've been doing the ML course on coursera and have started messing about with Weka. I'm doing classification on 50,000 records where 79% of my predictor variable, y = 0. Any classification simulations I run also have a 79% success rate. Is my data set too noisy? Is there anything I can do improve this or not?",,False,self,t5_2r3gv,False,,,True,t3_12evgi,http://www.reddit.com/r/MachineLearning/comments/12evgi/classification_when_80_of_my_training_set_is_of/,
1340135494.0,24,elliottlemenager.com,vahgl,"Big Data, 30,000 Scientists and a Startup ",29,5,3,http://www.reddit.com/r/MachineLearning/comments/vahgl/big_data_30000_scientists_and_a_startup/,,,False,http://a.thumbs.redditmedia.com/L8NX3MNv0OpHpnt0.jpg,t5_2r3gv,False,,,False,t3_vahgl,http://www.elliottlemenager.com/2012/06/19/big-data-30000-scientists-and-a-startup/,
1334293999.0,24,self.MachineLearning,s7ihy,"A website that lists state of the art results in various machine learning problems, and by which methods it was achieved?",24,0,6,http://www.reddit.com/r/MachineLearning/comments/s7ihy/a_website_that_lists_state_of_the_art_results_in/,"I remember I have seen such a website before, but I can't find it anymore, does anybody have a link?",,False,self,t5_2r3gv,False,,,True,t3_s7ihy,http://www.reddit.com/r/MachineLearning/comments/s7ihy/a_website_that_lists_state_of_the_art_results_in/,
1319477155.0,23,cran.r-project.org,lnb3y,List of R functions and packages for machine learning,26,3,1,http://www.reddit.com/r/MachineLearning/comments/lnb3y/list_of_r_functions_and_packages_for_machine/,,,False,default,t5_2r3gv,False,,,False,t3_lnb3y,http://cran.r-project.org/web/views/MachineLearning.html,
1319143638.0,21,self.MachineLearning,lj4ol,"How well do Decision Trees scale 
to very large training datasets?",26,5,9,http://www.reddit.com/r/MachineLearning/comments/lj4ol/how_well_do_decision_trees_scale_to_very_large/,"I'm going to use Decision Trees for very large datasets (from megabytes to terabytes).  There are any good implementation in Java? And what kind of DT are best scalable? I see that Mahout uses Random forest. GUIDE also seems interesting. Are ensemble methods right way to go? Or can you suggest good and actual paper to read? Point to science case using decision trees on big data also highly appreciated.

Thanks

edit1: There will be many examples with small number of classes.",,False,self,t5_2r3gv,True,,,True,t3_lj4ol,http://www.reddit.com/r/MachineLearning/comments/lj4ol/how_well_do_decision_trees_scale_to_very_large/,
1314653040.0,23,blog.echen.me,jycwb,Introduction to Latent Dirichlet Allocation,26,3,15,http://www.reddit.com/r/MachineLearning/comments/jycwb/introduction_to_latent_dirichlet_allocation/,,,False,http://thumbs.reddit.com/t3_jycwb.png,t5_2r3gv,False,,,False,t3_jycwb,http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/,
1312783705.0,23,self.MachineLearning,jc5x9,Introduction to Artificial Intelligence - Fall 2011,30,7,8,http://www.reddit.com/r/MachineLearning/comments/jc5x9/introduction_to_artificial_intelligence_fall_2011/,An online course by Thrun and Norvig. You'll even will be scored. No certificate though.,,False,self,t5_2r3gv,False,,,True,t3_jc5x9,http://www.reddit.com/r/MachineLearning/comments/jc5x9/introduction_to_artificial_intelligence_fall_2011/,
1310046253.0,22,gaussianprocess.org,ij0o7,Gaussian Processes for Machine Learning,25,3,4,http://www.reddit.com/r/MachineLearning/comments/ij0o7/gaussian_processes_for_machine_learning/,,,False,default,t5_2r3gv,False,,,False,t3_ij0o7,http://www.gaussianprocess.org/gpml/,
1305290507.0,24,tunedit.org,hai95,"$45,000 algorithmic contest!",28,4,6,http://www.reddit.com/r/MachineLearning/comments/hai95/45000_algorithmic_contest/,,,False,http://thumbs.reddit.com/t3_hai95.png,t5_2r3gv,False,,,False,t3_hai95,http://tunedit.org/challenge/material-classification,
1297994294.0,23,blog.okfn.org,fnlt1,"DataMarket.com Launches with 100 Million Open 
Data Time Series [crosspost from /r/opendata]",27,4,1,http://www.reddit.com/r/MachineLearning/comments/fnlt1/datamarketcom_launches_with_100_million_open_data/,,,False,http://thumbs.reddit.com/t3_fnlt1.png,t5_2r3gv,False,,,False,t3_fnlt1,http://blog.okfn.org/2011/02/14/datamarket-com-launches-with-100-million-open-data-time-series-remains-firmly-commited-to-open-data/,
1297671376.0,21,nypost.com,fl0ng,The machine age by Peter Norvig,24,3,4,http://www.reddit.com/r/MachineLearning/comments/fl0ng/the_machine_age_by_peter_norvig/,,,False,http://thumbs.reddit.com/t3_fl0ng.png,t5_2r3gv,False,,,False,t3_fl0ng,http://www.nypost.com/p/news/opinion/opedcolumnists/the_machine_age_tM7xPAv4pI4JslK0M1JtxI/0,
1292185406.0,25,csb.uncw.edu,ekmgd,"I am now a Masters of Computer Science and Information Systems! Here is my thesis: ""Identifying Individuals Using Facial Dynamics with Active Appearance-based Hidden Markov Models""",33,8,5,http://www.reddit.com/r/MachineLearning/comments/ekmgd/i_am_now_a_masters_of_computer_science_and/,,,False,http://thumbs.reddit.com/t3_ekmgd.png,t5_2r3gv,False,,,False,t3_ekmgd,http://csb.uncw.edu/mscsis/complete/GawedaAdam.htm,
1291645884.0,25,cs.cornell.edu,eh1dx,Reasoning About a Highly Connected World,26,1,1,http://www.reddit.com/r/MachineLearning/comments/eh1dx/reasoning_about_a_highly_connected_world/,,,False,http://thumbs.reddit.com/t3_eh1dx.png,t5_2r3gv,False,,,False,t3_eh1dx,http://www.cs.cornell.edu/home/kleinber/networks-book/,
1290042741.0,23,reddit.com,e7u4g,Redditor replies to a question regarding Free Data Sets.,23,0,0,http://www.reddit.com/r/MachineLearning/comments/e7u4g/redditor_replies_to_a_question_regarding_free/,,,False,default,t5_2r3gv,False,,,False,t3_e7u4g,http://www.reddit.com/r/compsci/comments/e6ktk/what_are_the_best_free_data_sets/c15twur,
1289565482.0,24,numenta.com,e53is,New white paper from Numenta/Jeff Hawkins on Hierarchical Temporal Memory algorithms,26,2,5,http://www.reddit.com/r/MachineLearning/comments/e53is/new_white_paper_from_numentajeff_hawkins_on/,,,False,default,t5_2r3gv,False,,,False,t3_e53is,http://numenta.com/htm-overview/education/HTM_CorticalLearningAlgorithms.pdf,
1286780258.0,23,kaggle.com,dplse,How they did it: The methods used by top three in the 2010 INFORMS Data Mining Contest,23,0,2,http://www.reddit.com/r/MachineLearning/comments/dplse/how_they_did_it_the_methods_used_by_top_three_in/,,,False,http://thumbs.reddit.com/t3_dplse.png,t5_2r3gv,False,,,False,t3_dplse,http://kaggle.com/blog/2010/10/11/how-i-did-it-the-top-three-from-the-2010-informs-data-mining-contest/,
1275601459.0,23,radar.oreilly.com,cb6ky,What is data science? - O'Reilly Radar,24,1,0,http://www.reddit.com/r/MachineLearning/comments/cb6ky/what_is_data_science_oreilly_radar/,,,False,http://thumbs.reddit.com/t3_cb6ky.png,t5_2r3gv,False,,,False,t3_cb6ky,http://radar.oreilly.com/2010/06/what-is-data-science.html,
1269815162.0,23,self.MachineLearning,bjfs9,Reddit Machine Learning:  Anyone want to work on and apply machine learning to something?  ,27,4,33,http://www.reddit.com/r/MachineLearning/comments/bjfs9/reddit_machine_learning_anyone_want_to_work_on/,"I've been applying machine learning algorithms to everything I can think of.  I've had a few ideas for a few projects, but would be slightly too large for one person.  I have finally learned when something is beyond the scope of one person :).  So anyone working on anything cool and need a partner,  or send me a line sometime, would love to discuss a few things/projects/ideas.    
Edit:
Basically do you have a fair amount of time and have decent skills?  Send me a message lets get a group of people together skype it up, discuss ideas, go with a project we like and crank out something awesome in 3 weeks.  My skillset is mech eng, machine learning algorithms, and data mining/collecting, preferred language python, matlab. I could really use a front end person, someone that could create a dynamic website.  I've been messing with cherrypy but realize one person can't do everything.",,False,self,t5_2r3gv,True,,,True,t3_bjfs9,http://www.reddit.com/r/MachineLearning/comments/bjfs9/reddit_machine_learning_anyone_want_to_work_on/,
1265825022.0,22,rattle.togaware.com,b0gqu,Rattle - A Data Mining GUI for R,25,3,0,http://www.reddit.com/r/MachineLearning/comments/b0gqu/rattle_a_data_mining_gui_for_r/,,,False,default,t5_2r3gv,False,,,False,t3_b0gqu,http://rattle.togaware.com/,
1262618636.0,23,cs.cornell.edu,alel7,Opinion mining and sentiment analysis - ebook,24,1,1,http://www.reddit.com/r/MachineLearning/comments/alel7/opinion_mining_and_sentiment_analysis_ebook/,,,False,http://thumbs.reddit.com/t3_alel7.png,t5_2r3gv,False,,,False,t3_alel7,http://www.cs.cornell.edu/home/llee/opinion-mining-sentiment-analysis-survey.html,
1259860032.0,23,drewconway.com,aaqve,My Five Rules for Data Visualization ,24,1,0,http://www.reddit.com/r/MachineLearning/comments/aaqve/my_five_rules_for_data_visualization/,,,False,http://thumbs.reddit.com/t3_aaqve.png,t5_2r3gv,False,,,False,t3_aaqve,http://www.drewconway.com/zia/?p=1582,
1371126433.0,22,blog.yhathq.com,1g9hzz,Content-based image classification in Python,30,8,8,http://www.reddit.com/r/MachineLearning/comments/1g9hzz/contentbased_image_classification_in_python/,,,False,default,t5_2r3gv,False,,,False,t3_1g9hzz,http://blog.yhathq.com/posts/image-classification-in-Python.html,
1367087299.0,20,plus.google.com,1d87be,Yann LeCun on Deep Learning and Graphical Models,23,3,0,http://www.reddit.com/r/MachineLearning/comments/1d87be/yann_lecun_on_deep_learning_and_graphical_models/,,,False,http://f.thumbs.redditmedia.com/UtRAQkeQBZyzMa3Y.jpg,t5_2r3gv,False,,,False,t3_1d87be,https://plus.google.com/104362980539466846301/posts/gWE7Jca3Zoq,
1363379978.0,23,self.MachineLearning,1addic,"Dear r/MachineLearning, what software package do you use?",26,3,15,http://www.reddit.com/r/MachineLearning/comments/1addic/dear_rmachinelearning_what_software_package_do/,"I've been using more and more machine learning algorithms at work and I've really taken a huge interest in them. I was wondering what Machine Learners use to analyze their data. I'm using R right now, but I've decided to start learning Python (I think it's popular amongst machine learning, please, correct me if I'm wrong).

Anyways, I'd love to know which software package you use to do your work. Thanks!",,False,self,t5_2r3gv,False,,,True,t3_1addic,http://www.reddit.com/r/MachineLearning/comments/1addic/dear_rmachinelearning_what_software_package_do/,
1361570246.0,23,datalab.lu,191ns5,"From 1th to 15th at Kaggle challenge ""Event recommendation engine""",26,3,7,http://www.reddit.com/r/MachineLearning/comments/191ns5/from_1th_to_15th_at_kaggle_challenge_event/,,,False,http://f.thumbs.redditmedia.com/IdKC4Ll_P-zy_cSY.jpg,t5_2r3gv,False,,,False,t3_191ns5,http://datalab.lu/blog/2013/02/21/kaggle-event-recommentation-engine/,
1359977410.0,23,self.MachineLearning,17v1xq,Can anybody suggest some interesting articles on Machine Learning?,29,6,15,http://www.reddit.com/r/MachineLearning/comments/17v1xq/can_anybody_suggest_some_interesting_articles_on/,"The place I work has sends around innovative articles each week, I've been asked to pick some for this week. I wanted to pick a few interesting ones on machine learning applications/successes/innovations in business. Can anyone suggest some good ones? 

One good one I've found so far is http://swampland.time.com/2012/11/07/inside-the-secret-world-of-quants-and-data-crunchers-who-helped-obama-win/ but it's more about analytics than machine learning.",,False,self,t5_2r3gv,False,,,True,t3_17v1xq,http://www.reddit.com/r/MachineLearning/comments/17v1xq/can_anybody_suggest_some_interesting_articles_on/,
1359643051.0,21,blog.locut.us,17mowd,The perils of treating a model’s predictions as actual probabilities,28,7,2,http://www.reddit.com/r/MachineLearning/comments/17mowd/the_perils_of_treating_a_models_predictions_as/,,,False,default,t5_2r3gv,False,,,False,t3_17mowd,http://blog.locut.us/2011/11/23/the-perils-of-treating-a-models-predictions-as-actual-probabilities/,
1358743652.0,24,github.com,16yzj4,New Gaussian Process Toolbox for Matlab,28,4,3,http://www.reddit.com/r/MachineLearning/comments/16yzj4/new_gaussian_process_toolbox_for_matlab/,,,False,http://a.thumbs.redditmedia.com/N9ziDOG-qLvzlzNH.jpg,t5_2r3gv,False,,,False,t3_16yzj4,https://github.com/NICTA/TacoPig,
1352195778.0,22,wired.com,12q0ss,The Grapes of Math,28,6,2,http://www.reddit.com/r/MachineLearning/comments/12q0ss/the_grapes_of_math/,,,False,http://f.thumbs.redditmedia.com/bfPLxsK3SFf2-eu5.jpg,t5_2r3gv,False,,,False,t3_12q0ss,http://www.wired.com/wiredscience/2012/10/mf-fruition-sciences-winemakers/,
1350428167.0,24,r-bloggers.com,11lhlp,"R at 12,000 Cores!",32,8,6,http://www.reddit.com/r/MachineLearning/comments/11lhlp/r_at_12000_cores/,,,False,http://a.thumbs.redditmedia.com/4gzcFpWHg-eBcR10.jpg,t5_2r3gv,False,,,False,t3_11lhlp,http://www.r-bloggers.com/r-at-12000-cores/,
1347181746.0,21,self.MachineLearning,zlh2m,Clustering high dimensional trajectories,25,4,19,http://www.reddit.com/r/MachineLearning/comments/zlh2m/clustering_high_dimensional_trajectories/,"I am not at all a machine learning expert and as I am setting out on a new project I thought I would ask for some pointers.

I would like to cluster some high-dimensional trajectories. They are quite short - between 10-20 time points in a 50-dimensional space. I will have several hundred trials and expect there to be around 5-20 clusters.

What would people recommend to approach this problem? At first I thought just ignore the time structure so I have 50 dims x 10 time points = 500 features. Another approach might be to define distance between two trajectories as the sum over time points of the euclidean distances in the 50dim space and then cluster the similarity matrix. Would this be better - I don't have a good intuition for how it would differ from the full 500 feature vector? Are there any better techniques or approaches?

I actually have an external labelling of the data into 6 classes - but I would like to try an unsupervised approach to see if the same comes out of the data, or if there might be more structure - and also investigation the evolution with time of the cluster structure.",,False,self,t5_2r3gv,False,,,True,t3_zlh2m,http://www.reddit.com/r/MachineLearning/comments/zlh2m/clustering_high_dimensional_trajectories/,
1343667087.0,21,self.MachineLearning,xecs0,How important is Java/C++ vs just using R/Matlab for big data?,24,3,19,http://www.reddit.com/r/MachineLearning/comments/xecs0/how_important_is_javac_vs_just_using_rmatlab_for/,"hey guys, I am a biostats student currently working in genomics and neural signals processing.  I am very comfortable with R and Matlab and have a good amount of ML experience (in R) as well.  

It seems to me that a lot of these jobs want people that can develop in Java or have a much stronger CS background than I have (I've done a little C from way back when).  I'm sure I can pick up the basics, but have no experience in actual software development or working directly with data bases (sql).  My questions are: 

On what level is Java/C++ usually implemented in these types of jobs and are there any resources to get familiar with using Java in a big data type of setting?  

Other than speed, are there other big advantages to using a compiled language?  ",,False,self,t5_2r3gv,False,,,True,t3_xecs0,http://www.reddit.com/r/MachineLearning/comments/xecs0/how_important_is_javac_vs_just_using_rmatlab_for/,
1343306802.0,20,arxiv.org,x6qh8,An Algorithm for Pattern Discovery in Time Series,25,5,3,http://www.reddit.com/r/MachineLearning/comments/x6qh8/an_algorithm_for_pattern_discovery_in_time_series/,,,False,default,t5_2r3gv,False,,,False,t3_x6qh8,http://arxiv.org/pdf/cs/0210025v3.pdf,
1338752002.0,21,self.MachineLearning,uixqw,Explain LDA like I'm stupid!,29,8,18,http://www.reddit.com/r/MachineLearning/comments/uixqw/explain_lda_like_im_stupid/,"Well lets say I have to generate topics over a bunch of documents. First I assume [correct me if I'm wrong] that all the documents have same number of words *N* in them. Then the part after this is what I am confused on. After that we choose the topics labeling each of them with certain probabilistic weight? 
**Do we have to supply the topics to the LDA model?**

According to this [blog] (http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/) in the ""LDA Model"" section, it says 
&gt;Choose a topic mixture for the document (according to a Dirichlet distribution over a fixed set of K topics). For example, assuming that we have the two food and cute animal topics above, you might choose the document to consist of 1/3 food and 2/3 cute animals. 

It does not make sense to me, I always thought LDA would generate topics by itself. 

Please correct me if I am wrong anywhere. I would like to be clear about this. 

Thanks!",,False,self,t5_2r3gv,False,,,True,t3_uixqw,http://www.reddit.com/r/MachineLearning/comments/uixqw/explain_lda_like_im_stupid/,
1337080556.0,21,investuotojas.eu,to1tf,Data analysis of GitHub timeline data,23,2,4,http://www.reddit.com/r/MachineLearning/comments/to1tf/data_analysis_of_github_timeline_data/,,,False,http://e.thumbs.redditmedia.com/qt86zt8-imq9m_74.jpg,t5_2r3gv,False,,,False,t3_to1tf,http://www.investuotojas.eu/2012/05/15/github-data-analysis/,
1335507042.0,23,eblearn.sourceforge.net,suxbd,Tutorial and code to get state-of-the-art performance on Google Streetview House Numbers using deep learning  with EBLearn C++ ML library 1.1 (new release),31,8,2,http://www.reddit.com/r/MachineLearning/comments/suxbd/tutorial_and_code_to_get_stateoftheart/,,,False,http://e.thumbs.redditmedia.com/1dVy2XiLUniHpXhR.jpg,t5_2r3gv,False,,,False,t3_suxbd,http://eblearn.sourceforge.net/svhn_tutorial.html,
1334783368.0,25,blog.mikiobraun.de,sgnye,Beyond Prediction Accuracy,35,10,9,http://www.reddit.com/r/MachineLearning/comments/sgnye/beyond_prediction_accuracy/,,,False,http://d.thumbs.redditmedia.com/6oRbfVQDMSyi35aQ.jpg,t5_2r3gv,False,,,False,t3_sgnye,http://blog.mikiobraun.de/2011/01/machine-learning-beyond-prediction-accuracy.html,
1332698255.0,22,cacm.acm.org,rcwee,Probabilistic Topic Models | CACM,23,1,0,http://www.reddit.com/r/MachineLearning/comments/rcwee/probabilistic_topic_models_cacm/,,,False,http://a.thumbs.redditmedia.com/X0ssY7vsSBR0VXIT.jpg,t5_2r3gv,False,,,False,t3_rcwee,http://cacm.acm.org/magazines/2012/4/147361-probabilistic-topic-models/fulltext#.T27CgLd_4ac.facebook,
1323171527.0,21,self.MachineLearning,n2eu3,Creating a simple recommendation system for reddit: any advice?,27,6,43,http://www.reddit.com/r/MachineLearning/comments/n2eu3/creating_a_simple_recommendation_system_for/,"I want to create a simple user-based recommendation system for reddit, mainly for personal use. The idea is to get training data in the ""liked"" and ""disliked"" items for the user (this requires the password, so training will be on one user only). The recommender will then periodically retrieve new links from reddit and present the most promising ones to the user.

So far the features I've identified are the following: url domain, number of upvotes, number of downvotes, author id, and link title.

**I don't really know what family of machine learning algorithms I should use. What would you recommend?**

Thanks for your help!

EDIT: if you want to try your hand at it, [here is](https://gist.github.com/1438003) a simple python script that retrieves the data from reddit.",,False,self,t5_2r3gv,True,,,True,t3_n2eu3,http://www.reddit.com/r/MachineLearning/comments/n2eu3/creating_a_simple_recommendation_system_for/,
1322446386.0,20,cwiki.apache.org,mrh1p,Apache Mahout could use your help,24,4,10,http://www.reddit.com/r/MachineLearning/comments/mrh1p/apache_mahout_could_use_your_help/,,,False,default,t5_2r3gv,False,,,False,t3_mrh1p,https://cwiki.apache.org/confluence/display/MAHOUT/Algorithms,
1322056994.0,21,intelligentmining.com,mmpk2,Introduction to Matrix Factorization Collaborative Filtering,28,7,5,http://www.reddit.com/r/MachineLearning/comments/mmpk2/introduction_to_matrix_factorization/,,,False,default,t5_2r3gv,False,,,False,t3_mmpk2,http://www.intelligentmining.com/2011/08/08/intro-to-matrix-factorization/,
1321183610.0,20,ibm.com,mang0,Apache Mahout: Scalable machine learning for everyone,27,7,7,http://www.reddit.com/r/MachineLearning/comments/mang0/apache_mahout_scalable_machine_learning_for/,,,False,http://f.thumbs.redditmedia.com/45zjUDayXKYPtwWq.jpg,t5_2r3gv,False,,,False,t3_mang0,http://www.ibm.com/developerworks/java/library/j-mahout-scaling/index.html?ca=drs-,
1320594833.0,23,videolectures.net,m2fry,Videolectures: Machine Learning Summer School '11,26,3,0,http://www.reddit.com/r/MachineLearning/comments/m2fry/videolectures_machine_learning_summer_school_11/,,,False,default,t5_2r3gv,False,,,False,t3_m2fry,http://videolectures.net/mlss2011_bordeaux/,
1319578131.0,22,self.MachineLearning,low4y,"What makes Big Data so different from ""not Big Data""?",23,1,19,http://www.reddit.com/r/MachineLearning/comments/low4y/what_makes_big_data_so_different_from_not_big_data/,"Any time I interview, people make ""Big Data"" seem like it's completely different from data measured in mere megabytes. They also do not provide a good concrete reason of how it changes the analysis. So what changes need to be made to work with a data set measured in GB/TB, aside from worrying about being efficient with the code?",,False,self,t5_2r3gv,False,,,True,t3_low4y,http://www.reddit.com/r/MachineLearning/comments/low4y/what_makes_big_data_so_different_from_not_big_data/,
1316836259.0,23,fil.ion.ucl.ac.uk,kprcu,A neurobiologically plausible model for how the brain might do inference by minimizing a free energy functional.,26,3,10,http://www.reddit.com/r/MachineLearning/comments/kprcu/a_neurobiologically_plausible_model_for_how_the/,,,False,default,t5_2r3gv,False,,,False,t3_kprcu,http://www.fil.ion.ucl.ac.uk/~karl/Is%20this%20a%20unified%20theory%20of%20the%20brain.pdf,
1314968802.0,23,datawithoutborders.cc,k2epa,"Inaugural Data Without Borders Datadive: NYC, Oct. 14-16",23,0,5,http://www.reddit.com/r/MachineLearning/comments/k2epa/inaugural_data_without_borders_datadive_nyc_oct/,,,False,default,t5_2r3gv,False,,,False,t3_k2epa,http://datawithoutborders.cc/events/nykickoff/,
1313179508.0,22,research.microsoft.com,jh34e,Infer.NET - a Framework for Running Bayesian Inference in Graphical Models,26,4,6,http://www.reddit.com/r/MachineLearning/comments/jh34e/infernet_a_framework_for_running_bayesian/,,,False,http://thumbs.reddit.com/t3_jh34e.png,t5_2r3gv,False,,,False,t3_jh34e,http://research.microsoft.com/en-us/um/cambridge/projects/infernet/default.aspx,
1310719484.0,21,slideshare.net,iq9if,Python for brain mining: (neuro)science with state of the art machine learning and data visualization,23,2,5,http://www.reddit.com/r/MachineLearning/comments/iq9if/python_for_brain_mining_neuroscience_with_state/,,,False,default,t5_2r3gv,False,,,False,t3_iq9if,http://www.slideshare.net/GaelVaroquaux/python-for-brain-mining-neuroscience-with-state-of-the-art-machine-learning-and-data-visualization,
1308673202.0,21,scholarpedia.org,i5cus,Algorithmic probability and Solomonoff Induction,22,1,6,http://www.reddit.com/r/MachineLearning/comments/i5cus/algorithmic_probability_and_solomonoff_induction/,,,False,http://thumbs.reddit.com/t3_i5cus.png,t5_2r3gv,False,,,False,t3_i5cus,http://www.scholarpedia.org/article/Algorithmic_probability,
1299185679.0,23,tomazkovacic.com,fwsv0,Overview: Extracting article text from HTML documents ,26,3,4,http://www.reddit.com/r/MachineLearning/comments/fwsv0/overview_extracting_article_text_from_html/,,,False,http://thumbs.reddit.com/t3_fwsv0.png,t5_2r3gv,False,,,False,t3_fwsv0,http://tomazkovacic.com/blog/14/extracting-article-text-from-html-documents/,
1297553989.0,23,self.MachineLearning,fka75,biologist looking for advice on pros and cons of bayesian networks,25,2,20,http://www.reddit.com/r/MachineLearning/comments/fka75/biologist_looking_for_advice_on_pros_and_cons_of/,"I am wondering about the pros and cons of learning bayesian networks. In the past ten years they have come up over and over in the computational biology literature, but I keep hearing that they are more over-fitted than useful. 


I am asking because I am wondering if using bayesian networks is worth it in my situation:

I have 2000 samples each with a 1000 discrete features that I want to use to predict 1 continuous variable. The hope is that I could build up a bayesian network that would characterize a small portion of my 1000 features as important and to identify logic gates between the important features. 

I thought about doing this as an alternative to doing regressions, because the dimensionality of the models limits me to testing interactions of two features at a time and prohibits me from finding higher order interactions. 

What I am not sure of is: 

(1) do people currently learn the networks using MCMC or GA or is there something better?

(2) what are the usual criticisms of Bayes Nets?

(3) I think I should test the significance of the bayes net using the likelihood ratio test with the naive bayes as the null hypothesis, but should this be done for different parts of the network or only for the whole thing?

thanks in advance for any feedback.

**edit: **

**thanks for the feedback everyone, especially the backwards moose, esoom! **

**I have some more things to mull over and will likely be back after I have tried several of the things that were suggested.
**",,False,self,t5_2r3gv,True,,,True,t3_fka75,http://www.reddit.com/r/MachineLearning/comments/fka75/biologist_looking_for_advice_on_pros_and_cons_of/,
1294764738.0,20,r-bloggers.com,f0arr,OpenData + R + Google = Easy Maps ,22,2,3,http://www.reddit.com/r/MachineLearning/comments/f0arr/opendata_r_google_easy_maps/,,,False,http://thumbs.reddit.com/t3_f0arr.png,t5_2r3gv,False,,,False,t3_f0arr,http://www.r-bloggers.com/opendata-r-google-easy-maps/,
1291033740.0,21,wired.com,edaj3,Wall Street Firm Uses Algorithms to Make Sports Betting Like Stock Trading,26,5,4,http://www.reddit.com/r/MachineLearning/comments/edaj3/wall_street_firm_uses_algorithms_to_make_sports/,,,False,http://thumbs.reddit.com/t3_edaj3.png,t5_2r3gv,False,,,False,t3_edaj3,http://www.wired.com/magazine/2010/11/ff_midas,
1289395951.0,22,infoq.com,e40g3,Machine Learning: A Love Story,24,2,7,http://www.reddit.com/r/MachineLearning/comments/e40g3/machine_learning_a_love_story/,,,False,http://thumbs.reddit.com/t3_e40g3.png,t5_2r3gv,False,,,False,t3_e40g3,http://www.infoq.com/presentations/Machine-Learning,
1280573341.0,23,cran.r-project.org,cvt30,Developing recommendation algorithms in R (pdf) ,23,0,0,http://www.reddit.com/r/MachineLearning/comments/cvt30/developing_recommendation_algorithms_in_r_pdf/,,,False,default,t5_2r3gv,False,,,False,t3_cvt30,http://cran.r-project.org/web/packages/recommenderlab/vignettes/recommenderlab.pdf,
1273588161.0,22,ibm.com,c2m14,"Data mining with WEKA, Part 2: Classification and clustering",25,3,3,http://www.reddit.com/r/MachineLearning/comments/c2m14/data_mining_with_weka_part_2_classification_and/,,,False,http://thumbs.reddit.com/t3_c2m14.png,t5_2r3gv,False,,,False,t3_c2m14,http://www.ibm.com/developerworks/opensource/library/os-weka2/index.html,
1267892929.0,21,videolectures.net,ba252,"Re-unifying the several clusters AI has 
been divided into, and to build a 
general-purpose, consistent, and 
realistic system: Markov Logic.[Vid 
Lecture]",23,2,8,http://www.reddit.com/r/MachineLearning/comments/ba252/reunifying_the_several_clusters_ai_has_been/,,,False,http://thumbs.reddit.com/t3_ba252.png,t5_2r3gv,False,,,False,t3_ba252,http://videolectures.net/cikm08_domingos_mlmaul/,
1266054671.0,23,nlp.stanford.edu,b1lu6,Introduction to Information Retrieval,23,0,1,http://www.reddit.com/r/MachineLearning/comments/b1lu6/introduction_to_information_retrieval/,,,False,default,t5_2r3gv,False,,,False,t3_b1lu6,http://nlp.stanford.edu/IR-book/html/htmledition/irbook.html,
1256283349.0,22,self.MachineLearning,9wxqe,Is it possible to get an interesting job doing ML without an advanced degree?,26,4,13,http://www.reddit.com/r/MachineLearning/comments/9wxqe/is_it_possible_to_get_an_interesting_job_doing_ml/,"Hi ML'ers,
I am currently in my last quarter of undergrad at a 2nd-tier UC doing computer science, and am interested in machine learning. I've taken a couple grad-level Machine Learning classes and have been having a lot of fun with my homework and projects. I also have several years' experience working as a software engineer and am currently working (nearly) full-time.

Since I am supporting my fiancee who is also in school right now (and will be for a while), I don't think grad school is an immediate option for me without taking on enormous amounts of debt. Does anyone know of an employer who will consider someone without an advanced degree for a position doing data mining / machine learning? Any tips on getting into the specialty with only a BS in CS?

Ultimately, I would like to be doing work creating/adapting algorithms to solve interesting problems (recommendation engines, advertising optimization, IR, NLP, etc), but wouldn't mind maintaining/enhancing existing systems at first to get my feet wet if needed.

Edit: Thanks for the interesting and insightful comments everyone!

What I'm going to do is find work doing some type of ML ASAP (or at least in proximity to the guys doing it) and then figure out how to afford to get a Master's once I have a little bit more experience applying the stuff. BTW, I got some anonymous comments that there are companies out there that are not too hung up on the piece of paper... so I guess it's like the rest of the industry: if you're good at it, someone will hire you to do it!",,False,self,t5_2r3gv,True,,,True,t3_9wxqe,http://www.reddit.com/r/MachineLearning/comments/9wxqe/is_it_possible_to_get_an_interesting_job_doing_ml/,
1252335249.0,22,youtube.com,9i4fp,"The Next Generation of Neural Networks from Geoffrey Hinton, a leading AI researcher. [ Google Talk]",22,0,3,http://www.reddit.com/r/MachineLearning/comments/9i4fp/the_next_generation_of_neural_networks_from/,,,False,http://thumbs.reddit.com/t3_9i4fp.png,t5_2r3gv,False,,,False,t3_9i4fp,http://www.youtube.com/watch?v=AyzOUbkUf3M,
1249929295.0,24,mat.tepper.cmu.edu,99b43,Data Mining and the Stock Market,26,2,1,http://www.reddit.com/r/MachineLearning/comments/99b43/data_mining_and_the_stock_market/,,,False,default,t5_2r3gv,False,,,False,t3_99b43,http://mat.tepper.cmu.edu/blog/?p=804,
1369411096.0,20,kaggle.com,1ez6cq,"It's been just over a year since it was launched, and Kaggle's data science wiki is still pretty weak and disappointing. I think we should beef it up.",31,11,25,http://www.reddit.com/r/MachineLearning/comments/1ez6cq/its_been_just_over_a_year_since_it_was_launched/,,,False,default,t5_2r3gv,False,,,False,t3_1ez6cq,http://www.kaggle.com/wiki/Home,
1368715299.0,22,npr.org,1egb0u,Analyzing The Language Of Suicide Notes To Help Save Lives (xpost from r/linguistics),30,8,1,http://www.reddit.com/r/MachineLearning/comments/1egb0u/analyzing_the_language_of_suicide_notes_to_help/,,,False,http://a.thumbs.redditmedia.com/Y3KUa4IGdzzIl6e6.jpg,t5_2r3gv,False,,,False,t3_1egb0u,http://www.npr.org/2013/05/15/184232472/analyzing-the-language-of-suicide-notes-to-help-save-lives,
1366909386.0,22,cs.waikato.ac.nz,1d3dai,Classiﬁer Chains for Multi-label Classiﬁcation - A nice multi-label classification -&gt; binary classification reduction,23,1,2,http://www.reddit.com/r/MachineLearning/comments/1d3dai/classiﬁer_chains_for_multilabel_classiﬁcation_a/,,,False,default,t5_2r3gv,False,,,False,t3_1d3dai,http://www.cs.waikato.ac.nz/~eibe/pubs/chains.pdf,
1365642267.0,21,self.MachineLearning,1c3rf8,"What's a typical, or your, ML hourly contracting rate in the Bay Area (experienced practitioner)",32,11,25,http://www.reddit.com/r/MachineLearning/comments/1c3rf8/whats_a_typical_or_your_ml_hourly_contracting/,,,False,self,t5_2r3gv,False,,,True,t3_1c3rf8,http://www.reddit.com/r/MachineLearning/comments/1c3rf8/whats_a_typical_or_your_ml_hourly_contracting/,
1365545275.0,21,drdobbs.com,1c0q8h,"The secret is that ""big data"" means different things depending on whether you are on the engineering or business side of the problem.",29,8,0,http://www.reddit.com/r/MachineLearning/comments/1c0q8h/the_secret_is_that_big_data_means_different/,,,False,http://d.thumbs.redditmedia.com/zp-XE9ej-u70jBAQ.jpg,t5_2r3gv,False,,,False,t3_1c0q8h,http://www.drdobbs.com/database/the-pragmatic-side-of-using-big-data/240152350,
1362970448.0,21,camdp.com,1a25uz,"How to sort ""Top"" comments like the Reddit and HackerNews pros",23,2,3,http://www.reddit.com/r/MachineLearning/comments/1a25uz/how_to_sort_top_comments_like_the_reddit_and/,,,False,default,t5_2r3gv,False,,,False,t3_1a25uz,http://camdp.com/blogs/how-sort-comments-intelligently-reddit-and-hacker-,
1360652512.0,23,self.MachineLearning,18d6kj,Entry level jobs in Machine Learning?,26,3,29,http://www.reddit.com/r/MachineLearning/comments/18d6kj/entry_level_jobs_in_machine_learning/,"Hi all,

I'm wondering what an entry level job for an ML career would look like. Embarrassingly, I actually have a Master's in ML, but I know I'm not qualified to tackle the ML jobs listed on Monster.com. I was lucky to survive with a diploma - I can program decently well, but I don't have the intuition behind the math (also, I believe it's hard to fail out of Master's programs in general because they are cash cows for Universities, and hence there is a general reluctance to punish people that are reasonably smart and paying a lot of money). And so I just don't have the confidence to tackle the Amazon/IBM type jobs that I often see. I've done some courses on Coursera (ML with Andrew Ng, which was awesome, and PGM, which is a total beast), and some self-study on statistics, but I would really like an entry level job in ML. However, the search terms ""entry level"" and ""machine learning"" don't really turn up sensible results when I use them. Is there another, easier job title that eventually leads to ML? Or, what else can I be doing to kick start a career in ML?

I apologize if this is a noob/frequently posted query.

Edit: Thanks all! I think I'll hang out here more often for inspiration and industry news. ",,False,self,t5_2r3gv,1360691433.0,,,True,t3_18d6kj,http://www.reddit.com/r/MachineLearning/comments/18d6kj/entry_level_jobs_in_machine_learning/,
1354171360.0,22,masi.cscs.lsa.umich.edu,13zdq5,Information Geometry,28,6,4,http://www.reddit.com/r/MachineLearning/comments/13zdq5/information_geometry/,,,False,default,t5_2r3gv,False,,,False,t3_13zdq5,http://masi.cscs.lsa.umich.edu/~crshalizi/notabene/info-geo.html?em_x=22,
1349194772.0,21,www-stat.stanford.edu,10tm50,Oldie but a goodie: Stein's Paradox in statistics and Empirical Bayes (1977),22,1,1,http://www.reddit.com/r/MachineLearning/comments/10tm50/oldie_but_a_goodie_steins_paradox_in_statistics/,,,False,default,t5_2r3gv,False,,,False,t3_10tm50,http://www-stat.stanford.edu/~ckirby/brad/other/Article1977.pdf,
1348082735.0,20,npr.org,105g43,Big Data And Its Big Problems,28,8,8,http://www.reddit.com/r/MachineLearning/comments/105g43/big_data_and_its_big_problems/,,,False,http://c.thumbs.redditmedia.com/94D_vD9D1hqnXftt.jpg,t5_2r3gv,False,,,False,t3_105g43,http://www.npr.org/blogs/13.7/2012/09/18/161334704/big-data-and-its-big-problems,
1348007931.0,22,overkillanalytics.net,103rik,Kaggle's WordPress Challenge: The Like Graph,29,7,1,http://www.reddit.com/r/MachineLearning/comments/103rik/kaggles_wordpress_challenge_the_like_graph/,,,False,http://a.thumbs.redditmedia.com/5zKs5uz6d7Wu3KT6.jpg,t5_2r3gv,False,,,False,t3_103rik,http://www.overkillanalytics.net/kaggles-wordpress-challenge-the-like-graph/,
1347863476.0,23,heatonresearch.com,100fob,A Non-Mathematical Introduction to Using Neural Networks,34,11,6,http://www.reddit.com/r/MachineLearning/comments/100fob/a_nonmathematical_introduction_to_using_neural/,,,False,http://b.thumbs.redditmedia.com/_rNKh0RNGEohwZCO.jpg,t5_2r3gv,False,,,False,t3_100fob,http://www.heatonresearch.com/content/non-mathematical-introduction-using-neural-networks,
1341253702.0,19,self.MachineLearning,vxomj,L1 vs. L2 Regularization?,23,4,14,http://www.reddit.com/r/MachineLearning/comments/vxomj/l1_vs_l2_regularization/,"I read that L1 favours sparse models where as L2 favours models with small coefficients. However I don't see how this is the case, sure with both L1 and L2 regularization (sum |theta| vs. sum theta^2) setting theta to zero will be favourable, so what makes the distinction between L1 being sparse and L2 having small coefficients. 

",,False,self,t5_2r3gv,False,,,True,t3_vxomj,http://www.reddit.com/r/MachineLearning/comments/vxomj/l1_vs_l2_regularization/,
1340148448.0,21,research.microsoft.com,vau6t,Nobody ever got fired for using Hadoop on a cluster,23,2,6,http://www.reddit.com/r/MachineLearning/comments/vau6t/nobody_ever_got_fired_for_using_hadoop_on_a/,,,False,default,t5_2r3gv,False,,,False,t3_vau6t,http://research.microsoft.com/pubs/163083/hotcbp12%20final.pdf,
1339441926.0,22,self.MachineLearning,uwkt9,Kmeans -- ensuring homogeneous cluster size?,23,1,28,http://www.reddit.com/r/MachineLearning/comments/uwkt9/kmeans_ensuring_homogeneous_cluster_size/,"I'm working on an implementation of kmeans++ and for the clusters I get that have about 30 datapoints assigned to them, it seems to work pretty well.  But I consistently seem to get one or two clusters of about 700 datapoints in size (out of ~2000!) when k is 100, which turn out to be pretty useless.  I also get a bunch of clusters that are 1 or two datapoints in size, which look to be pretty similar to other clusters of that size and should be grouped together.

Are there methods to ensure that clusters get to be a roughly homogeneous size compared to each other?  I thought it was a problem with my cluster initialization, but I tried random datapoints at centers, I tried furthest distance, and now kmeans++, but the different methods all seem to give me the same problem with regards to relative cluster size.",,False,self,t5_2r3gv,False,,,True,t3_uwkt9,http://www.reddit.com/r/MachineLearning/comments/uwkt9/kmeans_ensuring_homogeneous_cluster_size/,
1332990048.0,20,blog.echen.me,rinw9,Choosing a Machine Learning Classifier,26,6,25,http://www.reddit.com/r/MachineLearning/comments/rinw9/choosing_a_machine_learning_classifier/,,,False,default,t5_2r3gv,False,,,False,t3_rinw9,http://blog.echen.me/2011/04/27/choosing-a-machine-learning-classifier/,
1332774522.0,22,nytimes.com,re9o5,Factual’s Gil Elbaz Wants to Gather the Data Universe,23,1,0,http://www.reddit.com/r/MachineLearning/comments/re9o5/factuals_gil_elbaz_wants_to_gather_the_data/,,,False,default,t5_2r3gv,False,,,False,t3_re9o5,http://www.nytimes.com/2012/03/25/business/factuals-gil-elbaz-wants-to-gather-the-data-universe.html,
1326754062.0,21,vimeo.com,ojxe1,"Tidy Data, talk by Hadley Wickham [vid]",23,2,1,http://www.reddit.com/r/MachineLearning/comments/ojxe1/tidy_data_talk_by_hadley_wickham_vid/,,,False,http://a.thumbs.redditmedia.com/BBKAzIjTQXtqGGoZ.jpg,t5_2r3gv,False,,,False,t3_ojxe1,http://vimeo.com/33727555,
1326209049.0,20,bickson.blogspot.com,oaw4d,The world's coolest machine learning internships,25,5,3,http://www.reddit.com/r/MachineLearning/comments/oaw4d/the_worlds_coolest_machine_learning_internships/,,,False,http://b.thumbs.redditmedia.com/3YlzHCwCZj7d9wmO.jpg,t5_2r3gv,False,,,False,t3_oaw4d,http://bickson.blogspot.com/2012/01/worlds-coolest-machine-learning.html,
1320231492.0,21,darpa.mil,lxki9,"DARPA Shredder Challenge ($50,00 Prize)",25,4,21,http://www.reddit.com/r/MachineLearning/comments/lxki9/darpa_shredder_challenge_5000_prize/,,,False,http://c.thumbs.redditmedia.com/G0gAOV4_9HDXB6vV.jpg,t5_2r3gv,False,,,False,t3_lxki9,http://www.darpa.mil/Shredder_Puzzle.aspx,
1314591979.0,20,autonlab.org,jxna7,Best order to go through these Data Mining tutorials?,23,3,3,http://www.reddit.com/r/MachineLearning/comments/jxna7/best_order_to_go_through_these_data_mining/,,,False,default,t5_2r3gv,False,,,False,t3_jxna7,http://www.autonlab.org/tutorials/index.html,
1312018038.0,20,self.MachineLearning,j4127,Ask reddit: what Machine Learning package(s) do you use under linux?,22,2,31,http://www.reddit.com/r/MachineLearning/comments/j4127/ask_reddit_what_machine_learning_packages_do_you/,"I'm getting started with machine learning and more precisely, classification, and I'd like to know what tools more experienced people used. If possible, I'd prefer to work from python, but really, any tool is fine, as long as it is good :)",,False,self,t5_2r3gv,False,,,True,t3_j4127,http://www.reddit.com/r/MachineLearning/comments/j4127/ask_reddit_what_machine_learning_packages_do_you/,
1311489734.0,21,self.MachineLearning,iy83b,Where's the best place to start learning how to program neural networks?,26,5,13,http://www.reddit.com/r/MachineLearning/comments/iy83b/wheres_the_best_place_to_start_learning_how_to/,"My degree was in psychology and I became very interested in neural nets after reading Rumelhart, Elman, Sejnowski, etc. I never learned how to actually program them though. Any help on where to start? I downloaded Python and am trying to learn the basics but I'm still very much a noob. Thanks!",,False,self,t5_2r3gv,False,,,True,t3_iy83b,http://www.reddit.com/r/MachineLearning/comments/iy83b/wheres_the_best_place_to_start_learning_how_to/,
1306656687.0,22,research.microsoft.com,hmq9c,"Infer.NET, a framework for running Bayesian inference in graphical models « MSR Cambridge",27,5,2,http://www.reddit.com/r/MachineLearning/comments/hmq9c/infernet_a_framework_for_running_bayesian/,,,False,http://thumbs.reddit.com/t3_hmq9c.png,t5_2r3gv,False,,,False,t3_hmq9c,http://research.microsoft.com/en-us/um/cambridge/projects/infernet/,
1296951835.0,19,nytimes.com,fg199,What Is Artificial Intelligence? - NYTimes.com,25,6,3,http://www.reddit.com/r/MachineLearning/comments/fg199/what_is_artificial_intelligence_nytimescom/,,,False,default,t5_2r3gv,False,,,False,t3_fg199,http://www.nytimes.com/2011/02/06/opinion/06powers.html?_r=1&amp;hp,
1295361215.0,19,youtube.com,f4fwr,Statistics in the Real World: The Search for the Scorpion,21,2,0,http://www.reddit.com/r/MachineLearning/comments/f4fwr/statistics_in_the_real_world_the_search_for_the/,,,False,http://thumbs.reddit.com/t3_f4fwr.png,t5_2r3gv,False,,,False,t3_f4fwr,http://www.youtube.com/watch?v=U9-G-noZrwc&amp;playnext=1&amp;list=PLA7DA844FB4ABB6F2&amp;index=33,
1295159815.0,21,kaggle.com,f360y,Deanonymization used to win the IJCNN Social Network Challenge,24,3,2,http://www.reddit.com/r/MachineLearning/comments/f360y/deanonymization_used_to_win_the_ijcnn_social/,,,False,http://thumbs.reddit.com/t3_f360y.png,t5_2r3gv,False,,,False,t3_f360y,http://www.kaggle.com/blog/2011/01/15/how-we-did-it-the-winners-of-the-ijcnn-social-network-challenge/,
1294271133.0,23,peekaboo-vision.blogspot.com,ewwl1,Single Layer Networks in Unsupervised Feature Learning: The Deep Learning Killer,27,4,1,http://www.reddit.com/r/MachineLearning/comments/ewwl1/single_layer_networks_in_unsupervised_feature/,,,False,http://thumbs.reddit.com/t3_ewwl1.png,t5_2r3gv,False,,,False,t3_ewwl1,http://peekaboo-vision.blogspot.com/2010/12/nips-2010-single-layer-networks-in.html,
1293946284.0,22,jeromyanglim.blogspot.com,eutho,"Videos on Data Analysis with R: Introductory, Intermediate, and Advanced Resources",23,1,1,http://www.reddit.com/r/MachineLearning/comments/eutho/videos_on_data_analysis_with_r_introductory/,,,False,default,t5_2r3gv,False,,,False,t3_eutho,http://jeromyanglim.blogspot.com/2010/05/videos-on-data-analysis-with-r.html,
1290159911.0,19,kaggle.com,e8kv8,Jeremy Howard on how he finished second in the chess rating competition (in just 15 days),21,2,1,http://www.reddit.com/r/MachineLearning/comments/e8kv8/jeremy_howard_on_how_he_finished_second_in_the/,,,False,http://thumbs.reddit.com/t3_e8kv8.png,t5_2r3gv,False,,,False,t3_e8kv8,http://kaggle.com/blog/2010/11/19/how-i-did-it-jeremy-howard-on-finishing-second/,
1288104464.0,21,streamhacker.com,dwn3j,Training Binary Text Classifiers with NLTK Trainer,24,3,0,http://www.reddit.com/r/MachineLearning/comments/dwn3j/training_binary_text_classifiers_with_nltk_trainer/,,,False,http://thumbs.reddit.com/t3_dwn3j.png,t5_2r3gv,False,,,False,t3_dwn3j,http://streamhacker.com/2010/10/25/training-binary-text-classifiers-nltk-trainer/,
1283868834.0,22,sas.com,damcm,Top Ten Data Mining Mistakes,28,6,17,http://www.reddit.com/r/MachineLearning/comments/damcm/top_ten_data_mining_mistakes/,,,False,http://thumbs.reddit.com/t3_damcm.png,t5_2r3gv,False,,,False,t3_damcm,http://www.sas.com/news/sascom/2010q3/column_tech.html,
1281302002.0,21,docs.google.com,cyu9o,Google Prediction API,22,1,5,http://www.reddit.com/r/MachineLearning/comments/cyu9o/google_prediction_api/,,,False,default,t5_2r3gv,False,,,False,t3_cyu9o,http://docs.google.com/a/m4xl1n.com/present/view?id=0AQ85RzjPG_zXZHFoZzhkNl8ybm1wamhkZmc&amp;hl=en,
1280098638.0,21,i2pi.com,ctlq0,This file gives a quick demonstration of a few ML techniques that are available in R,23,2,0,http://www.reddit.com/r/MachineLearning/comments/ctlq0/this_file_gives_a_quick_demonstration_of_a_few_ml/,,,False,default,t5_2r3gv,False,,,False,t3_ctlq0,http://i2pi.com/rez/ml_talk/ml_demo.R,
1279036555.0,21,self.MachineLearning,cp375,Machine Learning Job Positions,27,6,7,http://www.reddit.com/r/MachineLearning/comments/cp375/machine_learning_job_positions/,,,False,self,t5_2r3gv,False,,,True,t3_cp375,http://www.reddit.com/r/MachineLearning/comments/cp375/machine_learning_job_positions/,
1276804081.0,20,r-statistics.com,cg4z3,Support a new Q&amp;A website for Data-mining (based on the StackOverFlow engine): please join &amp; vote up!,24,4,1,http://www.reddit.com/r/MachineLearning/comments/cg4z3/support_a_new_qa_website_for_datamining_based_on/,,,False,http://thumbs.reddit.com/t3_cg4z3.png,t5_2r3gv,False,,,False,t3_cg4z3,http://www.r-statistics.com/2010/06/a-new-qa-website-for-data-analysis-based-on-stackoverflow-engine-is-waiting-for-you/,
1272646877.0,19,ibm.com,byf76,"Data mining with WEKA, Part 1: Introduction and regression",23,4,0,http://www.reddit.com/r/MachineLearning/comments/byf76/data_mining_with_weka_part_1_introduction_and/,,,False,http://thumbs.reddit.com/t3_byf76.png,t5_2r3gv,False,,,False,t3_byf76,http://www.ibm.com/developerworks/opensource/library/os-weka1/index.html,
1272619923.0,20,self.MachineLearning,by97n,Finance and machine learning master's thesis,23,3,16,http://www.reddit.com/r/MachineLearning/comments/by97n/finance_and_machine_learning_masters_thesis/,"I'm doing a master's in economics and business administration and this fall I'll have to write my thesis. I'm the process of finding a research topic, and I would like your input. I would like to use machine learning techniques instead of typically used (time series) econometrics. My background in machine learning is lacking, I'm afraid, but I'm sure I can get up to speed during the process (I've only done one course in machine learning, but a few courses in econometrics). 

My idea is something along the line of forecasting and algorithmic trading/portfolio selection. I'm trying to set up a meeting with (hopefully) my future supervisor in a few weeks and thought that you guys might have just the right ideas for me. I'm currently trying to read up on relevant litterature, if you have any good sources for journal articles not to be missed, or even good textbooks, I'm all ears. 

Thanks!",,False,self,t5_2r3gv,False,,,True,t3_by97n,http://www.reddit.com/r/MachineLearning/comments/by97n/finance_and_machine_learning_masters_thesis/,
1260029758.0,20,self.MachineLearning,abfln,What do you think are the top 10 most influential algorithm in Data Mining?,25,5,13,http://www.reddit.com/r/MachineLearning/comments/abfln/what_do_you_think_are_the_top_10_most_influential/,"Do you agree or disagree with these lists:

http://www.cs.uvm.edu/~icdm/algorithms/index.shtml",,False,self,t5_2r3gv,False,,,True,t3_abfln,http://www.reddit.com/r/MachineLearning/comments/abfln/what_do_you_think_are_the_top_10_most_influential/,
1248973332.0,21,umiacs.umd.edu,961up,"Introductory yet extensive tutorial on 
the basic ideas behind Support Vector 
Machines (SVMs).",24,3,3,http://www.reddit.com/r/MachineLearning/comments/961up/introductory_yet_extensive_tutorial_on_the_basic/,,,False,default,t5_2r3gv,False,,,False,t3_961up,http://www.umiacs.umd.edu/~joseph/support-vector-machines4.pdf,
1374927948.0,22,algorithmicthoughts.wordpress.com,1j5o63,A short article on mini batch K-Means,27,5,0,http://www.reddit.com/r/MachineLearning/comments/1j5o63/a_short_article_on_mini_batch_kmeans/,,,False,http://f.thumbs.redditmedia.com/2YcYOzZb3fh76UE_.jpg,t5_2r3gv,False,,,False,t3_1j5o63,http://algorithmicthoughts.wordpress.com/2013/07/26/machine-learning-mini-batch-k-means/,
1372897351.0,20,self.MachineLearning,1hlpz9,"Came across something intriguing called Grey System Theory - anyone here heard of it? Apparently even with tiny data sets (as few as 4-6 data points), it's capable of outperforming many bread-and-butter time series algorithms with 10-100x larger data sets.",25,5,25,http://www.reddit.com/r/MachineLearning/comments/1hlpz9/came_across_something_intriguing_called_grey/,"You can read a few papers about it at [Scholar Google](http://scholar.google.com/scholar?as_vis=1&amp;q=%22grey+system+theory%22+OR+%22gray+system+theory%22&amp;hl=en&amp;as_sdt=1,21)

Here's the [paper](https://docs.google.com/viewer?url=http%3A%2F%2Fwww.researchinformation.co.uk%2Fgrey%2FIntroGreySysTheory.pdf) introducing the theory.

I'm baffled that something so promising could be so obscure (there's no article about it @ Wikipedia). Did the articles oversell Grey System? 

I haven't had a chance to read the introductory article yet, and only skimmed through the other articles to get a gist. I'm not really qualified to judge the merit of a predictive algorithm even if I were to read through everything anyway. Hopefully somebody is capable of enlightening me as well as the future interested parties.",,False,self,t5_2r3gv,False,,,True,t3_1hlpz9,http://www.reddit.com/r/MachineLearning/comments/1hlpz9/came_across_something_intriguing_called_grey/,
1367820356.0,17,self.MachineLearning,1ds1dh,Intutive difference between Hidden Markov Models and Conditional Random Field?,22,5,3,http://www.reddit.com/r/MachineLearning/comments/1ds1dh/intutive_difference_between_hidden_markov_models/,"

I understand that HMM are generative models, and CRF are discriminative models. I also understand how CRFs' are designed and used. What I do not understand is how they are different from HMMs'? I read that in the case of HMM, we can only model our next state on the previous node, current node, and transition probability, but in the case of CRFs' we can do this, and can connect an arbitrary number of nodes together to form dependencies or contexts? Am I correct here?
",,False,self,t5_2r3gv,False,,,True,t3_1ds1dh,http://www.reddit.com/r/MachineLearning/comments/1ds1dh/intutive_difference_between_hidden_markov_models/,
1361774422.0,20,norvigaward.github.com,196hsc,Traitor - associating Concepts using the World Wide Web - Norvig Web Data Science Award Winner,24,4,4,http://www.reddit.com/r/MachineLearning/comments/196hsc/traitor_associating_concepts_using_the_world_wide/,,,False,http://e.thumbs.redditmedia.com/l09cLQ04TQiwjiM4.jpg,t5_2r3gv,False,,,False,t3_196hsc,http://norvigaward.github.com/entries.html#naward13,
1360581540.0,22,self.MachineLearning,18ay0g,What is the current state of artificial creativity?,26,4,23,http://www.reddit.com/r/MachineLearning/comments/18ay0g/what_is_the_current_state_of_artificial_creativity/,"I have no idea how are the developments in this area, and I'm willing to try emulating creativity (literature, music, painting... etc).",,False,self,t5_2r3gv,False,,,True,t3_18ay0g,http://www.reddit.com/r/MachineLearning/comments/18ay0g/what_is_the_current_state_of_artificial_creativity/,
1359681224.0,20,blog.newsle.com,17nzv9,Text Classification and Feature Hashing: Sparse Matrix-Vector Multiplication with Cython,27,7,5,http://www.reddit.com/r/MachineLearning/comments/17nzv9/text_classification_and_feature_hashing_sparse/,,,False,http://b.thumbs.redditmedia.com/3ykxiAlJlDj2r2OU.jpg,t5_2r3gv,False,,,False,t3_17nzv9,http://blog.newsle.com/2013/02/01/text-classification-and-feature-hashing-sparse-matrix-vector-multiplication-with-cython/,
1356732932.0,21,masi.cscs.lsa.umich.edu,15le9i,Learning spatio-temporal dynamics.,27,6,3,http://www.reddit.com/r/MachineLearning/comments/15le9i/learning_spatiotemporal_dynamics/,,,False,http://a.thumbs.redditmedia.com/zkJ31dI3kxF-NmsZ.jpg,t5_2r3gv,False,,,False,t3_15le9i,http://masi.cscs.lsa.umich.edu/~crshalizi/weblog/988.html,
1355371696.0,20,self.MachineLearning,14rmwg,Andrew Ng's class vs Tom Mitchell's class,28,8,10,http://www.reddit.com/r/MachineLearning/comments/14rmwg/andrew_ngs_class_vs_tom_mitchells_class/,"I am a sophomore in CS and have taken Thrun's Intro to AI. I have good basics in linear algebra, probability and some basic stats. I want to take a ML class to learn about Machine Learning techniques to a point where it is intuitive and I can actually apply the techniques if I choose to work in a ML lab. 


The most popular class seems to be Andrew Ng's ML class. I also came across CMU's Tom Mitchell's ML class. I'd like your opinion on which class would give me an intuitive understanding of the techniques in ML and prepare me to start off with research in ML. There are many labs doing AI and ML at the school I go to.

Here's the link to Tom Mitchell's class videos and assignments: https://www.cs.cmu.edu/~tom/10701_sp11/lectures.shtml

[EIDT] Sorry I should have made it clear that I am looking at Andrew Ng's Stanford class that was taken by Stanford students. They are lecture videos. I prefer this as many people have said the Coursera class is dumbed down.",,False,self,t5_2r3gv,1355378912.0,,,True,t3_14rmwg,http://www.reddit.com/r/MachineLearning/comments/14rmwg/andrew_ngs_class_vs_tom_mitchells_class/,
1338717558.0,20,self.MachineLearning,uig6o,"Functional Programming as an alternative to Octave, R, Julia",28,8,48,http://www.reddit.com/r/MachineLearning/comments/uig6o/functional_programming_as_an_alternative_to/,"While reading articles about pros and cons of programming languages for statisticians and researchers I never came across anyone, who would suggest Functional Programming instead of Octave or R and I'm trying to understand myself, whether it's because of Octave/R shine so much in the field of quickly prototyping some algorithms or maybe those, who compare Octave, R and Julia simply don't have any background in other types of programming.

Even Professor Andrew Ng from Stanford University (Machine Learning Class) suggests prototyping in Octave and then re-implementing in more general purpose programming languages such as C/C++ or Java for better performance. But how about using let's say Scala programming language for both prototyping and production implementations?

I'm asking this question, because I use Scala myself and I find it to be very good language for both prototyping and production ready systems. Most of the programming assignments for Probabilistic Graphical Models Course given by Professor Daphne Koller, I believe it would be much easier and faster to develop in Scala rather than in Octave, with the goodness of map, flatMap, reduce, prod and sum Scala functions, and an ability to use object oriented programming for data representation instead of putting everything into Octave matrices. (Scala is both object oriented and functional programming language).

I would like to hear some opinions here from someone with an experience in both Scala (or other functional/object oriented programming language) and R/Octave. I'm considering learning R myself or simply prototyping in Octave instead of still using Scala but I'm trying to find a good justification for it.

For this question I'm asking about the pure programming language and not the availability of some stats packages where R rocks.

Thank you for any comments.",,False,self,t5_2r3gv,False,,,True,t3_uig6o,http://www.reddit.com/r/MachineLearning/comments/uig6o/functional_programming_as_an_alternative_to/,
1337617388.0,20,technologyreview.com,txofc,Is There Big Money in Big Data? - Technology Review,33,13,36,http://www.reddit.com/r/MachineLearning/comments/txofc/is_there_big_money_in_big_data_technology_review/,,,False,http://a.thumbs.redditmedia.com/OGgrMj3wgGViOpm0.jpg,t5_2r3gv,False,,,False,t3_txofc,http://www.technologyreview.com/business/40320/,
1334232380.0,20,self.MachineLearning,s61mr,Are there any recent books which contain info on deep learning?,20,0,17,http://www.reddit.com/r/MachineLearning/comments/s61mr/are_there_any_recent_books_which_contain_info_on/,"By recent I mean the ones which incorporate the discoveries from 2006 papers by Hinton et al.
The only one which I know is ""Neural Networks and Learning Machines (3rd Edition)"" by Simon Haykin, which was published in 2008.",,False,self,t5_2r3gv,False,,,True,t3_s61mr,http://www.reddit.com/r/MachineLearning/comments/s61mr/are_there_any_recent_books_which_contain_info_on/,
1333777702.0,18,self.MachineLearning,rxjdt,Homework advice - Clustering w/o K-Means?,21,3,46,http://www.reddit.com/r/MachineLearning/comments/rxjdt/homework_advice_clustering_wo_kmeans/,"Hello all,
I'm working on a data mining project that ends with me clustering bag-of-words type data. 

The majority of the project so far has been pre-processing (the data is an awesome web-crawled data set of tweets from middle eastern countries during the arab spring!). I have a dictionary made of word counts, so I can assign some sort of weight to each word. 

I'm getting to the point now where I need to actually cluster the data. The vectors are very sparse (each feature is a word :/ Maybe I should try something else for this? Kernel method to map it onto some subspace??) After alllll the work I've done preprocessing rough, incomplete, arabic/french/english mixtures of tweets I feel like I've got to find SOME algorithm that's more complicated than the k-means that the professor spoon fed us. 

Any thoughts? If anyone knows of an algorithm that's particularly good on sparse data, I will upvote you and your family.",,False,self,t5_2r3gv,False,,,True,t3_rxjdt,http://www.reddit.com/r/MachineLearning/comments/rxjdt/homework_advice_clustering_wo_kmeans/,
1333609019.0,20,self.MachineLearning,rubew,Machine Learning with Python,23,3,13,http://www.reddit.com/r/MachineLearning/comments/rubew/machine_learning_with_python/,"(xpost from [/r/learnprogramming](/r/learnprogramming) because I hadn't known this subreddit existed)

Hi, so I'm trying to learn how to use Orange with python to do data comparisons, and machine learning to make educated predictions and would be grateful if i could be pointed into the right direction for what I wanted to do. 

So to begin with, i'm trying to compare 2 sets of data, and see if one affects the other. For example, if i had the following data sets:

A = [1,2,3,2,1] 

B = [2,5,8,1,3] 

C = [10,14,16,14,10]

Is there some kind of analysis that could be done, where Orange could figure out that A and C are similar, as they increase and decrease at the same points? I'm hoping to be able to identify that C is closer to A than B in that regard, and then, say if C had another value given, be able to predict what the new value in A was.

I'm currently still following the tutorials found on the Orange site , but, I feel like i still may not know how to approach my problem at the end.
If anyone knows how to go about this, do you think you could point out some functions or classes I should be looking into?

Would it be better to do this with something other than Orange? such as PyBrain or PyML?",,False,self,t5_2r3gv,False,,,True,t3_rubew,http://www.reddit.com/r/MachineLearning/comments/rubew/machine_learning_with_python/,
1332499752.0,20,self.MachineLearning,r9t7j,Under what conditions would it be logical to choose SVM over Boosted Regression Trees (BRT) or CART?,21,1,15,http://www.reddit.com/r/MachineLearning/comments/r9t7j/under_what_conditions_would_it_be_logical_to/,"I've studied both to some degree and to the extent I've used them I always seem to end up using BRT or Boosted Cart.   

The subspace and and subset techniques, and a small learning rate, seem to make what would seem a recipe for overfitting, due to univariate partitioning, work well(1) and I don't have to normalize data or worry to much about missing features like I do for SVM(2) nor do I have try and divine the optimal C or the best Kernal etc.  I imagine that SVM is better when the number of observations are really small but beyond that I just haven't seen it yet.  

I imagine that there's a whole world of specialized kernels for special problems but for I don't see the point of SVM for typical generic supervised learning problems. 

Flame away.


1) I had thousands of features.  I used the max squares stat used to select the variable at each node to show me which features BRT had deemed important.  Then I took just the top ones (e.g. 20 to 50 of features) and retrained getting almost the same test set ROC.  In fact, most of the time the original kitcken sink model worked better (insignificantly but it was consistent)

2) - Example: One of my features was a standard deviation of the size of some found defect but sometimes, i.e. for some observations, there were no such defects so there was no std. dev.  For BRT I just put in a flag value (e.g. -1) but for SVM I'm not sure what I'd do.

**EDIT**

I guess my ultimate desire from this post is to get a rule of thumb as to when it might be preferable to use SVM (besides really small data sets).  Some of my best friends use SVM but when I ask them why the don't seem to be able to articulate any benefits and yet I know lots of people use them so I assume I must be missing something.",,False,self,t5_2r3gv,True,,,True,t3_r9t7j,http://www.reddit.com/r/MachineLearning/comments/r9t7j/under_what_conditions_would_it_be_logical_to/,
1330970057.0,21,medriscoll.com,qitet,The data science debate: domain expertise or machine learning?,27,6,1,http://www.reddit.com/r/MachineLearning/comments/qitet/the_data_science_debate_domain_expertise_or/,,,False,http://b.thumbs.redditmedia.com/w7FcIatg90Oygzrm.jpg,t5_2r3gv,False,,,False,t3_qitet,http://medriscoll.com/post/18784448854/the-data-science-debate-domain-expertise-or-machine,
1330290945.0,20,self.MachineLearning,q747d,"/r/ML, whats your current career, and how did you end up here?",23,3,45,http://www.reddit.com/r/MachineLearning/comments/q747d/rml_whats_your_current_career_and_how_did_you_end/,I'm trying to gauge the diversity of the /r/ML community. I see the range of interesting problems that are asked here everyday and am curious about what areas of application they are from. ,,False,self,t5_2r3gv,False,,,True,t3_q747d,http://www.reddit.com/r/MachineLearning/comments/q747d/rml_whats_your_current_career_and_how_did_you_end/,
1326721548.0,22,epjdatascience.com,oj9x5,"New open-access journal on data science, now accepting submissions",27,5,0,http://www.reddit.com/r/MachineLearning/comments/oj9x5/new_openaccess_journal_on_data_science_now/,,,False,http://f.thumbs.redditmedia.com/aKwRhPYuQNk0_bJe.jpg,t5_2r3gv,False,,,False,t3_oj9x5,http://www.epjdatascience.com/,
1318181092.0,22,self.MachineLearning,l65dm,How well do Support Vector Machines scale to very large training datasets?,22,0,56,http://www.reddit.com/r/MachineLearning/comments/l65dm/how_well_do_support_vector_machines_scale_to_very/,"I'm considering using a Support Vector Machine on a very large training set consisting of millions of rows of data, where each row will have hundreds of attributes (once the data is converted to a form suitable for a SVM).

Is it practical to train a SVM on such a large training set?  How long is it likely to take on a modern consumer-grade laptop?

Oh, also, I've been looking for a good pure-Java SVM library.  I found [SVM-JAVA](https://sites.google.com/site/postechdm/research/implementation/svm-java) but looking through its source code it isn't well written.

Can anyone recommend a good Java SVM library?",,False,self,t5_2r3gv,False,,,True,t3_l65dm,http://www.reddit.com/r/MachineLearning/comments/l65dm/how_well_do_support_vector_machines_scale_to_very/,
1316438990.0,21,github.com,kkg9c,Python implementation of Breiman's Random Forests,25,4,11,http://www.reddit.com/r/MachineLearning/comments/kkg9c/python_implementation_of_breimans_random_forests/,,,False,default,t5_2r3gv,False,,,False,t3_kkg9c,https://github.com/capitalk/treelearn,
1314136770.0,18,cran.r-project.org,js6sl,"RTextTools v1.3.1, a text classification toolkit, is finally available on CRAN",23,5,0,http://www.reddit.com/r/MachineLearning/comments/js6sl/rtexttools_v131_a_text_classification_toolkit_is/,,,False,default,t5_2r3gv,False,,,False,t3_js6sl,http://cran.r-project.org/web/packages/RTextTools/,
1311621768.0,22,arstechnica.com,izfw4,"Running high-performance neural networks on a ""gamer"" GPU",29,7,26,http://www.reddit.com/r/MachineLearning/comments/izfw4/running_highperformance_neural_networks_on_a/,,,False,http://thumbs.reddit.com/t3_izfw4.png,t5_2r3gv,False,,,False,t3_izfw4,http://arstechnica.com/science/news/2011/07/running-high-performance-neural-networks-on-a-gamer-gpu.ars,
1303241657.0,20,r-bloggers.com,gtu75,"How Kaggle competitors use R
",23,3,2,http://www.reddit.com/r/MachineLearning/comments/gtu75/how_kaggle_competitors_use_r/,,,False,http://thumbs.reddit.com/t3_gtu75.png,t5_2r3gv,False,,,False,t3_gtu75,http://www.r-bloggers.com/how-kaggle-competitors-use-r/,
1300976567.0,21,self.MachineLearning,gahph,New free MATLAB machine learning toolbox ,22,1,6,http://www.reddit.com/r/MachineLearning/comments/gahph/new_free_matlab_machine_learning_toolbox/,"Hi ML Reddit,

We’re a couple of machine learning enthusiasts who have been working for a few years on a MATLAB toolbox to help in our research and projects.  We finally put the effort in to make the toolbox more than a hobby (maybe somewhat respectable even), and we’re looking for some feedback…

The toolbox is currently in a free Beta, and we’d appreciate feedback from everyone who is interested in  machine learning with MATLAB.  Like I said, it’s completely free, and available [here](http://www.newfolderconsulting.com/prt).
Just sign up for a free account (we promise to never sell your e-mail address, and we won’t spam you).
You can get a sense for how the toolbox works by checking out [the quick start guide](http://www.newfolderconsulting.com/prtdoc/prtDocQuickStart.html).

We’ve decided that the toolbox will always be free for academic/educational use (we’re still deciding what to do for commercial use).
Although you do need MATLAB (later than 2009A) to use the toolbox, no additional MATLAB toolboxes (e.g., stats, optimization) are required.

Thanks in advance for your time, and if anyone has any questions please e-mail one of us:

* kenny@newFolderConsulting.com
* pete@newFolderConsulting.com

Or post on our [forum](http://www.newfolderconsulting.com/forum).

Thanks again,

-Kenny and Pete
",,False,self,t5_2r3gv,True,,,True,t3_gahph,http://www.reddit.com/r/MachineLearning/comments/gahph/new_free_matlab_machine_learning_toolbox/,
1300097787.0,20,r-bloggers.com,g3mfc,RStudio 0.92.44 Release: another great R IDE release...,22,2,0,http://www.reddit.com/r/MachineLearning/comments/g3mfc/rstudio_09244_release_another_great_r_ide_release/,,,False,http://thumbs.reddit.com/t3_g3mfc.png,t5_2r3gv,False,,,False,t3_g3mfc,http://www.r-bloggers.com/rstudio-0-92-44-release-try-it-you%E2%80%99ll-be-surprised/,
1297690723.0,20,mklab.iti.gr,fl47u,GPU-accelerated LIBSVM,21,1,2,http://www.reddit.com/r/MachineLearning/comments/fl47u/gpuaccelerated_libsvm/,,,False,http://thumbs.reddit.com/t3_fl47u.png,t5_2r3gv,False,,,False,t3_fl47u,http://mklab.iti.gr/project/GPU-LIBSVM,
1296472887.0,21,blog.stephenwolfram.com,fcbpa,"Jeopardy, IBM, and Wolfram",25,4,14,http://www.reddit.com/r/MachineLearning/comments/fcbpa/jeopardy_ibm_and_wolfram/,,,False,http://thumbs.reddit.com/t3_fcbpa.png,t5_2r3gv,False,,,False,t3_fcbpa,http://blog.stephenwolfram.com/2011/01/jeopardy-ibm-and-wolframalpha/,
1290257107.0,22,self.MachineLearning,e93dw,Hello /MachineLearning. I am hoping to get a Masters(and perhaps a PhD) in Machine Learning and was wondering if you can answer some questions.,26,4,48,http://www.reddit.com/r/MachineLearning/comments/e93dw/hello_machinelearning_i_am_hoping_to_get_a/,"First, what is seen as the difference between Machine Learning and Artificial Intelligence in academia? Has AI fallen into disrepute? 

Second, I believe that studying the brain is necessary in order to learn how to build AI systems. If a professor studies ""Neural Networks"", is that the same thing? I am interested in studying the entire brain(and nervous system). How far would that be from ""neural networks""?

Thirdly, does anyone have any information about ETH in Zurich? I am determined to go there, please send me a PM.

Edit:
Thanks for all the info everyone!",,False,self,t5_2r3gv,True,,,True,t3_e93dw,http://www.reddit.com/r/MachineLearning/comments/e93dw/hello_machinelearning_i_am_hoping_to_get_a/,
1290002491.0,18,detexifyblog.kirelabs.org,e7iby,Detexify Explained,21,3,0,http://www.reddit.com/r/MachineLearning/comments/e7iby/detexify_explained/,,,False,default,t5_2r3gv,False,,,False,t3_e7iby,http://detexifyblog.kirelabs.org/past/2009/7/19/detexify_explained/,
1288784296.0,20,metaoptimize.com,e0kko,MetaOptimize/Q+A: Good Machine Learning Blogs ,25,5,1,http://www.reddit.com/r/MachineLearning/comments/e0kko/metaoptimizeqa_good_machine_learning_blogs/,,,False,default,t5_2r3gv,False,,,False,t3_e0kko,http://metaoptimize.com/qa/questions/3163/good-machine-learning-blogs,
1279120434.0,19,online.wsj.com,cphms,Investment Firms Look to 'Artificial Intelligence' in Trade Decisions,21,2,15,http://www.reddit.com/r/MachineLearning/comments/cphms/investment_firms_look_to_artificial_intelligence/,,,False,http://thumbs.reddit.com/t3_cphms.png,t5_2r3gv,False,,,False,t3_cphms,http://online.wsj.com/article/SB10001424052748703834604575365310813948080.html?mod=WSJ_hps_MIDDLESecondNews,
1278367029.0,20,blog.steinberg.org,cm9k0,"Some of the near-term implications of AI: Autonomous Automobiles, Risk Analysis  and others.",22,2,1,http://www.reddit.com/r/MachineLearning/comments/cm9k0/some_of_the_nearterm_implications_of_ai/,,,False,http://thumbs.reddit.com/t3_cm9k0.png,t5_2r3gv,False,,,False,t3_cm9k0,http://blog.steinberg.org/?p=11,
1269868494.0,19,homepages.inf.ed.ac.uk,bjoph,Naive Bayes Classifiers: A fairly intuitive explanation of naive Bayes models.,23,4,7,http://www.reddit.com/r/MachineLearning/comments/bjoph/naive_bayes_classifiers_a_fairly_intuitive/,,,False,default,t5_2r3gv,False,,,False,t3_bjoph,http://homepages.inf.ed.ac.uk/keller/teaching/connectionism/lecture10_4up.pdf,
1263246565.0,21,cocosci.berkeley.edu,aoddy,Good reading list for Bayesian inference,22,1,0,http://www.reddit.com/r/MachineLearning/comments/aoddy/good_reading_list_for_bayesian_inference/,,,False,default,t5_2r3gv,False,,,False,t3_aoddy,http://cocosci.berkeley.edu/tom/bayes.html,
1256270693.0,20,self.MachineLearning,9wvz6,Machine Learning Algorithms,28,8,28,http://www.reddit.com/r/MachineLearning/comments/9wvz6/machine_learning_algorithms/,"Dear MachineLearning,

I'm a computer science student taking a course on algorithms. We are close to finishing covering the book we are using, Introduction to Analysis and Design of Algorithms by Anany Levitin. Since we have the class until December, the professor is currently open to suggestions of algorithms we would like him to discuss in class. I would love to seize this opportunity to learn of algorithms used in the AI and Machine Learning fields.

For example, I remember that in the Super Mario Bros. AI competition, the A* algorithm was used by almost everyone. It'd be interesting to discuss it and see why it was used.

Soooo, if some of you could suggest interesting algorithms and a brief example on where it's used, I would highly appreciate it.

Thank you!",,False,self,t5_2r3gv,False,,,True,t3_9wvz6,http://www.reddit.com/r/MachineLearning/comments/9wvz6/machine_learning_algorithms/,
1252062105.0,20,home.comcast.net,9h9ao,[Repost] Machine learning classifier gallery,23,3,2,http://www.reddit.com/r/MachineLearning/comments/9h9ao/repost_machine_learning_classifier_gallery/,,,False,default,t5_2r3gv,False,,,False,t3_9h9ao,http://home.comcast.net/~tom.fawcett/public_html/ML-gallery/pages/index.html,
1251709699.0,18,videolectures.net,9fsew,Dirichlet Processes: Tutorial and Practical Course,20,2,0,http://www.reddit.com/r/MachineLearning/comments/9fsew/dirichlet_processes_tutorial_and_practical_course/,,,False,http://thumbs.reddit.com/t3_9fsew.png,t5_2r3gv,False,,,False,t3_9fsew,http://videolectures.net/mlss07_teh_dp/,
1375904067.0,19,yaroslavvb.blogspot.com,1jwk4p,"Sometimes simplest learners are best -- a short article reporting results from a training algorithm showdown, plus bonus comic strip",23,4,4,http://www.reddit.com/r/MachineLearning/comments/1jwk4p/sometimes_simplest_learners_are_best_a_short/,,,False,http://c.thumbs.redditmedia.com/exzZEeZ8aLW4jCSJ.jpg,t5_2r3gv,False,,,False,t3_1jwk4p,http://yaroslavvb.blogspot.com/2010/10/sometimes-simplest-learners-are-best.html,
1375706892.0,17,compneurobio.wordpress.com,1jqj7o,Impressions from ICML 2013,21,4,1,http://www.reddit.com/r/MachineLearning/comments/1jqj7o/impressions_from_icml_2013/,,,False,http://d.thumbs.redditmedia.com/N_XlesLJr_RMRIy3.jpg,t5_2r3gv,False,,,False,t3_1jqj7o,http://compneurobio.wordpress.com/2013/07/30/impressions-from-icml-2013/,
1375705249.0,19,climin.readthedocs.org,1jqhyv,"climin; optimization, straight forward",23,4,1,http://www.reddit.com/r/MachineLearning/comments/1jqhyv/climin_optimization_straight_forward/,,,False,default,t5_2r3gv,False,,,False,t3_1jqhyv,http://climin.readthedocs.org/en/latest/,
1375109412.0,21,databozo.com,1ja1c3,Modeling complex cause &amp; effect with Bayesian Networks,21,0,0,http://www.reddit.com/r/MachineLearning/comments/1ja1c3/modeling_complex_cause_effect_with_bayesian/,,,False,default,t5_2r3gv,False,,,False,t3_1ja1c3,http://www.databozo.com/2013/07/28/Modeling_complex_cause_and_effect_with_Bayesian_Networks.html,
1374455885.0,19,blog.hackingevolution.net,1is796,Q: What is Evolutionary Computation Good For? A: A versatile form of computational learning,27,8,3,http://www.reddit.com/r/MachineLearning/comments/1is796/q_what_is_evolutionary_computation_good_for_a_a/,,,False,http://c.thumbs.redditmedia.com/dpoiBfei_IGW_pl8.jpg,t5_2r3gv,False,,,False,t3_1is796,http://blog.hackingevolution.net/2013/07/21/what-is-evolutionary-computation-good-for/,
1373518106.0,19,self.MachineLearning,1i27jd,Can you explain compressive sensing in a few words from a machine learning perspective?,22,3,27,http://www.reddit.com/r/MachineLearning/comments/1i27jd/can_you_explain_compressive_sensing_in_a_few/,"I've been reading about compressive sensing, looking at some tutorials / slides / papers.

All of the tutorials start with nyquist frequencies and other signal processing talk, treating samples as discrete frequency values. Couldn't find any papers that explain it from a non-DSP perspective.

**What I think I know:**

Most real data is sparse and that compressive sensing randomly samples your input with some (learnt?) bases to compress them to give an error bound that is extremely small.


**What I dont know but want to know:**

* If the bases are learnt, how are they learnt? Matrix factorization? Any very simple explanation on how its learnt? And maybe a link/paper for just understanding the learning process?

* How are the bases that are learnt in compressive sensing different from ones learnt from autoencoders (with sparsity enforced)? How are they different from kmeans centroids?

* If you can, can you explain how it is different in terms of one commonly used machine learning model? (so that it is easy to understand with a comparison)

* Are there any applications apart from reconstructing noisy data, saving bandwidth etc.? 

If you can answer any of these questions at all, or link to appropriate slides/blog entries etc. I'd be greatful. I took a look at some blog entries on Nuit Blanche. Thanks.

",,False,self,t5_2r3gv,False,,,True,t3_1i27jd,http://www.reddit.com/r/MachineLearning/comments/1i27jd/can_you_explain_compressive_sensing_in_a_few/,
1372837883.0,20,kickstarter.com,1hk07j,Artificial Intelligence for Humans - Fundamental Algorithms [KickStarter],37,17,4,http://www.reddit.com/r/MachineLearning/comments/1hk07j/artificial_intelligence_for_humans_fundamental/,,,False,http://d.thumbs.redditmedia.com/9DKBqM_URcfUzUdQ.jpg,t5_2r3gv,False,,,False,t3_1hk07j,http://www.kickstarter.com/projects/jeffheaton/artificial-intelligence-for-humans-vol-1-fund-algo,
1372658430.0,18,youtube.com,1hetj7,Jerome Friedman on the genesis of decision trees,19,1,0,http://www.reddit.com/r/MachineLearning/comments/1hetj7/jerome_friedman_on_the_genesis_of_decision_trees/,,,False,http://c.thumbs.redditmedia.com/VIJyyn-Y0qwxQr62.jpg,t5_2r3gv,False,,,False,t3_1hetj7,https://www.youtube.com/watch?feature=player_embedded&amp;v=8hupHmBVvb0,
1371485428.0,19,blog.mashape.com,1git9f,List of 15 Natural Language Processing (NLP) APIs,34,15,0,http://www.reddit.com/r/MachineLearning/comments/1git9f/list_of_15_natural_language_processing_nlp_apis/,,,False,default,t5_2r3gv,False,,,False,t3_1git9f,http://blog.mashape.com/post/48946187179/15-natural-language-processing-apis,
1370809612.0,19,self.MachineLearning,1g007h,"If anyone is interested here, a bunch of other Redditors and I are making a tournament for the awesome AI/programming game RoboCode!",26,7,7,http://www.reddit.com/r/MachineLearning/comments/1g007h/if_anyone_is_interested_here_a_bunch_of_other/,"You program robots to fight each other to the death!
If you're interested, join our Google+ community [here](https://plus.google.com/communities/103504002946783762633).

To learn more about RoboCode, look at the [IBM Developer Works](http://robocode.sourceforge.net/developerWorks.php) and the [robo wiki!](http://robowiki.net/)

RoboCode is beginner friendly and you don't really have to know much about Java to use it so if you're a beginner, feel free to join! 

We will begin have our first tournament on 6/23/13 so you should have your robot ready and join the community by that date!",,False,self,t5_2r3gv,False,,,True,t3_1g007h,http://www.reddit.com/r/MachineLearning/comments/1g007h/if_anyone_is_interested_here_a_bunch_of_other/,
1370117051.0,20,arxiv.org,1fhab8,"Language and Cultural Evolution As Supervised Learning of Deep Architectures (Bengio, 2013; PDF)",23,3,2,http://www.reddit.com/r/MachineLearning/comments/1fhab8/language_and_cultural_evolution_as_supervised/,,,False,default,t5_2r3gv,False,,,False,t3_1fhab8,http://arxiv.org/pdf/1203.2990.pdf,
1369163554.0,20,engineering.richrelevance.com,1es5o3,Bayesian A/B Tests - with Python code,25,5,0,http://www.reddit.com/r/MachineLearning/comments/1es5o3/bayesian_ab_tests_with_python_code/,,,False,http://c.thumbs.redditmedia.com/U35yWzPrs6IIfEg2.jpg,t5_2r3gv,False,,,False,t3_1es5o3,http://engineering.richrelevance.com/bayesian-ab-tests/#more-124,
1367264353.0,19,self.MachineLearning,1dcw4k,Alternatives to Bag of Words representation for text documents?,23,4,13,http://www.reddit.com/r/MachineLearning/comments/1dcw4k/alternatives_to_bag_of_words_representation_for/,"I've seen in literature and practice that most machine learning systems in the text domain use Bag-of-Words representation of data. Is this really the best option? 

I really think we can come up with something better, BOW is extremely naive and throws away a ton of useful information.",,False,self,t5_2r3gv,False,,,True,t3_1dcw4k,http://www.reddit.com/r/MachineLearning/comments/1dcw4k/alternatives_to_bag_of_words_representation_for/,
1364530390.0,19,self.MachineLearning,1b82s4,Requesting pros/cons of Python vs Matlab from people that are well experienced in both.  Thanks.,27,8,67,http://www.reddit.com/r/MachineLearning/comments/1b82s4/requesting_proscons_of_python_vs_matlab_from/,"Yes, I know Matlab isn't free but besides that.  I myself have a ton of experience in Matlab so I'm really looking for the other side from a people that know Matlab

This isn't just about language but rather libraries, debugging, IDE (what python IDE?), visualization, fielding as part of a C or Java app (as so often happens) etc",,False,self,t5_2r3gv,False,,,True,t3_1b82s4,http://www.reddit.com/r/MachineLearning/comments/1b82s4/requesting_proscons_of_python_vs_matlab_from/,
1363014456.0,20,snippyhollow.github.com,1a323a,Collapsed Gibbs Sampling for Dirichlet Process Gaussian Mixture Models,22,2,1,http://www.reddit.com/r/MachineLearning/comments/1a323a/collapsed_gibbs_sampling_for_dirichlet_process/,,,False,http://e.thumbs.redditmedia.com/EufZMdAN-NSiIUxv.jpg,t5_2r3gv,False,,,False,t3_1a323a,http://snippyhollow.github.com/blog/2013/03/10/collapsed-gibbs-sampling-for-dirichlet-process-gaussian-mixture-models/,
1361432076.0,19,refactorthis.net,18xz2e,Machine Learning: 5 examples of what it is and why you should care,35,16,7,http://www.reddit.com/r/MachineLearning/comments/18xz2e/machine_learning_5_examples_of_what_it_is_and_why/,,,False,http://d.thumbs.redditmedia.com/wlWAvZZUVcgSKH3E.jpg,t5_2r3gv,False,,,False,t3_18xz2e,http://www.refactorthis.net/post/2013/02/19/Machine-Learning-5-examples-of-what-it-is-and-why-you-should-care.aspx,
1358459101.0,19,deeplearning.stanford.edu,16ry1w,Good tutorial on Deep Belief Networks (and pre-reqs) put together by Andrew Ng and team.,25,6,5,http://www.reddit.com/r/MachineLearning/comments/16ry1w/good_tutorial_on_deep_belief_networks_and_prereqs/,,,False,default,t5_2r3gv,False,,,False,t3_16ry1w,http://deeplearning.stanford.edu/wiki/index.php/Main_Page,
1353445104.0,19,seanjtaylor.com,13j0y7,Optimal Descriptive NFL Rankings,24,5,2,http://www.reddit.com/r/MachineLearning/comments/13j0y7/optimal_descriptive_nfl_rankings/,,,False,default,t5_2r3gv,False,,,False,t3_13j0y7,http://seanjtaylor.com/post/36149816687/optimal-descriptive-nfl-rankings,
1345244554.0,17,inference.phy.cam.ac.uk,yehhg,"Information Theory, Pattern Recognition, and Neural Networks: class from David MacKay",20,3,5,http://www.reddit.com/r/MachineLearning/comments/yehhg/information_theory_pattern_recognition_and_neural/,,,False,default,t5_2r3gv,False,,,False,t3_yehhg,http://www.inference.phy.cam.ac.uk/itprnn_lectures/,
1342029470.0,18,blog.explainmydata.com,we90i,Should you apply PCA to your data?,23,5,9,http://www.reddit.com/r/MachineLearning/comments/we90i/should_you_apply_pca_to_your_data/,,,False,default,t5_2r3gv,False,,,False,t3_we90i,http://blog.explainmydata.com/2012/07/should-you-apply-pca-to-your-data.html,
1340496439.0,19,self.MachineLearning,vi53w,Out of my league at SeaTac...,32,13,7,http://www.reddit.com/r/MachineLearning/comments/vi53w/out_of_my_league_at_seatac/,"Hey /r/machinelearning! I was reading the ""nicest celebrities"" thread on AskReddit, but I figured my story should probably go here instead, considering it's kind of a niche thing.

About a month ago, I was leaving Seattle after an interview (just graduated college in CS) and I decided to grab a beer at the bar.  As I was joking with the bartender, an older gentleman sat down next to me and we started talking.  At some point he mentions to the bartender that he has a PhD in Math and Computer Science, so naturally I'm interested and mention that I'm graduating.  He mentions that his company is involved in statistical programing.

Immediately I ask ""oh, so do you do a lot of work with R?""

Nope.

This guy was none other than Tom Lehman, the director of the SAS Advanced Analytics lab.  Whoops.  Turns out he had been in Seattle on business, and he had been meeting with the board of directors of *Nordstrom*.

After a bit of a talk about life and stuff, he gave me his card and mentioned that if I ended up in machine learning, to give him a call.  Finished his beer and left for his flight.  All around class-act kinda guy.  He also spent a lot of time talking up SAS itself, and left me with a business card.

Just a fun story, I suppose.  I really wish I was more into ML (or fly fishing) so we could've had more to talk about, but all in all, great guy, and although I ended up taking another job, for awhile I seriously considered applying at SAS.

Cool story, huh? ",,False,self,t5_2r3gv,False,,,True,t3_vi53w,http://www.reddit.com/r/MachineLearning/comments/vi53w/out_of_my_league_at_seatac/,
1338643176.0,20,wkiri.com,uh4lq,Machine Learning that Matters - position paper from upcoming ICML,30,10,23,http://www.reddit.com/r/MachineLearning/comments/uh4lq/machine_learning_that_matters_position_paper_from/,,,False,default,t5_2r3gv,False,,,False,t3_uh4lq,http://www.wkiri.com/research/papers/wagstaff-MLmatters-12.pdf,
1337041868.0,17,self.MachineLearning,tncod,Books on probabilistic reasoning?,19,2,31,http://www.reddit.com/r/MachineLearning/comments/tncod/books_on_probabilistic_reasoning/,"I was looking to read on this topic (and Bayesian inference in general) but wonder if J. Pearl's more recent book on causality supersedes his seminal work, _Probabilistic Reasoning in Intelligent Systems_ (or is that still book relevant in its timeless form?). Also, would appreciate other books that might be relevant for someone with an applied science/engineering background. Thanks!",,False,self,t5_2r3gv,1337063206.0,,,True,t3_tncod,http://www.reddit.com/r/MachineLearning/comments/tncod/books_on_probabilistic_reasoning/,
1336924621.0,18,icml.cc,tl24u,ICML 2012 – Accepted papers,23,5,6,http://www.reddit.com/r/MachineLearning/comments/tl24u/icml_2012_accepted_papers/,,,False,default,t5_2r3gv,False,,,False,t3_tl24u,http://icml.cc/2012/papers/,
1336574300.0,18,scikit-learn.org,teqi6,scikit-learn: machine learning in Python,28,10,6,http://www.reddit.com/r/MachineLearning/comments/teqi6/scikitlearn_machine_learning_in_python/,,,False,default,t5_2r3gv,False,,,False,t3_teqi6,http://scikit-learn.org/,
1335302999.0,19,blog.bigml.com,sqm8m,Machine Learning in Action: Interactive Model Gallery ,25,6,0,http://www.reddit.com/r/MachineLearning/comments/sqm8m/machine_learning_in_action_interactive_model/,,,False,http://c.thumbs.redditmedia.com/CGn2d8pE5d2T45ih.jpg,t5_2r3gv,False,,,False,t3_sqm8m,http://blog.bigml.com/2012/04/24/machine-learning-in-action-interactive-model-gallery/,
1332318882.0,18,self.MachineLearning,r6i99,Proper method for Calculating Similarity Between Two Similarity Matrices?,20,2,8,http://www.reddit.com/r/MachineLearning/comments/r6i99/proper_method_for_calculating_similarity_between/,"We want to calculate how similar two *similarity* matrices are. First of all I clarify some points. We have two similarity matrices which contain same set of items for which we gather information from two different sources.

You can assume that similarity matrices contain pairwise closeness of two people. These closeness values come from two different sources such as Facebook and MySpace.

Let's give you an example to illustrate what I want to say.

We have 4 people: John, Paul, George, Ringo. All they have Facebook and MySpace accounts.

From their Facebook profiles, we made some processing and somehow we evaluated the closeness of these people as follows.

* Paul - John = 0.5
* Paul - George = 0.4
* Paul - Ringo = 0.6
* John - George = 0.6
* John - Ringo = 0.5
* George - Ringo = 0.6

From MySpace,

* Paul - John = 0.2
* Paul - George = 0.3
* Paul - Ringo = 0.4
* John - George = 0.2
* John - Ringo = 0.1
* George - Ringo = 0.15

From informations above, we can easily create two matrices both of which are symmetric with respect to the main diagonal. Our ultimate goal is to calculate how similar these two matrices are.

1- What if I align all those values (of course only one triangular for each matrix) in one row (like below) and simply evaluate Pearson Correlation Coefficient between
these rows?

* facebook = [0.5, 0.4, 0.6, 0.6, 0.5, 0.6]
* myspace  = [0.2, 0.3, 0.4, 0.2, 0.1, 0.15]

You may have noticed that these similarities are **not independent** of each other. So, is it enough or appropriate method to calculate similarity between two matrices?
According to an article named Mandel Test on [Wikipedia](http://en.wikipedia.org/wiki/Mantel_test) this simple procedure is not appropriate.

&gt;Because distances are not independent of each other – since changing the ""position"" of one object would change n − 1 of these distances (the distance from that object to each of the others) – we can't assess the relationship between the two matrices by simply evaluating the correlation coefficient between the two sets of distances and testing its statistical significance. The Mantel test deals with this problem.

2- How about the rank correlation techniques such as Kendall?

3- Is there more specific or proper technique to evaluate this? 

4- Mantel Test calculates correlation between two matrices. It seems it is proper for our purpose. I will read [Spatial Analysis in Ecology - Mantel's Test](http://www.nceas.ucsb.edu/scicomp/Dloads/SpatialAnalysisEcologists/SpatialEcologyMantelTest.pdf) which can be reached by Wikipedia but could anyone who use this method for same reason share his/her experience?",,False,self,t5_2r3gv,True,,,True,t3_r6i99,http://www.reddit.com/r/MachineLearning/comments/r6i99/proper_method_for_calculating_similarity_between/,
1330708400.0,20,stiglerdiet.com,qenw0,The Spelling Corrector that Got Me Interested in Machine Learning,24,4,1,http://www.reddit.com/r/MachineLearning/comments/qenw0/the_spelling_corrector_that_got_me_interested_in/,,,False,http://d.thumbs.redditmedia.com/UNhg_Ivlcn9MxJl-.jpg,t5_2r3gv,False,,,False,t3_qenw0,http://www.stiglerdiet.com/2012/03/02/the-spelling-corrector-that-got-me-interested-in-machine-learning/,
1330114489.0,18,ipam.ucla.edu,q4i11,"Graduate Summer School: Deep Learning, Feature Learning (July 9-27)",21,3,1,http://www.reddit.com/r/MachineLearning/comments/q4i11/graduate_summer_school_deep_learning_feature/,,,False,http://d.thumbs.redditmedia.com/bUhx81wd2WsD-9ii.jpg,t5_2r3gv,False,,,False,t3_q4i11,http://www.ipam.ucla.edu/programs/gss2012/,
1328489882.0,17,self.MachineLearning,pcia7,How to improve RTextTools?,21,4,10,http://www.reddit.com/r/MachineLearning/comments/pcia7/how_to_improve_rtexttools/,"I'm one of the authors of RTextTools: a free, open source machine learning package for semi-automated text classification. I've been working with social scientists and software engineers during the past year to create a simple yet functional R package to categorize text documents into discrete categories.

I'm sure there are statistical methods that haven't been implemented in RTextTools that could improve functionality and accuracy. I'd really appreciate if you could test the package ( in R 2.14+, *install.packages(""RTextTools"")* ) and provide some feedback. Thank you in advance for your help!

**EDIT:** If you'd like more details, RTextTools has a [website](http://www.rtexttools.com/).",,False,self,t5_2r3gv,True,,,True,t3_pcia7,http://www.reddit.com/r/MachineLearning/comments/pcia7/how_to_improve_rtexttools/,
1326992979.0,19,wired.com,onhax,Air Force's Top Brain Wants a 'Social Radar' to 'See Into Hearts and Minds',20,1,2,http://www.reddit.com/r/MachineLearning/comments/onhax/air_forces_top_brain_wants_a_social_radar_to_see/,,,False,default,t5_2r3gv,False,,,False,t3_onhax,http://www.wired.com/dangerroom/2012/01/social-radar-sees-minds/,
1326178394.0,18,self.MachineLearning,oajwo,Data Analyst/Data Scientist/Data Miner/etc job salaries,21,3,20,http://www.reddit.com/r/MachineLearning/comments/oajwo/data_analystdata_scientistdata_mineretc_job/,"Hi /r/ML. I am graduating soon with my Ph.D. in ml/data mining, and I've been looking around for jobs. A lot of companies advertise ""competitive salaries"", and I was wondering if people here wouldn't mind giving me an idea of what that means.

For instance if someone is advertising a ""competitive salary"" in San Franciso, does that mean $50k / year? 80k? 100k? What about NYC? San Diego? Seattle? etc?

Non US-redditors what are the salaries in Europe/Asia/Australia/etc like?

Hopefully this question doesn't offend anyone, I'm just trying to gauge when a company is actually offering me what they claim, i.e., a competitive salary, and I think such knowledge is a great tool for new grads. Thanks!

**EDIT** If you don't feel comfortable saying your salary/giving knowledge under your main, throw aways are a great resource.",,False,self,t5_2r3gv,True,,,True,t3_oajwo,http://www.reddit.com/r/MachineLearning/comments/oajwo/data_analystdata_scientistdata_mineretc_job/,
1324767007.0,18,people.seas.harvard.edu,npkdb,"Interesting paper on the relationship between information, boosting, and philosophy",26,8,2,http://www.reddit.com/r/MachineLearning/comments/npkdb/interesting_paper_on_the_relationship_between/,,,False,default,t5_2r3gv,False,,,False,t3_npkdb,http://people.seas.harvard.edu/~ely/ThingsThatStartWithB.pdf,
1317667565.0,17,pyevolve.sourceforge.net,kzm77,Text feature extraction (tf-idf) - Part II,20,3,8,http://www.reddit.com/r/MachineLearning/comments/kzm77/text_feature_extraction_tfidf_part_ii/,,,False,http://thumbs.reddit.com/t3_kzm77.png,t5_2r3gv,False,,,False,t3_kzm77,http://pyevolve.sourceforge.net/wordpress/?p=1747,
1314911268.0,19,reddit.com,k1pyu,"Just a little exposure, if you like vast fields of data  with semantic data in it, you might want to check out /r/SemanticWeb",22,3,0,http://www.reddit.com/r/MachineLearning/comments/k1pyu/just_a_little_exposure_if_you_like_vast_fields_of/,,,False,http://thumbs.reddit.com/t3_k1pyu.png,t5_2r3gv,False,,,False,t3_k1pyu,http://www.reddit.com/r/semanticweb/,
1311751973.0,19,citeseerx.ist.psu.edu,j0yss,"What is your opinion on Probabilistic Boosting Trees? In particular, how do they compare with SVM?",22,3,5,http://www.reddit.com/r/MachineLearning/comments/j0yss/what_is_your_opinion_on_probabilistic_boosting/,,,False,default,t5_2r3gv,False,,,False,t3_j0yss,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.92.4511&amp;rep=rep1&amp;type=pdf,
1311190084.0,21,math.umaine.edu,iv3m8,The GMDH algorithm (pdf),23,2,3,http://www.reddit.com/r/MachineLearning/comments/iv3m8/the_gmdh_algorithm_pdf/,,,False,default,t5_2r3gv,False,,,False,t3_iv3m8,http://www.math.umaine.edu/~farlow/gmdh%20in%20pdf.pdf,
1307305720.0,18,quora.com,hsbfj,"Quora :""What are some introductory resources for learning about Large Scale machine learning?""",25,7,0,http://www.reddit.com/r/MachineLearning/comments/hsbfj/quora_what_are_some_introductory_resources_for/,,,False,default,t5_2r3gv,False,,,False,t3_hsbfj,http://www.quora.com/Machine-Learning/What-are-some-introductory-resources-for-learning-about-large-scale-machine-learning,
1304620356.0,18,blog.echen.me,h502x,"Building a TWSS Classifier, Applying it to Fairy Tales",20,2,0,http://www.reddit.com/r/MachineLearning/comments/h502x/building_a_twss_classifier_applying_it_to_fairy/,,,False,http://thumbs.reddit.com/t3_h502x.png,t5_2r3gv,False,,,False,t3_h502x,http://blog.echen.me/2011/05/05/twss-building-a-thats-what-she-said-classifier/,
1302976912.0,18,sites.google.com,grkfk,Rank is an open source project consisting of various Machine Learning algorithms which uses Regression Trees,21,3,0,http://www.reddit.com/r/MachineLearning/comments/grkfk/rank_is_an_open_source_project_consisting_of/,,,False,default,t5_2r3gv,False,,,False,t3_grkfk,https://sites.google.com/site/rtranking/home,
1297428224.0,21,arxiv.org,fjer2,From Machine Learning to Machine Reasoning,24,3,1,http://www.reddit.com/r/MachineLearning/comments/fjer2/from_machine_learning_to_machine_reasoning/,,,False,default,t5_2r3gv,False,,,False,t3_fjer2,http://arxiv.org/abs/1102.1808,
1292602616.0,21,self.MachineLearning,engmb,Redditors: Let me know your preferred data mining software,22,1,25,http://www.reddit.com/r/MachineLearning/comments/engmb/redditors_let_me_know_your_preferred_data_mining/,"For data prediction (not statistical analysis) which one is your favourite and preferred tool: Weka vs R vs IBM SPSS.

Or do you have any other personal favourite?",,False,self,t5_2r3gv,False,,,True,t3_engmb,http://www.reddit.com/r/MachineLearning/comments/engmb/redditors_let_me_know_your_preferred_data_mining/,
1291897473.0,19,reddit.com,eiw2w,"/r/datasets/ - Datasets for Data Mining, Analytics and Knowledge Discovery",20,1,1,http://www.reddit.com/r/MachineLearning/comments/eiw2w/rdatasets_datasets_for_data_mining_analytics_and/,,,False,default,t5_2r3gv,False,,,False,t3_eiw2w,http://www.reddit.com/r/datasets/,
1291215815.0,19,junauza.com,eeiup,5 of the Best Free Data Mining Software,20,1,9,http://www.reddit.com/r/MachineLearning/comments/eeiup/5_of_the_best_free_data_mining_software/,,,False,http://thumbs.reddit.com/t3_eeiup.png,t5_2r3gv,False,,,False,t3_eeiup,http://www.junauza.com/2010/11/free-data-mining-software.html,
1286471598.0,18,dataists.com,do56r,Contest to build an R package recommendation engine,19,1,0,http://www.reddit.com/r/MachineLearning/comments/do56r/contest_to_build_an_r_package_recommendation/,,,False,default,t5_2r3gv,False,,,False,t3_do56r,http://www.dataists.com/2010/10/using-data-tools-to-find-data-tools-the-yo-dawg-of-data-hacking/,
1285457822.0,18,dataists.com,diwg1,A Taxonomy of Data Science,21,3,3,http://www.reddit.com/r/MachineLearning/comments/diwg1/a_taxonomy_of_data_science/,,,False,default,t5_2r3gv,False,,,False,t3_diwg1,http://www.dataists.com/2010/09/a-taxonomy-of-data-science/,
1282639639.0,21,boston.com,d4rm9,How do we choose a mate? What data scientists are learning from online dating,22,1,1,http://www.reddit.com/r/MachineLearning/comments/d4rm9/how_do_we_choose_a_mate_what_data_scientists_are/,,,False,http://thumbs.reddit.com/t3_d4rm9.png,t5_2r3gv,False,,,False,t3_d4rm9,http://www.boston.com/bostonglobe/ideas/articles/2010/08/22/data_mining_the_heart/?page=1,
1280851515.0,19,dbs.ifi.lmu.de,cwvv4,Clustering techniques for outlier detection - Tutorial from ACM SIGKDD 2010 (PDF),21,2,2,http://www.reddit.com/r/MachineLearning/comments/cwvv4/clustering_techniques_for_outlier_detection/,,,False,default,t5_2r3gv,False,,,False,t3_cwvv4,http://www.dbs.ifi.lmu.de/~zimek/publications/KDD2010/kdd10-outlier-tutorial.pdf,
1279447115.0,19,self.MachineLearning,cquuu,Please recommend a good book on Genetic Algorithms.,25,6,6,http://www.reddit.com/r/MachineLearning/comments/cquuu/please_recommend_a_good_book_on_genetic_algorithms/,"I found these but I don't know how they are:

* Genetic Algorithms in Search, Optimization, and Machine Learning by David E. Goldberg 

* An Introduction to Genetic Algorithms by Melanie Mitchell

* Practical Genetic Algorithms by Randy L. Haupt and Sue Ellen Haup",,False,self,t5_2r3gv,False,,,True,t3_cquuu,http://www.reddit.com/r/MachineLearning/comments/cquuu/please_recommend_a_good_book_on_genetic_algorithms/,
1275661319.0,20,videolectures.net,cbfaz,"Introduction to spectral clustering, a very nice 50m talk",21,1,1,http://www.reddit.com/r/MachineLearning/comments/cbfaz/introduction_to_spectral_clustering_a_very_nice/,,,False,http://thumbs.reddit.com/t3_cbfaz.png,t5_2r3gv,False,,,False,t3_cbfaz,http://videolectures.net/mlcued08_azran_mcl/,
1269444375.0,19,mloss.org,bhm99,Python lib for rule extraction,19,0,2,http://www.reddit.com/r/MachineLearning/comments/bhm99/python_lib_for_rule_extraction/,,,False,http://thumbs.reddit.com/t3_bhm99.png,t5_2r3gv,False,,,False,t3_bhm99,http://mloss.org/software/view/239/,
1266135643.0,17,petewarden.typepad.com,b1vh6,Splitting up the USA: clustering 210 million Facebook profiles,23,6,7,http://www.reddit.com/r/MachineLearning/comments/b1vh6/splitting_up_the_usa_clustering_210_million/,,,False,http://thumbs.reddit.com/t3_b1vh6.png,t5_2r3gv,False,,,False,t3_b1vh6,http://petewarden.typepad.com/searchbrowser/2010/02/how-to-split-up-the-us.html,
1262815090.0,20,stats202.com,amfji,data mining course (same one as given at Stanford as stats 202) - look for video links towards the bottom,20,0,0,http://www.reddit.com/r/MachineLearning/comments/amfji/data_mining_course_same_one_as_given_at_stanford/,,,False,default,t5_2r3gv,False,,,False,t3_amfji,http://stats202.com/,
1262626193.0,21,analyticsx.com,alg6f,Analytics X Prize,23,2,7,http://www.reddit.com/r/MachineLearning/comments/alg6f/analytics_x_prize/,,,False,http://thumbs.reddit.com/t3_alg6f.png,t5_2r3gv,False,,,False,t3_alg6f,http://analyticsx.com/,
1261364422.0,21,cs.toronto.edu,agwos,Probabilistic Matrix Factorization for CF which scales linearly and performs well on very imbalanced and sparse datasets.,21,0,1,http://www.reddit.com/r/MachineLearning/comments/agwos/probabilistic_matrix_factorization_for_cf_which/,,,False,default,t5_2r3gv,False,,,False,t3_agwos,http://www.cs.toronto.edu/~rsalakhu/papers/nips07_pmf.pdf,
1249237514.0,17,self.MachineLearning,96v74,"Hi Machine Learning enthusiasts, if 
you were to design a ""Subreddit 
Suggestion"" for Reddit , what 
methods would you use?",21,4,19,http://www.reddit.com/r/MachineLearning/comments/96v74/hi_machine_learning_enthusiasts_if_you_were_to/,"We have ""Suggest a Title"" for our links. But if you were to design a ""Suggest a Subreddit"" that  suggested an appropriate subreddit for your document, how would you develop that classifier?
If you refer to a paper, please provide a link to the original paper also. Thanks.",,False,self,t5_2r3gv,True,,,True,t3_96v74,http://www.reddit.com/r/MachineLearning/comments/96v74/hi_machine_learning_enthusiasts_if_you_were_to/,
1375946265.0,19,nature.com,1jxy2f,"New single unit recordings suggest that prefrontal cortex uses something like ""the kernel trick"" of support vector machines. [xpost form /r/neuro]",27,8,16,http://www.reddit.com/r/MachineLearning/comments/1jxy2f/new_single_unit_recordings_suggest_that/,,,False,default,t5_2r3gv,False,,,False,t3_1jxy2f,http://www.nature.com/nature/journal/vaop/ncurrent/full/nature12160.html,
1375457457.0,19,self.MachineLearning,1jkhg2,How can an ensemble of predictive models provide better predictions than any individual model in the ensemble?,24,5,30,http://www.reddit.com/r/MachineLearning/comments/1jkhg2/how_can_an_ensemble_of_predictive_models_provide/,"Consider a situation where we have 99 mediocre predictive models, and 1 good one.  The models are tasked with predicting the probability of a particular classification.  We combine the model's predictions by averaging them to obtain the ensemble's prediction.

Wouldn't the 99 bad models (which will produce probabilities closer to the global probability of that classification) drag the prediction of the good model back towards the global mean - making it a worse prediction?

Or should I be using something other than averaging to combine these probabilities?

**edit:** Lots of people are suggesting that I look at boosting.  From what I've read it is sensitive to noisy data, and my data is extremely noisy (I'm predicting the probability that people will click on something).

My real question is not so much whether there may be better approaches, I'm sure there are, but whether my approach is seriously flawed.",,False,self,t5_2r3gv,1375462516.0,,,True,t3_1jkhg2,http://www.reddit.com/r/MachineLearning/comments/1jkhg2/how_can_an_ensemble_of_predictive_models_provide/,
1373870724.0,16,alandgraf.blogspot.com,1ibq56,Restricted Boltzmann Machines in R,20,4,2,http://www.reddit.com/r/MachineLearning/comments/1ibq56/restricted_boltzmann_machines_in_r/,,,False,http://d.thumbs.redditmedia.com/NH0W5xGgHPczmW3Q.jpg,t5_2r3gv,False,,,False,t3_1ibq56,http://alandgraf.blogspot.com/2013/01/restricted-boltzmann-machines-in-r.html,
1371634029.0,19,github.com,1gn9cy,pyhsmm - Python Sampling Inference for Bayesian HSMMs and HMMs,20,1,5,http://www.reddit.com/r/MachineLearning/comments/1gn9cy/pyhsmm_python_sampling_inference_for_bayesian/,,,False,http://c.thumbs.redditmedia.com/qXf13PkX_FTS-heD.jpg,t5_2r3gv,False,,,False,t3_1gn9cy,https://github.com/mattjj/pyhsmm,
1369675100.0,19,self.MachineLearning,1f59sv,"Building a PC Mainly for Use With Machine Learning and Massive Data Problems, Looking for Input",28,9,42,http://www.reddit.com/r/MachineLearning/comments/1f59sv/building_a_pc_mainly_for_use_with_machine/,"So I've been working on ML and NLP type problems for awhile now and I'd like to invest in some better hardware. I've built computers in the past, but they have mainly been for general purpose use. I've primarily been working with MatLab (but also use java, c++, python, and perl, and someday probably R), and was hoping for some input on what to put in this machine. 

Currently this is my build (except using 1600 RAM instead of 1333):

[PCPartPicker part list](http://pcpartpicker.com/p/10lAp) / [Price breakdown by merchant](http://pcpartpicker.com/p/10lAp/by_merchant/) / [Benchmarks](http://pcpartpicker.com/p/10lAp/benchmarks/)

Type|Item|Price
:----|:----|:----
**CPU** | [Intel Core i7-3930K 3.2GHz 6-Core Processor](http://pcpartpicker.com/part/intel-cpu-bx80619i73930k) | $499.99 @ Microcenter 
**Motherboard** | [MSI Big Bang - XPower II XL ATX  LGA2011 Motherboard](http://pcpartpicker.com/part/msi-motherboard-bigbangxpowerii) | $369.99 @ Newegg 
**Memory** | [G.Skill Ripjaws Z Series 64GB (8 x 8GB) DDR3-1333 Memory](http://pcpartpicker.com/part/gskill-memory-f310666cl9q264gbzl) | $449.99 @ Newegg 
**Storage** | [Samsung 840 Series 500GB 2.5"" Solid State Disk](http://pcpartpicker.com/part/samsung-internal-hard-drive-mz7td500kw) | $334.99 @ NCIX US 
**Video Card** | [Asus GeForce GTX Titan 6GB Video Card](http://pcpartpicker.com/part/asus-video-card-gtxtitan6gd5) | $999.99 @ NCIX US 
**Case** | [NZXT Switch 810 (Gun Metal) ATX Full Tower Case](http://pcpartpicker.com/part/nzxt-case-casw810g1) | $152.94 @ Amazon 
**Power Supply** | [Corsair Professional 850W 80 PLUS Gold Certified ATX12V / EPS12V Power Supply](http://pcpartpicker.com/part/corsair-power-supply-hx850) | $139.99 @ Amazon 
 | | **Total**
 | Prices include shipping, taxes, and discounts when available. | $2947.88
 | Generated by PCPartPicker 2013-05-27 01:48 EDT-0400 |

I plan to use watercooling so that I can overclock the cpu and graphics card as well.
    
I would appreciate any input anyone here has about this setup. Also, I'm considering going with dual six core xeons instead of the single intel i7. If anyone has a recommendation about that in particular (especially using them with the parallel processing toolbox in MatLab), I'd love to hear it. ",,False,self,t5_2r3gv,False,,,True,t3_1f59sv,http://www.reddit.com/r/MachineLearning/comments/1f59sv/building_a_pc_mainly_for_use_with_machine/,
1368479050.0,20,strata.oreilly.com,1e9p7r,Evaluating machine learning systems: Kaggle’s not enough,27,7,25,http://www.reddit.com/r/MachineLearning/comments/1e9p7r/evaluating_machine_learning_systems_kaggles_not/,,,False,http://c.thumbs.redditmedia.com/OPMXkFI5LngyIsln.jpg,t5_2r3gv,False,,,False,t3_1e9p7r,http://strata.oreilly.com/2013/05/different-evaluation-criteria-for-machine-learning-systems.html,
1367090869.0,17,self.MachineLearning,1d8b90,"What are your thoughts on ""Deep Learning""?",22,5,18,http://www.reddit.com/r/MachineLearning/comments/1d8b90/what_are_your_thoughts_on_deep_learning/,"I've read a bit about deep learning, and it seems quite compelling.  Basically, we finally figured out how to train the kinds of feedback networks everyone was excited about in the 70s.  And surprise, they're awesome.  What are your thoughts?
* Great for feature extraction/dimensionality reduction?
* Great for supervised learning?
* Great for unsupervised learning?
* Interesting, but too finicky to rely on?
* Effective, but difficult to intuit/trust so unsuitable for business applications?

I've felt all these things at various times about neural networks.  They're neat, and when they work it's impressive, but I've had trouble in the past with them being extremely finicky about learning rates/configuration, and they seem potentially difficult to debug and I could have trouble trusting them when reliability really mattered.",,False,self,t5_2r3gv,False,,,True,t3_1d8b90,http://www.reddit.com/r/MachineLearning/comments/1d8b90/what_are_your_thoughts_on_deep_learning/,
1366490407.0,19,self.MachineLearning,1crei7,Help needed with Bayesian Spectral Analysis,21,2,5,http://www.reddit.com/r/MachineLearning/comments/1crei7/help_needed_with_bayesian_spectral_analysis/,"I have recently discovered Larry Bretthorst's article on  [Bayesian Spectral Analysis](http://bayes.wustl.edu/glb/excerpts.pdf) and I'm trying it out. I'm struggling with making the method able for use to detect multiple harmonic signals though. Can anyone point me somewhere I would be able to get some example code for BSA or be able to help me? Much appreciated.

More detail: I'm particularly struggling with harmonic signals that have close frequencies. As input I have two signals with very little noise that are far apart (w1 and w2 frequencies). The output I get suggests it is just as likley that there are two very close frequencies near w1 or two very close frequencies near w2 respectively as it is that there is a frequency at w1 and w2.

Edit: Here is my [output](http://i.imgur.com/vHwrVU8h.png) which suggests two very close frequencies at either 0.2 and 0.8 hertz/sample is more likely than two signals at 0.2 and 0.8 hertz/sample respectively. [Here](http://i.imgur.com/qbN3Hajh.png) is a closeup of 0.2 hertz/sample. It would seem that the probability of two signals on top of one another at 0.2 hertz per sample is low but then the probability shoots up around that area. Very strange and likely not correct. I would expect [this](http://i.imgur.com/a4iQxlw.jpg) output, but with a function that decreases the probability by 0.5 on the diagonal and gradually less as one moves away from the diagonal.",,False,self,t5_2r3gv,1366492711.0,,,True,t3_1crei7,http://www.reddit.com/r/MachineLearning/comments/1crei7/help_needed_with_bayesian_spectral_analysis/,
1366257478.0,17,kaggle.com,1cl2k2,The 2013 KDD Cup: Author-Paper Identification in the Microsoft Academic Search Dataset,24,7,2,http://www.reddit.com/r/MachineLearning/comments/1cl2k2/the_2013_kdd_cup_authorpaper_identification_in/,,,False,default,t5_2r3gv,False,,,False,t3_1cl2k2,http://www.kaggle.com/c/kdd-cup-2013-author-paper-identification-challenge,
1363729236.0,20,self.MachineLearning,1amc2l,"Dear /r/MachineLearning, any book recommendations for a gift?",23,3,24,http://www.reddit.com/r/MachineLearning/comments/1amc2l/dear_rmachinelearning_any_book_recommendations/,The gift is for an intern who is leaving to pursue a PhD in machine learning.,,False,self,t5_2r3gv,False,,,True,t3_1amc2l,http://www.reddit.com/r/MachineLearning/comments/1amc2l/dear_rmachinelearning_any_book_recommendations/,
1362312597.0,18,self.MachineLearning,19knvr,Deep learning research labs,27,9,21,http://www.reddit.com/r/MachineLearning/comments/19knvr/deep_learning_research_labs/,"There is a list of research groups here: http://deeplearning.net/deep-learning-research-groups-and-labs/  
Do you know any other places where deep learning is researched?",,False,self,t5_2r3gv,False,,,True,t3_19knvr,http://www.reddit.com/r/MachineLearning/comments/19knvr/deep_learning_research_labs/,
1357322862.0,19,camdp.com,15yln1,Interior design using machine learning,28,9,8,http://www.reddit.com/r/MachineLearning/comments/15yln1/interior_design_using_machine_learning/,,,False,default,t5_2r3gv,False,,,False,t3_15yln1,http://camdp.com/blogs/interior-design-machine-learning,
1354770800.0,18,blog.al.com,14daen,Successful Test Flight of Autonomous Black Hawk Helicopter,23,5,1,http://www.reddit.com/r/MachineLearning/comments/14daen/successful_test_flight_of_autonomous_black_hawk/,,,False,http://e.thumbs.redditmedia.com/2AmqNhGhSfeYdmOp.jpg,t5_2r3gv,False,,,False,t3_14daen,http://blog.al.com/breaking/2012/12/black_hawk_flies_lands_and_avo.html,
1353863603.0,17,self.MachineLearning,13rjpg,"I'm interested in building a robust Monopoly board game simulator, anyone familiar with previous work done in this area?",22,5,4,http://www.reddit.com/r/MachineLearning/comments/13rjpg/im_interested_in_building_a_robust_monopoly_board/,"As a hobby I'm considering building a program to simulate Monopoly games to test strategies. I know that there are many models out there that simply calculate the likelihood of landing on a particular space. My goal would be to build something a bit more detailed to gather some more interesting data about the game. I'd like to incorporate agent based learning into the model to test and develop strategies for playing. I'm wondering if anyone has seen a similar project done in the past. I spent about an hour searching on google and I found a couple of things:


*Monopoly Nerd's blog: 

http://monopolynerd.wordpress.com/

This guy built a web-based simulator to produce winning percentages based on starting conditions.


*ESTIMATING THE PROBABILITY THAT THE GAME OF MONOPOLY NEVER ENDS

http://www.informs-sim.org/wsc09papers/036.pdf

This is a paper that a couple of guys from Cornell wrote about their analysis on the game and determining the likelihood of having a game that ""never ends"". The model they used had some severe limitations (only two players, limited to no trading, etc).


*Agent Based Simulation, Negotiation, and Strategy Optimization of Monopoly

http://www.tjhsst.edu/~rlatimer/techlab08/LoffredoPaperQ2-08.pdf

This is the only thing that comes close to what I want to do, but the paper is extremely vague as it doesn't include any results so I don't know if the project was even completed. There is no institution or organization listed but the author's name is there.

Let me know if any of you have stumbled across something related to Monopoly simulations on the internet. I know it's probably not likely but it's worth a shot. Thanks.",,False,self,t5_2r3gv,False,,,True,t3_13rjpg,http://www.reddit.com/r/MachineLearning/comments/13rjpg/im_interested_in_building_a_robust_monopoly_board/,
1353039429.0,18,self.MachineLearning,13a5xi,List of unsupervised learning algorithms. ,21,3,25,http://www.reddit.com/r/MachineLearning/comments/13a5xi/list_of_unsupervised_learning_algorithms/,"
Hi r/machineLearning!


So, after having dabbled here and there in machine learning for some time now, I think I now know what I am truly interested in. It took me some time to figure it out, but I needed to survey the landscape first. 


I want to really dive into _un_supervised learning. This has a two fold advantage for me, one, I am very interested in the subject, and two, I believe I will be able to use it in my line of work which is very signal-processing intensive. 


So, quite simply, I wanted to ask any of you, and those more experienced than me, for an ""executive summary"" or list, of unsupervised learning algorithms. 


(If you like, feel free to add a brief run down of your thoughts for each one on the list. What are their strengths? What might be some disadvantages? Pitfalls? Can you sprinkle some intuition on each one?)


From the list, I am fairly certain that I will be able to do enough focused research and learn them all very well eventually. I just need a starting point list. 


(I have already taken Andrew Ngs class on coursera). 


So far my list includes: 

1) K-Means

2) ICA


Thanks in advance!! 


",,False,self,t5_2r3gv,False,,,True,t3_13a5xi,http://www.reddit.com/r/MachineLearning/comments/13a5xi/list_of_unsupervised_learning_algorithms/,
1352842029.0,17,self.MachineLearning,1356ii,Discussion: Google's Scalable Deep Learning + 1000 Genome Project?,27,10,24,http://www.reddit.com/r/MachineLearning/comments/1356ii/discussion_googles_scalable_deep_learning_1000/,"Should google be applying their recently devised scalable deep learning approach to freely available human genome data?

Some thoughts/links/info...

The [1000 genome project](http://aws.amazon.com/1000genomes/) has already released data for 1700 genomes, weighing in at 200TB. We know the 3 billion base pairs of a human can be represented directly (uncompressed) in 750MB. 750MB * 1700 sequences = 1.275 TB. One suggestion I've encountered is that this is raw sequencing output that needs splicing together, if you do that and are happy with that one interpretation for each genome we're perhaps looking at 1.275TB instead of 200 - a good start at making this data more manageable.

1.275TB will fit on a single HD. Furthermore it's not unreasonable to conceive of a single PC box with say 2TB of RAM. However...

Google already perform deep learning on large data sets, see [Scaling Deep Learning, Jeff Dean, Google](http://techtalks.tv/talks/57639/) and [Peter Norvig: Channeling the Flood of Data](http://fora.tv/2012/10/14/Peter_Norvig_Channeling_the_Flood_of_Data). tl;dr - they partition the data between machines within a data centre and communicate connection weight deltas between machines.

It seems to me that deep learning may be able to discover deeper structures in the genetic sequences than are currently known, and that we might be able to find correlations between these deep structures and phenotype level features. Would this work? Is anyone aware of such a project? Thanks for reading.",,False,self,t5_2r3gv,False,,,True,t3_1356ii,http://www.reddit.com/r/MachineLearning/comments/1356ii/discussion_googles_scalable_deep_learning_1000/,
1349980132.0,19,spectrum.ieee.org,11bl9i,Article: Deconstructing Recommender Systems,19,0,1,http://www.reddit.com/r/MachineLearning/comments/11bl9i/article_deconstructing_recommender_systems/,,,False,default,t5_2r3gv,False,,,False,t3_11bl9i,http://spectrum.ieee.org/computing/software/deconstructing-recommender-systems,
1348624479.0,20,self.MachineLearning,10hgdr,AskMachineLearning: has anyone enhanced the quality of audio voice recognition by reading lips?,23,3,8,http://www.reddit.com/r/MachineLearning/comments/10hgdr/askmachinelearning_has_anyone_enhanced_the/,"There are many facial recognition algorithms, eye and mouth recognition algorithms. I was wondering if anyone had tried utilizing them to enhance voice recognition algorithms. 

I thought of this while I was trying to dictate on my Mac and was staring at the little Hal9000 camera in the middle of the screen. I searched around on Google Scholar and couldn't find anything.

Just thought I'd ask.

cheers",,False,self,t5_2r3gv,False,,,True,t3_10hgdr,http://www.reddit.com/r/MachineLearning/comments/10hgdr/askmachinelearning_has_anyone_enhanced_the/,
1345886710.0,20,self.MachineLearning,ystt7,Search engine for a researching,28,8,18,http://www.reddit.com/r/MachineLearning/comments/ystt7/search_engine_for_a_researching/,"Hi Redditors!

I've [asked](http://www.reddit.com/r/MachineLearning/comments/w1du3/is_there_a_search_engine_over_artificial/) about a month ago, if there is a search engine to search over a Artificial Intelligence or Machine Learning -related sites. Unfortunately, the best answer I'd been given was to use Google's advanced search operators like 'inurl'.

I was able to find a better solution by using the Google Custom Search technology. I made a custom search engine with *.edu, *.ac.uk, *.edu.au and so on sites and domain zones, 145 in a total at this moment.
From my point of view that search engine gives much better result pages, than an ordinary search. Also, the search index is almost spam-free and paid content -free.

There is a feature, that allows one to inspect what sites are included in the index, to comment them and to vote for or against them (to purge unrelevant site from the index, for example). Also, everyone is welcome to suggest new sites using a special form on the site.
In short, it has all very basic machinery needed to make such scoped search engine to be community driven.

Try it at [http://neatserpent.com/](http://neatserpent.com/)

Give me your feedback, please.
Do you find it helpful and better than ordinary search engine?
Would you use it?

Please, spread the word, if you like it.
",,False,self,t5_2r3gv,False,,,True,t3_ystt7,http://www.reddit.com/r/MachineLearning/comments/ystt7/search_engine_for_a_researching/,
1345245514.0,18,self.MachineLearning,yeicp,Do I need to learn R?,28,10,34,http://www.reddit.com/r/MachineLearning/comments/yeicp/do_i_need_to_learn_r/,"I've been focusing mostly on learning python and it has allowed me to work through some intros on machine learning and data mining, and build a few applications for practice. I'm trying to think of what I should focus on next to get past the ""beginner"" stage, and I'm wondering if anyone have any recommendations for what someone in my situation should be learning next...should I learn something more specialized toward statistical analysis like R (I've got a decent base in pen and paper mathematics &amp; statistics) or should I just keep using python to tackle more &amp; more challenging problems?

My main interest is the implementation of machine learning in internet applications - finding where and how to apply them on the web in the most useful way. My goal is to be able to find new and creative ways to apply ML/AI toward making web applications better and more useful. I'm perfectly willing to spend years to get there, just wondering if someone with experience with this can help work out a roadmap.   ",,False,self,t5_2r3gv,False,,,True,t3_yeicp,http://www.reddit.com/r/MachineLearning/comments/yeicp/do_i_need_to_learn_r/,
1339677490.0,16,viksalgorithms.blogspot.com,v1k5q,Finding word use patterns in Wikileaks cables,23,7,11,http://www.reddit.com/r/MachineLearning/comments/v1k5q/finding_word_use_patterns_in_wikileaks_cables/,,,False,http://e.thumbs.redditmedia.com/ydapcVgNU_H0icHd.jpg,t5_2r3gv,False,,,False,t3_v1k5q,http://viksalgorithms.blogspot.com/2012/06/finding-word-use-patterns-in-wikileaks.html,
1338854659.0,18,self.MachineLearning,ul5dk,"Ask Machine Learning: Which model for a simple ""Customers Who Bought This Item Also Bought""-recommendation?",22,4,18,http://www.reddit.com/r/MachineLearning/comments/ul5dk/ask_machine_learning_which_model_for_a_simple/,"I am looking to implement a small recommendation engine for a VoD movie database. I am looking at the following type of recommendation:

When the customer is already looking at a certain movie, I would like to make a recommendation like Amazon's ""Customers Who Bought This Item Also Bought..."".

The data i have available to me is all customer's previous purchases and metadata for the movies (genre and such).

Given this information, which algorithms or methods would be the most effective?

My first (perhaps naive) idea is, given the movie the customer is currently looking at, to find all the other customers who have bought this movie and and among these customers to find the movies they have bought the most times.

Got something better?",,False,self,t5_2r3gv,False,,,True,t3_ul5dk,http://www.reddit.com/r/MachineLearning/comments/ul5dk/ask_machine_learning_which_model_for_a_simple/,
1334034472.0,16,self.MachineLearning,s243g,"Can someone explain the Perceptron Learning Algorithm to me?  Like I'm a 5-year-old, please.",24,8,11,http://www.reddit.com/r/MachineLearning/comments/s243g/can_someone_explain_the_perceptron_learning/,"I'm trying to slog through the Caltech online course called ""Learning from Data.""  We haven't even turned in the first homework yet, and I'm lost.  We're supposed to code our own PLA:

Create 100 random points above and below a random line and designate those that are above as +1 and those that are below as -1.  Got it. I can do that pretty easily.

I understand initializing all of the weights to zero.

But, I get really lost when it comes to how the algorithm iterates.  I know that I'm supposed to multiply the weights across the inputs to create an output for each point.  I'm supposed to compare it to the desired output and then iterate.  How do I calculate desired output?  

To help myself, I choice a random line y=2x and then points above and below the line.  (1,1,3), (1,3,7), (1,2,3), (1,4,7) which map to  +1, +1, and -1, -1, respectively.

Can anyone on Reddit walk me through the actual steps that the computer would take with these data points as it iterates?  It's easy enough to copy a script from the net, but I still don't quite understand what it all does, and the mathematical notations aren't as helpful as I would have hoped.

Any help would be VERY much appreciated.  ",,False,self,t5_2r3gv,False,,,True,t3_s243g,http://www.reddit.com/r/MachineLearning/comments/s243g/can_someone_explain_the_perceptron_learning/,
1331591677.0,17,bostonglobe.com,qtl95,Rise of the crossword robots,21,4,2,http://www.reddit.com/r/MachineLearning/comments/qtl95/rise_of_the_crossword_robots/,,,False,default,t5_2r3gv,False,,,False,t3_qtl95,http://bostonglobe.com/ideas/2012/03/11/rise-crossword-robots/xK4TRBW2MfhqAwnj6tMv3H/story.html?camp,
1330374767.0,17,github.com,q8kaw,Help build a machine learning system to predict college basketball,25,8,4,http://www.reddit.com/r/MachineLearning/comments/q8kaw/help_build_a_machine_learning_system_to_predict/,,,False,default,t5_2r3gv,False,,,False,t3_q8kaw,https://github.com/dtarlow/Machine-March-Madness,
1328727932.0,19,drewconway.com,pglpe,"""Machine Learning for Hackers"" table of contents",31,12,18,http://www.reddit.com/r/MachineLearning/comments/pglpe/machine_learning_for_hackers_table_of_contents/,,,False,http://a.thumbs.redditmedia.com/w9qAMy4a9vG4QNlx.jpg,t5_2r3gv,False,,,False,t3_pglpe,http://www.drewconway.com/zia/?p=2864,
1324844650.0,17,self.MachineLearning,nqfi0,"What is the prerequisite knowledge to *really* ""get"" conditional random fields, HMMs, etc?",24,7,4,http://www.reddit.com/r/MachineLearning/comments/nqfi0/what_is_the_prerequisite_knowledge_to_really_get/,"I do work in computer vision, but I have avoided these topics for a while since the Bayesian probability theory doesn't always seem to make sense to me in the context of computer vision.  

I want to understand it right down to the theory.  I'm going to have some off time over the holidays that I will do some reading in.  If I want this stuff to be entirely concrete to me, what should I be reading?  It doesn't seem like starting right from the initial CRF paper is the right approach :)",,False,self,t5_2r3gv,False,,,True,t3_nqfi0,http://www.reddit.com/r/MachineLearning/comments/nqfi0/what_is_the_prerequisite_knowledge_to_really_get/,
1321843750.0,19,self.MachineLearning,mjodn,Any tips about becoming an AI engineer?,23,4,25,http://www.reddit.com/r/MachineLearning/comments/mjodn/any_tips_about_becoming_an_ai_engineer/,"I'm extremely interested in studying AI for graduate school. Any tips on where I should go,and what I can expect as a career? 

I am currently working on my Software Engineering degree at Oregon Institute of Technology.",,False,self,t5_2r3gv,False,,,True,t3_mjodn,http://www.reddit.com/r/MachineLearning/comments/mjodn/any_tips_about_becoming_an_ai_engineer/,
1321671325.0,17,self.MachineLearning,mhodz,Data Scientist vs Statistician?,21,4,41,http://www.reddit.com/r/MachineLearning/comments/mhodz/data_scientist_vs_statistician/,Hi I thought this would be the most appropriate sub reddit for this kind of thing. My question is what exactly is the difference between the two? I tried googling the answers but most people are dodging the question or give an inaccurate description of statisticians.,,False,self,t5_2r3gv,False,,,True,t3_mhodz,http://www.reddit.com/r/MachineLearning/comments/mhodz/data_scientist_vs_statistician/,
1320437226.0,19,self.MachineLearning,m0od7,looking for ML aficionado in London for great chats and maybe a startup,23,4,4,http://www.reddit.com/r/MachineLearning/comments/m0od7/looking_for_ml_aficionado_in_london_for_great/,"TL;DR? Here's the gist:

Me: 3 startups under my belt. Started as a programmer, then trainer, then entrepreneur, now CTO &amp; Board member for a leading customer insight company part of large bank. Large system and infrastructure specialist. Extensive &amp; practical experience in raising funds and successfully managing both startup and established businesses. Fascinated by the power of data. Can't imagine myself spending the rest of my life being a cog in the machine.

You: Machine learning specialist, programmer, analyst, understands how to navigate and crunch large datasets, from BI to predictive analytics. Interested in implementing applications from fraud detection to margin improvements through better clustering regardless of industry. Fascinated by the power of data. Can't imagine himself spending the rest of his or her life being a cog in the machine.


The startup:

The core idea it to build platforms and systems around the progressively larger datasets held by various sized companies, helping them solve big issues - cost reduction, profitability and reducing risk. I’m an infrastructure and software specialist and have access to 1) systems, 2) datasets 3) extensive practical in certain industry segments, namely web-scale companies and tier 1 retailers.

This project is in the very early planning stages. I'm looking forward to discuss the form it could take with like-minded individuals but with complementary skills sets, namely: predictive analytics &amp; AI as it applies to machine learning on large datasets. 

Want more specifics ideas? I have plenty of these, but I’m sure you do to, so let’s meet face to face and discuss them.

Ultimately the goal is to crystallize on a specific concept, develop together a minimum viable product and get the company bootstrapped or angel-funded (something I also have plenty of experience with), all via a lean startup model.


My philosophy on startups:

Startups built in one’s free time often fail because they drag on, ending up as little more than side projects you can’t quite get rid of (due to co-founder guilt, or perhaps the little money they bring in every month). 

The core idea for this project is based on lean, that is, to launch a minimum viable product as early as possible. Getting feedback. Measuring results (important!). Pivot if it’s not working. This helps tremendously in staying motivated, limits the dreaded paralyzing fear of failure, and more importantly, keep the time from inception to first client/funding to a minimum.

If it sounds interesting please message me and we can exchange contact details! Worst that can happen is we have a great chat!",,False,self,t5_2r3gv,False,,,True,t3_m0od7,http://www.reddit.com/r/MachineLearning/comments/m0od7/looking_for_ml_aficionado_in_london_for_great/,
1317646204.0,17,users.cis.fiu.edu,kzaty,A Survey on Music Data Mining Papers,20,3,1,http://www.reddit.com/r/MachineLearning/comments/kzaty/a_survey_on_music_data_mining_papers/,,,False,default,t5_2r3gv,False,,,False,t3_kzaty,http://users.cis.fiu.edu/~lli003/Music/music.html,
1317263703.0,18,self.MachineLearning,kutiz,Can anyone provide an intuitive explanation or point me somewhere that describes entropy in the context of information theory?,19,1,10,http://www.reddit.com/r/MachineLearning/comments/kutiz/can_anyone_provide_an_intuitive_explanation_or/,This measure manifests itself in many different contexts and I would love to figure it out once and for all. Thanks!!!,,False,self,t5_2r3gv,False,,,True,t3_kutiz,http://www.reddit.com/r/MachineLearning/comments/kutiz/can_anyone_provide_an_intuitive_explanation_or/,
1314710877.0,17,engineered.typepad.com,jz18j,Two Analytics Success Stories,18,1,2,http://www.reddit.com/r/MachineLearning/comments/jz18j/two_analytics_success_stories/,,,False,default,t5_2r3gv,False,,,False,t3_jz18j,http://engineered.typepad.com/thoughts_on_business_engi/2011/08/two-analytics-success-stories.html,
1304037456.0,18,self.MachineLearning,gzrd0,Looking for good resources in NLP (Natural Language Processing).,20,2,11,http://www.reddit.com/r/MachineLearning/comments/gzrd0/looking_for_good_resources_in_nlp_natural/,"I've recently become interested in natural language processing but the field seem pretty big and I'm having trouble figuring out where to start, what would be the best place to start to learn the basics or if there any communities for this kind of stuff.",,False,self,t5_2r3gv,False,,,True,t3_gzrd0,http://www.reddit.com/r/MachineLearning/comments/gzrd0/looking_for_good_resources_in_nlp_natural/,
1303860515.0,18,the-locster.livejournal.com,gy66s,Deep Learning for Image Compression,23,5,3,http://www.reddit.com/r/MachineLearning/comments/gy66s/deep_learning_for_image_compression/,,,False,http://thumbs.reddit.com/t3_gy66s.png,t5_2r3gv,False,,,False,t3_gy66s,http://the-locster.livejournal.com/110724.html,
1299098234.0,19,scikit-learn.sourceforge.net,fw17b,scikit-learn 0.7 machine learning lib for python / numpy is out: what's new?,21,2,1,http://www.reddit.com/r/MachineLearning/comments/fw17b/scikitlearn_07_machine_learning_lib_for_python/,,,False,http://thumbs.reddit.com/t3_fw17b.png,t5_2r3gv,False,,,False,t3_fw17b,http://scikit-learn.sourceforge.net/whats_new.html,
1297796188.0,17,r-bloggers.com,flzxo,OkCupid: finding your Valentine using statistics (with R),24,7,4,http://www.reddit.com/r/MachineLearning/comments/flzxo/okcupid_finding_your_valentine_using_statistics/,,,False,http://thumbs.reddit.com/t3_flzxo.png,t5_2r3gv,False,,,False,t3_flzxo,http://www.r-bloggers.com/okcupid-finding-your-valentine-with-r/,
1290599343.0,20,beckman.illinois.edu,eb273,Jeff Hawkins talking about recent advances in Hierarchical Temporal Memory algorithms -- 12th November 2010,24,4,1,http://www.reddit.com/r/MachineLearning/comments/eb273/jeff_hawkins_talking_about_recent_advances_in/,,,False,default,t5_2r3gv,False,,,False,t3_eb273,http://www.beckman.illinois.edu/gallery/video.aspx?webSiteID=o2RWiAWUQEKPgd_8QBTYOA&amp;videoID=fYhfoB6NFE2ytFPl7XLnTA,
1289175625.0,19,inclass.kaggle.com,e2ohx,"Just launched: ""Kaggle in Class"" for student machine learn competitions. Stanford Stats 202 is the pioneering class",19,0,0,http://www.reddit.com/r/MachineLearning/comments/e2ohx/just_launched_kaggle_in_class_for_student_machine/,,,False,http://thumbs.reddit.com/t3_e2ohx.png,t5_2r3gv,False,,,False,t3_e2ohx,http://inclass.kaggle.com/,
1288718992.0,17,kdd.org,e057x,KDD-Cup 2011: Recommending Music Items based on the Yahoo! Music Dataset,19,2,2,http://www.reddit.com/r/MachineLearning/comments/e057x/kddcup_2011_recommending_music_items_based_on_the/,,,False,default,t5_2r3gv,False,,,False,t3_e057x,http://www.kdd.org/kdd2011/kddcup.shtml,
1288059272.0,16,cs.manchester.ac.uk,dwe59,"""Embracing Uncertainty: The new machine intelligence""
Speaker: Professor Christopher Bishop. The IET/BCS Manchester Turing Lecture 2010.",18,2,2,http://www.reddit.com/r/MachineLearning/comments/dwe59/embracing_uncertainty_the_new_machine/,,,False,http://thumbs.reddit.com/t3_dwe59.png,t5_2r3gv,False,,,False,t3_dwe59,http://www.cs.manchester.ac.uk/aboutus/events/Turing/10-Christopher-Bishop/,
1287149284.0,17,dataists.com,drm9v,Thoughts on data visualization at Dataists,20,3,1,http://www.reddit.com/r/MachineLearning/comments/drm9v/thoughts_on_data_visualization_at_dataists/,,,False,http://thumbs.reddit.com/t3_drm9v.png,t5_2r3gv,False,,,False,t3_drm9v,http://www.dataists.com/2010/10/what-data-visualization-should-do-simple-small-truth/,
1284476329.0,17,r-bloggers.com,ddpj3,"“simply start over and build something better” | Ross Ihaka, the father of R",21,4,0,http://www.reddit.com/r/MachineLearning/comments/ddpj3/simply_start_over_and_build_something_better_ross/,,,False,http://thumbs.reddit.com/t3_ddpj3.png,t5_2r3gv,False,,,False,t3_ddpj3,http://www.r-bloggers.com/%E2%80%9Csimply-start-over-and-build-something-better%E2%80%9D/,
1283661586.0,17,self.MachineLearning,d9qzy,what are the state-of-the art methods for classifying time series?,20,3,27,http://www.reddit.com/r/MachineLearning/comments/d9qzy/what_are_the_stateofthe_art_methods_for/,"classifying, not predicting...
",,False,self,t5_2r3gv,True,,,True,t3_d9qzy,http://www.reddit.com/r/MachineLearning/comments/d9qzy/what_are_the_stateofthe_art_methods_for/,
1279219963.0,19,ocw.mit.edu,cpztq,"MIT's ""Techniques in AI"" course notes",20,1,4,http://www.reddit.com/r/MachineLearning/comments/cpztq/mits_techniques_in_ai_course_notes/,,,False,default,t5_2r3gv,False,,,False,t3_cpztq,http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-825-techniques-in-artificial-intelligence-sma-5504-fall-2002/lecture-notes/,
1270611273.0,18,awards.acm.org,bnfnv,"Michael I Jordan is the  recipient of the 
ACM/AAAI Allen Newell Award for 
fundamental advances in statistical 
machine learning. ",21,3,4,http://www.reddit.com/r/MachineLearning/comments/bnfnv/michael_i_jordan_is_the_recipient_of_the_acmaaai/,,,False,default,t5_2r3gv,False,,,False,t3_bnfnv,http://awards.acm.org/citation.cfm?id=5177076&amp;srt=all&amp;aw=150&amp;ao=ANEWELL&amp;yr=2009,
1264116484.0,18,blog.smellthedata.com,aslpi,Party conversation: Machine Learning in one sentence?,20,2,5,http://www.reddit.com/r/MachineLearning/comments/aslpi/party_conversation_machine_learning_in_one/,,,False,http://thumbs.reddit.com/t3_aslpi.png,t5_2r3gv,False,,,False,t3_aslpi,http://blog.smellthedata.com/2010/01/machine-learning-in-one-sentence.html,
1261009570.0,19,nlpers.blogspot.com,afisl,"K-means vs GMM, sum-product vs max-product",20,1,0,http://www.reddit.com/r/MachineLearning/comments/afisl/kmeans_vs_gmm_sumproduct_vs_maxproduct/,,,False,http://thumbs.reddit.com/t3_afisl.png,t5_2r3gv,False,,,False,t3_afisl,http://nlpers.blogspot.com/2009/11/k-means-vs-gmm-sum-product-vs-max.html,
1252334937.0,17,datawrangling.com,9i4dq,Some Datasets Available on the Web.,19,2,0,http://www.reddit.com/r/MachineLearning/comments/9i4dq/some_datasets_available_on_the_web/,,,False,default,t5_2r3gv,False,,,False,t3_9i4dq,http://www.datawrangling.com/some-datasets-available-on-the-web,
1252282535.0,18,archive.ics.uci.edu,9hxxz,UC Irvine's Machine Learning Datasets,19,1,2,http://www.reddit.com/r/MachineLearning/comments/9hxxz/uc_irvines_machine_learning_datasets/,,,False,default,t5_2r3gv,False,,,False,t3_9hxxz,http://archive.ics.uci.edu/ml/datasets.html,
1250563782.0,18,undirectedgrad.blogspot.com,9bkvr,To R or not to R. What do you guys think?,21,3,10,http://www.reddit.com/r/MachineLearning/comments/9bkvr/to_r_or_not_to_r_what_do_you_guys_think/,,,False,default,t5_2r3gv,False,,,False,t3_9bkvr,http://undirectedgrad.blogspot.com/2009/08/to-r-or-not-to-r.html,
1375064958.0,19,self.MachineLearning,1j92au,Why isn't there much talk about neural networks with mixed depth connections?,20,1,10,http://www.reddit.com/r/MachineLearning/comments/1j92au/why_isnt_there_much_talk_about_neural_networks/,"Practically all of the literature focuses on neural networks with separated hidden layers, in which a neuron in the n'th layer only has input connections from layer n - 1. I was playing with the idea of putting together sigmoid units by hand as a white box model, and realized that this model can be seen as a neural net with no distinct layers. My intuition tells me that it also has more representational power, if just by a constant factor. It definitely has the downside of being harder to implement quickly on a computer (matrix multiplication won't work as nicely) but if it has greater representational power per neuron than a network with discrete layers, perhaps it is worth some research.

**Edit**: I am mainly asking about feedforward nets in which there is no restriction on connectivity, aside from having no cycles (that is required for it to be considered a feedforward net). So far all the responses seem to be about nets with more structure than this (they all consider nets that are still organized into layers, whose activations are computed using possibly more than one previous layer). Still on topic, but my main concern is still unanswered here.",,False,self,t5_2r3gv,1375121356.0,,,True,t3_1j92au,http://www.reddit.com/r/MachineLearning/comments/1j92au/why_isnt_there_much_talk_about_neural_networks/,
1373321378.0,18,self.MachineLearning,1hw6bk,"Opinion?: ""A correlation for the 21st century""",23,5,27,http://www.reddit.com/r/MachineLearning/comments/1hw6bk/opinion_a_correlation_for_the_21st_century/,"Ref: http://www.sciencemag.org/content/334/6062/1502

What does r/ML think about the MIC correlation-measure proposed in the article above? Digging deeper into what people are saying about the paper referred to by the article reveals some criticisms (eg. http://en.wikipedia.org/wiki/Maximal_information_coefficient). ",,False,self,t5_2r3gv,False,,,True,t3_1hw6bk,http://www.reddit.com/r/MachineLearning/comments/1hw6bk/opinion_a_correlation_for_the_21st_century/,
1368393835.0,18,mewo2.com,1e7d6n,Markov Chain Monte Carlo and the 2013 Eurovision Song Contest,20,2,1,http://www.reddit.com/r/MachineLearning/comments/1e7d6n/markov_chain_monte_carlo_and_the_2013_eurovision/,,,False,http://c.thumbs.redditmedia.com/fEB25U26Sr68gaFz.jpg,t5_2r3gv,False,,,False,t3_1e7d6n,http://mewo2.com/nerdery/2013/05/12/eurovision-2013-first-predictions/,
1368048403.0,17,kaggle.com,1dyhy5,ICML 2013 Bird Challenge - Identify bird species within continuous audio recordings,22,5,9,http://www.reddit.com/r/MachineLearning/comments/1dyhy5/icml_2013_bird_challenge_identify_bird_species/,,,False,default,t5_2r3gv,False,,,False,t3_1dyhy5,https://www.kaggle.com/c/the-icml-2013-bird-challenge,
1368044866.0,17,reddit.com,1dycyd,Why not model computer programs? It's just as fun and challenging as natural language modelling. =),29,12,16,http://www.reddit.com/r/MachineLearning/comments/1dycyd/why_not_model_computer_programs_its_just_as_fun/,,,False,default,t5_2r3gv,False,,,False,t3_1dycyd,http://www.reddit.com/r/REMath/,
1365476662.0,15,self.MachineLearning,1byrts,"What do people think about Jeff Hawkins' Cortical Learning Algorithm? Seems like it should be the ""holy grail"", what are it's flaws?",19,4,29,http://www.reddit.com/r/MachineLearning/comments/1byrts/what_do_people_think_about_jeff_hawkins_cortical/,,,False,self,t5_2r3gv,False,,,True,t3_1byrts,http://www.reddit.com/r/MachineLearning/comments/1byrts/what_do_people_think_about_jeff_hawkins_cortical/,
1363644535.0,17,faculty.ucmerced.edu,1ajvxb,Excellent notes for Optimization from UC Merced!,20,3,1,http://www.reddit.com/r/MachineLearning/comments/1ajvxb/excellent_notes_for_optimization_from_uc_merced/,,,False,default,t5_2r3gv,False,,,False,t3_1ajvxb,http://faculty.ucmerced.edu/mcarreira-perpinan/teaching/EECS260/lecture-notes.pdf,
1359858171.0,13,dilbert.com,17sb87,Dilbert's Definition of Machine Learning,52,39,18,http://www.reddit.com/r/MachineLearning/comments/17sb87/dilberts_definition_of_machine_learning/,,,False,http://a.thumbs.redditmedia.com/YdamtyR82n2OLyUT.jpg,t5_2r3gv,False,,,False,t3_17sb87,http://dilbert.com/strips/comic/2013-02-02/,
1356578704.0,16,self.MachineLearning,15i0o1,Can anyone provide an intuitive explanation of the Restricted Boltzmann Machine learning algorithm?,21,5,7,http://www.reddit.com/r/MachineLearning/comments/15i0o1/can_anyone_provide_an_intuitive_explanation_of/,"I'm trying to figure out how well RBMs can handle very large numbers of sparse input neurons (over &gt;100k, but where all but 20 or 30 are set to 0).",,False,self,t5_2r3gv,False,,,True,t3_15i0o1,http://www.reddit.com/r/MachineLearning/comments/15i0o1/can_anyone_provide_an_intuitive_explanation_of/,
1353690673.0,15,self.MachineLearning,13o8t4,I want to build a crime index and political instability index based in news stories.,22,7,11,http://www.reddit.com/r/MachineLearning/comments/13o8t4/i_want_to_build_a_crime_index_and_political/,"Hello, I have this side project where I crawl the local news websites in my country and want to build a crime index and political instability index.

I have already covered the information retrieval part of the project. My plan is:

1. Unsupervised topic extraction.
2. Near duplicates detection.
3. Supervised classification and incident level (crime/political - high/medium/low).

I will use python and sklearn and have already research the algorithms that I can use for those tasks. I think 1 - 2 could give me a relevancy factor of a story: the more news papers publish about an story or topic the more relevant.

My next step is to build the monthly, weekly and daily index (nation-wide and per cities) based on the features that I have, and I'm a little lost here as the ""instability sensitivity"" might increase to the time. I mean, the index from the major instability incident of the last year could be less than the index for this year. Also if to use fixed scale 0-100 or not.

I would appreciate any pointer to a paper, relevant readings or thoughts.

Thanks.",,False,self,t5_2r3gv,False,,,True,t3_13o8t4,http://www.reddit.com/r/MachineLearning/comments/13o8t4/i_want_to_build_a_crime_index_and_political/,
1350624010.0,15,ftc.gov,11qflo,FTC Challenges Innovators to Do Battle with Robocallers,21,6,9,http://www.reddit.com/r/MachineLearning/comments/11qflo/ftc_challenges_innovators_to_do_battle_with/,,,False,http://b.thumbs.redditmedia.com/6ckznQqlqannuYMC.jpg,t5_2r3gv,False,,,False,t3_11qflo,http://www.ftc.gov/opa/2012/10/robocalls3.shtm,
1342476098.0,16,investuotojas.eu,wo0kv,Data mining for network security and intrusion detection,21,5,1,http://www.reddit.com/r/MachineLearning/comments/wo0kv/data_mining_for_network_security_and_intrusion/,,,False,http://d.thumbs.redditmedia.com/PjEPJd4j9_LSbuaE.jpg,t5_2r3gv,False,,,False,t3_wo0kv,http://www.investuotojas.eu/2012/07/16/data-mining-for-network-security-and-intrusion-detection/,
1334149080.0,17,cleveralgorithms.com,s4942,Clever Algorithms: Statistical Machine Learning Recipes,22,5,8,http://www.reddit.com/r/MachineLearning/comments/s4942/clever_algorithms_statistical_machine_learning/,,,False,http://f.thumbs.redditmedia.com/Y5l2NRNtmmx6lXKq.jpg,t5_2r3gv,False,,,False,t3_s4942,http://www.cleveralgorithms.com/machinelearning/index.html,
1333999222.0,16,self.MachineLearning,s18je,Extracting Structure on a Very Complexly Interacting Feature Space,18,2,12,http://www.reddit.com/r/MachineLearning/comments/s18je/extracting_structure_on_a_very_complexly/,"Consider the case where you have a dataset with fairly low dimensionality and a very high number of data points. One such that in most supervised learning approaches you'd be more concerned with minimizing bias rather than variance.

However in this problem the relatively low dimensionality is somewhat deceptive because the variables have very complex high dimensional interactions. I'll give you an example of what I'm talking about:

Suppose you were looking at randomly sampled points in chess games between evenly matches players. The data you had was which pieces each player had lost and you wanted to predict whether the game would ultimately end up in win/lose/draw.

Your feature space in this case is 30 0/1 variables: 8 pawns, 2 rooks, 2 knights, 2 bishops, 1 queen, (no king because if he's missing the game's over) multiplied by 2 sides. Assume that you have access to hundreds of millions of independent data points (you can always run AI-AI games and sample new positions).

The idiosyncrasies of the interactions here runs far deeper than standard linear/quadratic variable interactions, for example:
---------------------------------------------------------------------------------------------------------------------------

* Early game when a lot of material's on the board knights tend to be better than bishops. When there's not much material bishops tend to be better.

* If a player is missing a few pawns from ranks far away from each other that's not as bad as a cluster of pawns missing which opens up a hole in his defense.

* At the end of the game if the other side has two bishops, but the difference between having one bishop and no bishop is the difference between a guaranteed draw and win.

* A queen is about equal to two rooks early game, but becomes much less powerful late game.

* The difference of one side having 1 pawn and the other side having no pawns is far more than the difference between having 7 pawns and 8 pawns (because of the chance to convert the pawn to another piece).

As you can see there are endless variations of how the variables can interact. Many of the interactions go along an early/late game dimension. I.e. fewer material more material interactions, which basically involve some derived metric from the underlying 30 variables (more pieces that are captured off the board the ""later game"" it is, so a rough approximation might just be a sum of the 30 0/1 variables).

This makes it very challenging because it's almost like you need a combined supervised-unsupervised learning process that can discover interesting projections of the variables to interact on (i.e. discover the early/late game metric and start interacting other variables on it). Then plug those into a supervised method. This brings me to the various approaches that I'm considering:
---------------------------------------------------------------------------------------------------------------------------

* Boosted trees: The problem is the underlying weak learners don't have any chance to capture any of the interesting structure in the feature space. For trees to work they need to have many nodes to discover the complex interactions, and boosting tends not to do well with deep trees.

* Random forests: This has a better chance of working. But I would have to use very deep trees to capture the interaction, and even though random forest does pretty well with deep trees I've never heard of trees 20+ levels deep which is what you would need to discover some of the early/late game interactions. (At least you would need to go 20+ deep if you were splitting nodes based on single variables).

* SVMs: This seems somewhat appealing. I'm not too experienced with SVMs, have much more experience with trees. But from what I understand they have a good reputation from capturing non-parametric interactions like these. My only concern here is that a Gaussian kernel wouldn't work here. But again I'm inexperienced so any input on this in particular would be greatly appreciated.

* Logistic regression: This one I have to throw out right away because the problem is so non-linear, and I would have to include 32! interactions (an interaction for every possible piece).

* Neural nets: I'm always somewhat skeptical of these, but the universal function feature does seem to be what I'm looking for here. It would have to be high layer though, and even though the data set's large, with ANNs over fitting is always a problem IMO. Maybe bagging many-layered ANNs here might be a good approach, but I've never heard of anyone doing this so I'm not sure if there are good arguments not to.

* Manifold learning: This is the most ""far out"" approach, but it seems like the only thing that has the direct capability of recovering what I want, i.e. low-material high-material variable projection. Of course I don't know how exactly to translate an unsupervised method into a supervised problem...

Anyway this problem has me tied up in knots. So any interesting approaches or good advice would be greatly appreciated. Thanks.
---------------------------------------------------------------------------------------------------------------------------
",,False,self,t5_2r3gv,True,,,True,t3_s18je,http://www.reddit.com/r/MachineLearning/comments/s18je/extracting_structure_on_a_very_complexly/,
1333466852.0,15,stiglerdiet.com,rr9xq,"Operations Research, Machine Learning, and Optimization",18,3,6,http://www.reddit.com/r/MachineLearning/comments/rr9xq/operations_research_machine_learning_and/,,,False,http://d.thumbs.redditmedia.com/UNhg_Ivlcn9MxJl-.jpg,t5_2r3gv,False,,,False,t3_rr9xq,http://www.stiglerdiet.com/2012/04/03/operations-research-machine-learning-and-optimization/,
1330758978.0,15,blogs.sas.com,qfo82,What is Mahalanobis Distance? An accessible and intuitive introduction.,22,7,2,http://www.reddit.com/r/MachineLearning/comments/qfo82/what_is_mahalanobis_distance_an_accessible_and/,,,False,http://a.thumbs.redditmedia.com/2WMNFyqYxb4tQt10.jpg,t5_2r3gv,False,,,False,t3_qfo82,http://blogs.sas.com/content/iml/2012/02/15/what-is-mahalanobis-distance/,
1330642909.0,17,blog.rtwilson.com,qdltz,Review: Machine Learning: An Algorithmic Perspective by Stephen Marsland,19,2,7,http://www.reddit.com/r/MachineLearning/comments/qdltz/review_machine_learning_an_algorithmic/,,,False,http://c.thumbs.redditmedia.com/qkC0_0JVSWIxI_eV.jpg,t5_2r3gv,False,,,False,t3_qdltz,http://blog.rtwilson.com/review-machine-learning-an-algorithmic-perspective-by-stephen-marsland/,
1328552716.0,18,allendowney.blogspot.com,pdg0g,"Part Three of Think Complexity, a new book about complex systems [x-post from statistics]",19,1,9,http://www.reddit.com/r/MachineLearning/comments/pdg0g/part_three_of_think_complexity_a_new_book_about/,,,False,http://a.thumbs.redditmedia.com/uksgK8MB94S_x5lr.jpg,t5_2r3gv,False,,,False,t3_pdg0g,http://allendowney.blogspot.com/2012/02/think-complexity-part-three.html,
1325847752.0,19,self.MachineLearning,o5ayp,Diagnosing the way a ML algorithm behaves on a problem is non trivial. Has anyone tried to apply machine learning on itself to automatically solve this?,20,1,11,http://www.reddit.com/r/MachineLearning/comments/o5ayp/diagnosing_the_way_a_ml_algorithm_behaves_on_a/,"I got the idea from seeing the title of this paper: [Knows what it knows: a framework for self-aware
learning](http://paul.rutgers.edu/~thomaswa/pub/Li11Knows.pdf).

So, it would be nice to have an extra layer on top of a ML algorithm that would look at its performance and fine tune it: suggest features, number of examples needed, complexity of the model and so on?

At a higher level, this ""ML expert"" could suggest algorithms (and kernels) that work best on the dataset at hand - why rely on human intuition alone?
",,False,self,t5_2r3gv,False,,,True,t3_o5ayp,http://www.reddit.com/r/MachineLearning/comments/o5ayp/diagnosing_the_way_a_ml_algorithm_behaves_on_a/,
1322470850.0,17,amatsukawa.posterous.com,mru1g,Basics of MCMC,19,2,3,http://www.reddit.com/r/MachineLearning/comments/mru1g/basics_of_mcmc/,,,False,http://b.thumbs.redditmedia.com/3qFCDPNZxg0-GSLC.jpg,t5_2r3gv,False,,,False,t3_mru1g,http://amatsukawa.posterous.com/markov-chain-monte-carlo,
1321169226.0,15,techcrunch.com,majym,Google acquires Katango for its Automatic Friend Finder based on ML clustering techniques,19,4,1,http://www.reddit.com/r/MachineLearning/comments/majym/google_acquires_katango_for_its_automatic_friend/,,,False,http://c.thumbs.redditmedia.com/EdiVN9WVZODkOiRn.jpg,t5_2r3gv,False,,,False,t3_majym,http://techcrunch.com/2011/11/10/google-acquires-katango-the-automatic-friend-sorter/,
1318623883.0,17,self.MachineLearning,lcgdu,Who wants to throw around ideas on a regression model for upvotes of a submission?,19,2,16,http://www.reddit.com/r/MachineLearning/comments/lcgdu/who_wants_to_throw_around_ideas_on_a_regression/,"Wouldn't it be cool (and maybe dumb) to provide reddit with a predictive model that would tell them how many upvotes their story might get? We could be reddit stars for a day. So far, I can think of the following relevant features:

continuous: Submission time, ~~subreddit~~ (meant to put that in discrete), submitter's karma, how long submitter has been a redditor, length of title, number of non alphanumeric characters in title, number of capital letters

discrete: is nsfw, maybe use pca to figure out which words are buzzwords or something like that and have them as binary variables (those of you with more nlp experience... suggestions?), is text, is link, is video, is image

i was thinking of trying to hit up .json's based on active learning principles to build a training set, anyone have suggestions on this? 

EDIT: news... Kickstarter said no, so maybe there is some other way to pool money together for this? Also, I have the json data in a sqlite db of 1,000,000 submissions culled from 30,000 users (i had to go from users because that seems like you will get a more representative distribution of all types of posts (except maybe people delete their bad posts...)) that im throwing up on infochimps, they have to approve it so it may take a while. pm me if you have better ideas about where to host it, or if you want me to send it to you directly",,False,self,t5_2r3gv,True,,,True,t3_lcgdu,http://www.reddit.com/r/MachineLearning/comments/lcgdu/who_wants_to_throw_around_ideas_on_a_regression/,
1315462778.0,17,r-bloggers.com,k8jo0,Analyzing big data in R (2 presentations from useR! 2011),20,3,0,http://www.reddit.com/r/MachineLearning/comments/k8jo0/analyzing_big_data_in_r_2_presentations_from_user/,,,False,default,t5_2r3gv,False,,,False,t3_k8jo0,http://www.r-bloggers.com/analyzing-big-data-in-r-two-presentations-from-user-2011/,
1313583184.0,17,radar.oreilly.com,jlirj,Data science is a pipeline between academic disciplines,27,10,5,http://www.reddit.com/r/MachineLearning/comments/jlirj/data_science_is_a_pipeline_between_academic/,,,False,http://thumbs.reddit.com/t3_jlirj.png,t5_2r3gv,False,,,False,t3_jlirj,http://radar.oreilly.com/2011/08/data-science-social-science-academic.html,
1307660147.0,16,self.MachineLearning,hvwxn,"Suggestion for Introductory Machine Learning Text-less technical/more examples than ""Elements of Statistical Learning""",19,3,25,http://www.reddit.com/r/MachineLearning/comments/hvwxn/suggestion_for_introductory_machine_learning/,"I'm a graduate student in statistics and want to branch out into statistical/machine learning.  Everyone I have spoken to has recommended that I read ""The Elements of Statistical Learning"" by Hastie, Tibshirani, and Friedman, but I feel that I need something a bit more remedial.
 
I have almost no background in computer science, except for an introductory computer science course (in Java) as an undergraduate and a course in computational statistics (taught by a statistics prof). 

I am fairly comfortable with mathematical statistics, at about the level of Larry Wasserman's ""All of Statistics"" and I do not feel that the statistical component of ""Elements of Statistical Learning"" is over my head, but after reading the first few chapters, I still don't really understand concepts like the ""nearest neighbor"" algorithm or the definitions/distinction of supervised/unsupervised learning.

I am looking for something at a bit slower pace that starts with a general overview in the field and definitions/elaboration of the key terms.  It would also be preferable if it had some example code of the various algorithms that I could test (preferably in R). 

Any input would be appreciated.      ",,False,self,t5_2r3gv,False,,,True,t3_hvwxn,http://www.reddit.com/r/MachineLearning/comments/hvwxn/suggestion_for_introductory_machine_learning/,
1304804329.0,16,kdnuggets.com,h6b5c,Heritage Health Prize Demands Exclusivity; Others Call for a Boycott,19,3,7,http://www.reddit.com/r/MachineLearning/comments/h6b5c/heritage_health_prize_demands_exclusivity_others/,,,False,default,t5_2r3gv,False,,,False,t3_h6b5c,http://www.kdnuggets.com/2011/05/heritage-health-prize-rule-change-boycott.html,
1301063410.0,18,al3xandr3.github.com,gbac1,Regression with R,19,1,1,http://www.reddit.com/r/MachineLearning/comments/gbac1/regression_with_r/,,,False,default,t5_2r3gv,False,,,False,t3_gbac1,http://al3xandr3.github.com/,
1299788307.0,15,acm.org,g1f0a,Leslie G. Valiant of Harvard winner of the 2010 Turing Award,17,2,0,http://www.reddit.com/r/MachineLearning/comments/g1f0a/leslie_g_valiant_of_harvard_winner_of_the_2010/,,,False,http://thumbs.reddit.com/t3_g1f0a.png,t5_2r3gv,False,,,False,t3_g1f0a,http://www.acm.org/press-room/news-releases/2011/turing-award-10/,
1293643974.0,16,cleverbot.com,et69t,"Winner of the 2010 Machine Intelligence competition: Me: I accidentally the whole thing. Bot: You accidentally what ? Me: I was just hanging out with my friends and a grapefruit, and I accidentally the whole thing. Bot: The WHOLE thing?!?!",30,14,8,http://www.reddit.com/r/MachineLearning/comments/et69t/winner_of_the_2010_machine_intelligence/,,,False,default,t5_2r3gv,False,,,False,t3_et69t,http://www.cleverbot.com/,
1292337952.0,16,icml-2011.org,elnbw,"ICML 2011, The 28th International Conference on Machine Learning",18,2,1,http://www.reddit.com/r/MachineLearning/comments/elnbw/icml_2011_the_28th_international_conference_on/,,,False,http://thumbs.reddit.com/t3_elnbw.png,t5_2r3gv,False,,,False,t3_elnbw,http://www.icml-2011.org/index.php,
1290376642.0,18,news.rpi.edu,e9mdr,Rensselaer Team Mining Data.gov ,21,3,0,http://www.reddit.com/r/MachineLearning/comments/e9mdr/rensselaer_team_mining_datagov/,,,False,http://thumbs.reddit.com/t3_e9mdr.png,t5_2r3gv,False,,,False,t3_e9mdr,http://news.rpi.edu/update.do?artcenterkey=2791,
1290120544.0,16,self.MachineLearning,e8ckl,What are some techniques for identifying unusual changes in a time series?,20,4,22,http://www.reddit.com/r/MachineLearning/comments/e8ckl/what_are_some_techniques_for_identifying_unusual/,"for example, if I'm logging CPU usage of an app, and I want an alert when it spikes, but isn't a blip that comes right back down. I know there are several parameters I need to define (like how much of a move is worth noting), but I'm interesting in learning about techniques in this area, examples, etc., if anyone can point me to some reading material or suggest related subjects to study (I assume signal processing?)",,False,self,t5_2r3gv,False,,,True,t3_e8ckl,http://www.reddit.com/r/MachineLearning/comments/e8ckl/what_are_some_techniques_for_identifying_unusual/,
1289904500.0,18,self.MachineLearning,e6w9x,Ask ML. What effect does sampling have on model accuracy?,20,2,9,http://www.reddit.com/r/MachineLearning/comments/e6w9x/ask_ml_what_effect_does_sampling_have_on_model/,,,False,self,t5_2r3gv,False,,,True,t3_e6w9x,http://www.reddit.com/r/MachineLearning/comments/e6w9x/ask_ml_what_effect_does_sampling_have_on_model/,
1289456131.0,19,blogs.forbes.com,e4gfh,Names You Need to Know in 2011: R Data Analysis Software ,20,1,5,http://www.reddit.com/r/MachineLearning/comments/e4gfh/names_you_need_to_know_in_2011_r_data_analysis/,,,False,http://thumbs.reddit.com/t3_e4gfh.png,t5_2r3gv,False,,,False,t3_e4gfh,http://blogs.forbes.com/smcnally/2010/11/10/names-you-need-to-know-in-2011-r-data-analysis-software/,
1287775630.0,17,r-bloggers.com,dv0qv,How to avoid annoying a referee (of an academic article),18,1,1,http://www.reddit.com/r/MachineLearning/comments/dv0qv/how_to_avoid_annoying_a_referee_of_an_academic/,,,False,http://thumbs.reddit.com/t3_dv0qv.png,t5_2r3gv,False,,,False,t3_dv0qv,http://www.r-bloggers.com/how-to-avoid-annoying-a-referee/,
1284547496.0,17,kaggle.com,de4f6,A profile of those who compete in machine learning competitions,18,1,1,http://www.reddit.com/r/MachineLearning/comments/de4f6/a_profile_of_those_who_compete_in_machine/,,,False,http://thumbs.reddit.com/t3_de4f6.png,t5_2r3gv,False,,,False,t3_de4f6,http://kaggle.com/blog/2010/09/14/profiling-kaggles-user-base/,
1282959679.0,16,umiacs.umd.edu,d6elu,"Data-Intensive Text Processing with MapReduce, book for people writing map-reduce algorithms.",19,3,0,http://www.reddit.com/r/MachineLearning/comments/d6elu/dataintensive_text_processing_with_mapreduce_book/,,,False,default,t5_2r3gv,False,,,False,t3_d6elu,http://www.umiacs.umd.edu/~jimmylin/book.html,
1279388239.0,19,videolectures.net,cqol3,Introduction to Statistical Machine Learning [VID],19,0,0,http://www.reddit.com/r/MachineLearning/comments/cqol3/introduction_to_statistical_machine_learning_vid/,,,False,default,t5_2r3gv,False,,,False,t3_cqol3,http://videolectures.net/mlss08au_hutter_isml/,
1278795368.0,16,metaoptimize.com,co5al,What are the most influential ideas we should tell other computer scientists about?,17,1,0,http://www.reddit.com/r/MachineLearning/comments/co5al/what_are_the_most_influential_ideas_we_should/,,,False,default,t5_2r3gv,False,,,False,t3_co5al,http://metaoptimize.com/qa/questions/867/most-influential-ideas-1995-2005,
1277260062.0,18,measuringmeasures.com,chz67,Learning about Machine Learning,20,2,2,http://www.reddit.com/r/MachineLearning/comments/chz67/learning_about_machine_learning/,,,False,http://thumbs.reddit.com/t3_chz67.png,t5_2r3gv,False,,,False,t3_chz67,http://measuringmeasures.com/blog/2010/3/12/learning-about-machine-learning-2nd-ed.html,
1271937058.0,16,pslcdatashop.web.cmu.edu,bukra,2010 KDD Cup Competition - Educational Data Mining Challenge,17,1,0,http://www.reddit.com/r/MachineLearning/comments/bukra/2010_kdd_cup_competition_educational_data_mining/,,,False,default,t5_2r3gv,False,,,False,t3_bukra,https://pslcdatashop.web.cmu.edu/KDDCup/,
1269325230.0,19,scpro.streamuk.com,bgyng,Prof. Bishop's lecture: Embracing Uncertainty: The New Machine Intelligence ,19,0,5,http://www.reddit.com/r/MachineLearning/comments/bgyng/prof_bishops_lecture_embracing_uncertainty_the/,,,False,default,t5_2r3gv,False,,,False,t3_bgyng,http://scpro.streamuk.com/uk/player/Default.aspx?wid=7739,
1265222269.0,18,labs.yahoo.com,axo7r,Yahoo Key Scientific Challenges - Machine Learning,22,4,3,http://www.reddit.com/r/MachineLearning/comments/axo7r/yahoo_key_scientific_challenges_machine_learning/,,,False,http://thumbs.reddit.com/t3_axo7r.png,t5_2r3gv,False,,,False,t3_axo7r,http://labs.yahoo.com/ksc/Machine_Learning,
1264188824.0,17,omopcup.orwik.com,aszb6,Data mining competition for predicting drug reactions from medical records (with prizes),18,1,1,http://www.reddit.com/r/MachineLearning/comments/aszb6/data_mining_competition_for_predicting_drug/,,,False,http://thumbs.reddit.com/t3_aszb6.png,t5_2r3gv,False,,,False,t3_aszb6,http://omopcup.orwik.com,
1257420209.0,17,mlcomp.org,a17pe,MLComp: a comparison site for machine learning algorithms,18,1,0,http://www.reddit.com/r/MachineLearning/comments/a17pe/mlcomp_a_comparison_site_for_machine_learning/,,,False,http://thumbs.reddit.com/t3_a17pe.png,t5_2r3gv,False,,,False,t3_a17pe,http://mlcomp.org/,
1257161771.0,17,citeseerx.ist.psu.edu,a0446,"Boosting algorithms: regularization, prediction and model fitting [pdf]",17,0,0,http://www.reddit.com/r/MachineLearning/comments/a0446/boosting_algorithms_regularization_prediction_and/,,,False,default,t5_2r3gv,False,,,False,t3_a0446,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.80.4075&amp;rep=rep1&amp;type=pdf,
1376045283.0,16,self.MachineLearning,1k0op2,"[Help] Dealing with high-variable, (relatively) low-observation data",17,1,25,http://www.reddit.com/r/MachineLearning/comments/1k0op2/help_dealing_with_highvariable_relatively/,"Apologies if this is inappropiate, but I'm fairly new to ML and having a bit of trouble finding resources for this particular problem.

I have 30 observations in 2 classes (15 in each). Each observation has several thousand variables (this could be reduced in a somewhat hand-wavy way, but I'd rather not). All variables are continuous; some are normally distributed and some aren't; some are most likely redundant; some are highly informative and others aren't/ are misinformative. I'm using SVM with the RBF kernel (from libSVM in Matlab) to build classifiers, using leave-one-out cross validation (or leave-pair-out, removing one from each class, for tests with fewer iterations) to test the feature selection algorithm, but I'm having real trouble finding a feature selection algorithm which is at all stable across the different iterations of the LOOCV. 

At first I tried ranking features in terms of their contrast-to-noise ratio and building a classifier by using the top one, then the top two, then the top n, and finding the optimal classifier out of those, but it meant that a lot of redundant information was included (possibly weighting the classifier in an unhelpful manner), and the results were poor, as well as the choice of features being very unstable- I think because small variations in CNR cause quite large changes in CNR rank. Then I tried greedy forward selection, which was better (80% sensitivity, 87% specificity), but still each classifier was picking up different features (although some were picked more frequently than others). The greedy algorithm used LOOCV within the remaining 29 variables to choose which feature should be added, so it was a sort of (LOO^2). It would be interesting to use the probability of any feature being selected to weight the final classifier, but to test this I'd need to go to a third level of LOO, which is getting absurd.

At the moment I'm trying to reduce the number of features by combining covarying variables, using PCA. However, it's my understanding that PCA doesn't really work very well with such rectangular data, and so I'd need to heuristically reduce the number of features first for it to effective. In particular, I found that the contrast:noise ratio of each PCC-transformed variable had no correlation with the latent of the PCC (even when the latent was 0). This means that PCA doesn't actually reduce the search space at all. *Edit: Also, none of the features actually seem to have a very high covariance.*

Have I missed some handy redundancy reduction, dimensionality reduction or other feature selection algorithm which is useful for this sort of data? Or is it crazy to be even looking at this rectangular a data set, and I should be trying to massively cut down the number of variables that I'm feeding in to any algorithm?

EDIT: Thanks for the help, guys! In the unlikely event that I can squeeze a publication out of this in the next couple of months I'll do my best to big up /r/machinelearning. ",,False,self,t5_2r3gv,1376064747.0,,,True,t3_1k0op2,http://www.reddit.com/r/MachineLearning/comments/1k0op2/help_dealing_with_highvariable_relatively/,
1374438032.0,16,jstatsoft.org,1irmun,"fastcluster: Fast Hierarchical, Agglomerative Clustering Routines for R and Python",17,1,0,http://www.reddit.com/r/MachineLearning/comments/1irmun/fastcluster_fast_hierarchical_agglomerative/,,,False,default,t5_2r3gv,False,,,False,t3_1irmun,http://www.jstatsoft.org/v53/i09/,
1373987609.0,15,mathbabe.org,1if11s,"New data set for analysis and visualization: the BFF project on campaign contributions, votes, speeches, and bill (co-)sponsorship in congress. How much does money influence politics?",17,2,1,http://www.reddit.com/r/MachineLearning/comments/1if11s/new_data_set_for_analysis_and_visualization_the/,,,False,http://e.thumbs.redditmedia.com/i4aQb_qCB_4GGsQd.jpg,t5_2r3gv,False,,,False,t3_1if11s,http://mathbabe.org/2013/07/16/money-in-politics-the-bff-project/,
1373408806.0,14,numenta.org,1hysgs,"Predicting Movement with IR Sensors, My Experience at the First NuPIC Hackathon",23,9,0,http://www.reddit.com/r/MachineLearning/comments/1hysgs/predicting_movement_with_ir_sensors_my_experience/,,,False,http://a.thumbs.redditmedia.com/vH5V8smbwg_qhoer.jpg,t5_2r3gv,False,,,False,t3_1hysgs,http://numenta.org/news/2013/07/09/predicting-movement-with-ir-sensors.html,
1373034808.0,17,danielfrg.github.io,1hoxaf,Basic [1 hidden layer] neural network in Python,27,10,9,http://www.reddit.com/r/MachineLearning/comments/1hoxaf/basic_1_hidden_layer_neural_network_in_python/,,,False,default,t5_2r3gv,False,,,False,t3_1hoxaf,http://danielfrg.github.io/blog/2013/07/03/basic-neural-network-python/,
1369350279.0,16,reddit.com,1exos4,New sub-reddit for Jobs in Big Data,18,2,0,http://www.reddit.com/r/MachineLearning/comments/1exos4/new_subreddit_for_jobs_in_big_data/,,,False,default,t5_2r3gv,False,,,False,t3_1exos4,http://www.reddit.com/r/BigDataJobs/,
1369162652.0,17,self.MachineLearning,1es4dh,Some Questions from a Beginner...,23,6,15,http://www.reddit.com/r/MachineLearning/comments/1es4dh/some_questions_from_a_beginner/,"I've been looking into Machine Learning and Data Science for a while, and I feel that it would be a very interesting field to get into. Anyways, I have some questions that need to be answered before I go into the deep end.

1. Is Python the language of choice for Machine Learning and Data Science? I know that Kaggle encourages people to use it, but I've also seen people look down on Kaggle. I'm not good at computer programming but I think that I could get the hang of Python if I practiced hard enough.

2. Do I need to be adept at calculus to excel at Machine Learning and Data Science? Because I'm not good at that, although I am decent at statistics (I took two courses of Statistics in graduate school and a course in Psychometrics). I like statistics because it actually puts meaning behind the numbers and formulas. I'm actually decent at mathematical theory (or at least I'm not so hopeless in that field), but I have trouble doing the actual calculations.

Any feedback would be appreciated. Thanks.",,False,self,t5_2r3gv,False,,,True,t3_1es4dh,http://www.reddit.com/r/MachineLearning/comments/1es4dh/some_questions_from_a_beginner/,
1367506554.0,14,reddit.com,1djxqt,"""Historically, we solved problems that required this algorithm (and, pre-digital revolution, problems requiring any kind of algorithm) by coming up with a cultural role and sticking a person in it (painter, blacksmith, photographer, architect, hunter, gatherer, etc.).""",22,8,0,http://www.reddit.com/r/MachineLearning/comments/1djxqt/historically_we_solved_problems_that_required/,,,False,default,t5_2r3gv,False,,,False,t3_1djxqt,http://www.reddit.com/r/Physics/comments/19xj71/newscientist_on_6_march_at_the_adiabatic_quantum/c8sd33u?context=1,
1366040786.0,17,self.MachineLearning,1ce7k5,Looking for info about machine learning for sound synthesis,19,2,8,http://www.reddit.com/r/MachineLearning/comments/1ce7k5/looking_for_info_about_machine_learning_for_sound/,"Can anyone find any information about using machine learning algorithms to learn to predict the next sample in a sound file from the previous samples, and using the trained model to generate novel sound? In particular, I would like to hear audio files associated with any projects out there. I made a synthesizer that works this way, and the only sound I have ever heard produced like this are my own. I am sure there are others out there, but google has failed me.",,False,self,t5_2r3gv,False,,,True,t3_1ce7k5,http://www.reddit.com/r/MachineLearning/comments/1ce7k5/looking_for_info_about_machine_learning_for_sound/,
1364923312.0,16,mutantturkey.com,1biyvs,pyfeast - a feature selection tool for python,21,5,0,http://www.reddit.com/r/MachineLearning/comments/1biyvs/pyfeast_a_feature_selection_tool_for_python/,,,False,http://c.thumbs.redditmedia.com/s_Bm6Cpg8EYNDMQz.jpg,t5_2r3gv,False,,,False,t3_1biyvs,http://mutantturkey.com/PyFeast,
1363124165.0,18,blog.bigml.com,1a68s8,"Machine Learning From Streaming Data: Two Problems, Two Solutions, Two Concerns, and Two Lessons",21,3,1,http://www.reddit.com/r/MachineLearning/comments/1a68s8/machine_learning_from_streaming_data_two_problems/,,,False,http://d.thumbs.redditmedia.com/-U8VlSeOdW6ovH6i.jpg,t5_2r3gv,False,,,False,t3_1a68s8,http://blog.bigml.com/2013/03/12/machine-learning-from-streaming-data-two-problems-two-solutions-two-concerns-and-two-lessons/,
1362863479.0,18,self.MachineLearning,19zllp,Looking for Predictive Modeling / Data Mining data set repository for demonstrations,23,5,4,http://www.reddit.com/r/MachineLearning/comments/19zllp/looking_for_predictive_modeling_data_mining_data/,"Hi

I'd like to demonstrate a new data mining technique to a client, where the client can then gain access to the same data set and use their own favorite techniques and compare results to what I have demonstrated.  I'd like to find a data set with a binary target variable and as many predictors (columns) and records (rows) as possible.  Anyone know of a repository of such data sets?  Domain (medicine, lending, etc) is not as important as the size of the data file to be tackled.  Thanks",,False,self,t5_2r3gv,False,,,True,t3_19zllp,http://www.reddit.com/r/MachineLearning/comments/19zllp/looking_for_predictive_modeling_data_mining_data/,
1356017055.0,17,machinedlearnings.com,15650b,Do you really have big data?,26,9,0,http://www.reddit.com/r/MachineLearning/comments/15650b/do_you_really_have_big_data/,,,False,http://a.thumbs.redditmedia.com/ULxKMxXBEBvzotXH.jpg,t5_2r3gv,False,,,False,t3_15650b,http://www.machinedlearnings.com/2012/12/do-you-really-have-big-data.html,
1353020763.0,15,littlestat.com,139lhv,Calculate Statistics Online,21,6,0,http://www.reddit.com/r/MachineLearning/comments/139lhv/calculate_statistics_online/,,,False,default,t5_2r3gv,False,,,False,t3_139lhv,http://littlestat.com,
1349043331.0,16,puffinwarellc.com,10qafp,A tutorial on Latent Semantic Analysis with Python code,18,2,0,http://www.reddit.com/r/MachineLearning/comments/10qafp/a_tutorial_on_latent_semantic_analysis_with/,,,False,http://d.thumbs.redditmedia.com/QJd-BmHFnGfQefzE.jpg,t5_2r3gv,False,,,False,t3_10qafp,http://www.puffinwarellc.com/index.php/news-and-articles/articles/33.html?showall=1,
1347621454.0,16,self.MachineLearning,zve1y,"What is a ""graph kernel""",16,0,15,http://www.reddit.com/r/MachineLearning/comments/zve1y/what_is_a_graph_kernel/,"Hello ML community.

I just found this place and probably will lurk around more from now on. Some great threads here!.

Maybe I will just go straight to the question:

Can someone explain to me the idea behind ""graph kernels"" in some simple terms? I haven't been able to find any educational material on it, just read some papers. It looked like they are reconstructing the graph into various parts (like walks, paths, etc) and then comparing those parts to get the distances between graphs. Is it the whole idea or did I miss it?

So for example: would simply taking all minimum spanning trees of some weighted graphs and then comparing the sets of those trees be a kernel? Or does it have to be something more (like satisfy triangle inequalities or something else).

best,
PMW.",,False,self,t5_2r3gv,False,,,True,t3_zve1y,http://www.reddit.com/r/MachineLearning/comments/zve1y/what_is_a_graph_kernel/,
1347461513.0,15,self.MachineLearning,zrnf6,"Taking beginner's course in machine learning focusing on NLP, and not very happy with the literature so far. What's your recommendation for beginner's book in ML?",17,2,13,http://www.reddit.com/r/MachineLearning/comments/zrnf6/taking_beginners_course_in_machine_learning/,"The course book we're using is 'Introduction to Machine Learning' by Ethem Alpayden, and feel like I have a difficulty of understanding his explanations within certain areas. I would like to have some extra literature for guidance when I feel like I'm stuck. Any recommendations?",,False,self,t5_2r3gv,False,,,True,t3_zrnf6,http://www.reddit.com/r/MachineLearning/comments/zrnf6/taking_beginners_course_in_machine_learning/,
1344512992.0,16,self.MachineLearning,xxo4u,Introduction to Random Forests?,19,3,12,http://www.reddit.com/r/MachineLearning/comments/xxo4u/introduction_to_random_forests/,"Could anyone recommend a good introduction to random forests? Perhaps even something of tutorial level? My google-fu seems to have failed me.

Thanks!",,False,self,t5_2r3gv,False,,,True,t3_xxo4u,http://www.reddit.com/r/MachineLearning/comments/xxo4u/introduction_to_random_forests/,
1339635370.0,13,static.googleusercontent.com,v0tmw,The Unreasonable Effectiveness of Data,17,4,2,http://www.reddit.com/r/MachineLearning/comments/v0tmw/the_unreasonable_effectiveness_of_data/,,,False,default,t5_2r3gv,False,,,False,t3_v0tmw,http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/35179.pdf,
1339603782.0,17,self.MachineLearning,uzzkl,Would mastering the algorithm's in Andrew Ng's machine learning course on coursera.org be enough to break into the field?,26,9,22,http://www.reddit.com/r/MachineLearning/comments/uzzkl/would_mastering_the_algorithms_in_andrew_ngs/,"I've been going through [the course](https://class.coursera.org/ml/class/index) and realized that many of the exercises are lacking depth, so I intend on re-writing most of the algorithms without Octave/Matlab so I can get a genuine understanding of the process. 

Current I'm doing a lot of web development with Ruby on Rails, but I'd like to break into machine learning. I have a strong feeling that mastering (not just doing the exercises, but practicing them regularly) the algorithms that Andrew Ng has shown in the course might be enough that I may end up with one or two opportunities to use these skills while doing my job, say for example classifying users based on site activity or being able to predict the amount of traffic on any given day.. 

However, I'm being lured into a lot more other challenging courses, like coursera's NLP course. I don't want to end up a jack-of-all-trades with little chance of actually applying what I've learned to my daily job, so I feel focusing on a small number of algorithms to master would be better than getting a general understanding of many algorithms.

Has anyone else gone the web development to machine learning route? How as it worked out for you? How did you manage to break in?

**TLDR**: Do I have to learn lots of algorithms to become an effective ML-er or know a handful really well?",,False,self,t5_2r3gv,1339606148.0,,,True,t3_uzzkl,http://www.reddit.com/r/MachineLearning/comments/uzzkl/would_mastering_the_algorithms_in_andrew_ngs/,
1339390175.0,15,csie.ntu.edu.tw,uvowm,A Practical Guide to Support Vector Classification,16,1,1,http://www.reddit.com/r/MachineLearning/comments/uvowm/a_practical_guide_to_support_vector_classification/,,,False,default,t5_2r3gv,False,,,False,t3_uvowm,http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf,
1336606469.0,16,self.MachineLearning,tfjs5,Machine Learning Summer School Program Impressions?,20,4,3,http://www.reddit.com/r/MachineLearning/comments/tfjs5/machine_learning_summer_school_program_impressions/,"I was wondering if anyone here has had any experience with the [Machine Learning Summer School program](http://www.mlss.cc/).  For those who have attended, 

* Was it a worthwhile experience?  
* Do you feel that you learned something useful beyond what you would have found on  your own time?  
* Did the talks go into sufficient technical depth to truly understand an area of research without becoming too opaque to understand?",,False,self,t5_2r3gv,False,,,True,t3_tfjs5,http://www.reddit.com/r/MachineLearning/comments/tfjs5/machine_learning_summer_school_program_impressions/,
1329556782.0,14,self.MachineLearning,pv36y,"Stanford delays machine learning class 
again",22,8,16,http://www.reddit.com/r/MachineLearning/comments/pv36y/stanford_delays_machine_learning_class_again/,"Got this email tonight...


We're sorry to have to tell you that our Machine Learning course will be delayed further. There have naturally been legal and administrative issues to be sorted out in offering Stanford classes freely to the outside world, and it's just been taking time. We have, however, been able to take advantage of the extra time to debug and improve our course content!

We now expect that the course will start either late in February or early in March. We will let you know as soon as we hear a definite date. We apologize for the lack of communication in recent weeks; we kept hoping we would have a concrete launch date to give you, but that date has kept slipping.

Thanks so much for your patience! We are really sorry for repeatedly making you wait, and for any interference this causes in your schedules. We're as excited and anxious as you are to get started, and we both look forward to your joining us soon in Machine Learning!

Andrew Ng and the ML Course Staff

",,False,self,t5_2r3gv,False,,,True,t3_pv36y,http://www.reddit.com/r/MachineLearning/comments/pv36y/stanford_delays_machine_learning_class_again/,
1328116809.0,16,self.MachineLearning,p6c0o,"New to machine learning, need some advice on the math involved.",25,9,22,http://www.reddit.com/r/MachineLearning/comments/p6c0o/new_to_machine_learning_need_some_advice_on_the/,What math classes should I have under my belt to be able to fully grasp machine learning?  Any suggestions would be a big help.,,False,self,t5_2r3gv,False,,,True,t3_p6c0o,http://www.reddit.com/r/MachineLearning/comments/p6c0o/new_to_machine_learning_need_some_advice_on_the/,
1327442016.0,15,youtube.com,ov1q7,hiragana stroke prediction.,20,5,5,http://www.reddit.com/r/MachineLearning/comments/ov1q7/hiragana_stroke_prediction/,,,False,http://b.thumbs.redditmedia.com/SsMPJsUr2hUX8t0g.jpg,t5_2r3gv,False,,,False,t3_ov1q7,http://www.youtube.com/watch?v=N38Ry7xvD8I&amp;feature=g-upl&amp;context=G27a9118AUAAAAAAAAAA,
1323810736.0,17,divvy.ucsd.edu,nbgpk,Divvy - unsupervised learning data exploration tool (OS/X),21,4,10,http://www.reddit.com/r/MachineLearning/comments/nbgpk/divvy_unsupervised_learning_data_exploration_tool/,,,False,default,t5_2r3gv,False,,,False,t3_nbgpk,http://divvy.ucsd.edu/,
1316367755.0,15,pyevolve.sourceforge.net,kjncl,Text feature extraction (tf-idf) - Part I,19,4,0,http://www.reddit.com/r/MachineLearning/comments/kjncl/text_feature_extraction_tfidf_part_i/,,,False,http://thumbs.reddit.com/t3_kjncl.png,t5_2r3gv,False,,,False,t3_kjncl,http://pyevolve.sourceforge.net/wordpress/?p=1589,
1315363793.0,14,designbyrobots.com,k751o,Automated Design of Trading Strategies: Intro to Automated Design and Demo [Video],20,6,4,http://www.reddit.com/r/MachineLearning/comments/k751o/automated_design_of_trading_strategies_intro_to/,,,False,default,t5_2r3gv,False,,,False,t3_k751o,http://designbyrobots.com/2011/09/06/automated-design-of-trading-strategies/,
1313139648.0,16,mblondel.org,jgm15,Kernel Perceptrons in Python,22,6,1,http://www.reddit.com/r/MachineLearning/comments/jgm15/kernel_perceptrons_in_python/,,,False,http://thumbs.reddit.com/t3_jgm15.png,t5_2r3gv,False,,,False,t3_jgm15,http://www.mblondel.org/journal/2010/10/31/kernel-perceptron-in-python/,
1312413716.0,15,rtexttools.com,j88lw,RTextTools: an R machine learning package for text classification,18,3,0,http://www.reddit.com/r/MachineLearning/comments/j88lw/rtexttools_an_r_machine_learning_package_for_text/,,,False,default,t5_2r3gv,False,,,False,t3_j88lw,http://www.rtexttools.com/,
1311683721.0,17,self.MachineLearning,j03no,Tips for coding long-running calculations?,19,2,17,http://www.reddit.com/r/MachineLearning/comments/j03no/tips_for_coding_longrunning_calculations/,"Hi /r/MachineLearning,

My current gig involves some machine-learning, and a lot of the experiments I want to run take up to a day to complete. My previous programming work has been in domains where the edit/compile/test cycle has been much faster, and it's no problem to restart the program every few minutes if need be. I'm struggling with this: often bugs only become apparent several hours into the run, while I'm asleep or otherwise engaged, so it's easy to lose days to trivial mistakes. Some of the people here must deal with this all the time: what tools and strategies do you use to handle it?

Some things seem obvious:

 * Make the code faster, by parallelising it, distributing it to a cluster, running it on GPUs, running it on faster hardware, or just old-fashioned profiling and hotspot elimination. I've done some of this, and intend to do more - the 1-day runtime quoted above is after parallelisation.
 * Unit testing and static checks. I've been pretty lax about this, but I'm now starting to bring my code under test so I can have some confidence my changes will work before I kick off a full run.
 * Making my code self-monitoring: watching for anomalous situations and logging warnings then handling them, or aborting rather than continuing in an inconsistent state.
I learned this one in a nasty way: an external tool that I invoked as part of my fitness function was failing when given certain combinations of arguments. This meant that there was no ""total energy"" line in its output, so the simulated energy use for that test was zero; my GA proceeded to optimise until the bug was *always* triggered :-(
 * Periodically checkpoint the program's state, so you can restore from the last good state before a bug is triggered or the machine goes down.
 * Output log data in a machine-readable fashion, so you can copy-and-paste that line to get a ready-made testcase when something goes wrong.

... but I'm sure there's more to it than that.

I also have some more focussed questions:

 * People have suggested that I try watcher daemons or cron jobs to periodically restart my code if it hangs or dies. That makes sense for something like a web server, but I don't understand how it would help for a single long-running calculation. Do you do this? Does it help?
 * How do you handle the situation where your program is sitting there using up 100% CPU but producing no output?
 * How much logging do you do? How do you decide what to log?

Thanks!",,False,self,t5_2r3gv,True,,,True,t3_j03no,http://www.reddit.com/r/MachineLearning/comments/j03no/tips_for_coding_longrunning_calculations/,
1311587188.0,16,self.MachineLearning,iz1vq,How would one go around creating an AI player for magic the gathering?,19,3,17,http://www.reddit.com/r/MachineLearning/comments/iz1vq/how_would_one_go_around_creating_an_ai_player_for/,"I was wondering about this yesterday. Magic the Gathering is a very broad game and a new set of cards is released every year so the cards people are playing with are always changing. There are some big competitions and money to be earned in it if you're good.

Magic got a pretty solid [rules](http://www.wizards.com/Magic/TCG/Article.aspx?x=magic/rules) so implementing the rules in code shouldn't be that much of a hassle (taking Hofstadter's law into account...) but hammering all the cards in would take some time.

My question now is, what method would you use to train an AI player? I was thinking about using monte carlo but then it occurred to me that I can't let the deck of cards be in a predefined state because then I would be allowing the player to ""see"" the future when he's drawing the cards. Some cards however allow the player to change the order of e.g. the top three cards of his deck so I can't let the player choose a random card from it.

Training a neural network for each possible deck seems out of hand because of the immense range of cards out there.

Would it also be possible to let two AI players play against each other to find the best possible deck?

This is merely just a speculation for me at the moment, my assumptions might be naive. I've only taken one undergraduate course in Machine Learning but also a few in optimization so I was wondering if I could use this idea to expand my knowledge.",,False,self,t5_2r3gv,False,,,True,t3_iz1vq,http://www.reddit.com/r/MachineLearning/comments/iz1vq/how_would_one_go_around_creating_an_ai_player_for/,
1310997642.0,17,aura.fi.muni.cz,ist9f,"	
*
Semantic analysis of text: demo of gensim over arXiv.org",17,0,1,http://www.reddit.com/r/MachineLearning/comments/ist9f/semantic_analysis_of_text_demo_of_gensim_over/,,,False,http://thumbs.reddit.com/t3_ist9f.png,t5_2r3gv,False,,,False,t3_ist9f,http://aura.fi.muni.cz:8080/,
1307885202.0,14,news.ycombinator.com,hxr8g,I asked HN on how to effectively start on Machine Learning (I have web dev background),21,7,5,http://www.reddit.com/r/MachineLearning/comments/hxr8g/i_asked_hn_on_how_to_effectively_start_on_machine/,,,False,default,t5_2r3gv,False,,,False,t3_hxr8g,http://news.ycombinator.com/item?id=2645671,
1304976652.0,17,self.MachineLearning,h7mjn,Looking for overviews of ways of measuring similarity,21,4,28,http://www.reddit.com/r/MachineLearning/comments/h7mjn/looking_for_overviews_of_ways_of_measuring/,"If I have two sets of things - let's take fruit as an example - how might I go about measuring how similar those sets are? I'm curious about approaches taken to this problem and the technical, statistical and philosophical underpinnings of it.

For example, if my sets are identical and both contain one banana, I could say they are 100% alike. But if one has a banana and apple, the other a banana and pear, how can I measure this?

As a starting point, I could give 1 point for a match and divide by the average length of the sets. In this case, my sets have 0.5 similarity, while the two bananas score 1. But I can see there are problematic implications here - sets with four matching items and length nine have a lower score but more matches. I'm not sure if this is what I want or not. Similarly, I can see there are consequences to deducting points when items don't match.

I'm asking such a broad question seeking general overviews of approaches and options. Are there any good articles about similarity which you could recommend? I'd also be interested to see some examples of different similarity measures used in different applications and discussion of why they were chosen.

tl;dr there's a lot to the concept of similarity - can you suggest some overviews?

",,False,self,t5_2r3gv,False,,,True,t3_h7mjn,http://www.reddit.com/r/MachineLearning/comments/h7mjn/looking_for_overviews_of_ways_of_measuring/,
1296516777.0,17,theswimmingsubmarine.blogspot.com,fcph1,An Machine Learning system that can hear what you're typing ,18,1,7,http://www.reddit.com/r/MachineLearning/comments/fcph1/an_machine_learning_system_that_can_hear_what/,,,False,http://thumbs.reddit.com/t3_fcph1.png,t5_2r3gv,False,,,False,t3_fcph1,http://theswimmingsubmarine.blogspot.com/2011/01/ai-system-that-can-hear-what-youre.html,
1291338432.0,16,online.wsj.com,efc4s,"Some Internet-Use Tracking Firms to Reveal What They Know -- a group of online tracking rivals are building a service that lets consumers see what information those companies know about them.

",18,2,0,http://www.reddit.com/r/MachineLearning/comments/efc4s/some_internetuse_tracking_firms_to_reveal_what/,,,False,http://thumbs.reddit.com/t3_efc4s.png,t5_2r3gv,False,,,False,t3_efc4s,http://online.wsj.com/article/SB10001424052748704377004575650802136721966.html?mod=WSJ_hp_MIDDLETopStories,
1290077972.0,16,infochimps.com,e81go,UFO dataset,18,2,1,http://www.reddit.com/r/MachineLearning/comments/e81go/ufo_dataset/,,,False,default,t5_2r3gv,False,,,False,t3_e81go,http://infochimps.com/datasets/d60000-documented-ufo-sightings-with-text-descriptions-and-metad,
1281973457.0,16,freakonomics.blogs.nytimes.com,d1r2d,Suicide bombers do not buy life insurance,22,6,10,http://www.reddit.com/r/MachineLearning/comments/d1r2d/suicide_bombers_do_not_buy_life_insurance/,,,False,http://thumbs.reddit.com/t3_d1r2d.png,t5_2r3gv,False,,,False,t3_d1r2d,http://freakonomics.blogs.nytimes.com/2010/08/16/superfreakonomics-book-club-can-a-bankers-algorithm-help-catch-would-be-terrorists/,
1280949997.0,17,arstechnica.com,cxehn,Gamers beat algorithms at finding protein structures,20,3,1,http://www.reddit.com/r/MachineLearning/comments/cxehn/gamers_beat_algorithms_at_finding_protein/,,,False,http://thumbs.reddit.com/t3_cxehn.png,t5_2r3gv,False,,,False,t3_cxehn,http://arstechnica.com/science/news/2010/08/gamers-beat-algorithms-for-finding-protein-structures.ars,
1280789106.0,16,chariotsolutions.blogspot.com,cwlee,Using Google's Prediction API to Write a Spam Filter,19,3,2,http://www.reddit.com/r/MachineLearning/comments/cwlee/using_googles_prediction_api_to_write_a_spam/,,,False,default,t5_2r3gv,False,,,False,t3_cwlee,http://chariotsolutions.blogspot.com/2010/08/machine-learning-google-prediction-api.html,
1279722525.0,15,nlp.stanford.edu,cs1vo,Introduction to Information Retrieval Ebook,17,2,1,http://www.reddit.com/r/MachineLearning/comments/cs1vo/introduction_to_information_retrieval_ebook/,,,False,http://thumbs.reddit.com/t3_cs1vo.png,t5_2r3gv,False,,,False,t3_cs1vo,http://nlp.stanford.edu/IR-book/information-retrieval-book.html,
1279484956.0,16,mitworld.mit.edu,cqz7u,State and future of AI- Marvin Minsky Video Lecture.,17,1,0,http://www.reddit.com/r/MachineLearning/comments/cqz7u/state_and_future_of_ai_marvin_minsky_video_lecture/,,,False,http://thumbs.reddit.com/t3_cqz7u.png,t5_2r3gv,False,,,False,t3_cqz7u,http://mitworld.mit.edu/video/484/,
1277395242.0,15,self.MachineLearning,cile6,AskML: What's the difference between Independent Component Analysis and Principal Component Analysis?,21,6,10,http://www.reddit.com/r/MachineLearning/comments/cile6/askml_whats_the_difference_between_independent/,"Both seem to take data down into lower dimensional space. Is there any practical difference between the two? Is one a more general case of the other?

[ICA](http://en.wikipedia.org/wiki/Independent_component_analysis)

[PCA](http://en.wikipedia.org/wiki/Principal_component_analysis)",,False,self,t5_2r3gv,False,,,True,t3_cile6,http://www.reddit.com/r/MachineLearning/comments/cile6/askml_whats_the_difference_between_independent/,
1272872197.0,16,hunch.net,bzb6d,John Langford discusses connections between online learning and the state of the financial system,17,1,0,http://www.reddit.com/r/MachineLearning/comments/bzb6d/john_langford_discusses_connections_between/,,,False,default,t5_2r3gv,False,,,False,t3_bzb6d,http://hunch.net/?p=1346,
1271448188.0,16,kaggle.com,brzk5,Know machinelearning? Really camp? Have I got a competition for you.,18,2,0,http://www.reddit.com/r/MachineLearning/comments/brzk5/know_machinelearning_really_camp_have_i_got_a/,,,False,http://thumbs.reddit.com/t3_brzk5.png,t5_2r3gv,False,,,False,t3_brzk5,http://kaggle.com/Eurovision2010,
1268954036.0,15,stamina.chefbe.net,bf82e,STAMINA: finite state machine learning competition,16,1,0,http://www.reddit.com/r/MachineLearning/comments/bf82e/stamina_finite_state_machine_learning_competition/,,,False,http://thumbs.reddit.com/t3_bf82e.png,t5_2r3gv,False,,,False,t3_bf82e,http://stamina.chefbe.net/,
1266243162.0,16,videolectures.net,b29q3,Algebraic statistics for random graph models: Markov bases and their uses ,17,1,0,http://www.reddit.com/r/MachineLearning/comments/b29q3/algebraic_statistics_for_random_graph_models/,,,False,http://thumbs.reddit.com/t3_b29q3.png,t5_2r3gv,False,,,False,t3_b29q3,http://videolectures.net/aml08_fienberg_asrgmmbtu/,
1264665791.0,15,princeton.edu,av4mo,[fMRI Analysis; Machine Learning] Machine Learning Classifiers and fMRI: A tutorial overview [Link to PDF],19,4,0,http://www.reddit.com/r/MachineLearning/comments/av4mo/fmri_analysis_machine_learning_machine_learning/,,,False,default,t5_2r3gv,False,,,False,t3_av4mo,http://www.princeton.edu/~fpereira/Presentations/ipam2008.pdf,
1264070725.0,17,readwriteweb.com,asbrh,UK Launches Open Data Site; Puts Data.gov to Shame,18,1,0,http://www.reddit.com/r/MachineLearning/comments/asbrh/uk_launches_open_data_site_puts_datagov_to_shame/,,,False,http://thumbs.reddit.com/t3_asbrh.png,t5_2r3gv,False,,,False,t3_asbrh,http://www.readwriteweb.com/archives/uk_launches_open_data_site_puts_datagov_to_shame.php?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%3A+readwriteweb+%28ReadWriteWeb%29&amp;utm_content=Google+Feedfetcher,
1262705008.0,16,mat.tepper.cmu.edu,alth3,"Data Mining, Operations Research, and Predicting Murders",18,2,0,http://www.reddit.com/r/MachineLearning/comments/alth3/data_mining_operations_research_and_predicting/,,,False,default,t5_2r3gv,False,,,False,t3_alth3,http://mat.tepper.cmu.edu/blog/?p=1024,
1257784074.0,16,en.wikipedia.org,a2isi,Repost from /r/programming: Has anyone here used the Kalman filter for approximating state from noisy data? I could use a little help.,18,2,11,http://www.reddit.com/r/MachineLearning/comments/a2isi/repost_from_rprogramming_has_anyone_here_used_the/,,,False,default,t5_2r3gv,False,,,False,t3_a2isi,http://en.wikipedia.org/wiki/Kalman_filter,
1254449891.0,14,daniweb.com,9q1zt,K-means clustering - Python,18,4,2,http://www.reddit.com/r/MachineLearning/comments/9q1zt/kmeans_clustering_python/,,,False,default,t5_2r3gv,False,,,False,t3_9q1zt,http://www.daniweb.com/forums/thread31449.html,
1254384641.0,17,wired.com,9psfo,Data-Mining Medical Records Could Predict Domestic Violence,19,2,0,http://www.reddit.com/r/MachineLearning/comments/9psfo/datamining_medical_records_could_predict_domestic/,,,False,http://thumbs.reddit.com/t3_9psfo.png,t5_2r3gv,False,,,False,t3_9psfo,http://www.wired.com/wiredscience/2009/09/domestic-abuse-prediction/,
1250874515.0,17,onionesquereality.wordpress.com,9cuvc,Face Recognition/Authentication Using Support Vector Machines,18,1,0,http://www.reddit.com/r/MachineLearning/comments/9cuvc/face_recognitionauthentication_using_support/,,,False,http://thumbs.reddit.com/t3_9cuvc.png,t5_2r3gv,False,,,False,t3_9cuvc,http://onionesquereality.wordpress.com/2009/04/17/face-recognitionauthentication-using-support-vector-machines/,
1249054181.0,14,cdmurray80.googlepages.com,96cxb,"Collection of  some great Machine 
Learning Theory Papers and their 
Summary.",16,2,0,http://www.reddit.com/r/MachineLearning/comments/96cxb/collection_of_some_great_machine_learning_theory/,,,False,default,t5_2r3gv,False,,,False,t3_96cxb,http://cdmurray80.googlepages.com/(fundandstock)returnsandbetas2,
1249014053.0,16,cs.toronto.edu,967n1,"David MacKay: Information Theory, 
Inference, and Learning Algorithms. 
[Free Book]",17,1,2,http://www.reddit.com/r/MachineLearning/comments/967n1/david_mackay_information_theory_inference_and/,,,False,http://thumbs.reddit.com/t3_967n1.png,t5_2r3gv,False,,,False,t3_967n1,http://www.cs.toronto.edu/~mackay/itila/book.html,
1248930003.0,18,imonad.com,95vg6,"Restricted Boltzmann Machine, a Short Tutorial",20,2,4,http://www.reddit.com/r/MachineLearning/comments/95vg6/restricted_boltzmann_machine_a_short_tutorial/,,,False,http://thumbs.reddit.com/t3_95vg6.png,t5_2r3gv,False,,,False,t3_95vg6,http://imonad.com/blog/2008/10/restricted-boltzmann-machine/,
1375406140.0,17,self.MachineLearning,1jj9y0,Why don't sigmoid and tanh neural nets behave equivalently?,18,1,22,http://www.reddit.com/r/MachineLearning/comments/1jj9y0/why_dont_sigmoid_and_tanh_neural_nets_behave/,"A sigmoid net can emulate a tanh net of the same architecture, and vice versa. I calculated the gradient for a tanh net, and used the chain rule to find the corresponding gradient for a sigmoid net that emulated that net, and found the same exact gradient as for a sigmoid net. What am I missing?

**Edit**: It turns out that if learning occurs by following the gradient in the tanh net, and one observes what happens in the corresponding sigmoid net, the gradient of the sigmoid net is not followed. I guess I could calculate the tanh gradient and transform it into updates for a sigmoid net to simulate a tanh net with a sigmoid net. I couldn't find any literature on this, so I'm still suspicious I'm overlooking something.

**Edit**: By sigmoid function, I am referring to 1/(1 + exp(-x)).",,False,self,t5_2r3gv,1375411208.0,,,True,t3_1jj9y0,http://www.reddit.com/r/MachineLearning/comments/1jj9y0/why_dont_sigmoid_and_tanh_neural_nets_behave/,
1375251043.0,15,plus.google.com,1jelx7,"Google describes details of their ad system in this paper, to appear at KDD next month.",20,5,0,http://www.reddit.com/r/MachineLearning/comments/1jelx7/google_describes_details_of_their_ad_system_in/,,,False,http://b.thumbs.redditmedia.com/MzLo-vS0vtYCeJDI.jpg,t5_2r3gv,False,,,False,t3_1jelx7,https://plus.google.com/118227548810368513262/posts/Y2EuTQKYYVC,
1375215077.0,15,self.MachineLearning,1jde55,What other machine learning communities are there? Is there a way to find companies that use machine learning techniques?,17,2,18,http://www.reddit.com/r/MachineLearning/comments/1jde55/what_other_machine_learning_communities_are_there/,,,False,self,t5_2r3gv,False,,,True,t3_1jde55,http://www.reddit.com/r/MachineLearning/comments/1jde55/what_other_machine_learning_communities_are_there/,
1374858726.0,16,hunch.net,1j3vqy,ICML 2012 videos lost « Machine Learning (Theory),16,0,1,http://www.reddit.com/r/MachineLearning/comments/1j3vqy/icml_2012_videos_lost_machine_learning_theory/,,,False,default,t5_2r3gv,False,,,False,t3_1j3vqy,http://hunch.net/?p=2664,
1374510888.0,15,self.MachineLearning,1itjyb,[Question] Best resources for feature selection when classifying text using python??,17,2,10,http://www.reddit.com/r/MachineLearning/comments/1itjyb/question_best_resources_for_feature_selection/,"Hey /r/machinelearning--

I don't see too many [question] posts here, so I hope I'm not in the wrong sub.  If so, please point me to a better option.

Currently  I am using SciKit Learn to classify text documents.  I badly need to lower the dimensionality of my data, and I have began doing so by attempting to implement some feature selection classes.  The only problem is that they're not working very well.

I found this [streamhacker post](http://streamhacker.com/2010/06/16/text-classification-sentiment-analysis-eliminate-low-information-features/), but I am less familiar with the NLTK, so I was hoping to learn of other feature selection options (i.e., low information feature elimination) before I started.

Can anyone here suggest anything??  Has anyone here ever reduced dimensionality using SciKit before??  Thank you in advance for any leads!

PS: Is there a sub-group or sub-reddit dedicated to scikit question and, if not, is there any interest in starting one??",,False,self,t5_2r3gv,False,,,True,t3_1itjyb,http://www.reddit.com/r/MachineLearning/comments/1itjyb/question_best_resources_for_feature_selection/,
1374276241.0,14,self.MachineLearning,1inxnq,How to factor in tf-idf with Naive Bayes?,16,2,9,http://www.reddit.com/r/MachineLearning/comments/1inxnq/how_to_factor_in_tfidf_with_naive_bayes/,"From my understanding of naive bayes (multinomial edition), it has to deal with the count of the word for each class and the total count of all words in the class for the following part of the formula, so I am a tad confused:


    P(word|class)=(word_count_in_class + 1)/(total_words_in_class+total_unique_words_in_class) 



",,False,self,t5_2r3gv,1374277222.0,,,True,t3_1inxnq,http://www.reddit.com/r/MachineLearning/comments/1inxnq/how_to_factor_in_tfidf_with_naive_bayes/,
1374033822.0,15,self.MachineLearning,1igpxs,Ask ML: Next step after Andrews Ng's course,17,2,18,http://www.reddit.com/r/MachineLearning/comments/1igpxs/ask_ml_next_step_after_andrews_ngs_course/,"I recently finished Andrew Ng's course on machine learning offered at cousera. Im blown away with the applications of ML and I want to learn more. What should my next step be in continuing to learn about this area? Im able to find tons of information but honestly do not know where to start. My end goal is education, I would LOVE to be able to build something neat out of this (planning on doing linear regression and a classification ML application)

Secondary Question (if anyone has the time to answer!):
Ive also started doing work in cleaning some data I collected (I'm feeling that cleaning and gathering data is about 90% of the fight so far) and I'm running into issues with my computer not being fast/strong enough to handle the volume of data Im trying to make use of. Its slow to do operations such as shuffling a matrix (15mill x 14). Would anyone have a solution to this? Should I perhaps leverage AWS? 

I have a strong calculus and linear algebra background. ",,False,self,t5_2r3gv,False,,,True,t3_1igpxs,http://www.reddit.com/r/MachineLearning/comments/1igpxs/ask_ml_next_step_after_andrews_ngs_course/,
1373337515.0,15,self.MachineLearning,1hwqep,Would you use a LDA based Topic Modeling library in Java which handled a few million documents on a single 16 GB Machine,19,4,19,http://www.reddit.com/r/MachineLearning/comments/1hwqep/would_you_use_a_lda_based_topic_modeling_library/,"I am running a prototype which I developed in Java to perform LDA on a few million documents in Java. I have personally found it very useful as most LDA implementations in Java or R or Python either run out of memory for a few thousand documents or run down to a crawl. 

I am planning on open sourcing it but I still have to add the licensing text in my source files and create some documentations. I was curious if there would be any interest in such as library. Or are people using LDA content with what is out there in the Open Source space.

Edit : Forgot to add that for 500 topics on 2 million documents I am getting a performance of approximately 5 hours for 1000 iterations on EC2 High Memory Instance with Java Max Heap Memory set as 10GB.

Edit2: On my regular home machine with 8GB RAM and Quad Core I-7 processor I ran the process for 500,000 US Patent Abstract for 1000 topics and 1000 iterations in 1hr 30 minutes. The iterations take about 15 seconds initially but eventually started running in 3 seconds or less.",,False,self,t5_2r3gv,1373374075.0,,,True,t3_1hwqep,http://www.reddit.com/r/MachineLearning/comments/1hwqep/would_you_use_a_lda_based_topic_modeling_library/,
1372732072.0,16,self.MachineLearning,1hgxwx,Best Python IDE for Predictive Analytics and machine learning,21,5,23,http://www.reddit.com/r/MachineLearning/comments/1hgxwx/best_python_ide_for_predictive_analytics_and/,"What do you think it the best Python IDE for debugging support, refactoring, etc when dealing in predictive analytics and machine learning?",,False,self,t5_2r3gv,False,,,True,t3_1hgxwx,http://www.reddit.com/r/MachineLearning/comments/1hgxwx/best_python_ide_for_predictive_analytics_and/,
1371132880.0,15,self.MachineLearning,1g9o1a,Any Beginners books/site to get started using Scikit-Learn?,17,2,13,http://www.reddit.com/r/MachineLearning/comments/1g9o1a/any_beginners_bookssite_to_get_started_using/,"Hi, I'm trying to use scikit learn, and doing my best to correlate with the  functions and the formulas i've learn't in the ml-class by Andrew Ng. 



I am able to apply the scikit learn functions to machine learning problems in kaggle(beginner level) ,but i really don't know what i am doing, i'm just copy pasting a few things in the doc examples without really knowing how its parameters are controlling the method i apply. like this one 


    LogisticRegression(C=1.0,dual=False,fit_intercept=True,intercept_scaling=1,penalty='l2', scale_C=False, tol=0.0001)



i really don't know what C,dual,intercept_scaling,penalty,scale_C,tol actually mean. All i understand is that i am applying logistic regression.




Its really appreciated if any can help list a good book or a website to learn scikit and understand it better and know what the parameters are doing etc... 


PS: As you can see i'm a complete beginner .i've tried reading docs of scikit but they look completely cryptic to me any other advice or tips are better. Thanks.",,False,self,t5_2r3gv,False,,,True,t3_1g9o1a,http://www.reddit.com/r/MachineLearning/comments/1g9o1a/any_beginners_bookssite_to_get_started_using/,
1370616110.0,16,blog.quandl.com,1fv3pv,Free data meets free machine learning.,27,11,0,http://www.reddit.com/r/MachineLearning/comments/1fv3pv/free_data_meets_free_machine_learning/,,,False,http://c.thumbs.redditmedia.com/B53ZltKoVQX9JEA2.jpg,t5_2r3gv,False,,,False,t3_1fv3pv,http://blog.quandl.com/qblog/our-new-partner-bigml-lets-you-easily-create-powerful-financial-economic-and-social-predictive-models/,
1369427843.0,14,github.com,1ezqzs,Striate: Simple convolutional neural networks in Python,21,7,2,http://www.reddit.com/r/MachineLearning/comments/1ezqzs/striate_simple_convolutional_neural_networks_in/,,,False,http://e.thumbs.redditmedia.com/ILYn71KOL9Wrc8-L.jpg,t5_2r3gv,False,,,False,t3_1ezqzs,https://github.com/iskandr/striate,
1365708280.0,13,self.MachineLearning,1c5kdl,Are there non-PhD jobs in Machine Learning?,20,7,29,http://www.reddit.com/r/MachineLearning/comments/1c5kdl/are_there_nonphd_jobs_in_machine_learning/,"I've been on the job search for a little while now. I know that I would like to something that would give me a chance to practice and learn more about machine learning. I'm struggling to find a job or internship that is not at the PhD level. So my question is, do they exist? Even if it was mostly grunt work, but you could sit in on a few meetings with the real clever people. Thanks!",,False,self,t5_2r3gv,False,,,True,t3_1c5kdl,http://www.reddit.com/r/MachineLearning/comments/1c5kdl/are_there_nonphd_jobs_in_machine_learning/,
1365292002.0,14,self.MachineLearning,1bto9p,Getting started in Machine Learning from square one: please tell me if I'm wasting my time...,21,7,22,http://www.reddit.com/r/MachineLearning/comments/1bto9p/getting_started_in_machine_learning_from_square/,"Hi

I know next to nothing about Machine Learning, have a beginner-level (and growing) understanding of a variety of programming languages (mostly Ruby) and the highest level of math I've taken is Calculus I. No formal statistics. I read lesswrong.com and attempt to grok rationality and Bayes (no promises). 

From searching around ""noob"" threads on /r/MachineLearning I came across the O'Reilly [Natural Language Processing with Python](http://nltk.org/book/) book and was considering starting there. 

The reason I am posting this here: As I said, I have no formal statistics training/education and the highest math I've completed is Calculus I. Math and statistics are intriguing to me but I haven't had time to pursue further. Is it not worth getting into Machine Learning with the level of math education I currently have? I am not opposed to learning more (I'd like to), but if that's a necessity from day one or shortly thereafter I might be better off waiting and pursuing this again in the future. 

My interest is hobby-level at the moment, possibly developing into web-app applications down the line and of course with the ultimate goal of helping to save the planet and/or take over the world eventually.

Your advice appreciated! Be as honest as you want - you won't be crushing my dreams or anything. As I said: hobby-level interest at the moment.

Thanks!

EDIT: thanks thanks everyone so far! ",,False,self,t5_2r3gv,1365300187.0,,,True,t3_1bto9p,http://www.reddit.com/r/MachineLearning/comments/1bto9p/getting_started_in_machine_learning_from_square/,
1365061795.0,15,jeremydhoon.github.com,1bndah,Abusing hash kernels for wildly unprincipled machine learning,21,6,8,http://www.reddit.com/r/MachineLearning/comments/1bndah/abusing_hash_kernels_for_wildly_unprincipled/,,,False,default,t5_2r3gv,False,,,False,t3_1bndah,http://jeremydhoon.github.com/2013/03/19/abusing-hash-kernels-for-wildly-unprincipled-machine-learning/,
1363732363.0,13,fastml.com,1amgf4,Large scale L1 feature selection with Vowpal Wabbit,17,4,0,http://www.reddit.com/r/MachineLearning/comments/1amgf4/large_scale_l1_feature_selection_with_vowpal/,,,False,http://d.thumbs.redditmedia.com/z_q38oTJHQ7biJlQ.jpg,t5_2r3gv,False,,,False,t3_1amgf4,http://fastml.com/large-scale-l1-feature-selection-with-vowpal-wabbit/,
1362757052.0,15,bbc.co.uk,19wyu6,BBC News - Web-based 'brain' for robots goes live,18,3,7,http://www.reddit.com/r/MachineLearning/comments/19wyu6/bbc_news_webbased_brain_for_robots_goes_live/,,,False,http://a.thumbs.redditmedia.com/vQiIAynoLZJ0Rtol.jpg,t5_2r3gv,False,,,False,t3_19wyu6,http://www.bbc.co.uk/news/technology-21714191,
1361485146.0,15,self.MachineLearning,18zcme,Sentiment Analysis in the real world,17,2,11,http://www.reddit.com/r/MachineLearning/comments/18zcme/sentiment_analysis_in_the_real_world/,"Hi r/machinelearning,

I'm experimenting with performing a sentiment analysis (positive/negative classification) on review text for a commercial application.

As a training set I have ~200k labeled reviews from a popular domain specific website. I intend to experiment with training a classifier at the sentence and at the paragraph (or complete review) level.

The data to be classified is ~300k labeled reviews from the same domain. Due to legal reasons I am not able to train my classifier(s) with this data.

The approaches I am considering for constructing the feature vectors include: uni/bigrams, parts of speech filtered uni/bigrams, and parts of speech tagged uni/bigrams.


Anyways, to my questions:

Is it even feasible to train a model with a feature vector so large? Imagine each review is only 100 words, then the feature space of my training set is as high as 20 million dimensions.

If my feature vectors are all essentially bags of words, how can I use a model trained on the words in my training set to classify the words in my test set? That is to say, will there not be an issue with finding overlap between the vocabulary in the review to be classified and the group of reviews used to train the model?

Thanks :)",,False,self,t5_2r3gv,False,,,True,t3_18zcme,http://www.reddit.com/r/MachineLearning/comments/18zcme/sentiment_analysis_in_the_real_world/,
1358536148.0,15,self.MachineLearning,16ty8p,Are Hopfield neural networks used in any real world applications? Are they the best tool for anything?,16,1,1,http://www.reddit.com/r/MachineLearning/comments/16ty8p/are_hopfield_neural_networks_used_in_any_real/,"Really want to know the answer to this question, but didn't have any luck using google.",,False,self,t5_2r3gv,False,,,True,t3_16ty8p,http://www.reddit.com/r/MachineLearning/comments/16ty8p/are_hopfield_neural_networks_used_in_any_real/,
1355318894.0,14,plus.google.com,14q2n3,Data Science Community on G+ ,24,10,1,http://www.reddit.com/r/MachineLearning/comments/14q2n3/data_science_community_on_g/,,,False,http://e.thumbs.redditmedia.com/IA-E_MHq8xWW5TuF.jpg,t5_2r3gv,False,,,False,t3_14q2n3,https://plus.google.com/u/0/communities/104673320232127474190,
1354449481.0,15,self.MachineLearning,145cdg,Help implementing semantic hashing,19,4,9,http://www.reddit.com/r/MachineLearning/comments/145cdg/help_implementing_semantic_hashing/,"Recently I'm confused with semantic hashing. I want to, given a collect of documents, get the semantic hash codes for each document(semantic hashing is introduced here: http://www.cs.toronto.edu/~rsalakhu/papers/semantic_final.pdf). I downloaded the source code of Deep AutoEncoder from http://www.cs.toronto.edu/~hinton/MatlabForSciencePaper.html. It seems helpful but slightly different from semantic hashing especially in the fine-tuning part. That is, I don't know how to get binary codes for each document after fine-tuning. Anyone knows that? Any suggestions on learning semantic hashing are welcomed! Thank you!",,False,self,t5_2r3gv,False,,,True,t3_145cdg,http://www.reddit.com/r/MachineLearning/comments/145cdg/help_implementing_semantic_hashing/,
1350411840.0,14,self.MachineLearning,11kyvz,Machine Learning Prerequisites,17,3,23,http://www.reddit.com/r/MachineLearning/comments/11kyvz/machine_learning_prerequisites/,"Hello, I've decided to take advantage of the wealth of online materials and learn the basics of machine learning. I'm a self-taught computer programmer who went to art school, and the last math class I took was Algebra II/Trig in high school. So my question is, what are the maths I should study before getting into ML? From what I can gather, I'll need calculus, probability, and some kind of statistics -- but I'd like to hear from people who know :) Time is not an issue, I want to make sure I have the proper foundation so I can learn the topic well. Thanks!",,False,self,t5_2r3gv,False,,,True,t3_11kyvz,http://www.reddit.com/r/MachineLearning/comments/11kyvz/machine_learning_prerequisites/,
1349944324.0,15,arek-paterek.com,11audd,"E-book on the Netflix Prize, recommender systems, and machine learning in general",23,8,20,http://www.reddit.com/r/MachineLearning/comments/11audd/ebook_on_the_netflix_prize_recommender_systems/,,,False,http://b.thumbs.redditmedia.com/n0csf-dshWh-Ddy7.jpg,t5_2r3gv,False,,,False,t3_11audd,http://arek-paterek.com/book/,
1349189003.0,16,self.MachineLearning,10tges,Does anyone know of any economic studies involving AI? E.g. using models like Conway's Game of Life,20,4,15,http://www.reddit.com/r/MachineLearning/comments/10tges/does_anyone_know_of_any_economic_studies/,"I'm guessing you know all about http://en.wikipedia.org/wiki/Conway's_Game_of_Life

edit - I can program and know a thing or two about economics. Just a bit of an AI novice so intro to any basics concepts I should look up are helpful too.",,False,self,t5_2r3gv,1349259599.0,,,True,t3_10tges,http://www.reddit.com/r/MachineLearning/comments/10tges/does_anyone_know_of_any_economic_studies/,
1348952073.0,15,self.MachineLearning,10okc6,Relationship between joint probability distribution and causality?,17,2,7,http://www.reddit.com/r/MachineLearning/comments/10okc6/relationship_between_joint_probability/,"I'm trying to interpret the results of some measurements in geophysics and thought this crowd might know the answer:

If a set of events A and B have a joint probability distribution P(A,B), how might this causality be described (in laymen English) between A and B from this joint probability? 

If A and B have a joint expectation E(AB), how can causality be described from the elements of the matrix that can be written for each of the expected interactions A and B? [For instance, E(A_1B_1), E(A_2B_1), and so on]",,False,self,t5_2r3gv,False,,,True,t3_10okc6,http://www.reddit.com/r/MachineLearning/comments/10okc6/relationship_between_joint_probability/,
1347295018.0,14,self.MachineLearning,znqrk,Machine Learning of Links that I would click on,17,3,18,http://www.reddit.com/r/MachineLearning/comments/znqrk/machine_learning_of_links_that_i_would_click_on/,"As a personal project I want to create an extension of sorts that would highlight links that I would be likely to click on (based on history of clicked on and not clicked on)

I intend on using this as a filter as well in the future. Are there any projects like, is there anything I should know before embarking?

Thanks for reading!",,False,self,t5_2r3gv,False,,,True,t3_znqrk,http://www.reddit.com/r/MachineLearning/comments/znqrk/machine_learning_of_links_that_i_would_click_on/,
1347038240.0,15,blog.factual.com,ziiyq,The Wisdom of Crowds: Using Ensembles for Machine Learning,21,6,12,http://www.reddit.com/r/MachineLearning/comments/ziiyq/the_wisdom_of_crowds_using_ensembles_for_machine/,,,False,http://b.thumbs.redditmedia.com/37P1OV71Dj6Dx1qC.jpg,t5_2r3gv,False,,,False,t3_ziiyq,http://blog.factual.com/the-wisdom-of-crowds,
1344013923.0,17,self.MachineLearning,xmmdl,The Fortune 500 company I work for has many jobs open currently in the NLP area.,28,11,9,http://www.reddit.com/r/MachineLearning/comments/xmmdl/the_fortune_500_company_i_work_for_has_many_jobs/,"If you would be interested in learning more, PM me and I'll send you the link info where you can look at current job openings. Hopefully I'm not violating any rules by doing this. I work in sales in the company, but there is a cash incentive for employees to assist in recruiting folks in this field. ",,False,self,t5_2r3gv,False,,,True,t3_xmmdl,http://www.reddit.com/r/MachineLearning/comments/xmmdl/the_fortune_500_company_i_work_for_has_many_jobs/,
1343927523.0,15,blog.bigml.com,xklib,Machine Learning Throwdown: Part 1,23,8,0,http://www.reddit.com/r/MachineLearning/comments/xklib/machine_learning_throwdown_part_1/,,,False,http://d.thumbs.redditmedia.com/F7ZnUev6Ef22QsX3.jpg,t5_2r3gv,False,,,False,t3_xklib,http://blog.bigml.com/2012/08/02/machine-learning-throwdown-part-1-introduction/,
1343075767.0,15,aelag.com,x195c,Machine learning for the impatient: algorithms tuning algorithms - gift shop scientist,22,7,2,http://www.reddit.com/r/MachineLearning/comments/x195c/machine_learning_for_the_impatient_algorithms/,,,False,default,t5_2r3gv,False,,,False,t3_x195c,http://www.aelag.com/147952673,
1342609542.0,14,latimes.com,wr5le,"Computer analysis predicted rises, ebbs in Afghanistan violence",21,7,6,http://www.reddit.com/r/MachineLearning/comments/wr5le/computer_analysis_predicted_rises_ebbs_in/,,,False,http://e.thumbs.redditmedia.com/WnL6io7dJ7reBWg4.jpg,t5_2r3gv,False,,,False,t3_wr5le,"http://www.latimes.com/news/science/la-sci-warfare-data-20120717,0,409336.story",
1341370675.0,17,mohakshah.com,w0h85,"Performance evaluation of learning algorithms [PDF, 120 pp]",21,4,0,http://www.reddit.com/r/MachineLearning/comments/w0h85/performance_evaluation_of_learning_algorithms_pdf/,,,False,default,t5_2r3gv,False,,,False,t3_w0h85,http://www.mohakshah.com/tutorials/icml2012/Tutorial-ICML2012/Tutorial_at_ICML_2012_files/ICML2012-Tutorial.pdf,
1341155006.0,13,self.MachineLearning,vvpb2,Is there a supervised learning algorithm that can inject randomness into its output in proportion to its uncertainty about the result?,20,7,20,http://www.reddit.com/r/MachineLearning/comments/vvpb2/is_there_a_supervised_learning_algorithm_that_can/,"I'm wondering if there is a machine learning algorithm that produces a probability as an output, which can inject randomness into the output in proportion to uncertainty as to what the output should be.

The application is to decide what ad to show people when they visit a web page.  Our goal is to show people the ad they are most likely to click on, but for new ads we won't have much data, so initially there will be greater uncertainty as to what their click through rate will be.

A very simple version of this, which only looks at the number of impressions and clicks on each ad, is to use a beta distribution, this technique is described [here](http://blog.locut.us/2011/09/22/proportionate-ab-testing/) (it's also known as Thompson sampling, and it's a solution to the multi-armed bandit problem).

But I'd like to use a machine learning algorithm that uses a much wider range of attributes than simply the number of impressions and clicks on each ad.  Ideally the input attributes can be both categorical (where there could be thousands of possible values for each attribute, for example ""city/state/country""), and numeric (like time of day).

I was thinking perhaps a Bayesian Network learner, where we use a beta distribution to inject randomness into the probabilities used in the Bayesian Network when making a prediction, but I want to see whether others have looked into this problem.",,False,self,t5_2r3gv,1341155289.0,,,True,t3_vvpb2,http://www.reddit.com/r/MachineLearning/comments/vvpb2/is_there_a_supervised_learning_algorithm_that_can/,
1340731808.0,14,self.MachineLearning,vmzua,Required knowledge and education for a career in machine learning?,20,6,14,http://www.reddit.com/r/MachineLearning/comments/vmzua/required_knowledge_and_education_for_a_career_in/,"I am wrapping up my undergraduate degree in CS, and I've done a bit of specialization in AI/machine learning through these courses:  IR, CompLing, Data Mining, Robotics.  I also have some research experience applying machine learning to computer vision/object recognition for robotics.  At this point I would say I have an ""OK"" general understanding of various ML concepts:  classifiers, clustering, association rules, ANNs, etc.  However, I don't really have a deep understanding of the math behind these things, as my undergrad courses mostly glossed over those details.

I have been accepted into a MS CS program at a highly ranked university (top-5 in AI).  It will take me an additional 3 semesters of school to get the Masters vs. leaving with just a BS.  I am trying to decide if I need to continue with the MS degree.  I really like learning, and would LIKE to do the degree, but the opportunity cost is weighing on the decision.

My career goal is to become more than a general software engineer.  I like ML and related (vision, robotics, NLP, etc), and it seems like it's both interesting and practical to industry.  Ideally I would have a job where I keep up with the state-of-the-art and apply it to the needs of the organization.  Another great job would be doing applied (or basic) research.  I'm more interested in solving technically hard problems that say going to Scrum meetings, talking about unit tests and deployments, etc.  I'm not saying those aren't necessary, but if that's ALL I do at work I could not stand it.  I should also mention that I have substantial ""general"" software engineering experience and I like coding.  I chose to go back to school to do something more interesting.  The question now is whether to continue to the Masters or stop with a Bachelors.  PhD is not realistic for me in my situation.

I would love to hear from people who work with ML, AI, etc in industry, including level of education required.  Thanks!

tl;dr:  How much education is required to get an ML job in industry?
",,False,self,t5_2r3gv,False,,,True,t3_vmzua,http://www.reddit.com/r/MachineLearning/comments/vmzua/required_knowledge_and_education_for_a_career_in/,
1338455912.0,16,self.MachineLearning,udmrd,Advice for masters ML dissertation project,19,3,15,http://www.reddit.com/r/MachineLearning/comments/udmrd/advice_for_masters_ml_dissertation_project/,"I've just completed my first year of an AI-based masters programme (I'm a part-time student) and I'm beginning to think about my dissertation project that will be done in year two. Of all classes this year, both machine learning and natural language processing stood out and were the most interesting.

However, my BA is in music and switching to a CS programme has been a steep, but rewarding, learning curve. As a result, I'm not sure of areas most worthy of further research at this point.

Ideally, I'd like to work on a project focussed around music and machine learning but I'd welcome an advice of things to tackle. Any tips, areas of investigation, possible project suggestions?",,False,self,t5_2r3gv,False,,,True,t3_udmrd,http://www.reddit.com/r/MachineLearning/comments/udmrd/advice_for_masters_ml_dissertation_project/,
1334448709.0,14,self.MachineLearning,sa5va,Writing a paper on artificial intelligence,20,6,5,http://www.reddit.com/r/MachineLearning/comments/sa5va/writing_a_paper_on_artificial_intelligence/,"So I'm writing a very basic introductory paper on artificial intelligence for my university course. My main focus is on neural networking, and I really need to interview someone with knowledge in the field. I was wondering if anyone with some credentials in the field would be interested in answering some relatively basic questions I have. ",,False,self,t5_2r3gv,False,,,True,t3_sa5va,http://www.reddit.com/r/MachineLearning/comments/sa5va/writing_a_paper_on_artificial_intelligence/,
1333901997.0,14,self.MachineLearning,rzcfh,"Ask ML: While training sparse autoencoders, how do you decide values for the sparsity parameter and it's associated weight used in the cost-function?",16,2,33,http://www.reddit.com/r/MachineLearning/comments/rzcfh/ask_ml_while_training_sparse_autoencoders_how_do/,,,False,self,t5_2r3gv,False,,,True,t3_rzcfh,http://www.reddit.com/r/MachineLearning/comments/rzcfh/ask_ml_while_training_sparse_autoencoders_how_do/,
1333022849.0,15,self.MachineLearning,rj4a2,Book on the implementation of ML algorithms?,15,0,14,http://www.reddit.com/r/MachineLearning/comments/rj4a2/book_on_the_implementation_of_ml_algorithms/,"Hi there,

I'm quite familiar with machine learning and I'm looking for a book that covers all the implementation details of ML algorithms (conditioning, numerical stability, scalability, parallel implementations...)

Does such a book exist?",,False,self,t5_2r3gv,False,,,True,t3_rj4a2,http://www.reddit.com/r/MachineLearning/comments/rj4a2/book_on_the_implementation_of_ml_algorithms/,
1332473105.0,14,coursera.org,r9gkh,Free Stanford online class:  Probabilistic Graphical Models (registration ends Fri.),16,2,8,http://www.reddit.com/r/MachineLearning/comments/r9gkh/free_stanford_online_class_probabilistic/,,,False,default,t5_2r3gv,False,,,False,t3_r9gkh,https://www.coursera.org/pgm/class/,
1331903297.0,15,bbc.co.uk,qzbet,"University researchers are developing a system to help identify people who are behind offensive comments posted on the internet.
",20,5,6,http://www.reddit.com/r/MachineLearning/comments/qzbet/university_researchers_are_developing_a_system_to/,,,False,default,t5_2r3gv,False,,,False,t3_qzbet,http://www.bbc.co.uk/news/uk-england-merseyside-16877246,
1330992322.0,14,metamarkets.com,qjc26,Why generic machine learning fails.,23,9,6,http://www.reddit.com/r/MachineLearning/comments/qjc26/why_generic_machine_learning_fails/,,,False,http://e.thumbs.redditmedia.com/LYVHAGgmkT4jCxH4.jpg,t5_2r3gv,False,,,False,t3_qjc26,http://metamarkets.com/2011/machine-learning-in-wonderland/,
1328571756.0,14,kaggle.com,pdu3v,Is automated essay grading an appropriate machine learning task?,21,7,13,http://www.reddit.com/r/MachineLearning/comments/pdu3v/is_automated_essay_grading_an_appropriate_machine/,,,False,http://d.thumbs.redditmedia.com/jpN37bcQ3HGBlw1i.jpg,t5_2r3gv,False,,,False,t3_pdu3v,http://www.kaggle.com/c/asap-aes/forums/t/1300/troubling-premise,
1327008857.0,13,self.MachineLearning,onuiu,What is the most useless application of machine learning you've come across?,20,7,16,http://www.reddit.com/r/MachineLearning/comments/onuiu/what_is_the_most_useless_application_of_machine/,"Maybe your coworker modeled the parking lot to try and predict where he could most likely find an empty space, or you wanted to validate your intuition that the best place to start a minesweeper game is on the corners, but you're too lazy to do the math so you wrote a monte carlo simulation instead (OK...that last one was me).",,False,self,t5_2r3gv,False,,,True,t3_onuiu,http://www.reddit.com/r/MachineLearning/comments/onuiu/what_is_the_most_useless_application_of_machine/,
1326654169.0,15,datasciencetoolkit.org,oi7ra,Data Science Toolkit - A Linux distro for data science,21,6,4,http://www.reddit.com/r/MachineLearning/comments/oi7ra/data_science_toolkit_a_linux_distro_for_data/,,,False,http://b.thumbs.redditmedia.com/izkFy1Zo-rcQV4wI.jpg,t5_2r3gv,False,,,False,t3_oi7ra,http://www.datasciencetoolkit.org/about,
1326448129.0,13,self.MachineLearning,ofac9,Is using PCA a good way to reduce dimensionality of text features?,18,5,21,http://www.reddit.com/r/MachineLearning/comments/ofac9/is_using_pca_a_good_way_to_reduce_dimensionality/,"I'm working on a classifier for reddit posts, and I have the impression that non-text features such as subreddit, author, domain or votes are being drown by the sheer number of features from the text (link title, and optionnally comments and linked page).

So I'm thinking of using some sort of dimensionality reduction on the text features before handing them to the classifier. Am I on the right path?

EDIT: thanks everyone for the answers!",,False,self,t5_2r3gv,True,,,True,t3_ofac9,http://www.reddit.com/r/MachineLearning/comments/ofac9/is_using_pca_a_good_way_to_reduce_dimensionality/,
1326292055.0,15,self.MachineLearning,occsk,"Can someone explain to me what a 
Bayes Point Machine is?",16,1,2,http://www.reddit.com/r/MachineLearning/comments/occsk/can_someone_explain_to_me_what_a_bayes_point/,I'm having quite a bit of trouble understanding the original Herbrich paper. Can someone explain it to me in simple terms?,,False,self,t5_2r3gv,False,,,True,t3_occsk,http://www.reddit.com/r/MachineLearning/comments/occsk/can_someone_explain_to_me_what_a_bayes_point/,
1325703955.0,13,self.MachineLearning,o2ti2,Decision Tree implementation,16,3,20,http://www.reddit.com/r/MachineLearning/comments/o2ti2/decision_tree_implementation/,"Hi,
I'm looking for implementation of Decision Tree algorithm which is

* very scalable, 
* supports classification / regression, 
* customizable (for example selection of masure - entropy based / Chi-square Statistic / ...),
* in C++ / Java
* open source &amp; free

It will be used on supercomputer with very large data.

Now I'm observing

* [OpenDT](http://opendt.sourceforge.net/)
* [OpenCV](http://opencv.willowgarage.com/documentation/cpp/decision_trees.html)

Can You suggest any other implementation of DT algorithm? (No Mahout/Hadoop and idally with some references / real-word use cases.)


EDIT:

Supervisor about size of data: ""For massive datasets, we remark that our basic requirement is to efficiently handle datasets of at least hundreds of thousands patterns in a higher than 10-dimension feature space. In other words we must be able to ingest data files higher than hundreds of MB (TB is the final goal when survey projects will prompt observed data).""",,False,self,t5_2r3gv,True,,,True,t3_o2ti2,http://www.reddit.com/r/MachineLearning/comments/o2ti2/decision_tree_implementation/,
1325522123.0,16,self.MachineLearning,nzvtw,"Ask r/ML: k-means clustering is putting everything in one cluster, how come?",20,4,30,http://www.reddit.com/r/MachineLearning/comments/nzvtw/ask_rml_kmeans_clustering_is_putting_everything/,"Hi r/ML,

First, I'm not sure if this subreddit accepts questions like this. Please redirect me if it's better posted elsewhere.

The presenting problem I have is that running k-means clustering on my data set results in almost everything being put in one cluster. I've tried varying the number of clusters but it keeps happening. I'd like to understand why this is happening and what my options are for getting a more even, or more informative, distribution between clusters.

Some background: I've gathered a list of friends and their likes from Facebook, making a sparse matrix like this:

    data = {
        'friend1': ['like1', 'like2', 'like3'],
        'friend2': ['like4'],
        'friend3': ['like1', 'like4'],
    }

There's about 100 friends with about 1 to 300 likes each. I make k centroids, giving each a random set of likes, and count the shared likes for my distance function (dist = 1 - total_shared_likes / 1000).

Each iteration I calculate the distance between a friend and each centroid and assign them to the nearest. Almost all end up in the same centroid. To move the centroids to the average position of their members, I total all the user and centroid likes, then divide by the number of users + 1 (for the centroid's likes). Each users' likes count for 1, but the centroid likes are floats. 

Any thoughts on why this is happening? Am I missing something or doing something wrong? Or is this data set not amenable to k-means, should I try a different algorithm?

Thanks!

**edit** Still getting all friends in the same cluster despite

*(i)* creating a euclidian distance function

    def distance(self, other):
        dist = 0.0
        for i, l in enumerate(self.likes):
            if l != other.likes[i]:
                dist += 1
        
        return math.sqrt(diet)

The likes variables hold tuples where each item is 1 or 0 (like or dislike), and all users' tuples are the same length (equal to the number of all possible items to like). I'm adding 1 if they're different as this is the only possible distance (and it's 1 squared, of course).

*(ii)*

On initialisation, assigning a random friends' likes to the first centroid, then for each other centroid (up to *k*) assigning the likes of the friend furthest from all previous centroids.

*(iii)*

On each iteration, if a centroid has no members, it's assigned the likes of the friend furthest from all centroids.

*(iv)*

No longer including the centroid's likes when calculating the average position between its members.

I've put my code on paste bin as I might have overlooked something - http://pastebin.com/ZFvFfFe3

Here's some example output:

    --- iteration 4
    {'cluster 0': {'dist': 1256.4364795929926, 'members': 174},
     'cluster 1': {'dist': 0.0, 'members': 0},
     'cluster 2': {'dist': 0.0, 'members': 0},
     'cluster 3': {'dist': 0.0, 'members': 0},
     'cluster 4': {'dist': 0.0, 'members': 0}}
    --- iteration 5
    {'cluster 0': {'dist': 0.0, 'members': 0},
     'cluster 1': {'dist': 1256.4364795929926, 'members': 174},
     'cluster 2': {'dist': 0.0, 'members': 0},
     'cluster 3': {'dist': 0.0, 'members': 0},
     'cluster 4': {'dist': 0.0, 'members': 0}}

Thanks for all of your input, I'm very grateful. Please keep posting feedback, I'm set on solving this! 

**edit 2**

Fixed the distance function

    def distance(self, other):
        total_dist = 0.0
        for i, l in enumerate(self.likes):
            if l != other.likes[i]:
                total_dist += (l - other.likes[i])**2

        return math.sqrt(total_dist / len(self.likes))

And the error in the centroid update calculation (line 126)

    new_likes[i] += user_vote

The paste bin code is updated, it's still behaving as before.",,False,self,t5_2r3gv,True,,,True,t3_nzvtw,http://www.reddit.com/r/MachineLearning/comments/nzvtw/ask_rml_kmeans_clustering_is_putting_everything/,
1324367440.0,15,economist.com,njmg2,Computerized pathology,18,3,5,http://www.reddit.com/r/MachineLearning/comments/njmg2/computerized_pathology/,,,False,http://c.thumbs.redditmedia.com/4AyBmL_Avy2HCDdt.jpg,t5_2r3gv,False,,,False,t3_njmg2,http://www.economist.com/node/21540387,
1323186269.0,15,self.MachineLearning,n2kz5,Dataspora is hiring a Chief Analytics Officer! Based in either Boston or San Francisco. Apply state-of-the-art machine learning techniques to interesting problems.,21,6,0,http://www.reddit.com/r/MachineLearning/comments/n2kz5/dataspora_is_hiring_a_chief_analytics_officer/,"**Job Description**

We are looking for a smart, innovative and detail-oriented Chief Analytics Officer to join our predictive analytics team. You should thrive on working in a fast-paced and exciting team environment in one of the fastest growing areas today – predictive analytics.  You will be working with leading domestic and global companies and Via Science’s predictive analytics team, bringing to bear your scientific and communications acumen, along with both proprietary and open-source analytics tools, to address critical business questions for our clients’ C-suites.  Work may include incorporation of analytics models built by the Dataspora team into client workflows and operational systems. 

**Skills**

* Demonstrate thought leadership in big data analytics through compelling blogs, white papers, public presentations, and existing/prospective client meetings.
* Able to work in a fast-paced, multi-functional team environment and have a proactive mindset.
* Comfortable handling and manipulating large datasets.
* Excellent communication skills in order to relay technical findings to clients who may have no technical or mathematical background.
* Ability to produce high-quality, impactful visualizations of scientific results highly desirable.

**Requirements**

B.Sc with relevant work experience (internships or cooperative placements) is a minimum; M.Sc or Ph.D with relevant post-graduate research strongly preferred, in each case in a quantitative scientific discipline with a heavy statistical or other mathematical component. Statistical programming experience in R preferred. Ability to extract insights from large datasets using an array of methods from clustering to regression to network modeling. Experience implementing analytics solutions with Hadoop/Hive/Pig. Strong SQL knowledge to extract data from and to load data to databases.  Excellent written and oral presentation skills required. Experience in Bayesian inference, noSQL, machine-learning methods, and network modeling (social networks or general network analysis) is a bonus

Please PM me for more details.
",,False,self,t5_2r3gv,False,,,True,t3_n2kz5,http://www.reddit.com/r/MachineLearning/comments/n2kz5/dataspora_is_hiring_a_chief_analytics_officer/,
1320775883.0,16,research.nokia.com,m517e,Nokia Mobile Data Challenge ,18,2,3,http://www.reddit.com/r/MachineLearning/comments/m517e/nokia_mobile_data_challenge/,,,False,default,t5_2r3gv,False,,,False,t3_m517e,http://research.nokia.com/page/12000,
1319327621.0,14,self.MachineLearning,lli2t,What is wrong with Gaussian Processes?,18,4,13,http://www.reddit.com/r/MachineLearning/comments/lli2t/what_is_wrong_with_gaussian_processes/,"They seem like pretty awesome methods, and aside from the time and space issues of the matrix inversion are there any other limitation that they have for general non-parametric regression?

EDIT: Out of interest for research directions.",,False,self,t5_2r3gv,True,,,True,t3_lli2t,http://www.reddit.com/r/MachineLearning/comments/lli2t/what_is_wrong_with_gaussian_processes/,
1319124014.0,17,self.MachineLearning,lirni,What is marginal likelihood?,18,1,4,http://www.reddit.com/r/MachineLearning/comments/lirni/what_is_marginal_likelihood/,I'm trying to gain some intuition as to what marginal likelihood is (in the context of Bayesian inference) but I'm struggling. I understand it to be a measure how well a model fits the data in general (is this correct?) but I don't really get how?,,False,self,t5_2r3gv,False,,,True,t3_lirni,http://www.reddit.com/r/MachineLearning/comments/lirni/what_is_marginal_likelihood/,
1318903875.0,13,blog.kaggle.com,lfuam,Kernel Density at the Checkout: D'yakonov Alexander on Winning the Dunnhumby Shopper Challenge,16,3,2,http://www.reddit.com/r/MachineLearning/comments/lfuam/kernel_density_at_the_checkout_dyakonov_alexander/,,,False,default,t5_2r3gv,False,,,False,t3_lfuam,http://blog.kaggle.com/2011/10/16/kernel-density-at-the-checkout/,
1317588069.0,15,nlpers.blogspot.com,kymxr,A technique for me is a task for you,19,4,0,http://www.reddit.com/r/MachineLearning/comments/kymxr/a_technique_for_me_is_a_task_for_you/,,,False,http://thumbs.reddit.com/t3_kymxr.png,t5_2r3gv,False,,,False,t3_kymxr,http://nlpers.blogspot.com/2011/09/technique-for-me-is-task-for-you.html,
1317243717.0,16,freakonomics.com,kuhue,An Algorithm that Can Predict Weather a Year in Advance,23,7,15,http://www.reddit.com/r/MachineLearning/comments/kuhue/an_algorithm_that_can_predict_weather_a_year_in/,,,False,http://thumbs.reddit.com/t3_kuhue.png,t5_2r3gv,False,,,False,t3_kuhue,http://www.freakonomics.com/2011/09/27/an-algorithm-that-can-predict-weather-a-year-in-advance/,
1316521887.0,16,self.MachineLearning,klirw,What are some good Maths / Statistics resources for learning the prerequisites for ML?,19,3,17,http://www.reddit.com/r/MachineLearning/comments/klirw/what_are_some_good_maths_statistics_resources_for/,"I'm currently working my way through Programming Collective Intelligence and it's helping clarify some ideas for me, but I'm struggling a bit to remember some of the maths side of things.

For example, i wanted to read up a bit more on Naive Bayes classifiers for Document Classification and went to the wikipedia page. I just looked at this section: http://en.wikipedia.org/wiki/Naive_Bayes_classifier#The_naive_Bayes_probabilistic_model and i have no real idea what its trying to tell me. 

Another example is the Andrew Ng lectures. I was following fine right until he got to this blackboard, then he kinda lost me: http://www.youtube.com/watch?v=5u4G23_OohI&amp;feature=player_detailpage#t=1131s 

I originally learned some of this stuff 10 - 12 years ago and have barely used it since, so I could do with some recommendations on what I need to learn (or re-learn as the case may be).

I've looked at the Khan academy site and it seems really good, but I don't even know where to start with it. Do i need statistics / probability / algebra or linear algebra? If its linear algebra (which was mentioned by Andrew Ng in the lecture video) do I need to watch all 143 videos on it or are there specific parts which would be useful?

",,False,self,t5_2r3gv,False,,,True,t3_klirw,http://www.reddit.com/r/MachineLearning/comments/klirw/what_are_some_good_maths_statistics_resources_for/,
1311952240.0,15,lanyrd.com,j39jc,The Hitchhiker’s Guide to A Kaggle Competition,18,3,0,http://www.reddit.com/r/MachineLearning/comments/j39jc/the_hitchhikers_guide_to_a_kaggle_competition/,,,False,http://thumbs.reddit.com/t3_j39jc.png,t5_2r3gv,False,,,False,t3_j39jc,http://lanyrd.com/2011/oscon-data/sghpg/,
1311904446.0,15,stephenholiday.com,j2sg0,"Gender Prediction with Python
        ",18,3,2,http://www.reddit.com/r/MachineLearning/comments/j2sg0/gender_prediction_with_python/,,,False,default,t5_2r3gv,False,,,False,t3_j2sg0,http://stephenholiday.com/articles/2011/gender-prediction-with-python/,
1309826440.0,14,self.MachineLearning,igs3k,What are good ways of dealing with/organizing data when building a model?,15,1,14,http://www.reddit.com/r/MachineLearning/comments/igs3k/what_are_good_ways_of_dealing_withorganizing_data/,"Often data sets come in many parts that are all relevant to a modeling task. Usually I preprocess the files into a flat file database and then deal with the data line-by-line. This often works, but is fairly time-consuming and inflexible. Other times I will just load up all the separate files into a hash table, but this is inflexible in its own way, especially on big datasets. 

I've read a little on SQL and noSQL, but have no clue how to start using them in a python/C++ model. Nor do I really understand how they conceptually fit into a model or what their benefits are. Can anyone explain all this to me?",,False,self,t5_2r3gv,False,,,True,t3_igs3k,http://www.reddit.com/r/MachineLearning/comments/igs3k/what_are_good_ways_of_dealing_withorganizing_data/,
1303932238.0,15,r-bloggers.com,gymv4,VideoLectures.net Recommender System Competition,15,0,4,http://www.reddit.com/r/MachineLearning/comments/gymv4/videolecturesnet_recommender_system_competition/,,,False,default,t5_2r3gv,False,,,False,t3_gymv4,http://www.r-bloggers.com/videolectures-net-recommender-system-competition/,
1300320639.0,15,googleresearch.blogspot.com,g5ihh,"In an effort to advance the understanding of market algorithms and Internet economics, Google has launched an academic research initiative focused on the underlying aspects of online auctions, pricing, game-theoretic strategies, and information exchange. (crosspost from /r/science/)",17,2,1,http://www.reddit.com/r/MachineLearning/comments/g5ihh/in_an_effort_to_advance_the_understanding_of/,,,False,default,t5_2r3gv,False,,,False,t3_g5ihh,http://googleresearch.blogspot.com/2011/03/games-auctions-and-beyond.html,
1300288380.0,15,luispedro.org,g56q5,Milk: (Yet Another) Machine Learning Toolkit for Python,17,2,3,http://www.reddit.com/r/MachineLearning/comments/g56q5/milk_yet_another_machine_learning_toolkit_for/,,,False,http://thumbs.reddit.com/t3_g56q5.png,t5_2r3gv,False,,,False,t3_g56q5,http://luispedro.org/software/milk,
1297349436.0,16,self.MachineLearning,firmo,When is *interactive* data visualization useful to use?,16,0,4,http://www.reddit.com/r/MachineLearning/comments/firmo/when_is_interactive_data_visualization_useful_to/,"Hello all,

While preparing for a talk I will give soon,  I recently started digging into two major (Free) tools for interactive data visualization: [GGobi][1] and [mondrian][2] - both offer a great range of capabilities (even if they're a bit buggy).

I wish to ask for your help in articulating (both to myself, and for my future audience) **When is it helpful to use interactive plots? Either for data exploration (for ourselves) and data presentation (for a ""client"")?**

For when explaining the data to a client, I can see the value of animation for:

- Using ""identify/linking/brushing"" for seeing which data point in the graph is what.
- Presenting a sensitivity analysis of the data (e.g: ""if we remove this point, here is what we will get)
- Showing the effect of different groups in the data (e.g: ""let's look at our graphs for males and now for the females"")
- Showing the effect of time (or age, or in general, offering another dimension to the presentation)

For when exploring the data ourselves, I can see the value of identify/linking/brushing when exploring an outlier in a dataset we are working on.

But other then these two examples, I am not sure what other practical use these techniques offer.  Especially for our own data exploration!

It could be argued that the interactive part is good for exploring (For example) a different behavior of different groups/clusters in the data.  But when (in practice) I approached such situation, what I tended to do was to run the relevant statistical procedures (and post-hoc tests) - and what I found to be significant I would then plot with colors clearly dividing the data to the relevant groups.  From what I've seen, this is a safer approach then ""wondering around"" the data (which could easily lead to data dredging (were the scope of the multiple comparison needed for correction is not even clear).

I'd be very happy to read your experience/thoughts on this matter.

(this question can be a wiki - although it is not subjective and a well thought-out answer will gladly win my ""answer"" mark :) )



  [1]: http://www.ggobi.org/
  [2]: http://rosuda.org/mondrian/",,False,self,t5_2r3gv,False,,,True,t3_firmo,http://www.reddit.com/r/MachineLearning/comments/firmo/when_is_interactive_data_visualization_useful_to/,
1291993722.0,16,code.google.com,ejkcr,R client library for the Google Prediction API,16,0,5,http://www.reddit.com/r/MachineLearning/comments/ejkcr/r_client_library_for_the_google_prediction_api/,,,False,default,t5_2r3gv,False,,,False,t3_ejkcr,https://code.google.com/p/google-prediction-api-r-client/,
1291840830.0,13,infolab.stanford.edu,eihvx,"Mining of Massive Datasets: Rajaraman, Ullman (PDF, draft text)",15,2,1,http://www.reddit.com/r/MachineLearning/comments/eihvx/mining_of_massive_datasets_rajaraman_ullman_pdf/,,,False,default,t5_2r3gv,False,,,False,t3_eihvx,http://infolab.stanford.edu/~ullman/pub/book.pdf,
1290832541.0,16,springerlink.com,ecchp,"Just you you know, Machine Learning Journal from SpringerLink has free complete access until December 31",18,2,11,http://www.reddit.com/r/MachineLearning/comments/ecchp/just_you_you_know_machine_learning_journal_from/,,,False,http://thumbs.reddit.com/t3_ecchp.png,t5_2r3gv,False,,,False,t3_ecchp,http://www.springerlink.com/content/100309,
1290447405.0,16,gatech.edu,ea19p,GA Tech “dialect topic modeling” system learns to read medical documents with varying levels of technical detail,16,0,1,http://www.reddit.com/r/MachineLearning/comments/ea19p/ga_tech_dialect_topic_modeling_system_learns_to/,,,False,http://thumbs.reddit.com/t3_ea19p.png,t5_2r3gv,False,,,False,t3_ea19p,http://www.gatech.edu/newsroom/release.html?nid=62806,
1289829310.0,16,slate.com,e6de6,Data for a Better Planet,16,0,0,http://www.reddit.com/r/MachineLearning/comments/e6de6/data_for_a_better_planet/,,,False,http://thumbs.reddit.com/t3_e6de6.png,t5_2r3gv,False,,,False,t3_e6de6,http://www.slate.com/id/2274809/,
1289325579.0,16,vancouverdata.blogspot.com,e3ko3,A five part series on text mining with Rapidminer,18,2,1,http://www.reddit.com/r/MachineLearning/comments/e3ko3/a_five_part_series_on_text_mining_with_rapidminer/,,,False,default,t5_2r3gv,False,,,False,t3_e3ko3,http://vancouverdata.blogspot.com/2010/11/text-analytics-with-rapidminer-part-2.html,
1287087327.0,15,r-bloggers.com,drb9c,"""How I won the KDD Cup 2009 (using R)"" (~35 min video)",17,2,5,http://www.reddit.com/r/MachineLearning/comments/drb9c/how_i_won_the_kdd_cup_2009_using_r_35_min_video/,,,False,http://thumbs.reddit.com/t3_drb9c.png,t5_2r3gv,False,,,False,t3_drb9c,http://www.r-bloggers.com/how-to-build-a-world-beating-predictive-model-using-r/,
1283469735.0,15,www-950.ibm.com,d8wwa,Predictive analytics helps an IBM employee win fantasy football,18,3,4,http://www.reddit.com/r/MachineLearning/comments/d8wwa/predictive_analytics_helps_an_ibm_employee_win/,,,False,default,t5_2r3gv,False,,,False,t3_d8wwa,https://www-950.ibm.com/blogs/predictiveanalytics/entry/a_competitive_advantage_on_the_fantasy_football_field3?lang=en_us,
1282676546.0,15,self.MachineLearning,d4yif,Shane Legg - Machine Super Intelligence (incl. universal measure of intelligence),18,3,7,http://www.reddit.com/r/MachineLearning/comments/d4yif/shane_legg_machine_super_intelligence_incl/,"I was at the singularity summit a couple weekends ago, and there was an interesting talk given by Shane Legg.  He just finished his thesis on Machine Super Intelligence, and he talked about a formal definition of intelligence.  Most of his stuff is about theoretic optimal models which are uncomputable, such as AIXI.  However he has been able to implement some things using monte carlo methods.

Here is his [thesis](http://www.vetta.org/documents/Machine_Super_Intelligence.pdf).  I'll post the video when it becomes available.",,False,self,t5_2r3gv,False,,,True,t3_d4yif,http://www.reddit.com/r/MachineLearning/comments/d4yif/shane_legg_machine_super_intelligence_incl/,
1281905890.0,15,self.MachineLearning,d1hek,Ask an Analytics Professional a Question.,17,2,23,http://www.reddit.com/r/MachineLearning/comments/d1hek/ask_an_analytics_professional_a_question/,,,False,self,t5_2r3gv,False,,,True,t3_d1hek,http://www.reddit.com/r/MachineLearning/comments/d1hek/ask_an_analytics_professional_a_question/,
1278839468.0,16,highscalability.com,co9v0,"Facebook, because of the interconnectedness of the data, didn't find any clustering scheme that worked in practice",16,0,5,http://www.reddit.com/r/MachineLearning/comments/co9v0/facebook_because_of_the_interconnectedness_of_the/,,,False,default,t5_2r3gv,False,,,False,t3_co9v0,http://highscalability.com/blog/2009/10/13/why-are-facebook-digg-and-twitter-so-hard-to-scale.html,
1273502123.0,17,streamhacker.com,c252i,Text Classification for Sentiment Analysis with a Naive Bayes Classifier,20,3,2,http://www.reddit.com/r/MachineLearning/comments/c252i/text_classification_for_sentiment_analysis_with_a/,,,False,http://thumbs.reddit.com/t3_c252i.png,t5_2r3gv,False,,,False,t3_c252i,http://streamhacker.com/2010/05/10/text-classification-sentiment-analysis-naive-bayes-classifier/,
1271355370.0,16,imat2010.yandex.ru,brf0u,Machine Learning Contest: Predict the rate of traffic congestion based on previous observations,18,2,0,http://www.reddit.com/r/MachineLearning/comments/brf0u/machine_learning_contest_predict_the_rate_of/,,,False,default,t5_2r3gv,False,,,False,t3_brf0u,http://imat2010.yandex.ru/en/,
1268851056.0,15,neuroph.sourceforge.net,benfc,Neuroph - Java Neural Network Framework,17,2,0,http://www.reddit.com/r/MachineLearning/comments/benfc/neuroph_java_neural_network_framework/,,,False,http://thumbs.reddit.com/t3_benfc.png,t5_2r3gv,False,,,False,t3_benfc,http://neuroph.sourceforge.net/,
1268192234.0,14,blog.smellthedata.com,bbf7d,Data for 2009 + 2010 March Madness. Can you use machine learning predict the tournament?,18,4,1,http://www.reddit.com/r/MachineLearning/comments/bbf7d/data_for_2009_2010_march_madness_can_you_use/,,,False,http://thumbs.reddit.com/t3_bbf7d.png,t5_2r3gv,False,,,False,t3_bbf7d,http://blog.smellthedata.com/2010/03/2009-and-2010-march-madness-data.html,
1263491085.0,15,reddit.com,apn1d,computer vision subreddit,17,2,0,http://www.reddit.com/r/MachineLearning/comments/apn1d/computer_vision_subreddit/,,,False,default,t5_2r3gv,False,,,False,t3_apn1d,http://www.reddit.com/r/computervision/,
1262109359.0,15,www-users.cs.york.ac.uk,ajlx9,Algorithms for Graphical Models draft PDF [uses Python!] ,17,2,2,http://www.reddit.com/r/MachineLearning/comments/ajlx9/algorithms_for_graphical_models_draft_pdf_uses/,,,False,default,t5_2r3gv,False,,,False,t3_ajlx9,http://www-users.cs.york.ac.uk/~jc/teaching/agm/agm.pdf,
1257612316.0,14,scientificblogging.com,a1zcf,"Self-Improving Systems that Learn Through Human Interaction
By Yisong Yue",16,2,0,http://www.reddit.com/r/MachineLearning/comments/a1zcf/selfimproving_systems_that_learn_through_human/,,,False,http://thumbs.reddit.com/t3_a1zcf.png,t5_2r3gv,False,,,False,t3_a1zcf,http://www.scientificblogging.com/stated_degree_confidence/blog/selfimproving_systems_learn_through_human_interaction,
1249394740.0,15,julian.togelius.com,97eqb,"Develop the best Learning agent for 
MARIO AI Competition.",18,3,1,http://www.reddit.com/r/MachineLearning/comments/97eqb/develop_the_best_learning_agent_for_mario_ai/,,,False,http://thumbs.reddit.com/t3_97eqb.png,t5_2r3gv,False,,,False,t3_97eqb,http://julian.togelius.com/mariocompetition2009/,
1248881238.0,15,cs.cmu.edu,95o59,"Tom Mitchell on Learning. A good 
rationale  for this subreddit too.[PDF]",15,0,0,http://www.reddit.com/r/MachineLearning/comments/95o59/tom_mitchell_on_learning_a_good_rationale_for/,,,False,default,t5_2r3gv,False,,,False,t3_95o59,http://www.cs.cmu.edu/~tom/pubs/MachineLearning.pdf,moderator
1376398010.0,14,bizjournals.com,1k9w4l,Google scientist Jeff Dean on how neural networks are improving everything Google does,16,2,0,http://www.reddit.com/r/MachineLearning/comments/1k9w4l/google_scientist_jeff_dean_on_how_neural_networks/,,,False,http://d.thumbs.redditmedia.com/pU2ZhUWrU3KRD2A9.jpg,t5_2r3gv,False,,,False,t3_1k9w4l,http://www.bizjournals.com/seattle/blog/techflash/2013/08/google-scientist-jeff-dean-on-how.html?ana=rdt,
1375386948.0,13,engineering.richrelevance.com,1jile9,Bayesian Analysis of Normal Distributions with Python,15,2,0,http://www.reddit.com/r/MachineLearning/comments/1jile9/bayesian_analysis_of_normal_distributions_with/,,,False,default,t5_2r3gv,False,,,False,t3_1jile9,http://engineering.richrelevance.com/bayesian-analysis-of-normal-distributions-with-python/,
1373473884.0,15,moderntoolmaking.blogspot.com,1i0ld2,"For faster R on a mac, use Apple's BLAS (vecLib)",23,8,19,http://www.reddit.com/r/MachineLearning/comments/1i0ld2/for_faster_r_on_a_mac_use_apples_blas_veclib/,,,False,http://d.thumbs.redditmedia.com/qwVXHPgc_EN5keju.jpg,t5_2r3gv,False,,,False,t3_1i0ld2,http://moderntoolmaking.blogspot.com/2013/07/for-faster-r-on-mac-use-veclib.html,
1372556531.0,14,self.MachineLearning,1hcbmw,Explain deep belief networks as if I'm a complete moron.,19,5,18,http://www.reddit.com/r/MachineLearning/comments/1hcbmw/explain_deep_belief_networks_as_if_im_a_complete/,"Whenever I see someone talk about deep belief networks, its always a bit too technical for me. I have a really  hard time reading the original papers by Hinton, and I really have never seen a good explanation for how they're implemented. 

I'd really like to play with these things, but I don't know how to build them. 

Can anyone post a really simple (basic math) explanation of RBMs? ",,False,self,t5_2r3gv,False,,,True,t3_1hcbmw,http://www.reddit.com/r/MachineLearning/comments/1hcbmw/explain_deep_belief_networks_as_if_im_a_complete/,
1372507238.0,16,self.MachineLearning,1hb25r,calculus of variations,18,2,10,http://www.reddit.com/r/MachineLearning/comments/1hb25r/calculus_of_variations/,Where did you study the Calculus of Variations for Machine Learning? It's a prerequisite for understanding Decision Theory. Bishop's books has 3 pages about it but they're too sketchy. There are entire books on the subject but I just need the basics.,,False,self,t5_2r3gv,False,,,True,t3_1hb25r,http://www.reddit.com/r/MachineLearning/comments/1hb25r/calculus_of_variations/,
1372184750.0,15,self.MachineLearning,1h1x2a,what are hidden layers for?,19,4,15,http://www.reddit.com/r/MachineLearning/comments/1h1x2a/what_are_hidden_layers_for/,"aright, i am trying to figure how neural networks works so i can create an OCR and take over the universe. i've come to a point where i don't really understand hidden layers.

how do i know how many hidden nodes do i need in a layer? or how do i know how many layers i need anyway? what's the purpose of hidden layers? can't i just connect the input nodes to the output nodes and let it do the processing?",,False,self,t5_2r3gv,False,,,True,t3_1h1x2a,http://www.reddit.com/r/MachineLearning/comments/1h1x2a/what_are_hidden_layers_for/,
1372080250.0,15,self.MachineLearning,1gytjp,Mapping clusters between datasets,17,2,9,http://www.reddit.com/r/MachineLearning/comments/1gytjp/mapping_clusters_between_datasets/,"I am using MVN mixture model clustering to cluster observations in data with D features into K classes.  I fit my algorithm to few different data sets, with a key assumption that the clusters are consistent across the datasets except for some amount of drift in the cluster means.  In this unsupervised case, the cluster labels don't automatically match between the data sets.  How can I make them match?

I thought of doing a stochastic search of the space of orderings of the elements of the mean vectors in each dataset, seeking the set of orderings that minimizes Euclidean distance between each set of mean vectors.  But that seems like overkill.  I'm certain someone has solved this by now, anyone know how?",,False,self,t5_2r3gv,False,,,True,t3_1gytjp,http://www.reddit.com/r/MachineLearning/comments/1gytjp/mapping_clusters_between_datasets/,
1371926568.0,14,iro.umontreal.ca,1gv8p6,Notes from Yoshua Bengio's Representation Learning class,16,2,0,http://www.reddit.com/r/MachineLearning/comments/1gv8p6/notes_from_yoshua_bengios_representation_learning/,,,False,default,t5_2r3gv,False,,,False,t3_1gv8p6,http://www.iro.umontreal.ca/~bengioy/ift6266/H12/html/contents.html#contents-en,
1370049774.0,14,self.MachineLearning,1ffvm7,Recent approaches to non-linear dimensionality reduction.,16,2,9,http://www.reddit.com/r/MachineLearning/comments/1ffvm7/recent_approaches_to_nonlinear_dimensionality/,"I am learning about non-linear dimensionality reduction (so far only older stuff like isomap and LLE). And I had a few questions:

1. Most implemented packages for isomap that I found (in R) simply mapped all my data to the manifold they ""found"". Is there a way to get the map itself (function mapping from input space to the manifold)? So that I would be able to learn the manifold on the training set and apply it to test sets?

2. What are the newer/better methods for non-linear dimensionality reduction?

3. How does non-linear reduction perform for small sample sizes (p &gt;&gt; n)?

Thanks a lot,
PMW.",,False,self,t5_2r3gv,False,,,True,t3_1ffvm7,http://www.reddit.com/r/MachineLearning/comments/1ffvm7/recent_approaches_to_nonlinear_dimensionality/,
1369506938.0,15,self.MachineLearning,1f1h7j,DBN libraries in R or Python?,19,4,15,http://www.reddit.com/r/MachineLearning/comments/1f1h7j/dbn_libraries_in_r_or_python/,"I have a bunch of data I think deep belief networks would work well on. I know the theory well, but I'm not in the mood to code up my own solution. 

I'd prefer something in R or Python because that's where I primary do my work and my data is stored in R matrices (which I can easily load into python using rpy2).  

Any ideas? Everything I've looked at is either not supported well or requires a lot of effort to get running. I'd like something that is simple to get started with.  ",,False,self,t5_2r3gv,False,,,True,t3_1f1h7j,http://www.reddit.com/r/MachineLearning/comments/1f1h7j/dbn_libraries_in_r_or_python/,
1369229349.0,15,self.MachineLearning,1etza0,Real valued Boltzmann machines,19,4,3,http://www.reddit.com/r/MachineLearning/comments/1etza0/real_valued_boltzmann_machines/,"I've been reading about RBMs lately and one thing I realize I'd that almost all the examples assume binary visible units. The one exception was the Gaussian-binary RBM which can cope with real valued input. But it looked too complicated and much style top train. How do people use RBMs on such a wide variety of real valued data sets? Audio, natural images etc. Do they all use Gaussian-binary RBMs or am I missing something simple?",,False,self,t5_2r3gv,False,,,True,t3_1etza0,http://www.reddit.com/r/MachineLearning/comments/1etza0/real_valued_boltzmann_machines/,
1368136321.0,14,izbicki.me,1e11mq,A tutorial on using Haskell's HLearn library for Markov networks,21,7,0,http://www.reddit.com/r/MachineLearning/comments/1e11mq/a_tutorial_on_using_haskells_hlearn_library_for/,,,False,http://f.thumbs.redditmedia.com/MqlnkK6UAFP19vik.jpg,t5_2r3gv,False,,,False,t3_1e11mq,http://izbicki.me/blog/markov-networks-monoids-and-futurama,
1365959502.0,12,self.MachineLearning,1cc07z,What is the state of the art in unsupervised image clustering?,17,5,16,http://www.reddit.com/r/MachineLearning/comments/1cc07z/what_is_the_state_of_the_art_in_unsupervised/,"Is it worth building a business model around it, or it is still in heavy research mode?",,False,self,t5_2r3gv,False,,,True,t3_1cc07z,http://www.reddit.com/r/MachineLearning/comments/1cc07z/what_is_the_state_of_the_art_in_unsupervised/,
1365690017.0,16,self.MachineLearning,1c4w02,"Beginner here, where to start on document classification?",18,2,8,http://www.reddit.com/r/MachineLearning/comments/1c4w02/beginner_here_where_to_start_on_document/,"Problem: Assume I have a 100 TB worth of web pages. How do I go about classifying them?

* With little background in machine learning, what books/tutorials should I read to be able to accomplish this?

* After I'm done with reading, are there any libraries out there that should help me with such endeavor?",,False,self,t5_2r3gv,False,,,True,t3_1c4w02,http://www.reddit.com/r/MachineLearning/comments/1c4w02/beginner_here_where_to_start_on_document/,
1365343056.0,14,self.MachineLearning,1buol9,Datasets for using ML algorithms,20,6,15,http://www.reddit.com/r/MachineLearning/comments/1buol9/datasets_for_using_ml_algorithms/,"Hi,

I've worked through much of the machine learning course that is on Coursera from Andrew Ng. What I would like is the opportunity to play around with some of these algorithms in practice, for example, support vector machines, clustering, neural networks. 

I am quite experienced in R and have experience working mainly with regressions and time series forecasting, so I shouldn't have much problem figuring out the mechanics of doing it, I just need the datasets. Can anyone guide me to some useful datasets online that would be interesting for these types of algorithms? Thanks.",,False,self,t5_2r3gv,False,,,True,t3_1buol9,http://www.reddit.com/r/MachineLearning/comments/1buol9/datasets_for_using_ml_algorithms/,
1363561184.0,15,citeseerx.ist.psu.edu,1ahnix,K-means cluster centers for the basis of kernel approximation. [PDF],20,5,10,http://www.reddit.com/r/MachineLearning/comments/1ahnix/kmeans_cluster_centers_for_the_basis_of_kernel/,,,False,default,t5_2r3gv,False,,,False,t3_1ahnix,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.144.9009&amp;rep=rep1&amp;type=pdf,
1363045579.0,15,blog.smellthedata.com,1a444o,Machine March Madness 2013,19,4,19,http://www.reddit.com/r/MachineLearning/comments/1a444o/machine_march_madness_2013/,,,False,default,t5_2r3gv,False,,,False,t3_1a444o,http://blog.smellthedata.com/2013/03/machine-march-madness-2013-want-to.html,
1359821523.0,14,slideshare.net,17r9dc,Large scale malicious domain classification using only textual features,20,6,0,http://www.reddit.com/r/MachineLearning/comments/17r9dc/large_scale_malicious_domain_classification_using/,,,False,http://d.thumbs.redditmedia.com/TLp7r-2RtQLVAn0K.jpg,t5_2r3gv,False,,,False,t3_17r9dc,http://www.slideshare.net/jasontrost/flo-con-clairvoyant-squirrel-final,
1358828072.0,15,self.MachineLearning,171b0n,Free Data to practice with,19,4,15,http://www.reddit.com/r/MachineLearning/comments/171b0n/free_data_to_practice_with/,"What are some places to grab data to try out some ML with? 

or what are some great ways to produce data for free?",,False,self,t5_2r3gv,False,,,True,t3_171b0n,http://www.reddit.com/r/MachineLearning/comments/171b0n/free_data_to_practice_with/,
1355096196.0,12,europepmc.org,14klwi,"Derivation of a novel efficient supervised learning algorithm from cortical-subcortical loops, Ashok Chandrashekar, Richard Granger",19,7,4,http://www.reddit.com/r/MachineLearning/comments/14klwi/derivation_of_a_novel_efficient_supervised/,,,False,default,t5_2r3gv,False,,,False,t3_14klwi,http://europepmc.org/articles/PMC3254165/pdf/fncom-05-00050.pdf,
1352999671.0,15,self.MachineLearning,138xep,[ELI5] -Latent Dirichlet Allocation. Can you explain it like I'm five?,23,8,4,http://www.reddit.com/r/MachineLearning/comments/138xep/eli5_latent_dirichlet_allocation_can_you_explain/,New to ML would appreciate the help. Thanks in advance!,,False,self,t5_2r3gv,False,,,True,t3_138xep,http://www.reddit.com/r/MachineLearning/comments/138xep/eli5_latent_dirichlet_allocation_can_you_explain/,
1350063864.0,15,blog.kaggle.com,11dis8,Competitive Astronomy: Crowdsourcing the Universe,18,3,2,http://www.reddit.com/r/MachineLearning/comments/11dis8/competitive_astronomy_crowdsourcing_the_universe/,,,False,http://a.thumbs.redditmedia.com/dH0bYbbNBvTkfhFf.jpg,t5_2r3gv,False,,,False,t3_11dis8,http://blog.kaggle.com/2012/10/08/competitive-astronomy-crowd-sourcing-the-universe/,
1348347203.0,16,sharpneat.sourceforge.net,10b9sy,SharpNEAT - Evolution of neural networks (in C# / .Net / Task Parallel Library),20,4,0,http://www.reddit.com/r/MachineLearning/comments/10b9sy/sharpneat_evolution_of_neural_networks_in_c_net/,,,False,http://d.thumbs.redditmedia.com/Ctj8GaNySNuJ4mm-.jpg,t5_2r3gv,False,,,False,t3_10b9sy,http://sharpneat.sourceforge.net/,
1347360866.0,12,self.MachineLearning,zpayl,"In a Bayesian Network how do I 
""neutralize"" a node?",17,5,11,http://www.reddit.com/r/MachineLearning/comments/zpayl/in_a_bayesian_network_how_do_i_neutralize_a_node/,"If I have a node in the network that's no longer functioning or observable what probability do I have to assign to it to neutralize it completely.

Say for example that I have the [sprinkler, rain, wetgrass network example from wikipedia](http://upload.wikimedia.org/wikipedia/commons/f/f7/SimpleBayesNetNodes.png). If my sprinklers break how I do I make it so their variable doesn't  affect the outcome anymore? 

Obvsiouly I could remove the variable from the network but that's quite difficult to do in programming because it alters the structure. Instead I would like to assign it a probability that no longer alters the final result.  What's the proper way to deal with this?",,False,self,t5_2r3gv,False,,,True,t3_zpayl,http://www.reddit.com/r/MachineLearning/comments/zpayl/in_a_bayesian_network_how_do_i_neutralize_a_node/,
1347053266.0,14,arauhala.github.com,ziy1s,"Re-expression method, new powerful approach for machine learning",30,16,17,http://www.reddit.com/r/MachineLearning/comments/ziy1s/reexpression_method_new_powerful_approach_for/,,,False,http://c.thumbs.redditmedia.com/rjSOdpPM3e5uuxc8.jpg,t5_2r3gv,False,,,False,t3_ziy1s,http://arauhala.github.com/libreexpweb/,
1345527170.0,14,self.MachineLearning,ykfi4,What are the prospects for a MS versus a PhD in ML?,24,10,29,http://www.reddit.com/r/MachineLearning/comments/ykfi4/what_are_the_prospects_for_a_ms_versus_a_phd_in_ml/,"First off, I have actually used the search and found several threads similar to this, such as [this one](http://www.reddit.com/r/MachineLearning/comments/mu2ly/is_a_phd_worth_it_in_machine_learning/) from eight months ago. But this subreddit has grown since then, and I'd like the see if there is any sort of consensus.

Context: I'm a 2nd year PhD student in ML. In my first year, I decided that academia isn't for me, and that I'd like to go into industry after my PhD. Recently, I've seen that if one's intentions are to go into industry, then the MS is the superior degree. But I have also seen that a lot of machine learning jobs require PhDs.

To be honest, I'm leaning towards bailing with a masters, because I can always come back for the PhD if I dislike my options in industry. Before I bring this up with my advisor, though, I'd like to know what sort of jobs I can expect to get. If it changes anything, I have two bachelors degrees (applied math and physics) that aren't in CS. 

So, if I don't much care about doing fundamental research in ML, is stopping at a masters degree going to close a lot of doors? For those of you with MS degrees in ML, what is your day job?",,False,self,t5_2r3gv,False,,,True,t3_ykfi4,http://www.reddit.com/r/MachineLearning/comments/ykfi4/what_are_the_prospects_for_a_ms_versus_a_phd_in_ml/,
1344496481.0,12,plus.google.com,xxgln,deep learning powers android voice recognition,19,7,11,http://www.reddit.com/r/MachineLearning/comments/xxgln/deep_learning_powers_android_voice_recognition/,,,False,http://e.thumbs.redditmedia.com/bsl9_8cUb7VcAaBd.jpg,t5_2r3gv,False,,,False,t3_xxgln,https://plus.google.com/118227548810368513262/posts/2wtctFEsBk2,
1344232748.0,13,self.MachineLearning,xr3k3,Which models are better at regression and which models are better at classification?,18,5,4,http://www.reddit.com/r/MachineLearning/comments/xr3k3/which_models_are_better_at_regression_and_which/,As an example: are random forests great for classification but not so great at regression? What about neural nets and SVMs?,,False,self,t5_2r3gv,False,,,True,t3_xr3k3,http://www.reddit.com/r/MachineLearning/comments/xr3k3/which_models_are_better_at_regression_and_which/,
1342799614.0,16,cs.utah.edu,wvmmq,Frustratingly Easy Domain Adaptation - Hal Daumé 2007,17,1,0,http://www.reddit.com/r/MachineLearning/comments/wvmmq/frustratingly_easy_domain_adaptation_hal_daumé/,,,False,default,t5_2r3gv,False,,,False,t3_wvmmq,http://www.cs.utah.edu/~hal/docs/daume07easyadapt.pdf,
1340778078.0,12,self.MachineLearning,vo9d2,"Are there any books, articles or videos that explain 
the central concepts of machine learning from a 
layman's perspective?",17,5,9,http://www.reddit.com/r/MachineLearning/comments/vo9d2/are_there_any_books_articles_or_videos_that/,"I have very little programming knowledge and even less math. I would like to be able to understand the concepts, methods and paradigms of ML, even at a very high, broad level. Later in my education I'm going to be dealing with it in more detail, so I'd like to have some context, which makes anything easier to learn.

EDIT: Thanks everyone! :) I have a lot of reading to do!",,False,self,t5_2r3gv,1340840813.0,,,True,t3_vo9d2,http://www.reddit.com/r/MachineLearning/comments/vo9d2/are_there_any_books_articles_or_videos_that/,
1338866055.0,13,self.MachineLearning,ulgg8,Removing seasonality from time series data,15,2,9,http://www.reddit.com/r/MachineLearning/comments/ulgg8/removing_seasonality_from_time_series_data/,"is there a general way of removing seasonality from time series data? Many of the methods I have read about seem fairly ad-hoc, I was wondering if there is a 'best practice' recommended way of doing it? especially if there are multiple levels i.e. daily,weekly and monthly seasonality in the same series.",,False,self,t5_2r3gv,False,,,True,t3_ulgg8,http://www.reddit.com/r/MachineLearning/comments/ulgg8/removing_seasonality_from_time_series_data/,
1336666781.0,14,blog.bigml.com,tgnjl,R you ready for Big Machine Learning?,25,11,18,http://www.reddit.com/r/MachineLearning/comments/tgnjl/r_you_ready_for_big_machine_learning/,,,False,http://d.thumbs.redditmedia.com/mrKqBhjMZwUDxSx3.jpg,t5_2r3gv,False,,,False,t3_tgnjl,http://blog.bigml.com/2012/05/10/r-you-ready-for-bigml/,
1335900471.0,15,highlyscalable.wordpress.com,t1y4d,Probabilistic Data Structures for Web Analytics and Data Mining,15,0,1,http://www.reddit.com/r/MachineLearning/comments/t1y4d/probabilistic_data_structures_for_web_analytics/,,,False,http://a.thumbs.redditmedia.com/t1JUTInVatCI64x6.jpg,t5_2r3gv,False,,,False,t3_t1y4d,http://highlyscalable.wordpress.com/2012/05/01/probabilistic-structures-web-analytics-data-mining/,
1330396003.0,14,developers.google.com,q928i,Google's cloud-based machine learning tools,18,4,0,http://www.reddit.com/r/MachineLearning/comments/q928i/googles_cloudbased_machine_learning_tools/,,,False,default,t5_2r3gv,False,,,False,t3_q928i,https://developers.google.com/prediction/,
1327809565.0,14,self.MachineLearning,p1bl6,what is the State of the art in finding 'features' in images,14,0,17,http://www.reddit.com/r/MachineLearning/comments/p1bl6/what_is_the_state_of_the_art_in_finding_features/,"i was going through the Computer vision and pattern recognition, conference  papers  over the last few years , and was wondering what is the state of the art in finding 'dense' features in an image which may then be used to do image based content retrieval. ",,False,self,t5_2r3gv,False,,,True,t3_p1bl6,http://www.reddit.com/r/MachineLearning/comments/p1bl6/what_is_the_state_of_the_art_in_finding_features/,
1327504598.0,14,allendowney.blogspot.com,ow3vk,Excerpts from Redditor AllenDowney's new book 'Think Complexity' ,19,5,0,http://www.reddit.com/r/MachineLearning/comments/ow3vk/excerpts_from_redditor_allendowneys_new_book/,,,False,http://f.thumbs.redditmedia.com/bAAJsyNkAQQ_mNde.jpg,t5_2r3gv,False,,,False,t3_ow3vk,http://allendowney.blogspot.com/2012/01/think-complexity.html,
1324314699.0,13,broadinstitute.org,ningw,Tool detects patterns hidden in vast data sets | Broad Institute of MIT and Harvard,17,4,11,http://www.reddit.com/r/MachineLearning/comments/ningw/tool_detects_patterns_hidden_in_vast_data_sets/,,,False,http://e.thumbs.redditmedia.com/p5XVL6xqR65rDJ6d.jpg,t5_2r3gv,False,,,False,t3_ningw,http://www.broadinstitute.org/news/3784,
1324255597.0,15,self.MachineLearning,nhury,Ask r/ML: Why isn't R used often for game AI?,18,3,20,http://www.reddit.com/r/MachineLearning/comments/nhury/ask_rml_why_isnt_r_used_often_for_game_ai/,"I'm an undergraduate student, learning R at school, and I've been lately exploring use cases for R, and taking a look at several of the packages on CRAN.

I've noticed that there's a lot of data mining/classification type packages, and a lot for specialized fields, like ape for bioinformatics, and many more for natural language processing.  However, I haven't seen any for game decision trees, say chess or Go.  

I guess that C++ is often used more, because every bit of speed matters and it's easier to write object-oriented code in C++, but I can't imagine why R wouldn't be a good contender either.  Could anyone with experience in this area maybe explain why?",,False,self,t5_2r3gv,False,,,True,t3_nhury,http://www.reddit.com/r/MachineLearning/comments/nhury/ask_rml_why_isnt_r_used_often_for_game_ai/,
1322680601.0,14,www-stat.wharton.upenn.edu,mv1uh,A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition [PDF],23,9,8,http://www.reddit.com/r/MachineLearning/comments/mv1uh/a_tutorial_on_hidden_markov_models_and_selected/,,,False,default,t5_2r3gv,False,,,False,t3_mv1uh,http://www-stat.wharton.upenn.edu/~steele/Courses/956/Resource/HiddenMarkovModels/HMMTutorial/rabiner89.pdf,
1321363844.0,15,github.com,md1pa,"All code from ""Machine Learning for Email"" now on Github",21,6,2,http://www.reddit.com/r/MachineLearning/comments/md1pa/all_code_from_machine_learning_for_email_now_on/,,,False,default,t5_2r3gv,False,,,False,t3_md1pa,https://github.com/drewconway/ML-Email-Code,
1320319331.0,14,self.MachineLearning,lyv63,Machine learning methods for time series,14,0,19,http://www.reddit.com/r/MachineLearning/comments/lyv63/machine_learning_methods_for_time_series/,Does anyone knows some good material for machine learning techniques applied for time series analysis ? Thanks !,,False,self,t5_2r3gv,False,,,True,t3_lyv63,http://www.reddit.com/r/MachineLearning/comments/lyv63/machine_learning_methods_for_time_series/,
1318516192.0,13,yz.mit.edu,lauc9,What's there to like about R?,15,2,4,http://www.reddit.com/r/MachineLearning/comments/lauc9/whats_there_to_like_about_r/,,,False,default,t5_2r3gv,False,,,False,t3_lauc9,http://yz.mit.edu/wp/whats-there-to-like-about-r/,
1317341133.0,13,sites.google.com,kvvpc,k-means learning,17,4,2,http://www.reddit.com/r/MachineLearning/comments/kvvpc/kmeans_learning/,,,False,default,t5_2r3gv,False,,,False,t3_kvvpc,https://sites.google.com/site/kmeanslearning/,
1313387426.0,13,machinelearningjourney.blogspot.com,jj3rn,A Machine Learning Guide,19,6,1,http://www.reddit.com/r/MachineLearning/comments/jj3rn/a_machine_learning_guide/,,,False,default,t5_2r3gv,False,,,False,t3_jj3rn,http://machinelearningjourney.blogspot.com/,
1313099058.0,15,blog.smellthedata.com,jg4c5,Testing Intuitions about Markov Chain Monte Carlo: Do I have a bug?,15,0,0,http://www.reddit.com/r/MachineLearning/comments/jg4c5/testing_intuitions_about_markov_chain_monte_carlo/,,,False,http://thumbs.reddit.com/t3_jg4c5.png,t5_2r3gv,False,,,False,t3_jg4c5,http://blog.smellthedata.com/2011/08/testing-intuitions-about-markov-chain.html,
1312274250.0,13,self.MachineLearning,j6j7u,What open source handwriting identification programs exist?,14,1,10,http://www.reddit.com/r/MachineLearning/comments/j6j7u/what_open_source_handwriting_identification/,,,False,self,t5_2r3gv,False,,,True,t3_j6j7u,http://www.reddit.com/r/MachineLearning/comments/j6j7u/what_open_source_handwriting_identification/,
1312220981.0,14,socher.org,j5v49,Parsing Natural Scenes And Natural Language With Recursive Neural Networks - www.socher.org,17,3,2,http://www.reddit.com/r/MachineLearning/comments/j5v49/parsing_natural_scenes_and_natural_language_with/,,,False,default,t5_2r3gv,False,,,False,t3_j5v49,http://www.socher.org/index.php/Main/ParsingNaturalScenesAndNaturalLanguageWithRecursiveNeuralNetworks,
1308056809.0,14,examville.com,hzd9p,Machine Learning with Apache Mahout,18,4,1,http://www.reddit.com/r/MachineLearning/comments/hzd9p/machine_learning_with_apache_mahout/,,,False,http://thumbs.reddit.com/t3_hzd9p.png,t5_2r3gv,False,,,False,t3_hzd9p,http://www.examville.com/examville/Machine%20Learning%20with%20Apache%20Mahout-ID7537,
1307494453.0,16,self.MachineLearning,hu7r4,Explaining a Neural Net by fitting a binary tree to inputs and outputs,19,3,11,http://www.reddit.com/r/MachineLearning/comments/hu7r4/explaining_a_neural_net_by_fitting_a_binary_tree/,"In Leo Breiman's paper ""Statistical Modeling: The Two Cultures"" (PDF [here](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.156.4933&amp;rep=rep1&amp;type=pdf)), Breiman relates this anecdote, as part of his response to Bruce Hoadley's response:  

&gt; A computer scientist working in the machine learning area joined a large money management
company some years ago and set up a group to do portfolio management using stock predictions given by large neural nets. When we visited, I asked how he explained the neural nets to clients. “Simple,” he said; “We fit binary trees to the inputs and outputs of the neural nets and show the trees to the clients. Keeps them happy!” In both stock prediction and credit rating, the priority is accuracy. Interpretability is a secondary goal that can be finessed.

I want to make sure I understand what this computer scientist at the large money mgmt company is doing.  He's taking the predicted outputs of the neural net - the yhats - and using them as the dependent variable for a single binary tree model.  Is that right?  I understand that this is solely for client interpretability, and the tree wouldn't be used for prediction, but it still feels a little funny.  The tree wouldn't fit the neural net's predictions perfectly, so you'd have situations like this:

you: ""well the tree predicts this, but that's actually not our prediction, because our real model is a neural net.""  

client: ""why does the net make a different prediction?""

you: ""it's a black box, I can't say""  

and you're back to square one.  
Thoughts?  ",,False,self,t5_2r3gv,False,,,True,t3_hu7r4,http://www.reddit.com/r/MachineLearning/comments/hu7r4/explaining_a_neural_net_by_fitting_a_binary_tree/,
1305777142.0,14,citeseerx.ist.psu.edu,herod,Clustering by compression,15,1,0,http://www.reddit.com/r/MachineLearning/comments/herod/clustering_by_compression/,,,False,default,t5_2r3gv,False,,,False,t3_herod,http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.103.3082,
1305184870.0,13,r-bloggers.com,h9loe,Basics of LOESS Regression,16,3,0,http://www.reddit.com/r/MachineLearning/comments/h9loe/basics_of_loess_regression/,,,False,http://thumbs.reddit.com/t3_h9loe.png,t5_2r3gv,False,,,False,t3_h9loe,http://www.r-bloggers.com/sab-r-metrics-basics-of-loess-regression/,
1303545235.0,14,r-bloggers.com,gvmii,Visualizing iPhone location tracking with Google Maps and R,18,4,2,http://www.reddit.com/r/MachineLearning/comments/gvmii/visualizing_iphone_location_tracking_with_google/,,,False,http://thumbs.reddit.com/t3_gvmii.png,t5_2r3gv,False,,,False,t3_gvmii,http://www.r-bloggers.com/visualizing-iphone-location-tracking-with-r-and-google-maps/,
1302720098.0,13,www-personal.umich.edu,gp9gg,A stand alone simulated annealing package in python,15,2,2,http://www.reddit.com/r/MachineLearning/comments/gp9gg/a_stand_alone_simulated_annealing_package_in/,,,False,default,t5_2r3gv,False,,,False,t3_gp9gg,http://www-personal.umich.edu/~wagnerr/PythonAnneal.html,
1302135067.0,12,self.MachineLearning,gkbnj,How can classification be done with variable-sized data?,15,3,18,http://www.reddit.com/r/MachineLearning/comments/gkbnj/how_can_classification_be_done_with_variablesized/,"For instance, if I have n objects in the world, and each object has a feature vector of length m. Now I would like to do some binary classification on the world. Well I could train classifiers for each object individually, which would give me n different classifier decisions. But now I need to combine these decisions into a final classification (maybe by using another classifier, but here is where the variable-sized problem comes in). Traditional classification techniques assume a fixed-sized feature vector. Is there a way to overcome this?

Edit: I may have been unclear in my original post: I'm referring to the case when n can take on any value - it is completely unknown and may vary for different instances of the world. That is, I may have one training example where there are 3 objects but I have another example where there are 10. Assume m is fixed and known.",,False,self,t5_2r3gv,True,,,True,t3_gkbnj,http://www.reddit.com/r/MachineLearning/comments/gkbnj/how_can_classification_be_done_with_variablesized/,
1301271472.0,15,blog.smellthedata.com,gcro2,Algorithmic March Madness: Machines Lock in Victory Over Humans,17,2,1,http://www.reddit.com/r/MachineLearning/comments/gcro2/algorithmic_march_madness_machines_lock_in/,,,False,default,t5_2r3gv,False,,,False,t3_gcro2,http://blog.smellthedata.com/2011/03/2011-algorithmic-march-madness-machines.html,
1300882054.0,14,media.kaggle.com,g9n9z,Getting In Shape For The Sport of Data Science (Video on tools and strategies for doing well in data mining competitions by Jeremy Howard),17,3,0,http://www.reddit.com/r/MachineLearning/comments/g9n9z/getting_in_shape_for_the_sport_of_data_science/,,,False,default,t5_2r3gv,False,,,False,t3_g9n9z,http://media.kaggle.com/MelbURNiPad.html,
1299914205.0,15,r-bloggers.com,g2h77,Rexer Survey: R is used by more data miners than any other tool,17,2,0,http://www.reddit.com/r/MachineLearning/comments/g2h77/rexer_survey_r_is_used_by_more_data_miners_than/,,,False,http://thumbs.reddit.com/t3_g2h77.png,t5_2r3gv,False,,,False,t3_g2h77,http://www.r-bloggers.com/survey-r-used-by-more-data-miners-than-any-other-tool/,
1299769921.0,14,self.MachineLearning,g17wi,Help choosing a classifier,14,0,33,http://www.reddit.com/r/MachineLearning/comments/g17wi/help_choosing_a_classifier/,"Hi,

I'm a compsci academic. I have a problem for which I'm attempting to train a binary classifier, with some degree of success. The classifers I've tried are ID3, MaxEnt, and NaiveBayes (the versions built in to NLTK). I have a suspicion that to achieve great performance with my features requires a classifier that doesn't follow the independence assumption - that is, one that can weight feature values dependent on the values assigned to other features.

ID3 intuitively doesn't follow this assumption, and naive Bayes does (that's its naivety). I'mm not sure about MaxEnt. In any case, my error reduction rate is 43% with MaxEnt, 12% with NBayes and 38% with ID3.

Can anyone recommend a classifier that is good with handling noise, doesn't follow the independence assumption, and can accept nominal features without too much coaxing?

Thanks!",,False,self,t5_2r3gv,False,,,True,t3_g17wi,http://www.reddit.com/r/MachineLearning/comments/g17wi/help_choosing_a_classifier/,
1299257248.0,12,academic.research.microsoft.com,fxcy7,Top Authors in Machine Learning and Pattern Recognition (based on in-domain citations),17,5,10,http://www.reddit.com/r/MachineLearning/comments/fxcy7/top_authors_in_machine_learning_and_pattern/,,,False,http://thumbs.reddit.com/t3_fxcy7.png,t5_2r3gv,False,,,False,t3_fxcy7,http://academic.research.microsoft.com/RankList?entitytype=2&amp;domainID=6&amp;last=0&amp;start=1&amp;end=100,
1298239264.0,14,terrytao.wordpress.com,fp5xe,"Draft of a new book by Terence Tao, ""Topics in random matrix theory"", available for download",18,4,3,http://www.reddit.com/r/MachineLearning/comments/fp5xe/draft_of_a_new_book_by_terence_tao_topics_in/,,,False,default,t5_2r3gv,False,,,False,t3_fp5xe,http://terrytao.wordpress.com/2011/02/20/topics-in-random-matrix-theory/,
1297163186.0,14,github.com,fhfug,A Hidden Markov Model package for Weka,16,2,3,http://www.reddit.com/r/MachineLearning/comments/fhfug/a_hidden_markov_model_package_for_weka/,,,False,default,t5_2r3gv,False,,,False,t3_fhfug,https://github.com/marcogillies/HMMWeka,
1296840874.0,15,youtube.com,ffax2,Strataconf announcement for the $3 million Heritage Health Prize,16,1,2,http://www.reddit.com/r/MachineLearning/comments/ffax2/strataconf_announcement_for_the_3_million/,,,False,http://thumbs.reddit.com/t3_ffax2.png,t5_2r3gv,False,,,False,t3_ffax2,http://www.youtube.com/watch?v=ihyco_1lyAA,
1296079164.0,14,reddit.com,f9m1v,"New subreddit for bigdata! Also anyone going to the Strata conference in Santa Clara, CA from Feb. 1-3?",14,0,0,http://www.reddit.com/r/MachineLearning/comments/f9m1v/new_subreddit_for_bigdata_also_anyone_going_to/,,,False,default,t5_2r3gv,False,,,False,t3_f9m1v,http://www.reddit.com/r/bigdata,
1295972587.0,13,slate.com,f8r6s,Can police really predict crime before it happens?,14,1,8,http://www.reddit.com/r/MachineLearning/comments/f8r6s/can_police_really_predict_crime_before_it_happens/,,,False,http://thumbs.reddit.com/t3_f8r6s.png,t5_2r3gv,False,,,False,t3_f8r6s,http://www.slate.com/id/2282252/,
1295958122.0,15,reddit.com,f8o1j,Free E-Book: Clever Algorithms: Nature-Inspired Programming Recipes (/r/csbooks crosspost),17,2,3,http://www.reddit.com/r/MachineLearning/comments/f8o1j/free_ebook_clever_algorithms_natureinspired/,,,False,default,t5_2r3gv,False,,,False,t3_f8o1j,http://www.reddit.com/r/csbooks/comments/f8o0x/clever_algorithms_natureinspired_programming/,
1294757327.0,15,youtube.com,f08dc,Desk Set  a 1957 film where Spencer Tracy and Katharine Hepburn fight over how a computer and big data will get rid of researchers,16,1,7,http://www.reddit.com/r/MachineLearning/comments/f08dc/desk_set_a_1957_film_where_spencer_tracy_and/,,,False,http://thumbs.reddit.com/t3_f08dc.png,t5_2r3gv,False,,,False,t3_f08dc,http://www.youtube.com/watch?v=gd5CoMeip9o,
1292902986.0,14,99designs.com,ep4jk,Help vote for the best cover for my nature-inspired AI Algorithms book,21,7,16,http://www.reddit.com/r/MachineLearning/comments/ep4jk/help_vote_for_the_best_cover_for_my/,,,False,default,t5_2r3gv,False,,,False,t3_ep4jk,http://99designs.com/print-design/vote-ez1m45,
1289332061.0,13,self.MachineLearning,e3mm7,Anyone here attending NIPS 2010 this December?,16,3,8,http://www.reddit.com/r/MachineLearning/comments/e3mm7/anyone_here_attending_nips_2010_this_december/,"[Info](http://nips.cc/) about the conference.  It's in Vancouver, BC.  Post in the comments if you have a paper or poster accepted into the proceedings.  And it's not too late to register even if you didn't submit a paper.  Should be a good time. =)",,False,self,t5_2r3gv,False,,,True,t3_e3mm7,http://www.reddit.com/r/MachineLearning/comments/e3mm7/anyone_here_attending_nips_2010_this_december/,
1287709309.0,12,knol.google.com,dunyt,Looking for feedback - A Short Simple Introduction to Information Theory,16,4,5,http://www.reddit.com/r/MachineLearning/comments/dunyt/looking_for_feedback_a_short_simple_introduction/,,,False,http://thumbs.reddit.com/t3_dunyt.png,t5_2r3gv,False,,,False,t3_dunyt,http://knol.google.com/k/ryan-moulton/a-short-simple-introduction-to/3kbzhsxyg4467/7#view,
1280570511.0,15,slideshare.net,cvsue,Problem-Solving using Graph Traversals,15,0,0,http://www.reddit.com/r/MachineLearning/comments/cvsue/problemsolving_using_graph_traversals/,,,False,http://thumbs.reddit.com/t3_cvsue.png,t5_2r3gv,False,,,False,t3_cvsue,http://www.slideshare.net/slidarko/problemsolving-using-graph-traversals-searching-scoring-ranking-and-recommendation,
1279897314.0,14,scottaaronson.com,cswe9,"Repost from HN. Scott Aaronson, MIT Prof, replies to Roger Penrose's Emperor's new mind. ",14,0,3,http://www.reddit.com/r/MachineLearning/comments/cswe9/repost_from_hn_scott_aaronson_mit_prof_replies_to/,,,False,default,t5_2r3gv,False,,,False,t3_cswe9,http://www.scottaaronson.com/democritus/lec10.5.html,
1277163209.0,14,icml2010.org,chip4,ICML 2010 papers (International Conference on Machine Learning),17,3,0,http://www.reddit.com/r/MachineLearning/comments/chip4/icml_2010_papers_international_conference_on/,,,False,default,t5_2r3gv,False,,,False,t3_chip4,http://www.icml2010.org/abstracts.html,
1274008629.0,13,drmaciver.com,c4qg7,"What to do with 60,000 answers about programming languages?",17,4,2,http://www.reddit.com/r/MachineLearning/comments/c4qg7/what_to_do_with_60000_answers_about_programming/,,,False,default,t5_2r3gv,False,,,False,t3_c4qg7,http://www.drmaciver.com/2010/05/the-right-data/,
1271315660.0,15,self.MachineLearning,br638,Help me find this page again? Comparison of classification algorithms,18,3,9,http://www.reddit.com/r/MachineLearning/comments/br638/help_me_find_this_page_again_comparison_of/,"A while back I saw a page that compared the performance of various classification algorithms on a series of artificial data-sets. The results were displayed as a large grid of red/blue diagrams showing decision boundaries for the algorithm and true/false examples. 
A bit like http://blog.peltarion.com/2006/07/10/classifier-showdown/, but this isn't it.

The page had naive bayes, SVM with a range of kernels, some rule learners, etc. 

I was pretty sure I found it from reddit, but for the life of me I can't find it again now. 

Thanks!

**EDIT:**
Appropriately named [bayes](http://www.reddit.com/user/bayes) [found it](http://www.reddit.com/r/MachineLearning/comments/br638/help_me_find_this_page_again_comparison_of/c0o8rdm): 

http://home.comcast.net/~tom.fawcett/public_html/ML-gallery/pages/index.html

Thanks a lot!",,False,self,t5_2r3gv,True,,,True,t3_br638,http://www.reddit.com/r/MachineLearning/comments/br638/help_me_find_this_page_again_comparison_of/,
1266588019.0,14,self.MachineLearning,b3zq7,Ask ML: Which machine learning algorithm(SL or SSL) would you suggest for high performance and accurate classification?,17,3,24,http://www.reddit.com/r/MachineLearning/comments/b3zq7/ask_ml_which_machine_learning_algorithmsl_or_ssl/,"My dataset has 7 tuples, 11 classes and I should classify at least 80k items under 5 mins. And of course there is noise in the dataset. I'm thinking of using a semi-supervised learning technique for my case. Because i have a lot of unlabeled samples. But semi-supervised techniques, usually tend to have higher computational cost when compared to other techniques. But cluster and label or cotraining approaches are still in my mind. I have tested SVM(C-SVC in libsvm) on my dataset and got 91% percent accuracy rate but lasted about 13 min. Also tested C4.5 and got 85 percent accuracy rate but it finished under 5 min. Both algorithms are tested with default parameters without fine-tuning. C4.5 is quick and it can get better accuracy by using boosting. But i don't want to use C4.5 for personal reasons :). Bayesian techniques that i have tested are also too slow and have long training time. What is you opinion? 

Edit: I have also written KNN but it took longer than 10 mins and it was the least accurate one.
Edit 2: I meant 7 tuples=7 features.",,False,self,t5_2r3gv,True,,,True,t3_b3zq7,http://www.reddit.com/r/MachineLearning/comments/b3zq7/ask_ml_which_machine_learning_algorithmsl_or_ssl/,
1261765440.0,13,cs.washington.edu,aii73,Structured Machine Learning: Ten Problems for the Next Ten Years [pdf],16,3,1,http://www.reddit.com/r/MachineLearning/comments/aii73/structured_machine_learning_ten_problems_for_the/,,,False,default,t5_2r3gv,False,,,False,t3_aii73,http://www.cs.washington.edu/homes/pedrod/papers/ilp07.pdf,
1256120445.0,13,hakank.org,9w7i6,A page of weka examples,15,2,0,http://www.reddit.com/r/MachineLearning/comments/9w7i6/a_page_of_weka_examples/,,,False,default,t5_2r3gv,False,,,False,t3_9w7i6,http://www.hakank.org/weka/,
1253548053.0,15,archive.ics.uci.edu,9mn7g,UCI Machine Learning Repository,15,0,1,http://www.reddit.com/r/MachineLearning/comments/9mn7g/uci_machine_learning_repository/,,,False,default,t5_2r3gv,False,,,False,t3_9mn7g,http://archive.ics.uci.edu/ml/,
1248962405.0,13,gaussianprocess.org,95zpj,"""Gaussian Processes for Machine 
Learning"" book freely available 
online from MIT Press.",16,3,0,http://www.reddit.com/r/MachineLearning/comments/95zpj/gaussian_processes_for_machine_learning_book/,,,False,default,t5_2r3gv,False,,,False,t3_95zpj,http://www.gaussianprocess.org/gpml/chapters/,
1372708342.0,14,self.MachineLearning,1hg3f1,Opinions on NLTK,15,1,17,http://www.reddit.com/r/MachineLearning/comments/1hg3f1/opinions_on_nltk/,"Hi, I've been studying NLP for a little bit now and would like to do a project where I create a one sentence summary of a paragraph. I want to start off by analyzing sentence structure and creating a parse tree for each sentence. From the more experienced people, I'm wondering what are your thoughts on NLTK? Are there reason's why I would write my own parser? I don't have a lot of experience with NLP, so I'm wondering if NLTK is something I should always look at using when possible or if I would be better off learning the material myself and implementing my own tools.

Thanks in advance.",,False,self,t5_2r3gv,False,,,True,t3_1hg3f1,http://www.reddit.com/r/MachineLearning/comments/1hg3f1/opinions_on_nltk/,
1372631209.0,12,self.MachineLearning,1he0ig,An idea I have for improving ensemble and neural network models. May work well with nonconvex optimization.,15,3,13,http://www.reddit.com/r/MachineLearning/comments/1he0ig/an_idea_i_have_for_improving_ensemble_and_neural/,"This is an idea I had today, I figured I'd post it here. If it's been done before or wouldn't work, let me know.

The TL;DR is to add a term to the cost function of a model to prevent ensembles from learning the same representation of the data. I've thought about this for ensemble models and for neural networks (connected ensembles), and I think it could work for both.

If the ensembled models are parameterized by some vector theta, then we can tell how similar two models are by using a similarity measure on their parameter vectors. RBF, cosine, squared difference, whatever. Then what we do is penalize the model for having a larger similarity measure with the other models by introducing a new term to the cost function. For each model, this could be some constant times the sum of similarity measures with all the other models. If we don't want the O( n^2 ) complexity, maybe we sample the other models at random, or choose a few at the beginning such that through multiple time steps each model can affect the others. 

This would also work for neural nets, where we use the similarity penalty to prevent feature detectors from learning the same features. The reason I mentioned nonconvex optimization is because forcing the models to find different local minima could make for a better exploration of the feature space. 

Has this been investigated before? If not, I suppose I could put a test together to see how it impacts model performance, and whether the cost in training efficiency is worth it.",,False,self,t5_2r3gv,False,,,True,t3_1he0ig,http://www.reddit.com/r/MachineLearning/comments/1he0ig/an_idea_i_have_for_improving_ensemble_and_neural/,
1371250272.0,11,blog.mashape.com,1gdafp,A list of 40+ Machine Learning APIs,25,14,0,http://www.reddit.com/r/MachineLearning/comments/1gdafp/a_list_of_40_machine_learning_apis/,,,False,default,t5_2r3gv,False,,,False,t3_1gdafp,http://blog.mashape.com/post/48074869493/list-of-40-machine-learning-apis,
1370972984.0,13,numenta.org,1g4vi9,First NuPIC Hackathon,21,8,9,http://www.reddit.com/r/MachineLearning/comments/1g4vi9/first_nupic_hackathon/,,,False,http://a.thumbs.redditmedia.com/vH5V8smbwg_qhoer.jpg,t5_2r3gv,False,,,False,t3_1g4vi9,http://numenta.org/news/2013/06/03/hackathon-june-2013.html,
1370954656.0,12,self.MachineLearning,1g4861,"How to probabilistically generate a sequence according to hidden, noisy rules from other known sequences?",15,3,8,http://www.reddit.com/r/MachineLearning/comments/1g4861/how_to_probabilistically_generate_a_sequence/,"How would you generate a sequence based on previous known sequences, some of which may have some errors? For example, if one had symbols from an unknown script, but many examples of sentences, one could try to complete partial sentences in the script based on the previous examples.

One could use a simple Markov chain, but this is too simplified really for grammar or musical rules, etc.

",,False,self,t5_2r3gv,False,,,True,t3_1g4861,http://www.reddit.com/r/MachineLearning/comments/1g4861/how_to_probabilistically_generate_a_sequence/,
1367912813.0,13,self.MachineLearning,1dun0c,Has anyone used singular spectrum analysis before? How does it compare to PCA?,14,1,4,http://www.reddit.com/r/MachineLearning/comments/1dun0c/has_anyone_used_singular_spectrum_analysis_before/,"I have some time series data in the form of (x1, x2, ..., xn, y) for each example, and I  am wondering whether SSA would be good to use as a pre-processing step. I don't know very much about it yet, so I am wondering if anyone here has any experience using it and how that worked out. 

 Does SSA get computationally expensive for large amounts of data? Could I use multivariate SSA here for better accuracy? ",,False,self,t5_2r3gv,False,,,True,t3_1dun0c,http://www.reddit.com/r/MachineLearning/comments/1dun0c/has_anyone_used_singular_spectrum_analysis_before/,
1367216678.0,14,self.MachineLearning,1dbnrb,Need advice: Very small sample,15,1,12,http://www.reddit.com/r/MachineLearning/comments/1dbnrb/need_advice_very_small_sample/,"I'm looking for advice. I'm trying to predict the question mark using the following tiny data set.
 
    Tag1 Tag2 Tag3 Tag4	Score
    1	 0    0	   0	2000
    1	 0    0	   1	2400
    0	 1    0	   0	3000
    0	 1    0	   1	3600
    0	 0    1	   0	4000
    0    0    1    1    ?
 
I'm expecting the answer to be 4800. I'm very new to this space. I've tried a quick linear regression algorithm but the results aren't great. I've tried a simple neural network but I appreciate that I don't have enough samples to allow this approach to work. 
 
I feel like my options now are to either find another approach or invest the time in understanding how to apply one of the two approaches that I have tried so properly. Any advice at all would be appreciated.",,False,self,t5_2r3gv,False,,,True,t3_1dbnrb,http://www.reddit.com/r/MachineLearning/comments/1dbnrb/need_advice_very_small_sample/,
1365483502.0,13,self.MachineLearning,1byzvt,Using PCA to produce a black and white (grayscale) photo,15,2,8,http://www.reddit.com/r/MachineLearning/comments/1byzvt/using_pca_to_produce_a_black_and_white_grayscale/,"I was messing around with some image processing and tried out a fun (albeit trivial) use for PCA. For a given image, I took each pixel's RGB value as a 3 dimensional vector. Then projected each pixel onto the first PC and normalized for the appropriate value. 

The results are here:
http://imgur.com/a/a4kwY

I know this isn't anything crazy, I just thought it was kind of a fun use of a data processing algorithm. Also, if you think about it more deeply, this method of creating a black and white photo could possible preserve more of the original qualities of the color version than just taking the average of the color pixels. 

EDIT:

As requested, here is the image projected into HSV space. Looks like solarize filter.

http://i.imgur.com/d7J2Bjj.jpg",,False,self,t5_2r3gv,1365616265.0,,,True,t3_1byzvt,http://www.reddit.com/r/MachineLearning/comments/1byzvt/using_pca_to_produce_a_black_and_white_grayscale/,
1361565092.0,13,self.MachineLearning,191hbc,Backpropagation - how much training data do I need?,22,9,10,http://www.reddit.com/r/MachineLearning/comments/191hbc/backpropagation_how_much_training_data_do_i_need/,"Hello, 

For the last few weeks I've been working on a backprop network and posting a few questions to this forum; I thank you for all the help so far. I've gone from concept, to buggy implementation, to something that works. 

As a quick recap of my network - my network takes input/feature vectors of length 43, has 25 nodes in the hidden layer (arbitrary parameter choice I can change), and has a single output node. I want to train my network to take the 43 features and output a single value between 0 and 100. 

Unfortunately, I currently only have a very small pool or training data - 162 sets of feature vectors with corresponding scores out of 100 (I have to manually label this lol! Working on creating more data though obviously). So I take this limited training set, and here's a snapshot of how well my network adapts to it:

Output value:0.90406 | Test value:0.9 (pretend to multiply all values by 100)

Output value:0.21558 | Test value:0.2 

Output value:0.60394 | Test value:0.6

Output value:0.79604 | Test value:0.8

Output value:0.99846 | Test value:0.85

Output value:0.23444 | Test value:0.2

Output value:0.19609 | Test value:0.2

Output value:0.88889 | Test value:0.9

Output value:0.19178 | Test value:0.2

Output value:0.20549 | Test value:0.2

Output value:0.63248 | Test value:0.64

Output value:0.74367 | Test value:0.74

Output value:0.15477 | Test value:0.17

Output value:0.17084 | Test value:0.18

Output value:0.21143 | Test value:0.19

Output value:0.16179 | Test value:0.17

Output value:0.081413 | Test value:0.18

Output value:0.18287 | Test value:0.19

Output value:0.19118 | Test value:0.17

Output value:0.20018 | Test value:0.18

Output value:0.19222 | Test value:0.19

Output value:0.20719 | Test value:0.2

Output value:0.18718 | Test value:0.2

Output value:0.18064 | Test value:0.2

Output value:0.20925 | Test value:0.2

Output value:0.20731 | Test value:0.2

Output value:0.19914 | Test value:0.2

Output value:0.6033 | Test value:0.6

Output value:0.63723 | Test value:0.64

Output value:0.77831 | Test value:0.78

Output value:0.23468 | Test value:0.2

Output value:0.87713 | Test value:0.9

Output value:0.23822 | Test value:0.2

Output value:0.18954 | Test value:0.15

Output value:0.19912 | Test value:0.2

At first I'm like, ""wow this is sick!"" The results are much, much better than when I originally tried gradient descent on its own. Like, this is too good to be true. Hmm, maybe it is. So I decide to try something - use the same test/target values, but create 162 completely *random* feature vectors. 

Uh oh - my network was able to fit the random training data *even better* than my actual training data! In fact, it fit the random data perfectly. Shit:

Output value:0.92 | Test value:0.92

Output value:0.2 | Test value:0.2

Output value:0.2 | Test value:0.2

Output value:0.2 | Test value:0.2

Output value:0.2 | Test value:0.2

Output value:0.2 | Test value:0.2

Output value:0.2 | Test value:0.2

Output value:0.2 | Test value:0.2

Output value:0.2 | Test value:0.2

Output value:0.2 | Test value:0.2

Output value:0.62 | Test value:0.62

Output value:0.7 | Test value:0.7

Output value:0.77 | Test value:0.77

Now I'm thinking one of two possibilities:

1) Because I have so few training samples (only 162), my 3-layer network of 43-&gt;25-&gt;1 is able to over-fit the data with all its weights. 

2) My original feature vectors are absolutely worthless, and just as good as inputting plain garbage. These feature vectors I hand-coded based on what I researched would be appropriate to my problem domain. 

What do you guys think is going on, and will I only know once I have more training data? Given the topology of my network, any idea how much data I'll actually need? 

Cheers.
",,False,self,t5_2r3gv,False,,,True,t3_191hbc,http://www.reddit.com/r/MachineLearning/comments/191hbc/backpropagation_how_much_training_data_do_i_need/,
1359565712.0,14,arxiv.org,17kij1,Dense cohort of terms: An alternative text representation to TF-IDF and Bag-of-Words,16,2,2,http://www.reddit.com/r/MachineLearning/comments/17kij1/dense_cohort_of_terms_an_alternative_text/,,,False,default,t5_2r3gv,False,,,False,t3_17kij1,http://arxiv.org/abs/1301.6770,
1358049633.0,13,self.MachineLearning,16h3da,Proposed Machine Learning Q&amp;A Site,26,13,5,http://www.reddit.com/r/MachineLearning/comments/16h3da/proposed_machine_learning_qa_site/,"Here's a proposed machine learning [Q&amp;A site](http://area51.stackexchange.com/proposals/41738/machine-learning) that's part of the stackexchange network. It's looking for support to get up and running, so join it [here!](http://area51.stackexchange.com/proposals/41738/machine-learning?referrer=rDdBBwSG51Ho2c1h6tMvDQ2)",,False,self,t5_2r3gv,False,,,True,t3_16h3da,http://www.reddit.com/r/MachineLearning/comments/16h3da/proposed_machine_learning_qa_site/,
1354203094.0,12,self.MachineLearning,13zvxe,"IP law and machine learning, who owns the model?",19,7,27,http://www.reddit.com/r/MachineLearning/comments/13zvxe/ip_law_and_machine_learning_who_owns_the_model/,"Does anyone know how IP law works generally with respect to models produced using so called private data?  

Specifically, I'm referring to the case where someone uses private data to derive a model. 

Can the 'owner' of the data claim ownership of the model, even though the model may represent a domain far more generic than the privately owned data?  

(Let me know if this should be posted elsewhere... just thought you folks might have a bead on what the current view of this is.)
  ",,False,self,t5_2r3gv,False,,,True,t3_13zvxe,http://www.reddit.com/r/MachineLearning/comments/13zvxe/ip_law_and_machine_learning_who_owns_the_model/,
1349062800.0,14,self.MachineLearning,10qt8q,Looking for an approachable explanation of Variational Bayes,14,0,8,http://www.reddit.com/r/MachineLearning/comments/10qt8q/looking_for_an_approachable_explanation_of/,"Hi all, 

I am looking for an intuitive explanation of variational bayes. Does anyone know of an accessible tutorial or a video of someone who explains variational bayes as clearly as Andrew Ng?

Thanks in advance :)",,False,self,t5_2r3gv,False,,,True,t3_10qt8q,http://www.reddit.com/r/MachineLearning/comments/10qt8q/looking_for_an_approachable_explanation_of/,
1348591500.0,13,stonetemple.com,10ggxx,A mathematical model for accessing web page quality,17,4,0,http://www.reddit.com/r/MachineLearning/comments/10ggxx/a_mathematical_model_for_accessing_web_page/,,,False,http://d.thumbs.redditmedia.com/HPbiY7jNpvSY4ONK.jpg,t5_2r3gv,False,,,False,t3_10ggxx,http://www.stonetemple.com/a-mathematical-model-for-assessing-page-quality/,
1348252104.0,12,gigaom.com,109dbg,"Forget your fancy data science, try overkill analytics",20,8,6,http://www.reddit.com/r/MachineLearning/comments/109dbg/forget_your_fancy_data_science_try_overkill/,,,False,http://b.thumbs.redditmedia.com/-RrXpZmjn9MTC-nO.jpg,t5_2r3gv,False,,,False,t3_109dbg,http://gigaom.com/data/forget-your-fancy-data-science-try-overkill-analytics/,
1345518182.0,12,thenoisychannel.com,yk7am,"WTF @ k, measuring ineffectiveness in search and recommendation systems",16,4,3,http://www.reddit.com/r/MachineLearning/comments/yk7am/wtf_k_measuring_ineffectiveness_in_search_and/,,,False,http://a.thumbs.redditmedia.com/AjpZ9ShD-PHh_2G6.jpg,t5_2r3gv,False,,,False,t3_yk7am,http://thenoisychannel.com/2012/08/20/wtf-k-measuring-ineffectiveness/,
1342643063.0,13,ufldl.stanford.edu,ws18o,"Stanford's UFLDL tutorial seams to be down, so if anyone knows anyone who could get it back up, please, let them know the Internet is missing their wonderful site",17,4,7,http://www.reddit.com/r/MachineLearning/comments/ws18o/stanfords_ufldl_tutorial_seams_to_be_down_so_if/,,,False,default,t5_2r3gv,False,,,False,t3_ws18o,http://ufldl.stanford.edu/wiki/index.php/UFLDL_Tutorial,
1341871584.0,14,self.MachineLearning,wal0c,"Can anyone give an intuitive explanation of when a classifier would give below-chance classification results i.e. ""anti-learning"" as I've heard it called?",15,1,11,http://www.reddit.com/r/MachineLearning/comments/wal0c/can_anyone_give_an_intuitive_explanation_of_when/,"By working, I mean that there isn't some issue with the data being labelled wrong or that there is insufficient data, etc.",,False,self,t5_2r3gv,False,,,True,t3_wal0c,http://www.reddit.com/r/MachineLearning/comments/wal0c/can_anyone_give_an_intuitive_explanation_of_when/,
1341421805.0,13,self.MachineLearning,w1du3,Is there a search engine over Artificial Intelligence and Machine Learning -related sites?,19,6,2,http://www.reddit.com/r/MachineLearning/comments/w1du3/is_there_a_search_engine_over_artificial/,"Sometimes it is necessary to dig into Artificial Intelligence or specifically Machine Learning problems to make a research. Common googling (in my own experience) usually doesn't help much due to a lot of non relevant or paid materials in SERP. Google Scholar at the contrast is limited to scientific publications only, sometimes it is too narrow.

I wonder, if there is a kind of dedicated search engine over AI &amp; ML -related sites?

Thanks!",,False,self,t5_2r3gv,False,,,True,t3_w1du3,http://www.reddit.com/r/MachineLearning/comments/w1du3/is_there_a_search_engine_over_artificial/,
1334949398.0,13,blog.getprismatic.com,sk5jk,How Prismatic clusters related stories,14,1,1,http://www.reddit.com/r/MachineLearning/comments/sk5jk/how_prismatic_clusters_related_stories/,,,False,default,t5_2r3gv,False,,,False,t3_sk5jk,http://blog.getprismatic.com/blog/2012/4/17/clustering-related-stories.html,
1334331595.0,12,self.MachineLearning,s81mg,Could anybody explain Boltzmann Machines to me?,14,2,12,http://www.reddit.com/r/MachineLearning/comments/s81mg/could_anybody_explain_boltzmann_machines_to_me/,"I have to implement a single layer (no hidden units) Boltzmann Machine for a class. I have an implementation done, but I'm not sure it's working correctly.

I'll describe what I've done and hopefully somone can point out if I've made any mistakes.

* The BM machine model is a set of binary units in which each unit is connected to every other unit via a weighted connection.

* First, we train the machine on a training set of examples to determine the weights of the connections.

* This learning phase can be divided into two parts - one is the empirical correlation between the units of the examples in the training set and one is the correlation between these units according to some probability model.

* At the end of learning, the probability correlation is subtracted from the empirical correlation and the resulting correlation is the weights for our BM.

* We can then set our neurons to an input and run the activation model on them to recieve an output.

I realise as I type this that my understanding of the topic is really very fuzzy. Here's a few questions : 

Having trained the machine on a set of examples, what should be the output when providing it with one of those examples as input? Will you always recieve that example back or will you occasionally get one of the other examples or even nonsense patterns?

I've found several RBM implementations online. How does a Restricted Boltzmann Machine differ from one with no hidden units? I'd like to be able to edit a RBM into what I've described so that I can make sure my implementation works the way it should.
",,False,self,t5_2r3gv,False,,,True,t3_s81mg,http://www.reddit.com/r/MachineLearning/comments/s81mg/could_anybody_explain_boltzmann_machines_to_me/,
1333678882.0,14,self.MachineLearning,rvnvx,What do you guys think of Northwestn's Master of Science in Predictive Analytics?,15,1,14,http://www.reddit.com/r/MachineLearning/comments/rvnvx/what_do_you_guys_think_of_northwestns_master_of/,"I am currently enrolled in [Data Mining Certificate - UC San Diego Extension](http://extension.ucsd.edu/programs/index.cfm?vaction=certdetail&amp;vcertificateid=128&amp;vstudyareaid=14) and want to get more out of this subject than a certificate. I came across Northwestern's [Master of Science in Predictive Analytics](http://www.scs.northwestern.edu/grad/mspa/) and think I would enjoy it. Anyone enrolled in it or know anything about it?

*Just noticed I misspelled Northwestern",,False,self,t5_2r3gv,True,,,True,t3_rvnvx,http://www.reddit.com/r/MachineLearning/comments/rvnvx/what_do_you_guys_think_of_northwestns_master_of/,
1333464886.0,12,self.MachineLearning,rr8g0,Model Selection vs. Parameter Estimation vs. Optimization,14,2,8,http://www.reddit.com/r/MachineLearning/comments/rr8g0/model_selection_vs_parameter_estimation_vs/,"In the context of machine learning what is the difference between the terms models selection, parameter estimation and optimization. I don't think the terms are interchangeable, especially in machine learning. ",,False,self,t5_2r3gv,False,,,True,t3_rr8g0,http://www.reddit.com/r/MachineLearning/comments/rr8g0/model_selection_vs_parameter_estimation_vs/,
1333437184.0,13,videolectures.net,rqw4j,Optimization Algorithms in Machine Learning,13,0,1,http://www.reddit.com/r/MachineLearning/comments/rqw4j/optimization_algorithms_in_machine_learning/,,,False,default,t5_2r3gv,False,,,False,t3_rqw4j,http://videolectures.net/nips2010_wright_oaml/,
1330352483.0,12,self.MachineLearning,q83um,Best way to get Reuters and stock data?,16,4,14,http://www.reddit.com/r/MachineLearning/comments/q83um/best_way_to_get_reuters_and_stock_data/,I saw someone mention good tools for pulling down timely stock and news information but I can't seem to find the post.  Does anyone have any advice for this?,,False,self,t5_2r3gv,False,,,True,t3_q83um,http://www.reddit.com/r/MachineLearning/comments/q83um/best_way_to_get_reuters_and_stock_data/,
1325107298.0,12,self.MachineLearning,nu1kt,Has anyone used Microsoft's data mining tools?,19,7,12,http://www.reddit.com/r/MachineLearning/comments/nu1kt/has_anyone_used_microsofts_data_mining_tools/,"SQL Server ships with Analysis services. Within AS there's algorithms for dtrees, clustering, NB, regressions and more. It also looks like there's plugins for SVMs and parallelization. Does anyone have experience with this? Are there any resources for learning to use AS that you'd recommend? I'm somewhat hopeful about it, as SQL Server is quite good. ",,False,self,t5_2r3gv,False,,,True,t3_nu1kt,http://www.reddit.com/r/MachineLearning/comments/nu1kt/has_anyone_used_microsofts_data_mining_tools/,
1324043780.0,15,self.MachineLearning,nf5mv,Suggestions for Quickly Coming Up to Speed in Math for Machine Learning,20,5,16,http://www.reddit.com/r/MachineLearning/comments/nf5mv/suggestions_for_quickly_coming_up_to_speed_in/,"Hi r/MachineLearning,
I know there's lots of resources about what to learn, and they are really great.  If anything I have an embarrassment of riches and I am looking to prioritize.  The background is that I got accepted into a graduate certificate program in Data Mining that covers a lot of Machine Learning topics, and I am trying to make sure my math is up to speed.  I've got about a month before classes start and I'm trying to spend it on building math skills.  So I never had Linear Algebra so I am focusing on that and I am also planning to get in an overview of Probability Theory.  If I have extra time over the holidays (ha), I'm going to work on the rest of Statistics.  Is this the priority you guys would follow?  Is there another subject that I absolutely need to digest to hit the ground running?  I am obviously planning to continue to work to back fill my math as I get time, but looking to plan this initial flurry of activity 

EDIT: Thanks everyone for the great suggestions!",,False,self,t5_2r3gv,True,,,True,t3_nf5mv,http://www.reddit.com/r/MachineLearning/comments/nf5mv/suggestions_for_quickly_coming_up_to_speed_in/,
1321602571.0,15,self.MachineLearning,mgpz9,ML for making code recommendations (people that called X also called Y),18,3,0,http://www.reddit.com/r/MachineLearning/comments/mgpz9/ml_for_making_code_recommendations_people_that/,Interesting research project at http://eclipse.org/recommenders that leverages static analysis and ML to create nice tools around it in the Eclipse IDE.,,False,self,t5_2r3gv,False,,,True,t3_mgpz9,http://www.reddit.com/r/MachineLearning/comments/mgpz9/ml_for_making_code_recommendations_people_that/,
1320310722.0,15,r-bloggers.com,lysuj,"The next generation of parallel R
",17,2,0,http://www.reddit.com/r/MachineLearning/comments/lysuj/the_next_generation_of_parallel_r/,,,False,http://b.thumbs.redditmedia.com/gsXk_U02Dg4HG_5C.jpg,t5_2r3gv,False,,,False,t3_lysuj,http://www.r-bloggers.com/the-next-generation-of-parallel-r/,
1320074283.0,11,informationarbitrage.com,lv81n,Data is the new .com,19,8,4,http://www.reddit.com/r/MachineLearning/comments/lv81n/data_is_the_new_com/,,,False,default,t5_2r3gv,False,,,False,t3_lv81n,http://informationarbitrage.com/post/12160961604/data-is-the-new-com,
1319245340.0,14,izbicki.me,lkkdy,Data Mining Images Tutorial - Pt 1,20,6,2,http://www.reddit.com/r/MachineLearning/comments/lkkdy/data_mining_images_tutorial_pt_1/,,,False,http://thumbs.reddit.com/t3_lkkdy.png,t5_2r3gv,False,,,False,t3_lkkdy,http://izbicki.me/blog/data-mining-images-tutorial,
1318426631.0,12,self.MachineLearning,l9j0e,"Ask r/ml: I am extracting ngrams from my dataset, how should I store them efficently?",14,2,13,http://www.reddit.com/r/MachineLearning/comments/l9j0e/ask_rml_i_am_extracting_ngrams_from_my_dataset/,"I am extracting 4-grams from binary items in hexadecimal form, this mean I can have at most 65535 different grams per item. I want to associate every item to it's grams and their frequency but I am puzzled on how to store everything – this is my first data mining experience and I don't have any clue about best practices and common tools :|

I was trivially thinking to build a big table in a relational database with a schema like (ITEM, GRAM1, GRAM2... GRAM65535) and store inside it the frequencies but I can see this approach is uber impratical because of the number of columns. 

I know there must be better solutions out there but I don't know where to look at.

Suggestions? ",,False,self,t5_2r3gv,False,,,True,t3_l9j0e,http://www.reddit.com/r/MachineLearning/comments/l9j0e/ask_rml_i_am_extracting_ngrams_from_my_dataset/,
1318052625.0,11,economist.com,l4wiy,Mining Twitter,20,9,0,http://www.reddit.com/r/MachineLearning/comments/l4wiy/mining_twitter/,,,False,http://thumbs.reddit.com/t3_l4wiy.png,t5_2r3gv,False,,,False,t3_l4wiy,http://www.economist.com/node/21531025,
1317833352.0,13,self.MachineLearning,l1v7v,"What do you guys think of the Siri demo, professionally?",18,5,24,http://www.reddit.com/r/MachineLearning/comments/l1v7v/what_do_you_guys_think_of_the_siri_demo/,"from what I saw the NLP was pretty good, but I did not see signs of deep intelligence that CALO project suggested. Also, having Siri serve up WolframAlpha is a cheat :) (but kudos to Wolfram for putting his logo on every answer)",,False,self,t5_2r3gv,False,,,True,t3_l1v7v,http://www.reddit.com/r/MachineLearning/comments/l1v7v/what_do_you_guys_think_of_the_siri_demo/,
1316699652.0,12,moderntoolmaking.blogspot.com,knw67,Scraping web data in R,15,3,11,http://www.reddit.com/r/MachineLearning/comments/knw67/scraping_web_data_in_r/,,,False,default,t5_2r3gv,False,,,False,t3_knw67,http://moderntoolmaking.blogspot.com/2011/08/scraping-web-data-in-r.html,
1315391657.0,13,r-bloggers.com,k7gdg,Webinar: Leveraging R in Hadoop Environments,14,1,0,http://www.reddit.com/r/MachineLearning/comments/k7gdg/webinar_leveraging_r_in_hadoop_environments/,,,False,default,t5_2r3gv,False,,,False,t3_k7gdg,http://www.r-bloggers.com/webinar-leveraging-r-in-hadoop-environments/,
1313773804.0,14,forbes.com,jo13t,Groupon Explains Why It Wants To Constantly Track Customers' Whereabouts - Forbes,16,2,2,http://www.reddit.com/r/MachineLearning/comments/jo13t/groupon_explains_why_it_wants_to_constantly_track/,,,False,default,t5_2r3gv,False,,,False,t3_jo13t,http://www.forbes.com/sites/kashmirhill/2011/08/19/groupon-explains-why-it-wants-to-track-users-locations-on-their-phones/,
1310308865.0,13,self.MachineLearning,illz6,"Bias/Variance, Exploration/Exploitation, Stability/Flexibility: What other tradeoffs need to be managed by a machine learner?",15,2,13,http://www.reddit.com/r/MachineLearning/comments/illz6/biasvariance_explorationexploitation/,"""Tradeoffs"" that have to be managed by machine learners, or their programmers, such as the bias variance tradeoff, the exploration exploitation dilemma (i.e., whether to attempt to maximize performance by exploiting currently-known feature sets or, more generally, some aspect of the environment, or whether to seek out new feature sets in pursuit of even greater performance), and the stability flexibility dilemma (how much to let individual experiences warp knowledge, in an attempt to capture details of that experience, with detrimental effects on the stability and generality of knowledge), have been a real inspiration to those of us working in neuroscience.

If a machine learner is subject to these tradeoffs, the brain likely is too, and may have evolved a particular mechanism for managing it.  (I can go into more detail on this if anyone is curious.)

My question: Are there other tradeoffs, whether formally recognized or not, that you confront, or your learners confront?  

I'm also not sure I fully grok the bias/variance tradeoff; any intuitive explanations would be most welcome.  Thanks all.",,False,self,t5_2r3gv,False,,,True,t3_illz6,http://www.reddit.com/r/MachineLearning/comments/illz6/biasvariance_explorationexploitation/,
1307367497.0,13,alexbraunstein.com,hstyh,Why your Klout score is meaningless,22,9,0,http://www.reddit.com/r/MachineLearning/comments/hstyh/why_your_klout_score_is_meaningless/,,,False,http://thumbs.reddit.com/t3_hstyh.png,t5_2r3gv,False,,,False,t3_hstyh,http://alexbraunstein.com/2011/06/01/why-your-klout-score-is-meaningless/,
1305410285.0,13,self.MachineLearning,hbh91,Machine Learning Headstart?,16,3,22,http://www.reddit.com/r/MachineLearning/comments/hbh91/machine_learning_headstart/,"Hello, I still have a few years to go before I begin university but I'm already 110% sure that I definitely want to go into Machine Learning. I've been reading up and down and researching all around and I've gotten basic ideas on where to go from here but I'm a bit confused on where to actually begin. I managed to get my hands on three books in particular:

* *An Investigation of The Laws of Thought* by George Boole
* *Introduction to the Theory of Computation* by Michael Sipser
* *Set Theory And Logic* by Robert R. Stoll

And while I can understand them and am thrilled when reading them, I feel I won't get anywhere near their full value until I've got a much stronger foundation. That said, I've narrowed my first full step down to two fields, Mathematics in the way of Statistics &amp; Probability and Linear Algebra, and First-Order Logic in the way of Predicate Calculus and Boolean Algebra, but I can't decide which to go with first. Aside from this, any other tips at all would be awesome.",,False,self,t5_2r3gv,False,,,True,t3_hbh91,http://www.reddit.com/r/MachineLearning/comments/hbh91/machine_learning_headstart/,
1305218261.0,13,overstockreclabprize.com,h9vfg,"Product recommendations competition. Maximum Prize: $1,000,000",14,1,6,http://www.reddit.com/r/MachineLearning/comments/h9vfg/product_recommendations_competition_maximum_prize/,,,False,default,t5_2r3gv,False,,,False,t3_h9vfg,http://overstockreclabprize.com/overview,
1303528459.0,14,igvita.com,gvhyw,Using zlib as a similarity metric,17,3,6,http://www.reddit.com/r/MachineLearning/comments/gvhyw/using_zlib_as_a_similarity_metric/,,,False,http://thumbs.reddit.com/t3_gvhyw.png,t5_2r3gv,False,,,False,t3_gvhyw,http://www.igvita.com/2011/04/20/intuition-data-driven-machine-learning/,
1303160022.0,13,drewconway.com,gt1di,EC2 AMI for scientific computing in Python and R,16,3,5,http://www.reddit.com/r/MachineLearning/comments/gt1di/ec2_ami_for_scientific_computing_in_python_and_r/,,,False,http://thumbs.reddit.com/t3_gt1di.png,t5_2r3gv,False,,,False,t3_gt1di,http://www.drewconway.com/zia/?p=2701,
1302536578.0,13,r-bloggers.com,gngh1,"RStudio Beta 2 (v0.93)
",15,2,0,http://www.reddit.com/r/MachineLearning/comments/gngh1/rstudio_beta_2_v093/,,,False,http://thumbs.reddit.com/t3_gngh1.png,t5_2r3gv,False,,,False,t3_gngh1,http://www.r-bloggers.com/rstudio-beta-2-v0-93/,
1300899137.0,14,jmlr.csail.mit.edu,g9tfx,JMLR | Journal of Machine Learning Research,25,11,12,http://www.reddit.com/r/MachineLearning/comments/g9tfx/jmlr_journal_of_machine_learning_research/,,,False,default,t5_2r3gv,False,,,False,t3_g9tfx,http://jmlr.csail.mit.edu/,
1300025390.0,12,self.MachineLearning,g33pi,An idea for a platform where people can play the Turing game and chat bot developers can gather data and compete.,17,5,8,http://www.reddit.com/r/MachineLearning/comments/g33pi/an_idea_for_a_platform_where_people_can_play_the/,"While discussing with nadie854 on his [reserbot](http://www.reddit.com/r/MachineLearning/comments/f3uvz/a_chatterbot_built_using_a_neural_networks/) I had an idea for a platform where people can play the Turing game and people can submit bots that participate in the Turing game. The key Idea is that data is gathered by the conversations. This data can be used to train bots. Another strength is that the chatter bots stand in competition and can be tested.

The data-gathering idea is already there in [cleverbot](http://cleverbot.com/). But there is a key difference in this approach. In the original [Turing game](http://cogprints.org/499/1/turing.html) there is a human interrogator C, a Human A and a bot B. The interrogator tries to find out if A or B is the bot. Therefore, there are conversations between C and B, i.e. humans that can be used as training data. Imagine this on a large scale where many people play this game, as in google image labeler. This would bring a lot of good data with conversations that aim at the identification of chatbots. This data can then be used to further train chatbots. 

Further the idea is not to train a single bot, but to provide a platform for chatbot developers. The bots can stand in competition, as it is already established in the research community (for example the [Loebner prize](http://www.google.com/url?sa=t&amp;source=web&amp;cd=1&amp;sqi=2&amp;ved=0CBcQFjAA&amp;url=http%3A%2F%2Fwww.loebner.net%2FPrizef%2Floebner-prize.html&amp;rct=j&amp;q=turing%20test%20competition&amp;ei=ZMd8TY6uLsbGswaNxsHbBw&amp;usg=AFQjCNGNmtOxBD5jb1UYDbd4Mp53MOKWyA&amp;cad=rja)). The incentive for developers to use this platform would be the possibility to gather data.

I think this idea has quite a potential, if advertised in the AI-community. It is appealing to the general public as a game and appealing for developers as data-source and competition. As I won't have the time to implement this idea I wanted to share it here. ",,False,self,t5_2r3gv,False,,,True,t3_g33pi,http://www.reddit.com/r/MachineLearning/comments/g33pi/an_idea_for_a_platform_where_people_can_play_the/,
1297938654.0,14,slate.com,fn4bc,Is Google's Public Data Explorer the first step toward a universal data format?,15,1,0,http://www.reddit.com/r/MachineLearning/comments/fn4bc/is_googles_public_data_explorer_the_first_step/,,,False,http://thumbs.reddit.com/t3_fn4bc.png,t5_2r3gv,False,,,False,t3_fn4bc,http://www.slate.com/id/2285354/,
1297769261.0,13,youtube.com,flrpp,Human vs Machine IBM Challenge Day 1,13,0,4,http://www.reddit.com/r/MachineLearning/comments/flrpp/human_vs_machine_ibm_challenge_day_1/,,,False,http://thumbs.reddit.com/t3_flrpp.png,t5_2r3gv,False,,,False,t3_flrpp,http://www.youtube.com/watch?v=BfNBWJTGEEA,
1296754934.0,12,mallet.cs.umass.edu,fembb,"Mallet - Java-based package for NLP, document classification, clustering, topic modeling, information extraction, and other ML applications to text.",16,4,2,http://www.reddit.com/r/MachineLearning/comments/fembb/mallet_javabased_package_for_nlp_document/,,,False,default,t5_2r3gv,False,,,False,t3_fembb,http://mallet.cs.umass.edu/,
1296707397.0,12,youtube.com,fea60,Strata2011 Conference Videos on YouTube,13,1,0,http://www.reddit.com/r/MachineLearning/comments/fea60/strata2011_conference_videos_on_youtube/,,,False,http://thumbs.reddit.com/t3_fea60.png,t5_2r3gv,False,,,False,t3_fea60,http://www.youtube.com/user/OreillyMedia#grid/user/EF277D84FE2A28D5,
1294057664.0,13,self.MachineLearning,evdxb,What are your thoughts on Google prediction API?,16,3,18,http://www.reddit.com/r/MachineLearning/comments/evdxb/what_are_your_thoughts_on_google_prediction_api/,"I find the entire training process too opaque. (Perhaps because I haven't looked at the advanced features?)
What's the training algorithm they use? Is it neural networking or SVM or whatever?

Also, given the already innumerable open source alternatives like R, RapidMiner &amp; Weka I don't see any reason (except CPU horsepower) why I should start using this API.",,False,self,t5_2r3gv,True,,,True,t3_evdxb,http://www.reddit.com/r/MachineLearning/comments/evdxb/what_are_your_thoughts_on_google_prediction_api/,
1287546127.0,13,self.MachineLearning,dtnw5,Can someone help me understand boosting?,15,2,16,http://www.reddit.com/r/MachineLearning/comments/dtnw5/can_someone_help_me_understand_boosting/,"In particular AdaBoost, any papers accessible to an engineer but non-ML specialized one would be useful.  I'm particularly interested in how it can be used to combine many different weak classifiers into a stronger one.",,False,self,t5_2r3gv,False,,,True,t3_dtnw5,http://www.reddit.com/r/MachineLearning/comments/dtnw5/can_someone_help_me_understand_boosting/,
1287427235.0,13,r-bloggers.com,dsxb3,Generating graphs of Twitter using R and Gephi (retweets and @-messages) ,13,0,2,http://www.reddit.com/r/MachineLearning/comments/dsxb3/generating_graphs_of_twitter_using_r_and_gephi/,,,False,http://thumbs.reddit.com/t3_dsxb3.png,t5_2r3gv,False,,,False,t3_dsxb3,http://www.r-bloggers.com/generating-graphs-of-retweets-and-messages-on-twitter-using-r-and-gephi/,
1286144001.0,13,self.MachineLearning,dmci2,How good is the Cross Entropy Method for large-scale optimization?,13,0,1,http://www.reddit.com/r/MachineLearning/comments/dmci2/how_good_is_the_cross_entropy_method_for/,"Has anyone used the [Cross Entropy Method](http://en.wikipedia.org/wiki/Cross-entropy_method) to estimate the parameters of very large models? I'm curious how it performs when compared with more common techniques like stochastic gradient descent, coordinate descent, and algorithm-specific optimizations like SMO. Does it have the same wandering/slow convergence rate as evolutionary and annealing algorithms? ",,False,self,t5_2r3gv,False,,,True,t3_dmci2,http://www.reddit.com/r/MachineLearning/comments/dmci2/how_good_is_the_cross_entropy_method_for/,
1285448260.0,13,self.MachineLearning,diux0,best resource to learn wavelet transforms?,13,0,8,http://www.reddit.com/r/MachineLearning/comments/diux0/best_resource_to_learn_wavelet_transforms/,Im studying EEG for my PhD. What is the best resource out there for wavelets?,,False,self,t5_2r3gv,False,,,True,t3_diux0,http://www.reddit.com/r/MachineLearning/comments/diux0/best_resource_to_learn_wavelet_transforms/,
1281439889.0,14,kaggle.com,czg6s,How Chris Raimondi won the Predict HIV Progression data mining competition,15,1,2,http://www.reddit.com/r/MachineLearning/comments/czg6s/how_chris_raimondi_won_the_predict_hiv/,,,False,http://thumbs.reddit.com/t3_czg6s.png,t5_2r3gv,False,,,False,t3_czg6s,http://kaggle.com/blog/2010/08/09/how-i-won-the-hiv-progression-prediction-data-mining-competition/,
1281083043.0,14,theatlantic.com,cy1m1,Turing Test for Robot Stock Traders,16,2,1,http://www.reddit.com/r/MachineLearning/comments/cy1m1/turing_test_for_robot_stock_traders/,,,False,http://thumbs.reddit.com/t3_cy1m1.png,t5_2r3gv,False,,,False,t3_cy1m1,http://www.theatlantic.com/science/archive/2010/08/market-data-firm-spots-the-tracks-of-bizarre-robot-traders/60829/,
1278974958.0,13,mathnathan.com,cot8y,Starting off with OpenCV,22,9,3,http://www.reddit.com/r/MachineLearning/comments/cot8y/starting_off_with_opencv/,,,False,default,t5_2r3gv,False,,,False,t3_cot8y,http://mathnathan.com/2010/07/08/compiling-opencv/,
1278878437.0,13,thejit.org,coe14,JavaScript InfoVis Toolkit 2.0 released. Create Interactive Data visualization on the web.,14,1,1,http://www.reddit.com/r/MachineLearning/comments/coe14/javascript_infovis_toolkit_20_released_create/,,,False,http://thumbs.reddit.com/t3_coe14.png,t5_2r3gv,False,,,False,t3_coe14,http://thejit.org/demos,
1278542712.0,14,kaggle.com,cn274,Machine learning competitions facilitate real-time science,15,1,0,http://www.reddit.com/r/MachineLearning/comments/cn274/machine_learning_competitions_facilitate_realtime/,,,False,http://thumbs.reddit.com/t3_cn274.png,t5_2r3gv,False,,,False,t3_cn274,http://kaggle.com/blog/2010/07/07/data-modeling-competitions-a-potent-research-tool-that-facilitates-real-time-science/,
