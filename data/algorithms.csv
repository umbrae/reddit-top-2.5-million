created_utc,score,domain,id,title,ups,downs,num_comments,permalink,selftext,link_flair_text,over_18,thumbnail,subreddit_id,edited,link_flair_css_class,author_flair_css_class,is_self,name,url,distinguished
1361320022.0,63,google.com,18upxy,Mario Kart AI algorithm explained on a US Patent.,70,7,6,http://www.reddit.com/r/algorithms/comments/18upxy/mario_kart_ai_algorithm_explained_on_a_us_patent/,,,False,,t5_2qj1c,False,,,False,t3_18upxy,http://www.google.com/patents?id=aT-pAAAAEBAJ&amp;printsec=abstract&amp;zoom=4#v=onepage&amp;q&amp;f=false,
1366778135.0,43,qiao.github.io,1cznxs,"Visualize various path finding algorithms - A*, BFS, etc...",46,3,3,http://www.reddit.com/r/algorithms/comments/1cznxs/visualize_various_path_finding_algorithms_a_bfs/,,,False,,t5_2qj1c,False,,,False,t3_1cznxs,http://qiao.github.io/PathFinding.js/visual/,
1345534774.0,37,jamisbuck.org,ykkg0,"""Algorithm"" is Not a Four-Letter Word",50,13,5,http://www.reddit.com/r/algorithms/comments/ykkg0/algorithm_is_not_a_fourletter_word/,,,False,,t5_2qj1c,False,,,False,t3_ykkg0,http://www.jamisbuck.org/presentations/rubyconf2011/index.html#title-page,
1367282293.0,40,architects.dzone.com,1ddlnq,Algorithm of the Week: Generate Music Algorithmically,44,4,3,http://www.reddit.com/r/algorithms/comments/1ddlnq/algorithm_of_the_week_generate_music/,,,False,,t5_2qj1c,False,,,False,t3_1ddlnq,http://architects.dzone.com/articles/algorithm-week-generate-music,
1366485231.0,36,en.wikipedia.org,1cr8h1,Algorithm of the day: Delaunay triangulation,40,4,3,http://www.reddit.com/r/algorithms/comments/1cr8h1/algorithm_of_the_day_delaunay_triangulation/,,,False,,t5_2qj1c,False,,,False,t3_1cr8h1,http://en.wikipedia.org/wiki/Delaunay_triangulation,
1350830739.0,31,yuzhikov.com,11uf5b,Restoration of defocused and blurred images. ,38,7,4,http://www.reddit.com/r/algorithms/comments/11uf5b/restoration_of_defocused_and_blurred_images/,,,False,,t5_2qj1c,False,,,False,t3_11uf5b,http://yuzhikov.com/articles/BlurredImagesRestoration1.htm,
1366257138.0,29,en.wikipedia.org,1cl26d,Algorithm of the Day: Boruvka's Algorithm,33,4,0,http://www.reddit.com/r/algorithms/comments/1cl26d/algorithm_of_the_day_boruvkas_algorithm/,,,False,,t5_2qj1c,False,,,False,t3_1cl26d,http://en.wikipedia.org/wiki/Bor%C5%AFvka%27s_algorithm,
1375336367.0,31,youtube.com,1jh6t0,Visualization and 'audibilization' of 15 sorting algorithms,34,3,7,http://www.reddit.com/r/algorithms/comments/1jh6t0/visualization_and_audibilization_of_15_sorting/,,,False,,t5_2qj1c,False,,,False,t3_1jh6t0,http://www.youtube.com/watch?v=kPRA0W1kECg,
1368428253.0,29,keithschwarz.com,1e8dh0,"Given an array of integers of length n, where each element ranges from 0 to n - 2, inclusive give an O(n)-time, O(1)-space algorithm for finding some duplicate element.",34,5,16,http://www.reddit.com/r/algorithms/comments/1e8dh0/given_an_array_of_integers_of_length_n_where_each/,,,False,,t5_2qj1c,False,,,False,t3_1e8dh0,http://www.keithschwarz.com/interesting/code/?dir=find-duplicate,
1324872513.0,29,cg.cs.tsinghua.edu.cn,nqtay,Sketch2Photo,29,0,1,http://www.reddit.com/r/algorithms/comments/nqtay/sketch2photo/,,,False,,t5_2qj1c,False,,,False,t3_nqtay,http://cg.cs.tsinghua.edu.cn/montage/main.htm,
1358709203.0,26,self.algorithms,16xx4g,Users of Reddit: what are some techniques you use to visualize complex algorithms,30,4,5,http://www.reddit.com/r/algorithms/comments/16xx4g/users_of_reddit_what_are_some_techniques_you_use/,"Sometimes the complexity of an algorithm cannot exactly be ""tested"" with pen and paper, what are some strategies that you use to understand these complex algorithms?",,False,,t5_2qj1c,False,,,True,t3_16xx4g,http://www.reddit.com/r/algorithms/comments/16xx4g/users_of_reddit_what_are_some_techniques_you_use/,
1363490737.0,24,alienryderflex.com,1ag2qb,"A very simple point-in-polygon algorithm.  
",31,7,0,http://www.reddit.com/r/algorithms/comments/1ag2qb/a_very_simple_pointinpolygon_algorithm/,,,False,,t5_2qj1c,False,,,False,t3_1ag2qb,http://alienryderflex.com/polygon/,
1352085821.0,24,self.algorithms,12ncfr,I want to be better at solving algorithmic problems.,33,9,7,http://www.reddit.com/r/algorithms/comments/12ncfr/i_want_to_be_better_at_solving_algorithmic/,"I've just completed my third problem at InterviewStreet.com, but I realized that I haven't come up with any solutions on my own. Sure I coded them myself, but I got hints from other people. I want to reach a point where I can solve problems like this on my own.

What do you recommend? Books, blogs, etc?",,False,,t5_2qj1c,False,,,True,t3_12ncfr,http://www.reddit.com/r/algorithms/comments/12ncfr/i_want_to_be_better_at_solving_algorithmic/,
1365891062.0,23,en.wikipedia.org,1caj8j,Algorithm of the Day: Aho-Corasick string matching algorithm.(Simpler than it sounds),28,5,1,http://www.reddit.com/r/algorithms/comments/1caj8j/algorithm_of_the_day_ahocorasick_string_matching/,,,False,,t5_2qj1c,False,,,False,t3_1caj8j,http://en.wikipedia.org/wiki/Aho-Corasick,
1352218902.0,24,michaelnielsen.org,12qgvt,Why Bloom filters work the way they do,27,3,2,http://www.reddit.com/r/algorithms/comments/12qgvt/why_bloom_filters_work_the_way_they_do/,,,False,,t5_2qj1c,False,,,False,t3_12qgvt,http://www.michaelnielsen.org/ddi/why-bloom-filters-work-the-way-they-do/,
1363372262.0,22,self.algorithms,1ad3x7,Explain the Fast Fourier Transform algorithm like I'm 5,28,6,16,http://www.reddit.com/r/algorithms/comments/1ad3x7/explain_the_fast_fourier_transform_algorithm_like/,"Hey guys,


So, I'm trying to wrap my head around the FFT algorithm. My goal is to read in a coefficient vector(representing a polynomial), and transform it in O(nlg(n)) time. So far I understand what a dft is, and how to get it(in O(n^2)). As far as I can tell, the fft works because there are repeating expressions in the roots of unity for even and odd roots of unity, however when I write them out I fail to see any repeating patters. My book says that a given root of unity is: e^((2*pi*i*k) / n) for k = 0 to n-1. However on the web I've seen all these examples where they neglect the k, which makes no sense to me. My book is the third edition of introduction to algorithms in case anybody is wondering.



I sort of understand what a recursive fft does. Recursively breaks the vector into even and odd indexed coefficients(so two vectors total, one with the evens, one with the odds), until the vector lengths are 1, in which it retuns that value. I don't understand why this works, reminds me a lot of merge sort, but I can't grasp why breaking it into evens and odds works here. I don't understand the rebuild step whatsoever, where it loops from 0 up through n/2 - 1, I'm definitely going to need somebody to explain that part.



So, could somebody who understands the algorithm explain to me first why it works, and second what is happening in the recursive solution. Please explain like I'm 5, I can't stand these terse explanations on the web. The reason I want to understand it is because I need to write a recursive FFT algorithm that works for polynomials bounded by an n that is a base 3 number, rather than the traditional base 2 solution.


Thanks, if you guys need me to explain anything more just ask.",,False,,t5_2qj1c,False,,,True,t3_1ad3x7,http://www.reddit.com/r/algorithms/comments/1ad3x7/explain_the_fast_fourier_transform_algorithm_like/,
1370043777.0,22,cacr.uwaterloo.ca,1ffpcb,Handbook of applied cryptography book (free pdf),23,1,3,http://www.reddit.com/r/algorithms/comments/1ffpcb/handbook_of_applied_cryptography_book_free_pdf/,,,False,,t5_2qj1c,False,,,False,t3_1ffpcb,http://cacr.uwaterloo.ca/hac/,
1352688306.0,21,amix.dk,131isv,How would you improve Reddit's 'hot' algorithm?,24,3,3,http://www.reddit.com/r/algorithms/comments/131isv/how_would_you_improve_reddits_hot_algorithm/,,,False,,t5_2qj1c,False,,,False,t3_131isv,http://amix.dk/blog/post/19588,
1362773868.0,19,stackoverflow.com,19xiw9,Bomb dropping algorithm,25,6,1,http://www.reddit.com/r/algorithms/comments/19xiw9/bomb_dropping_algorithm/,,,False,,t5_2qj1c,False,,,False,t3_19xiw9,http://stackoverflow.com/q/15300149/1288,
1335314257.0,20,coursera.org,sqwkp,Princeton offering two open courses on Algorithms starting September,22,2,3,http://www.reddit.com/r/algorithms/comments/sqwkp/princeton_offering_two_open_courses_on_algorithms/,,,False,,t5_2qj1c,False,,,False,t3_sqwkp,https://www.coursera.org/course/algs4partI,
1371455652.0,20,cstheory.stackexchange.com,1gi611,The Book,21,1,0,http://www.reddit.com/r/algorithms/comments/1gi611/the_book/,,,False,,t5_2qj1c,False,,,False,t3_1gi611,http://cstheory.stackexchange.com/questions/189/algorithms-from-the-book,
1365708570.0,20,en.wikipedia.org,1c5kqq,Algorithm of the day: Heapsort,28,8,4,http://www.reddit.com/r/algorithms/comments/1c5kqq/algorithm_of_the_day_heapsort/,,,False,,t5_2qj1c,False,,,False,t3_1c5kqq,http://en.wikipedia.org/wiki/Heap_sort,
1364449987.0,17,self.algorithms,1b5vs5,"BFS, DFS, and Prims graphing visualizer",23,6,1,http://www.reddit.com/r/algorithms/comments/1b5vs5/bfs_dfs_and_prims_graphing_visualizer/,[A JavaScript based graphing visualizer](http://rafilabs.com/graphingSims/graphs.html) I built for my Algorithms class. Figured I'd share with Reddit. Enjoy!,,False,,t5_2qj1c,False,,,True,t3_1b5vs5,http://www.reddit.com/r/algorithms/comments/1b5vs5/bfs_dfs_and_prims_graphing_visualizer/,
1359891858.0,19,infocobuild.com,17sxwl,Introduction to Algorithms (MIT OCW) - It provides an introduction to mathematical modeling of computational problems.,21,2,2,http://www.reddit.com/r/algorithms/comments/17sxwl/introduction_to_algorithms_mit_ocw_it_provides_an/,,,False,,t5_2qj1c,False,,,False,t3_17sxwl,http://www.infocobuild.com/education/audio-video-courses/computer-science/6-006-fall2011-mitocw.html,
1350597890.0,19,self.algorithms,11pp5m,Self taught programmer looking for a book on algorithms,20,1,27,http://www.reddit.com/r/algorithms/comments/11pp5m/self_taught_programmer_looking_for_a_book_on/,"To make a long story short, I am a self taught computer programmer. I was just made aware that there is an entire field of algorithms that are taught in computer science courses that i never even knew existed. I looked on amazon and found tons of books on this subject. Can anyone recommend any good books on algorithms. I have been programming on my own for a few years I've just never used any official algorithms.

edit: Wow, thanks guys. A ton of great suggestions. I just ordered a few of the books recommended and signed up for one of the courses. If I have more questions, and I'm sure that I will, I'll be sure to come back here. Thanks a lot.",,False,,t5_2qj1c,1350655952.0,,,True,t3_11pp5m,http://www.reddit.com/r/algorithms/comments/11pp5m/self_taught_programmer_looking_for_a_book_on/,
1348345368.0,18,chrisp.gr,10b890,HTML5 Bird Flocks Simulation using KD-trees and binary heaps.,24,6,0,http://www.reddit.com/r/algorithms/comments/10b890/html5_bird_flocks_simulation_using_kdtrees_and/,,,False,,t5_2qj1c,False,,,False,t3_10b890,http://chrisp.gr/projects/boids/,
1359186975.0,18,facebook.com,17b2ql,Facebook Hacker Cup has started!,21,3,0,http://www.reddit.com/r/algorithms/comments/17b2ql/facebook_hacker_cup_has_started/,,,False,,t5_2qj1c,False,,,False,t3_17b2ql,https://www.facebook.com/hackercup/,
1357821688.0,17,syprog.blogspot.ru,16b7lf,Simple example of the Genetic Algorithm implementation,19,2,7,http://www.reddit.com/r/algorithms/comments/16b7lf/simple_example_of_the_genetic_algorithm/,,,False,,t5_2qj1c,False,,,False,t3_16b7lf,http://syprog.blogspot.ru/2013/01/genetic-algorithms-lame-example-solving.html,
1256202608.0,17,vwisb7.vkw.tu-dresden.de,9wkyn,Microsimulation of road traffic,18,1,0,http://www.reddit.com/r/algorithms/comments/9wkyn/microsimulation_of_road_traffic/,,,False,,t5_2qj1c,False,,,False,t3_9wkyn,http://vwisb7.vkw.tu-dresden.de/~treiber/MicroApplet/,
1375122829.0,16,jack.minardi.org,1jajkp,Interesting back-projection algorithm to extract 3D volume from shadows (Python),20,4,2,http://www.reddit.com/r/algorithms/comments/1jajkp/interesting_backprojection_algorithm_to_extract/,,,False,,t5_2qj1c,False,,,False,t3_1jajkp,http://jack.minardi.org/software/whats-in-a-shadow/,
1366846465.0,17,self.algorithms,1d1n8l,I have a problem and I need to find an appropriate algorithm to solve it. Where to start?,19,2,13,http://www.reddit.com/r/algorithms/comments/1d1n8l/i_have_a_problem_and_i_need_to_find_an/,"I started working on this problem recently, as part of a job hunt. I had to make an assignment for this company. I didn't make the cut, the reason they stated was that al though my code was clean and of higher quality than most submissions, the algorithm I chose to solve the problem was not a good fit for this particular problem.        

It occurred to me that my whole basic approach was wrong. When asked to make a solution, I thought of a fitting algorithm myself and made that. It would have been far better to research **existing** solutions to this **type** of problem. 

So, I have a problem I want to find a solution for, and now I want to find common solutions to this type of problem. Where do I start? Wikipedia does not help me, because it starts searching for solutions, not so much specific problems. How do I find out what type of problem I am facing?          


I guess what it boils down to is this: What do you usually do when you have to find a solution to a problem and you can not indentify problems similar to it?     ",,False,,t5_2qj1c,False,,,True,t3_1d1n8l,http://www.reddit.com/r/algorithms/comments/1d1n8l/i_have_a_problem_and_i_need_to_find_an/,
1358914451.0,18,i.imgur.com,173qhp,New to algorithms but is this a valid way to find the path that maximizes the sum of the leaves? ,21,3,32,http://www.reddit.com/r/algorithms/comments/173qhp/new_to_algorithms_but_is_this_a_valid_way_to_find/,,,False,,t5_2qj1c,False,,,False,t3_173qhp,http://i.imgur.com/0HcqPcg.png,
1358641905.0,17,stackoverflow.com,16wjek,How to pair socks from a pile efficiently?,20,3,3,http://www.reddit.com/r/algorithms/comments/16wjek/how_to_pair_socks_from_a_pile_efficiently/,,,False,,t5_2qj1c,False,,,False,t3_16wjek,http://stackoverflow.com/q/14415881/1288,
1357774209.0,17,self.algorithms,16a1vp,Data sets for standard algorithmic programming problems,20,3,6,http://www.reddit.com/r/algorithms/comments/16a1vp/data_sets_for_standard_algorithmic_programming/,"I was wondering if there is a collection of standard algorithm based programming data sets which can be used as a benchmark input data for testing algorithms (pedantically) in different programming languages? For example it might have data sets to test different sorting/searching algorithms (best case, worst case and many random cases), knapsack problems, scheduling problems, routing problems etc. Any free/wiki/course website or any other online database would be highly appreciated.",,False,,t5_2qj1c,False,,,True,t3_16a1vp,http://www.reddit.com/r/algorithms/comments/16a1vp/data_sets_for_standard_algorithmic_programming/,
1352570379.0,14,nomachetejuggling.com,12yys2,Traveling Salesman: The Most Misunderstood Problem,20,6,4,http://www.reddit.com/r/algorithms/comments/12yys2/traveling_salesman_the_most_misunderstood_problem/,,,False,,t5_2qj1c,False,,,False,t3_12yys2,http://www.nomachetejuggling.com/2012/09/14/traveling-salesman-the-most-misunderstood-problem/,
1350268027.0,15,self.algorithms,11hpyg,"""Reverse"" traveling salesman",17,2,11,http://www.reddit.com/r/algorithms/comments/11hpyg/reverse_traveling_salesman/,"I was asked the following question at an interview recently and thought you all might be interested.

Imagine we have a warehouse and a truck that can each visit exactly four houses before returning to the warehouse for more goods. We can assume we know the distance from the warehouse to each house and the distance between each of the houses (in time or actual distance or w/e). How do you optimally assign its path to reach all of the houses? What truck efficiency trade offs can we make to improve computational efficiency of the algorithm?

Similarly, suppose we have a network of employees, all trying to reach the office. How do we optimally assign car-pool groups where a group is acceptable if it doesn't more than double any members travel time?

I know I enjoyed plugging away at these. They seem like the sort of problems that would be in the literature but with different stories. If anyone could point me in the direction of some of that research I'd be grateful. ",,False,,t5_2qj1c,False,,,True,t3_11hpyg,http://www.reddit.com/r/algorithms/comments/11hpyg/reverse_traveling_salesman/,
1371182401.0,13,self.algorithms,1gbfza,Getting better at solving algorithm problems,16,3,4,http://www.reddit.com/r/algorithms/comments/1gbfza/getting_better_at_solving_algorithm_problems/,"What are things that you have done that have made you better at coming up with efficient algorithms? Does practice help you improve (doing algorithm problems from competitions (e.g topcoder))? 

Do similar approaches to problems come up frequently?


edit: I have taken an algorithms course and data structures course.

",,False,,t5_2qj1c,1371266458.0,,,True,t3_1gbfza,http://www.reddit.com/r/algorithms/comments/1gbfza/getting_better_at_solving_algorithm_problems/,
1370355031.0,14,meatfighter.com,1fnh7g,Tetris Printer Algorithm,19,5,0,http://www.reddit.com/r/algorithms/comments/1fnh7g/tetris_printer_algorithm/,,,False,,t5_2qj1c,False,,,False,t3_1fnh7g,http://meatfighter.com/tetrisprinteralgorithm/,
1368787498.0,16,self.algorithms,1eidwv,"When Log is used on Wikipedia, which base is implied?",21,5,18,http://www.reddit.com/r/algorithms/comments/1eidwv/when_log_is_used_on_wikipedia_which_base_is/,"For example, [Graham scan](http://en.wikipedia.org/wiki/Graham_scan) mentions that the time complexity for this algorithm is *n log n*. Which base is in *log* here? Is it consistent across all of wikipedia? What about other sources? Often no base is mentioned in articles on the internet.",,False,,t5_2qj1c,False,,,True,t3_1eidwv,http://www.reddit.com/r/algorithms/comments/1eidwv/when_log_is_used_on_wikipedia_which_base_is/,
1364293727.0,15,self.algorithms,1b18st,Clever Algorithms: Nature-Inspired Programming Recipes - Anybody knows similar sites or books?,18,3,3,http://www.reddit.com/r/algorithms/comments/1b18st/clever_algorithms_natureinspired_programming/,I was browsing this page http://www.cleveralgorithms.com/nature-inspired/index.html and thought it was incredibly cool. So I was wondering if anybody of you can push me to something similar.,,False,,t5_2qj1c,False,,,True,t3_1b18st,http://www.reddit.com/r/algorithms/comments/1b18st/clever_algorithms_natureinspired_programming/,
1353963594.0,14,youtube.com,13tyhc,Recursive random flood fill,17,3,8,http://www.reddit.com/r/algorithms/comments/13tyhc/recursive_random_flood_fill/,,,False,,t5_2qj1c,False,,,False,t3_13tyhc,http://www.youtube.com/watch?v=BfS7HDmVVlE&amp;feature=plcp&amp;hd=1,
1341442546.0,17,discrete.gr,w1vg9,A Gentle Introduction to Algorithm Complexity Analysis (x-post from r/programming),19,2,0,http://www.reddit.com/r/algorithms/comments/w1vg9/a_gentle_introduction_to_algorithm_complexity/,,,False,,t5_2qj1c,False,,,False,t3_w1vg9,http://discrete.gr/complexity,
1366052566.0,14,en.wikipedia.org,1cemug,Algorithm of the Day: Munkres' Assignment Algorithm. Also known as 'the Hungarian Algorithm',22,8,3,http://www.reddit.com/r/algorithms/comments/1cemug/algorithm_of_the_day_munkres_assignment_algorithm/,,,False,,t5_2qj1c,False,,,False,t3_1cemug,http://en.wikipedia.org/wiki/Munkres%27_assignment_algorithm,
1363632423.0,15,self.algorithms,1ajfb0,"Not sure how to begin this problem..
",21,6,37,http://www.reddit.com/r/algorithms/comments/1ajfb0/not_sure_how_to_begin_this_problem/,"There are a group of people that borrowed money from each other and now they want to settle their debts. They are using a service which charges per transaction, so the goal is to settle the debts with the least number of transactions overall.


Transactions can only be done between two individual people, so like (creditor, debtor, amount) would be a transaction.


The output is to find the transactions needed to settle the debts and do it with the least number of transactions.

Example:

A owes B 10

B owes C 10

C owes D 10


The optimization here would be that A pays D 10 dollars.

But remember, that many people can owe one person money. And that one person can owe many people money.

I tried think about this as a graph problem (each node is a person, directed edges are transactions) and then if the inward and outward edges values are equal, this person has net zero and doesn't need to participate in the transactions.

Actually, to be honest. I'm somewhat confused how to approach this problem. I feel like this is some sort of graph algorithm problem? Maybe something related to flow-cut problems? Would like some pointers.



",,False,,t5_2qj1c,1363663345.0,,,True,t3_1ajfb0,http://www.reddit.com/r/algorithms/comments/1ajfb0/not_sure_how_to_begin_this_problem/,
1353005613.0,14,self.algorithms,1393y2,Does anyone know a list of games and activities for teaching algorithms for kids?,17,3,4,http://www.reddit.com/r/algorithms/comments/1393y2/does_anyone_know_a_list_of_games_and_activities/,"I remember I once visited a site that had a list of games (physical games) and activities for teaching algorithms, data structures and CS concepts to kids. By any chance, does any one have any resources similar to that?",,False,,t5_2qj1c,False,,,True,t3_1393y2,http://www.reddit.com/r/algorithms/comments/1393y2/does_anyone_know_a_list_of_games_and_activities/,
1335867635.0,13,travellingsalesmanmovie.com,t1cfw,TSP - The movie ¬_¬,17,4,5,http://www.reddit.com/r/algorithms/comments/t1cfw/tsp_the_movie/,,,False,,t5_2qj1c,False,,,False,t3_t1cfw,http://www.travellingsalesmanmovie.com/,
1318646356.0,16,self.algorithms,lcs37,Looking for a good book (or some good books) on multi-threading and concurrency,16,0,2,http://www.reddit.com/r/algorithms/comments/lcs37/looking_for_a_good_book_or_some_good_books_on/,"I am not looking for a book that explains the concurrency APIs of a particular programming language, but I am looking for books that are good at one or may of the following topics:

* Theory and proof of correctness, etc.
* Low-level instruction set/architecture implementation details

Thanks in advance.",,False,,t5_2qj1c,False,,,True,t3_lcs37,http://www.reddit.com/r/algorithms/comments/lcs37/looking_for_a_good_book_or_some_good_books_on/,
1314573190.0,12,self.algorithms,jxe53,"Hey programmers, which algorithms would you say you use the most?",16,4,24,http://www.reddit.com/r/algorithms/comments/jxe53/hey_programmers_which_algorithms_would_you_say/,"Hello /r algorithms.  

Since Im both new to programming and algorithms, I'd like to get an idea of which interesting algorithms you use often at work?",,False,,t5_2qj1c,False,,,True,t3_jxe53,http://www.reddit.com/r/algorithms/comments/jxe53/hey_programmers_which_algorithms_would_you_say/,
1287561216.0,13,swtch.com,dtqmk,Regular Expression Matching Can Be Simple And Fast,15,2,2,http://www.reddit.com/r/algorithms/comments/dtqmk/regular_expression_matching_can_be_simple_and_fast/,,,False,,t5_2qj1c,False,,,False,t3_dtqmk,http://swtch.com/~rsc/regexp/regexp1.html,
1375959173.0,12,self.algorithms,1jy5ld,How to assign integers s.t. the sum of differences is minimal?,14,2,30,http://www.reddit.com/r/algorithms/comments/1jy5ld/how_to_assign_integers_st_the_sum_of_differences/,"Hi

I have a sequence of (possibly repeating) variables, for example:

    a b c d a e

I want to assign each variable a *distinct* integer (&gt;= 0) such that the sum of differences of adjacent variables (plus the first variable) is minimal. In the example, I want to minimize

    a + |b-a| + |c-b| + |d-c| + |a-d| + |e-a|

One solution to this instance would be `a=1, b=2, c=3, d=4, e=0`, turning the sequence into

     1 2 3 4 1 0

with the optimal value of 8. Assigning naively by just incrementing is not optimal and would yield `0 1 2 3 0 4` with a value of 10.

Does this problem ring a bell for anyone, i.e., can it be reduced to a known optimization problem? Does an efficient algorithm exist to either solve this or approximate it? 

The only algorithm I can come up with is trying all possible permutations of [0, 1, ..., N] (with N being the number of distinct variables), which has a horrible running time of O(N!).

Thanks for any input!",,False,,t5_2qj1c,False,,,True,t3_1jy5ld,http://www.reddit.com/r/algorithms/comments/1jy5ld/how_to_assign_integers_st_the_sum_of_differences/,
1374265731.0,14,self.algorithms,1inkt9,"Most efficient algorithm to get all the numbers from 1 to 1,000,000 randomly",18,4,53,http://www.reddit.com/r/algorithms/comments/1inkt9/most_efficient_algorithm_to_get_all_the_numbers/,"I want to get a random number from between 1 and 1,000,000. Then I want to do the same thing again, but exclude the number I previously got. I want to do that until all I've got all the numbers once.

My first thought is to make a big array of all the numbers, then array_rand() it, and then shift() until they're all gone. That's seems pretty inefficient though, because you have to store a million items in memory. 

Is there a better way?",,False,,t5_2qj1c,False,,,True,t3_1inkt9,http://www.reddit.com/r/algorithms/comments/1inkt9/most_efficient_algorithm_to_get_all_the_numbers/,
1370800189.0,14,reddit.com,1fzoxm,A place to discover and exchange algorithmic problems.,20,6,0,http://www.reddit.com/r/algorithms/comments/1fzoxm/a_place_to_discover_and_exchange_algorithmic/,,,False,,t5_2qj1c,False,,,False,t3_1fzoxm,http://www.reddit.com/r/algoprobs/,
1338498739.0,13,self.algorithms,uei2t,Elevator algorithm fun.,14,1,3,http://www.reddit.com/r/algorithms/comments/uei2t/elevator_algorithm_fun/,"So here's a fun problem. You have multiple elevators and people moving between floors. What is an algorithm that finds the optimal elevator paths? There are two possible optimizations:

A) Minimize the total time spent waiting for elevators and traveling on elevators for all passengers.

B) Minimize the maximum time spent waiting and traveling for any individual.

Here's what you know:

a) Time spent for elevator to move one floor.

b) Time for elevator to move one floor and stop.

c) Average time an elevator is stopped at a floor.

d) Number of elevators.

e) Number of floors.

f) Maximum number of people in an elevator (optional variable)

Now if that's too easy consider a real-time optimization algorithm where people randomly join the group of people traveling. You also know this additional information.

xi) % of embarkments that occur at floor i

yi) % of disembarkments that occur at floor i.

r) Average number of people who join in on the party per unit time. (unit time can be something like the time it takes an elevator to move one floor). You can assume it follows a discrete probability distribution (Poisson).

You can move an elevator while it's not in use!

[Edit] I should add that you can assume there is way for the passenger to know which elevator they're supposed to get on.",,False,,t5_2qj1c,1338499648.0,,,True,t3_uei2t,http://www.reddit.com/r/algorithms/comments/uei2t/elevator_algorithm_fun/,
1332078261.0,13,self.algorithms,r203u,"Anyone taking the Stanford ""Design and Analysis of Algorithms"" course?",16,3,7,http://www.reddit.com/r/algorithms/comments/r203u/anyone_taking_the_stanford_design_and_analysis_of/,"Hey all!  I'm going to be participating in Stanford's online algorithms course [found here](http://www.algo-class.org/), and I was wondering if there were other people here who were taking it (or who want to take it).  I think having access to a smaller community than the tens of thousands on the forums might be beneficial for problem solving and/or question answering.

I'm not sure if there's already a subreddit for this, but if there's not, and there's interest, we can surely make one.",,False,,t5_2qj1c,False,,,True,t3_r203u,http://www.reddit.com/r/algorithms/comments/r203u/anyone_taking_the_stanford_design_and_analysis_of/,
1323615386.0,13,self.algorithms,n8hgr,Understand Big O notation,14,1,8,http://www.reddit.com/r/algorithms/comments/n8hgr/understand_big_o_notation/,"What exactly did I learn Big-Something notation for in my Discrete Mathematics I class (I'm a Computer Science major and I hear people talking about how certain algorithms are Big-O/Theta/etc to other algorithms)? In DS I, we only looked at Big notation in terms of real functions, and even then it didn't really make a whole lot of sense. Can someone explain how to relate this to algorithms? ",,False,,t5_2qj1c,False,,,True,t3_n8hgr,http://www.reddit.com/r/algorithms/comments/n8hgr/understand_big_o_notation/,
1298828601.0,13,self.algorithms,ftrtv,Genetic algorithms vs. simulated annealing?,13,0,10,http://www.reddit.com/r/algorithms/comments/ftrtv/genetic_algorithms_vs_simulated_annealing/,"In *The Algorithm Design Manual*, Steven Skiena dismisses genetic algorithms as voodoo magic. Instead, he hawks simulated annealing as his ideal heuristic method. What are your thoughts guys?",,False,,t5_2qj1c,False,,,True,t3_ftrtv,http://www.reddit.com/r/algorithms/comments/ftrtv/genetic_algorithms_vs_simulated_annealing/,
1375738245.0,12,self.algorithms,1jrmyg,"Is there a good ""intuitive"" explanation for the correctness of Ford-Fulkerson?",14,2,4,http://www.reddit.com/r/algorithms/comments/1jrmyg/is_there_a_good_intuitive_explanation_for_the/,"For most of the standard-curricula algorithms (most well-known search algorithms, Dijkstra, Floyd-Warshall), I am 100% that the theory is sound, and I am also  ""intuitively convinced"" of the algorithms' correctness. 

However, for max-flow algorithms, and Ford-Fulkerson in particular, I've never been able to intuitively grasp exactly *why* it should work. I've puzzled a bit with the math, I do understand that the max flow is at a min-cut, and I've written correct implementations (of Edmonds-Karp) many times. Still, I can't wrap my head around exactly why arbitrarily saturating flow-augmenting paths should lead to a correct global solution. (...well, assuming that the capacities are rational.)

Can someone among the max-enlightened give me some tips? 


**Edit**: Thank you for your answers. I'm not grokking it 100% yet, but your input has helped a lot; especially the answers discussing the nature of the residual graph, and how it allows us to ""correct mistakes"". I've upvoted everyone.",,False,,t5_2qj1c,1376098086.0,,,True,t3_1jrmyg,http://www.reddit.com/r/algorithms/comments/1jrmyg/is_there_a_good_intuitive_explanation_for_the/,
1367617139.0,14,itsoc.org,1dn7e6,[IT SOC - endorsement needed] US stamp for the father of information theory - Claude Elwood Shannon,16,2,0,http://www.reddit.com/r/algorithms/comments/1dn7e6/it_soc_endorsement_needed_us_stamp_for_the_father/,,,False,,t5_2qj1c,False,,,False,t3_1dn7e6,http://www.itsoc.org/news-events/recent-news/shannons-centenary-us-postal-stamp,
1366264878.0,12,americanscientist.org,1cla6d,The Easiest Hard Problem,16,4,1,http://www.reddit.com/r/algorithms/comments/1cla6d/the_easiest_hard_problem/,,,False,,t5_2qj1c,False,,,False,t3_1cla6d,http://www.americanscientist.org/issues/pub/2002/3/the-easiest-hard-problem,
1364766767.0,11,self.algorithms,1bdpy6,Can someone explain how the Hirschberg's algorithm for string alignment works?,17,6,1,http://www.reddit.com/r/algorithms/comments/1bdpy6/can_someone_explain_how_the_hirschbergs_algorithm/,"Here is the code:

    1    function Hirschberg(X,Y)
    2    Z = """"
    3    W = """"
    4    if length(X) == 0 or length(Y) == 0
    5        if length(X) == 0
    6            for i=1 to length(Y)
    7                Z = Z + '-'
    8                W = W + Yi
    9             end
    10       else if length(Y) == 0
    11           for i=1 to length(X)
    12               Z = Z + Xi
    13               W = W + '-'
    14           end
    15       end
    16   else if length(X) == 1 or length(Y) == 1
    17       (Z,W) = (Z,W) + NeedlemanWunsch(X,Y)
    18   else
    19       xlen = length(X)
    20       xmid = length(X)/2
    21       ylen = length(Y)
    22       ScoreL = NWScore(X1:xmid, Y)
    23       ScoreR = NWScore(rev(Xxmid+1:xlen), rev(Y))
    24       ymid = PartitionY(ScoreL, ScoreR)
    25       (Z,W) = (Z,W) + Hirschberg(X1:xmid, y1:ymid)
    26       (Z,W) = (Z,W) + Hirschberg(Xxmid+1:xlen, Yymid+1:ylen)
    27   end
    28   return (Z,W)

    1    function PartitionY(ScoreL, ScoreR)
    2        return arg max ScoreL + rev(ScoreR)

I understand most of the pseudo code. I just don't understand what line number 17 does.  
Does it calculate the Needleman-Wunsch alignment if either of the two strings has a length of 1 and assign the alignment to Z and W? If this true, that means I need to implement Needleman-Wunsch algorithm first. Not that it's difficult, but it just doesn't make sense to implement this if I'm going to require the Needleman-Wunsch algorithm anyway.  

Any ideas?",,False,,t5_2qj1c,False,,,True,t3_1bdpy6,http://www.reddit.com/r/algorithms/comments/1bdpy6/can_someone_explain_how_the_hirschbergs_algorithm/,
1351174209.0,13,self.algorithms,122dpk,I want to learn about algorithms on my own. Where and how can a new guy start?,17,4,11,http://www.reddit.com/r/algorithms/comments/122dpk/i_want_to_learn_about_algorithms_on_my_own_where/,"I know a bit of C++ and also some statistical programming language (SAS and R mostly). I'm currently majoring in Economics and math and want to develop more skills so when it comes time to apply for jobs I have a lot of tools at my disposal. Where can I start learning about algorithms? Preferably from a very basic level so I can get a firm grasp before moving on to more technical concepts. Also, what's a good book to start with?",,False,,t5_2qj1c,False,,,True,t3_122dpk,http://www.reddit.com/r/algorithms/comments/122dpk/i_want_to_learn_about_algorithms_on_my_own_where/,
1374956409.0,13,self.algorithms,1j6e1l,How to show that job scheduling (with deadlines) is NP-Hard,14,1,1,http://www.reddit.com/r/algorithms/comments/1j6e1l/how_to_show_that_job_scheduling_with_deadlines_is/,"I'm new to this stuff, and this question really has me stumped.  Anyone know a good NP-H/C problem that would work well as a reduction to show that this JSP variant is NP-Hard?  Each job has a start time, running time, and deadline.  The decision problem asks whether we can schedule at least K jobs.  I've looked through a bunch of NP-C problems, and so far bin packing looks like it might work.",,False,,t5_2qj1c,False,,,True,t3_1j6e1l,http://www.reddit.com/r/algorithms/comments/1j6e1l/how_to_show_that_job_scheduling_with_deadlines_is/,
1371923505.0,11,eprint.iacr.org,1gv5o8,Cryptology ePrint Archive (pdfs of papers in the field of cryptology dating back to 1996),14,3,0,http://www.reddit.com/r/algorithms/comments/1gv5o8/cryptology_eprint_archive_pdfs_of_papers_in_the/,,,False,,t5_2qj1c,False,,,False,t3_1gv5o8,http://eprint.iacr.org/list.html,
1371243147.0,11,self.algorithms,1gd1wq,Help on some insight into why this recursive division algorithm works...,12,1,3,http://www.reddit.com/r/algorithms/comments/1gd1wq/help_on_some_insight_into_why_this_recursive/,"divide(x,y):

if y &gt; x return 0

q = divide(x,2y)

if (x-2qy) &lt; y

return 2q

else

return 2q + 1


I know it works but I'm not sure I am doing a good job of conceptualizing what's going on here. Anyone care to explain?",,False,,t5_2qj1c,False,,,True,t3_1gd1wq,http://www.reddit.com/r/algorithms/comments/1gd1wq/help_on_some_insight_into_why_this_recursive/,
1365947481.0,11,self.algorithms,1cbp68,Does anyone know where I can learn from scratch about time complexity of an algorithm?,15,4,8,http://www.reddit.com/r/algorithms/comments/1cbp68/does_anyone_know_where_i_can_learn_from_scratch/,"I have the basic competent mathematical knowledge of an HL IB math student. I need this for my extended essay (for anyone who's a little familiar with the IB program).
Any pointers are greatly appreciated!",,False,,t5_2qj1c,False,,,True,t3_1cbp68,http://www.reddit.com/r/algorithms/comments/1cbp68/does_anyone_know_where_i_can_learn_from_scratch/,
1361043868.0,11,self.algorithms,18ngtq,What is a good approach for maximizing the number of wines sold by a seller given a list of buyers?,14,3,11,http://www.reddit.com/r/algorithms/comments/18ngtq/what_is_a_good_approach_for_maximizing_the_number/,"This was an interview question given to a friend of mine. 

1) A seller (you) is given a list of n buyers. 

2) There is only one of each bottle of wine. So m total &amp; distinct bottles altogether.

3) Each buyer has 10 wines he/she desires (there might be the same wines in different lists). 

5) You can only sell to each buyer once.

6) You have the options of picking which bottles of wine a buyer receives. So he/she may receive 3 (minimal) through 10 bottles, depending on your inventory remaining.

7) Some customers might be left empty-handed if the remaining inventory does not satisfy their list (i.e a minimal of three bottles to an order).

Objective: Your goal is to maximize the number of wine sold, or minimize m, i.e. your inventory. I presume this is a combinatorial optimization problem, and since I have not formally studied this area, I'm stumped on a good solution. Any suggestions on an algorithm to use?

EDIT: 

Also consider run-time of the problem.

Example:

  m=14   

  Buyer 1 wants: [1,2,3,4,5,6,7,8,9,10]

  Buyer 2 wants: [3,4,5,6,7,8,9,10,11,12]

  Buyer 3 wants: [3,4,5,6,7,8,9,10,13,14]

If all 10 wines of buyer 1 was processed first, then buyer 2 and 3 would not be able to place an order to minimize m.

A permutation of the optimal solution would be:

  Buyer 1 receives [1,2,3,4,5,6,7,8]

  Buyer 2 receives [9,11,12]

  Buyer 3 receives [10,13,14]
",,False,,t5_2qj1c,1361052060.0,,,True,t3_18ngtq,http://www.reddit.com/r/algorithms/comments/18ngtq/what_is_a_good_approach_for_maximizing_the_number/,
1358725089.0,11,self.algorithms,16yf1u,Algorithm for dividing up doubles,12,1,11,http://www.reddit.com/r/algorithms/comments/16yf1u/algorithm_for_dividing_up_doubles/,"You're given an unsorted array (A) of size N that contains double-precision floating point values. 

The task is to divide the doubles into two new arrays (A1 and A2) of size N1 and N2 (where N1 + N2 = N), such that you minimize this quantity:

N1 * variance(A1) + N2 * variance(A2)

In other words you want the values in each array to have as little variance as possible, weighted by the number of elements in that array. 

You do not have to maintain any order of any kind. Any element can go into any of the two arrays.

What is the most efficient algorithm to achieve this and what is it's complexity?",,False,,t5_2qj1c,False,,,True,t3_16yf1u,http://www.reddit.com/r/algorithms/comments/16yf1u/algorithm_for_dividing_up_doubles/,
1352762192.0,11,self.algorithms,1338o0,Enumerating Values With a Single Constraint (x-post from /r/CompSci - I just found out about /r/algorithms!),11,0,9,http://www.reddit.com/r/algorithms/comments/1338o0/enumerating_values_with_a_single_constraint_xpost/,"This question is actually rooted in a much more practical project I'm working on for a scheduler app where I volunteer, but I've managed to simplify the thing I'm not sure how to do down to the following problem:


**Write a method f(n,m) which returns the 'n'th positive integer whose binary representation contains 'm' or fewer 1s.**


I know I could iterate through each time the function is called and count how many satisfy my condition until getting to the correct value, but I'm trying to find it in constant time.

For the curious, this maps back to my scheduler app as a part of the app which allows each person to specify their requested schedule for the week (represented by an encoded integer, or 'n') and then give a maximum number of shifts they'd like to volunteer (the constraint, 'm'). 

Haven't done work like this in a while so my head is spinning a little. Any thoughts would be much appreciate!

TL;DR Read the **bold**.",,False,,t5_2qj1c,False,,,True,t3_1338o0,http://www.reddit.com/r/algorithms/comments/1338o0/enumerating_values_with_a_single_constraint_xpost/,
1344092170.0,11,self.algorithms,xo7bk,CompSci student struggling with time complexity and algorithms -- how can I improve?,16,5,17,http://www.reddit.com/r/algorithms/comments/xo7bk/compsci_student_struggling_with_time_complexity/,"So, I love writing code, but when it comes to calculating the time complexity of my algorithms, I'm completely lost. I really want to get a better handle on things before school starts in September, so any suggestions? -- books, online courses, etc.?",,False,,t5_2qj1c,False,,,True,t3_xo7bk,http://www.reddit.com/r/algorithms/comments/xo7bk/compsci_student_struggling_with_time_complexity/,
1330627708.0,11,self.algorithms,qd8vw,Alpha beta pruning tree,11,0,12,http://www.reddit.com/r/algorithms/comments/qd8vw/alpha_beta_pruning_tree/,"What does one do if the game tree allows loops to form? Continuing that branch will lead to an endless loop, but storing all visited states will waste a lot of space. The same issue exists without the pruning, and just using minimax.",,False,,t5_2qj1c,False,,,True,t3_qd8vw,http://www.reddit.com/r/algorithms/comments/qd8vw/alpha_beta_pruning_tree/,
1323239206.0,11,self.algorithms,n3mjg,"Ask: Are there any good available video lectures on Algorithms? or Computer Science, or any Science for that matter?",12,1,8,http://www.reddit.com/r/algorithms/comments/n3mjg/ask_are_there_any_good_available_video_lectures/,"The algorithms topics that I'm interested in are Quantum Computing, Swarm and/or Ant Colony Systems, or Genetic Algorithms. I would prefer actual lectures (like to a undergrad or grad class), but talks, documentaries are cool too.

I recently took the CS GRE and to prepare I ended up watching a bunch of CS lectures, and it really helped me out. I'm having trouble finding new ones (that are good) that I am interested in online. 


The videos from this site helped me on the GRE. I've watched mostly selected topics from Theory of Computation (Excellent) and Algorithms. In Algorithms, the last lecture on DNA Computing is cool if you've never seen it before.
http://aduni.org/courses/

The following two are both by the same guy, who actually teaches at my school. The lectures are a bit dry, but they are informative.

Hungarian Algorithm for the Assignment Problem
http://www.youtube.com/watch?v=BUGIhEecipE
Branch and Bound method for the TSP
http://www.youtube.com/watch?v=nN4K8xA8ShM

I didn't like the MIT algorithms lectures very much. Maybe they would be good as a lullaby.

I've also watched the Feynman Lectures and would recommend Stephen Hawking's Into the Universe (show/documentary).


EDIT: This is also a good site I found for a wide variety of courses. http://www.cosmolearning.com/courses/
",,False,,t5_2qj1c,True,,,True,t3_n3mjg,http://www.reddit.com/r/algorithms/comments/n3mjg/ask_are_there_any_good_available_video_lectures/,
1310045229.0,12,self.algorithms,ij0a0,Would like to learn more about algorithms. Where should I start?,13,1,18,http://www.reddit.com/r/algorithms/comments/ij0a0/would_like_to_learn_more_about_algorithms_where/,I'm a first year CS student and algorithms have really started to interest me. Is there a good place to start learning them? Thanks for your input,,False,,t5_2qj1c,False,,,True,t3_ij0a0,http://www.reddit.com/r/algorithms/comments/ij0a0/would_like_to_learn_more_about_algorithms_where/,
1309872104.0,12,altdevblogaday.com,ih593,A way to visualise the Fourier Transform and by that gain intuition. X-post from programming.,13,1,0,http://www.reddit.com/r/algorithms/comments/ih593/a_way_to_visualise_the_fourier_transform_and_by/,,,False,,t5_2qj1c,False,,,False,t3_ih593,http://altdevblogaday.com/2011/05/17/understanding-the-fourier-transform/,
1359920264.0,9,self.algorithms,17tjtj,Algorithms for approximating interactions of mobile force-generating objects in three-dimensional space in better than O(N!) time?,11,2,4,http://www.reddit.com/r/algorithms/comments/17tjtj/algorithms_for_approximating_interactions_of/,"**EDIT:** I put N! in the title when I should have put N^2. 

Let's say I have a set of 999 electrons floating in a vacuum. If I calculate the force of every object on every other object, I have to do 999+998+997... calculations per tick. What are some of the best ways to approximate such interactions without exerting such colossal amounts of computation?

A simple method would be to implement a cutoff range, where objects only exert forces on each other if they are within a certain range. But that obviously doesn't work if the objects are all close together. I imagine there have to be some better algorithms out there.",,False,,t5_2qj1c,1359925509.0,,,True,t3_17tjtj,http://www.reddit.com/r/algorithms/comments/17tjtj/algorithms_for_approximating_interactions_of/,
1356913487.0,11,self.algorithms,15p3pi,Song rating algorithm based on listening habits?,16,5,12,http://www.reddit.com/r/algorithms/comments/15p3pi/song_rating_algorithm_based_on_listening_habits/,"Hey,

I'm looking for algorithms that take listening habits into account. Say we have a rating of 0-100 and a song starts with 50. Now I'm skipping this song over and over again. As a result the song gets downrated. It should also take into account how much of the song was played.

What I'd like to add, is: I already found a library or service which was doing exactly that. But it was some time ago and I forgot its name :(

Maybe anyone here can help me. Also, this is my first post here, so bear with me if I'm wrong here or something.",,False,,t5_2qj1c,False,,,True,t3_15p3pi,http://www.reddit.com/r/algorithms/comments/15p3pi/song_rating_algorithm_based_on_listening_habits/,
1354682898.0,10,self.algorithms,14b1ct,A graph theory / AST problem?,13,3,11,http://www.reddit.com/r/algorithms/comments/14b1ct/a_graph_theory_ast_problem/,"I have two programs that do the exact same thing:
    
    sum1() {
      int i = 0;
      int sum = 0;
      while (i &lt; 10) {
        sum = sum + 1;
        i = i + 1;
      }
    return sum;
    }
and

    sum2() {
      int sum = 0;
      for (int i = 0; i &lt; 10; i++) {sum = sum + 1;}
    return sum;
    }

If I were to turn these two into abstract syntax trees (AST's), I would get two different trees with similar components (some exactly the same).  I intend to compare different AST's and I want to be able to figure out, when I hit situations like this, that these two are the exact same program.  The thing is, I can't forfeit all of the differences in different implementations of the same program because I'm using them to come up with a set of recommended edits to achieve the tree. Is there a way to generalize the AST representation so that I could overlook this detail, while still keeping in mine the original AST?",,False,,t5_2qj1c,1354688726.0,,,True,t3_14b1ct,http://www.reddit.com/r/algorithms/comments/14b1ct/a_graph_theory_ast_problem/,
1353334133.0,9,self.algorithms,13g83v,"Twist on the Knapsack Problem, does it have a name?",11,2,8,http://www.reddit.com/r/algorithms/comments/13g83v/twist_on_the_knapsack_problem_does_it_have_a_name/,"I've been playing with the knapsack problem as a way to find optimal fantasy sport lineups, based on a budget system where you are given $150,000 and must choose your roster from a list of players with dollar valuations.  I'm wondering if somebody has solved the problems that I'm having or if there's a name for them.  

Doing some slight modifications on a knapsack algorithm I've been able to get a program to set what it considers an optimal basketball lineup, but it's missing something:

It doesn't take roster restrictions into account, so the team could be all centers or guards, if it finds a combination that works.  Assuming that the algorithm calculates every available combination, could I add a check for roster validity and toss the programs ""optimum"" lineup if it is not also legal?  I'm sure this would be the least optimized method for solving this problem.

Any thoughts would be greatly appreciated.  I'm relatively new to all of this, but I do find it fascinating.  
",,False,,t5_2qj1c,False,,,True,t3_13g83v,http://www.reddit.com/r/algorithms/comments/13g83v/twist_on_the_knapsack_problem_does_it_have_a_name/,
1351569788.0,10,self.algorithms,12bksw,How do you figure out the edits required to transform one tree into another?,12,2,6,http://www.reddit.com/r/algorithms/comments/12bksw/how_do_you_figure_out_the_edits_required_to/,"There exists plenty of material out there that can tell you how to calculate the edit distance between two trees.  I think the most efficient one at the moment is [pq-Gram](http://www.vldb2005.org/program/paper/wed/p301-augsten.pdf) and we can get exact tree edit distance with [Zhang-Shasha](http://www.grantjenks.com/wiki/_media/ideas:simple_fast_algorithms_for_the_editing_distance_between_tree_and_related_problems.pdf), but please correct me if I'm wrong or there exist better choices.


I'm current figuring out tree-edit distances to figure out which solution tree, out of a set of solution trees, is the closest match to a given starting tree.  Now the trick is, how would I go about figuring the edits required to achieve this solution tree from the starting tree--preferably in the minimum amount of edits.",,False,,t5_2qj1c,False,,,True,t3_12bksw,http://www.reddit.com/r/algorithms/comments/12bksw/how_do_you_figure_out_the_edits_required_to/,
1349065638.0,11,aidriven.com,10qvsh,How to save earth from Alien invasion - Intelligent Network Part III– Tree Aggregation and Symmetric Push Sum Protocol (Gossip Protocol),11,0,3,http://www.reddit.com/r/algorithms/comments/10qvsh/how_to_save_earth_from_alien_invasion_intelligent/,,,False,,t5_2qj1c,False,,,False,t3_10qvsh,http://www.aidriven.com/index.php/2012/09/23/intelligent-network-part-iii-tree-aggregation-and-symmetric-push-sum-protocol-gossip-protocol/,
1347747720.0,10,self.algorithms,zy0yk,Graph theory: Graph equivalence,12,2,9,http://www.reddit.com/r/algorithms/comments/zy0yk/graph_theory_graph_equivalence/,"I have to check whether two graphs are equivalent or not. Unfortunately, the notion of equivalence is more relaxed than usually: 

Let's say my nodes are labelled with a letter, followed by a number, i.e. A0, A1, A2, B0, B1, C0, C1 etc. (Both the letter alphabet as well as the number alphabet are finite in case this matters). Now two graphs are not only equivalent if their adjacency matrices are equal, but it is allowed to swap rows/columns with the same letter.

For example, the two graphs A0 -- B0 -- A1 -- B1 and A0 -- B1 -- A1 -- B0 are deemed to be equivalent. The same holds for A0 -- B0 and A1 -- B1 but not for A0 -- B0 -- A1 -- B1 and A0 -- B0 -- B1 -- A1.

I am using ""chains"" here because it would be messy to submit something more elaborated to reddit, but my problem is clearly not restricted to chains.

Is there any better way than brute forcing the whole problem space?

Also, I hope this is the right subreddit for this question and I apologize in case it's not.

Regards and thank you

Matt",,False,,t5_2qj1c,False,,,True,t3_zy0yk,http://www.reddit.com/r/algorithms/comments/zy0yk/graph_theory_graph_equivalence/,
1347694964.0,8,self.algorithms,zx2yf,Algorithm for finding words containing all letters of the alphabet,11,3,5,http://www.reddit.com/r/algorithms/comments/zx2yf/algorithm_for_finding_words_containing_all/,"I occasionally set myself little problems.  The other day I noticed a variation of ""The quick brown fox..."" which got me wondering about the following problem:  Given a dictionary, what is the shortest set of words that will contain all the letters of the alphabet.  We can define 'shortest' as either fewest words or shortest string when all the words are concatenated with spaces.  I was thinking of using a set cover approach, but felt that the search space may make it infeasible (we will assume the dictionary has 100k words).

Any ideas or suggestions?",,False,,t5_2qj1c,False,,,True,t3_zx2yf,http://www.reddit.com/r/algorithms/comments/zx2yf/algorithm_for_finding_words_containing_all/,
1342433106.0,11,self.algorithms,wmyfh,Request: optimization algorithm.,12,1,17,http://www.reddit.com/r/algorithms/comments/wmyfh/request_optimization_algorithm/,"Okay Reddit, I'm sure I'm not the first person in the world to ask this question, so the answer is probably easier to find than I think. All I'm asking for is a link, or a description, if you guys know of any.

So, suppose that I have a function of an arbitrary number of variables between, say, 3 and 100. We'll call this *f*. *f* probably has a vast number of local minimums, as well as probably some local maximums.

1. Given that it has a unique absolute minimum, how can I find its position? That is, what combination of values for the input variables shall produce the absolute minimum as the output?
2. Suppose that *f*'s absolute minimum *isn't* unique; that is, that more than one combination of the input variables produces an output that is as small as possible. Then what algorithm should be used to find the position of any one of the absolute minimums?

Please feel free to comment and ask for more information, if that's needed. Thanks very much in advance to anyone who so kindly helps out.",,False,,t5_2qj1c,False,,,True,t3_wmyfh,http://www.reddit.com/r/algorithms/comments/wmyfh/request_optimization_algorithm/,
1328121028.0,11,self.algorithms,p6fho,Greedy Algorithm Help,12,1,4,http://www.reddit.com/r/algorithms/comments/p6fho/greedy_algorithm_help/,"Here's the problem:

The manager of a large student union on campus comes to you with the following problem. She’s in charge of a group of students, each of whom is scheduled to work one shift during the week. There are different jobs associated with these shifts , but we can view each shift as a single contiguous interval of time. There can be multiple shifts going on at once. The manager is trying to find a subset of these students to form a supervising committee that she can meet with once a week. She considers such a committee to be complete if, for every student not on the committee, the student shift overlaps (at least partially) the shift of some student who is on the committee. In this way, each student’s performance can be observed by at least one person who is serving on the committee. Give an efficient algorithm that takes the schedule of n shifts and produces a complete supervising committee containing as few students as possible.

The efficient way to do this is by utilizing a greedy algorithm.  I'm not sure what my greedy criteria should be.  I tried sorting the set of shifts by the start time and finish time, but that doesn't seem to satisfy all my test cases.

Any help would be greatly appreciated.  Thanks.",,False,,t5_2qj1c,False,,,True,t3_p6fho,http://www.reddit.com/r/algorithms/comments/p6fho/greedy_algorithm_help/,
1288680333.0,9,lbrandy.com,dzx4l,Using genetic algorithms to find Starcraft 2 build orders,12,3,1,http://www.reddit.com/r/algorithms/comments/dzx4l/using_genetic_algorithms_to_find_starcraft_2/,,,False,,t5_2qj1c,False,,,False,t3_dzx4l,http://lbrandy.com/blog/2010/11/using-genetic-algorithms-to-find-starcraft-2-build-orders/,
1373651694.0,10,reddit.com,1i60s3,Algorithm to shrink a DFA by introducing nondeterminism? [x-post from /r/compsci],13,3,0,http://www.reddit.com/r/algorithms/comments/1i60s3/algorithm_to_shrink_a_dfa_by_introducing/,,,False,,t5_2qj1c,False,,,False,t3_1i60s3,http://www.reddit.com/r/compsci/comments/1i5sr8/algorithm_to_shrink_a_dfa_by_introducing/,
1369204203.0,9,self.algorithms,1etjf4,optimizing Conway's Game of Life,12,3,6,http://www.reddit.com/r/algorithms/comments/1etjf4/optimizing_conways_game_of_life/,"So I'm a computer science student but haven't quite taken any algorithm classes yet, and while I'm fascinated by the subject, I have very little technical knowledge of it.  

Anyway, for one of my classes we have to build our own implementation of Conway's Game of Life.  

I'm assuming this is a popular enough concept that I won't have to go into it, but if you're unfamiliar with it, [check out it's wikipedia page](http://en.wikipedia.org/wiki/Conways_Game_of_Life), it's not really all that complicated.

So one of the main parts in implementing a solution is counting the live neighbors a cell has, which is necessary in order to determine the state of the next generation. Currently I've implemented this as a 2D array of bools to represent the state of the cells, and I'm iterating through each cell and just incrementing/decrementing the x/y indexes by 1 in order to get the state of the neighbors and keep count. That means that for each cell, I always have to check the state of 8 other cells (except for margins) in order to determine its live neighbor count.

I'm assuming this is the predominant solution, but also that it's not the most efficient way of doing it.  

I've thought of a different way of doing this that I think might be more efficient, but due to my lack of knowledge in calculating the expense of an algorithm, I was hoping maybe somebody more knowledgeable might be able to tell me if that is the case.  

Now my second implementation requires the use of the same bool array representing the state of the cells, but also the use of a second int array that would keep track of the live neighbor count. It would loop through the bool array and whenever a true value is encountered, the coordinates of its neighbors would be calculated, similar to my previous solution, but they would be used to increment the ints in the second array which keeps track of the neighbor count. If the current index in the bool array is false, then it is ignored and no neighbors need to be calculated.

One reason why I thought this might be more efficient is due to the fact that only the neighbors of live cells need to be calculated now. However, the use of a secondary array and the constant writes to that array might also make it slower than the first.

Thanks for any help, and I know algorithms are meant to be more theoretical than I've described mine above, but I apologize for being such a noob in the domain.",,False,,t5_2qj1c,False,,,True,t3_1etjf4,http://www.reddit.com/r/algorithms/comments/1etjf4/optimizing_conways_game_of_life/,
1368453023.0,10,facebook.com,1e8s81,Find duplicate in an array of triplicates.,16,6,29,http://www.reddit.com/r/algorithms/comments/1e8s81/find_duplicate_in_an_array_of_triplicates/,,,False,,t5_2qj1c,False,,,False,t3_1e8s81,http://www.facebook.com/codebnk/posts/446935628732445,
1367162856.0,7,self.algorithms,1d9wyy,Searching for the perfect tournament seating algorithm,11,4,9,http://www.reddit.com/r/algorithms/comments/1d9wyy/searching_for_the_perfect_tournament_seating/,"Hey guys - I'm not sure if this is the correct subreddit for my problem; if not, I'd appreciate if you could point me in the right direction.

---

My problem is as follows. We have an annual team board game tournament which generally has around 10 teams competing. Every year, the way the tables for the games are set up causes some grumbling, and I'm wondering if anyone could think of a perfect way to handle the seatings.

Here's the set up:

- The tournament consists of a minimum of four teams, of four players each
- Four rounds of 4-player games are played (different games, though I suppose that's irrelevant)

The seats are set up beforehand, so that each player knows which position he sits in each game:

- Player X has seat 1 in round A, seat 2 in round B, seat 3 in round C and seat 4 in round D
- Player Y has seat 2 in round A, seat 3 in round B, seat 4 in round C and seat 1 in round D
- Player Z has seat 3 in round A, seat 4 in round B, seat 1 in round C and seat 2 in round D
- Player W has seat 4 in round A, seat 1 in round B, seat 2 in round C and seat 3 in round D

---

In past tournaments, two separate algorithms have been used.

One algorithm has ensured that each team faces every other team an equal (or as close to equal as possible) amount of times. However, because of this some individual players had to face each other several times during the tournament (in the worst case, two players had to play each other in three rounds out of four).

Another algorithm ensured that each individual player never faced another individual player more than once. However, this made the different teams face each other an uneven amount of times: some teams faced each other 4 times and other teams 8 times, which is not good considering it's the team's combined results that count.

An optimal algorithm would do both:

- Individual players never face each other more than once
- All teams face every other team the same amount of times, or as close to the same amount as possible

Is this 'perfect algorithm' even possible? Obviously it's more difficult to achieve the less teams there are in the tournament - what would be the minimum amount of teams required to make this possible?

Thanks -- any help is greatly appreciated!",,False,,t5_2qj1c,False,,,True,t3_1d9wyy,http://www.reddit.com/r/algorithms/comments/1d9wyy/searching_for_the_perfect_tournament_seating/,
1361833231.0,8,self.algorithms,197ylb,Practical applications of merging heaps?,11,3,5,http://www.reddit.com/r/algorithms/comments/197ylb/practical_applications_of_merging_heaps/,"I've been looking over the Wikipedia pages on [Heaps](http://en.wikipedia.org/wiki/Heap_\(data_structure\)) and their many variations list on that page. I noticed that many of the variations appear to be motivated based on making merging heaps faster. Since a heap is the most common way to implement a priority queue, I assume this means that it's commonplace to need to merge priority queues, but I've never run into this in my own programming. Why the obsession with heap/priority-queue merging? Is this a common problem in allocators or something? (maybe when a thread dies, merging its thread specific allocator state back into the global pool?)

Edit: Fixed the link.",,False,,t5_2qj1c,1361892702.0,,,True,t3_197ylb,http://www.reddit.com/r/algorithms/comments/197ylb/practical_applications_of_merging_heaps/,
1356681204.0,9,self.algorithms,15kc1b,Poker chip breakdown: how is this problem called and solved?,11,2,5,http://www.reddit.com/r/algorithms/comments/15kc1b/poker_chip_breakdown_how_is_this_problem_called/,"Suppose I have a poker chip set, that is, there are a few types of chips, the quantity and value of those are specified. There are N of players, I want each of them to have a stack of chips worth X (suppose there are enough chips). How do I distribute the chips (in matching sets if possible)?

I suppose it's a well-known problem with a well-known solution. Is it? Some variation of the Knapsack perhaps?",,False,,t5_2qj1c,1356683519.0,,,True,t3_15kc1b,http://www.reddit.com/r/algorithms/comments/15kc1b/poker_chip_breakdown_how_is_this_problem_called/,
1354516675.0,9,self.algorithms,146tkm,"Looking to learn algorithms, any suggestions of resources?",11,2,10,http://www.reddit.com/r/algorithms/comments/146tkm/looking_to_learn_algorithms_any_suggestions_of/,"My school cut the computer science department so I'm trying to teach myself, any suggestions for books or sites that will help me learn algorithms?  I have a strong math background and will most likely be learning this over Christmas break.",,False,,t5_2qj1c,False,,,True,t3_146tkm,http://www.reddit.com/r/algorithms/comments/146tkm/looking_to_learn_algorithms_any_suggestions_of/,
1351763152.0,9,self.algorithms,12g8gv,What algorithms does the Magic Plan app use to measure rooms using the camera?,14,5,5,http://www.reddit.com/r/algorithms/comments/12g8gv/what_algorithms_does_the_magic_plan_app_use_to/,"I'm doing research to develop an app to measure surfaces. Id like to do this in a way similar to how [Magic Plan](https://itunes.apple.com/app/magicplan/id427424432?mt=8) measures rooms. Can someone explain to me what algorithms I need for doing this?

(In short, this app lets you take photos of all the corners of a room while standing in a single location and then calculates the shape of the room. It needs to be calibrated to give the correct absolute size of the room, but it can at least tell the relative sizes of the walls and the shape of the room.)",,False,,t5_2qj1c,False,,,True,t3_12g8gv,http://www.reddit.com/r/algorithms/comments/12g8gv/what_algorithms_does_the_magic_plan_app_use_to/,
1337033145.0,9,npr.org,tn4zm,"Algorithms: The Ever-Growing, All-Knowing Way Of The Future",12,3,5,http://www.reddit.com/r/algorithms/comments/tn4zm/algorithms_the_evergrowing_allknowing_way_of_the/,,,False,,t5_2qj1c,False,,,False,t3_tn4zm,http://www.npr.org/blogs/alltechconsidered/2012/05/14/152444019/algorithms-the-ever-growing-all-knowing-way-of-the-future,
1316968169.0,11,blog.susam.in,kqxfj,From the Tower of Hanoi to counting bits,12,1,0,http://www.reddit.com/r/algorithms/comments/kqxfj/from_the_tower_of_hanoi_to_counting_bits/,,,False,,t5_2qj1c,False,,,False,t3_kqxfj,http://blog.susam.in/2011/09/from-tower-of-hanoi-to-counting-bits.html,
1298812601.0,10,self.algorithms,ftogj,Which algorithm/data structure book do you prefer?,10,0,13,http://www.reddit.com/r/algorithms/comments/ftogj/which_algorithmdata_structure_book_do_you_prefer/,"Personally I'm prefer alternatives with pseudocode, do you have any suggestions?",,False,,t5_2qj1c,True,,,True,t3_ftogj,http://www.reddit.com/r/algorithms/comments/ftogj/which_algorithmdata_structure_book_do_you_prefer/,
1267693161.0,9,self.algorithms,b93cn,"So you go and implement an algorithm, and the performance sucks...",12,3,22,http://www.reddit.com/r/algorithms/comments/b93cn/so_you_go_and_implement_an_algorithm_and_the/,"...and now you have a problem, because you know the algorithm is much more efficient than your testing seems to indicate. You reread the algorithm specification and your implementation, and find a bug that halves runtime. But it's still too slow.

Now... what do you do? Reread the algorithm specification repeatedly until you find your problem? (nope, looks fine to me) Profile and see what the major cost centers are? (they're in the obvious place, the recursive call.) I'm slightly stumped; suggestions would be greatly appreciated!",,False,,t5_2qj1c,False,,,True,t3_b93cn,http://www.reddit.com/r/algorithms/comments/b93cn/so_you_go_and_implement_an_algorithm_and_the/,
1376171976.0,7,self.algorithms,1k4084,Dynamic Programming thought process. Is this correct?,8,1,4,http://www.reddit.com/r/algorithms/comments/1k4084/dynamic_programming_thought_process_is_this/,"Preface: I'm new to dynamic programming and as far as I can tell it is simply recursion + memoization.


Problem:

    There is a river that is n meters wide. At every meter from the edge, there may
    or may not be a stone. A frog needs to cross the river.  However the frog has
    the limitation that if she has just jumped x meters, then its next jump must be
    between (x-1) and (x+1) meters, inclusive. Assume the first jump can be of only 1
    meter. Given the position of the stones, determine whether the frog can make it
    across the river or not.


===

My immediate thought was to treat this is a graph search where nodes are a tuple of `(stone, previous leap size)` and neighbors of node `(x, y)` are `(x+y-1, y-1) (x+y, y) (x+y+1 , y+1)`, assuming of course that each node is in the list of stones. Then one simply follows paths of nodes, largest leaps first, until you get to the other side or run out of unvisited nodes.

However, this problem is in the chapter of my book on dynamic programming so I assume it's intended to be solved that way. I asked in #programming on freenode and had a short discussion where it seemed like my graph search idea somehow *was* dynamic programming in disguise.

Can anyone clarify for me exactly how dynamic programming would apply to this problem and why someone thought my graph search was a dynamic programming solution?",,False,,t5_2qj1c,False,,,True,t3_1k4084,http://www.reddit.com/r/algorithms/comments/1k4084/dynamic_programming_thought_process_is_this/,
1375741966.0,8,self.algorithms,1jrrxh,Any good resources for Evolutionary Computation?,11,3,5,http://www.reddit.com/r/algorithms/comments/1jrrxh/any_good_resources_for_evolutionary_computation/,I was looking for a Coursera/EDX similar resource. I want to dig a little bit in Evolutionary Computing / Genetic Algorithms,,False,,t5_2qj1c,False,,,True,t3_1jrrxh,http://www.reddit.com/r/algorithms/comments/1jrrxh/any_good_resources_for_evolutionary_computation/,
1374797897.0,8,self.algorithms,1j2cam,Radix Sort (in-place) vs. Quick Sort,9,1,7,http://www.reddit.com/r/algorithms/comments/1j2cam/radix_sort_inplace_vs_quick_sort/,"How do in-place Radix Sorts compare to Quick Sort in terms of speed on real systems?  I did a little test (though it is not a fair test) between the two.  I used this Radix Sort that utilizes the GPU but is not an in-place implementation (thus it always loses for small arrays and will throw out of memory exceptions before QuickSort): 
http://www.codeproject.com/Articles/237259/Faster-Sorting-in-Csharp-by-Utilizing-GPU-with-NVI

In the other corner was the built in Array.Sort() method provided by .NET which utilizes QuickSort for arrays with more than 16 entries.

Radix Sort did not do well on small arrays (&lt;20,000 entries) as I predicted, but it utterly spanked Array.Sort once you start going above 30,000 integers.  It managed to do 10 million integers in half the time it took Array.Sort() to process the same array.

I am not surprised by this at all, it seems that for large arrays, Radix Sort will always beat a comparison sort since it is O(32n) -&gt; O(n) on most systems.  Considering that this wasn't even an in-place radix sort, what advantages does QuickSort have that make it better than RadixSort, even on non-integer arrays?  I can maybe see strings giving it more trouble but for most other primitives (I know strings are not primitives in most languages) I can't see Radix Sort losing.

If this is the case, why is Quick Sort so much popular?  Is there some major flaw of in-place Radix Sort I have not seen yet?",,False,,t5_2qj1c,False,,,True,t3_1j2cam,http://www.reddit.com/r/algorithms/comments/1j2cam/radix_sort_inplace_vs_quick_sort/,
1374667907.0,7,self.algorithms,1iy984,"How to find the weighted ""center"" of a graph",11,4,10,http://www.reddit.com/r/algorithms/comments/1iy984/how_to_find_the_weighted_center_of_a_graph/,I am defining the center of a graph to be the node where the average distance between it and all other nodes is the lowest. The thing is that each node can have a weight ≥ 0. All edges have the same length.,,False,,t5_2qj1c,False,,,True,t3_1iy984,http://www.reddit.com/r/algorithms/comments/1iy984/how_to_find_the_weighted_center_of_a_graph/,
1368131947.0,7,self.algorithms,1e0w0h,Detecting which chunks a line passes through (2d),10,3,9,http://www.reddit.com/r/algorithms/comments/1e0w0h/detecting_which_chunks_a_line_passes_through_2d/,"I'm writing a program that determines two points on a plane (thus, a line) and sets each ""chunk"" of a graph that the line passes through as occupied, or some similar state. Each chunk is just the square formed by cartesian graph lines. 

I feel like I'm explaining this inadequately. Let me include a [drawing](http://i.imgur.com/G4Ab5NW.png) of what I mean.

I already have the points, I just need a way to determine all the squares the line passes through.
",,False,,t5_2qj1c,False,,,True,t3_1e0w0h,http://www.reddit.com/r/algorithms/comments/1e0w0h/detecting_which_chunks_a_line_passes_through_2d/,
1366084897.0,8,self.algorithms,1cfvkb,Mathematica vs. Matlab,12,4,17,http://www.reddit.com/r/algorithms/comments/1cfvkb/mathematica_vs_matlab/,"Hi everyone,
I am a high school student who is about to start a project on genetic algorithms, and I was wondering if someone could explain the differences between using Matlab and Mathematica for my project. My school offers access to both so the decision really lies on which interface will be most useful and easy to use for my project. Thanks!",,False,,t5_2qj1c,False,,,True,t3_1cfvkb,http://www.reddit.com/r/algorithms/comments/1cfvkb/mathematica_vs_matlab/,
1360640321.0,7,self.algorithms,18ct5p,Question on graph(s),11,4,16,http://www.reddit.com/r/algorithms/comments/18ct5p/question_on_graphs/,"Hi,

I have looked a lot online, but I have a few questions about graphs.  I will describe the problem that I want to solve, then people can tell me what the best way to proceed is.

I have a system where each node can be directional or bidirectional, and each of these length is a fractional, but non-negative number.  In the entire network, I have N nodes that I want to link in the least distance.  So I want to visit each node, but branching from the 'original' path is ok.  An additional bonus would be if I could not only return the optimal path(s), but also some number of slightly less than optimal paths (say, looking for +-leastdistance/sqrt(N nodes) or some other heuristic).

One other problem is that I would like to be able to add/remove/split/combine nodes at will.  I suspect that this will always completely destroy any previous information about the graph.  Another problem is that I would like to include unknown information nodes that can be used if a path between the two nodes cannot be found.

Looking through the tubes, I am looking for something with some (at least, somewhat) Markov properties, as well as graph theory.  I have looked at the different graph algorithms online, but I can't seem to find one that really suits my purpose.  I have a sneaking suspicion that this is an NP Hard problem, so I would just have to traverse every possible path in my graph.  I am on a mac (dur), and have boost installed and talking with Xcode, and was hoping to do this using the boost libraries and their graph/threading utilities.

Any thoughts?  Or anybody want more information?  If I need to move this to another area of compsci, I can definitely do that.",,False,,t5_2qj1c,False,,,True,t3_18ct5p,http://www.reddit.com/r/algorithms/comments/18ct5p/question_on_graphs/,
1360622501.0,9,self.algorithms,18c5dm,Creating an algorithm to graph matrix data,10,1,16,http://www.reddit.com/r/algorithms/comments/18c5dm/creating_an_algorithm_to_graph_matrix_data/,"Hey guys, sorry about the length of this post. It's hard to describe in text. It is about creating an algorithm to sort through a matrix of data and graph it.

I have to create a 3d graph that includes points(similar to a plot) and lines connecting the points. The catch is, the points are all placed in the graph *at positions in relation to where the other points are placed*.

For example, let's say I have a matrix of data. Each row/column is labeled by the point in the graph. Where Point A meets Point B, the data reads '3.' This '3' means that these two points' level of closeness should be '3.' Where Point A meets Point C, the data reads '5.' So Points A and C should be closer together than A and B, because 5 is more than 3.

So there's a number at every union in the matrix. The intersection with the largest number would mean that those two points should be the two closest points in the graph, and on the contrary the two points with the smallest number would be the farthest apart.

SO....I need to create an algorithm that would sort through the matrix and graph the points in respect to distance, based on the data in the matrix. Any ideas? Thank you for your time...

TL;DR - I need help creating a small program to sort through matrices of data and graph them in accordance to the data.",,False,,t5_2qj1c,False,,,True,t3_18c5dm,http://www.reddit.com/r/algorithms/comments/18c5dm/creating_an_algorithm_to_graph_matrix_data/,
1359991827.0,8,stackoverflow.com,17vbdl,Guards and demand,10,2,0,http://www.reddit.com/r/algorithms/comments/17vbdl/guards_and_demand/,,,False,,t5_2qj1c,False,,,False,t3_17vbdl,http://stackoverflow.com/q/14686745/1288,
1359746071.0,8,self.algorithms,17pk74,Best way to propagate light values across a 2d array?,11,3,5,http://www.reddit.com/r/algorithms/comments/17pk74/best_way_to_propagate_light_values_across_a_2d/,"I'm writing a little scrolling roguelike in QB64 for fun, and want to implement a tile-based lighting engine.

I had some simple solutions before, (simply iterate through a square of tiles around the light source and adjust each tile brightness by the distance from the source). Now, I'd like to get some advice on something a bit faster/more robust and hopefully still fairly simple.

Icing on the cake would be the ability to do simple shadows from point lights, and directional point lighting. I was thinking maybe  some kind of raytracing, since the effective resolution is low, but I really know nothing about where to start on that.",,False,,t5_2qj1c,False,,,True,t3_17pk74,http://www.reddit.com/r/algorithms/comments/17pk74/best_way_to_propagate_light_values_across_a_2d/,
1358045323.0,8,self.algorithms,16gz23,Detecting line/vector intersection within a given tolerance?,11,3,8,http://www.reddit.com/r/algorithms/comments/16gz23/detecting_linevector_intersection_within_a_given/,"I am looking for an algorithm that, given two vectors and a tolerance of some kind (linear, angular, etc.), will tell me if those two vectors intersect.

I have two objects, each with an origin and a vector. Each object represents an imaginary ""line"" coming out of a human finger in three-dimensional space. I am trying to detect if two fingers are being pointed towards each other (like a pinching gesture). Obviously these are not perfect platonic vectors; I need to check if they ""intersect"" with some arbitrary level of tolerance.

Collision detection algorithms seem much simpler in the abstract than when you actually have to implement them!

Edit:

I ended up using this: http://geomalgorithms.com/a07-_distance.html (dist3D_Segment_to_Segment()) to accomplish what I wanted. Thanks to qartar for putting me on the right track.",,False,,t5_2qj1c,1358124670.0,,,True,t3_16gz23,http://www.reddit.com/r/algorithms/comments/16gz23/detecting_linevector_intersection_within_a_given/,
1354597102.0,7,self.algorithms,148vkn,Modifying a scheduling algorithm?,10,3,13,http://www.reddit.com/r/algorithms/comments/148vkn/modifying_a_scheduling_algorithm/,"In the original scheduling problem I am working from which considers a single resource and a set of n requests.  Each request i is defined by a deadline di and a time interval to complete the task ti. The requests must be assigned to non-overlapping intervals.

The greedy solution to this problem is to order the jobs by their deadlines (the earliest deadline first approach).

I am currently trying to work out if it is possible to use a greedy approach to solve a more complex version of this problem.  Imagine the same initial problem, but with the addition of separate events that are 'hardcoded' into the schedule.  The problem here is to continue creating a schedule the minimizes maximum lateness based on deadlines while respecting these 'hardcoded' events.  Perhaps the greedy approach is not correct for this situation. Any thoughts, input, pseudocode would be appreciated!",,False,,t5_2qj1c,False,,,True,t3_148vkn,http://www.reddit.com/r/algorithms/comments/148vkn/modifying_a_scheduling_algorithm/,
1352934131.0,6,self.algorithms,137gvn,"[Q] Pretend I'm 5, help me understand runtime of Algorithm",14,8,12,http://www.reddit.com/r/algorithms/comments/137gvn/q_pretend_im_5_help_me_understand_runtime_of/,"As the question is stated above, I don't get why I'm having such a hard time getting this. I need to come up with a proof for school to find the worst case running time of a Binary Search Tree as a function of the depth. And I just cannot wrap my brain around it! HALP PLZ!1!!",,False,,t5_2qj1c,False,,,True,t3_137gvn,http://www.reddit.com/r/algorithms/comments/137gvn/q_pretend_im_5_help_me_understand_runtime_of/,
1352651392.0,9,self.algorithms,130i7m,I have to implement a machine learning algo to fill in missing pixel values in an image. Does anybody know good algorithms to do this? Can you point me to some good resources? Google has failed me this time unfortunately.,9,0,14,http://www.reddit.com/r/algorithms/comments/130i7m/i_have_to_implement_a_machine_learning_algo_to/,"I have googled for the following : ""missing data problems in machine learning"", ""image inpainting"", ""image data imputation"". But it keeps throwing up papers in which people have used compressed sensing. So I get the feeling that I've set an impossible project target for myself. Has anybody used machine learning algorithms to fill in missing pixel values in images? If yes, what algorithm did you use?

Thanks you very much.

EDIT : Suppose we are given a grey scale image with say a small square of data missing. I want to be able to fill in these pixel values as accurately as possible. One possible approach I thought of was the following:

Use a neural network with a linear regression function instead of a logistic sigmoid function. The input layer of this neural network will be the pixel values of pixels chosen from *around* the missing region. It will go through several hidden layers and then the output layer will output the pixel value for the missing layer. I know it's very rough right now, but do you think this would work?

EDIT 2: I am reading a couple of papers on collaborative filtering. Do you think this would work? ",,False,,t5_2qj1c,1352654533.0,,,True,t3_130i7m,http://www.reddit.com/r/algorithms/comments/130i7m/i_have_to_implement_a_machine_learning_algo_to/,
1351105636.0,7,self.algorithms,120roj,Can an algorithm calculate probability of under quoting estimates? I was provided a risk assessment algo that works but I don't understand it well enough to tweak it closer to my needs. Care to take a look?,8,1,2,http://www.reddit.com/r/algorithms/comments/120roj/can_an_algorithm_calculate_probability_of_under/,"There are a few variables to consider from a project standpoint-

* Complexity of the Tasks (C)
* Familiarity with the skills involved (S)
* Urgency (U)
* Importance (I)
* Frequency (F)

These values are input on a scale from .01 - 1

Here's the equation I was given as a base. It works but I'd like to understand why there are things like /20 or .7 that seem randomly thrown in for making the numbers more usable. But what's their purpose?

---------------

Probability(c) of going over estimate:

* c = ((U+C+I) * (1 - S))/20 * .7 * (1/(1-(sin(F/10))))*1000

Using the probability and initial estimate ( e^i ), re-estimate( e^n ) project time to expand the 'window' of the quote:

* e^n = e^i (1+(c/100*6))

------------------------

1. Why would one add the U,C,I variables together and reduce by the difference by the unknown skill factor? [Unknown skill I'd imagine is what (1-S) is attempting to determine]

2. Are you able to tell if /20 * .7 is significant for any reason or are these numbers arbitrary weights chosen by the original author?
Is sin() really the best way to factor in frequency of a project? I'd imagine the more frequent a project the less time each takes do to familiarity.. Is that what this section will produce?

3. Calculating the new estimates uses number ""*6"" - is there any place in other maths where this is used or is this another arbitrary number/weight?

4. This might be pushing it, but can someone EL5 this formula for me?",,False,,t5_2qj1c,False,,,True,t3_120roj,http://www.reddit.com/r/algorithms/comments/120roj/can_an_algorithm_calculate_probability_of_under/,
1343692649.0,8,self.algorithms,xf4kv,Help with an integer partition algorithm,8,0,10,http://www.reddit.com/r/algorithms/comments/xf4kv/help_with_an_integer_partition_algorithm/,"Hello! I need an algorithm to help me do the following: Suppose you have the number n, which is a positive integer. I need to be able to print out all the possible ways of adding four non-negative integers so that they add up to n, with order mattering, so that 0 +0 + 0 + n and n + 0 + 0+ 0 are both distinct possibilities. Could anybody point me towards some source for this? Thanks!  ",,False,,t5_2qj1c,False,,,True,t3_xf4kv,http://www.reddit.com/r/algorithms/comments/xf4kv/help_with_an_integer_partition_algorithm/,
1343213936.0,8,self.algorithms,x4jl0,Sieve of Eratosthenes : Help Translating this Article ,9,1,5,http://www.reddit.com/r/algorithms/comments/x4jl0/sieve_of_eratosthenes_help_translating_this/,"In [this Article](http://infoarena.ro/ciurul-lui-eratostene) the author gradually shows 5 version Sieve of Eratosthenes optimizing it at each step. I'm not familiar with the language (not programming language), and was hoping someone could explain each optimization in brief.

My Version (Euler Sieve storing only odd numbers) is about 300ms slower than the authors 5th version so I'm very interested in knowing the math behind it. :)

Google Translate was not very helpful. 

Thanks /r/algorithms ",,False,,t5_2qj1c,1343214230.0,,,True,t3_x4jl0,http://www.reddit.com/r/algorithms/comments/x4jl0/sieve_of_eratosthenes_help_translating_this/,
1336289773.0,8,uberpython.wordpress.com,t9gtk,Absolute Ratio,13,5,2,http://www.reddit.com/r/algorithms/comments/t9gtk/absolute_ratio/,,,False,,t5_2qj1c,False,,,False,t3_t9gtk,http://uberpython.wordpress.com/2012/04/28/introducing-absolute-ratio/,
1302669382.0,8,scientificamerican.com,got6q,Audio Alchemy: Getting Computers to Understand Overlapping Speech,11,3,0,http://www.reddit.com/r/algorithms/comments/got6q/audio_alchemy_getting_computers_to_understand/,,,False,,t5_2qj1c,False,,,False,t3_got6q,http://www.scientificamerican.com/article.cfm?id=speech-getting-computers-understand-overlapping,
1296854648.0,7,self.algorithms,ffft7,Can anyone walk me through the 3SUM Problem?,8,1,9,http://www.reddit.com/r/algorithms/comments/ffft7/can_anyone_walk_me_through_the_3sum_problem/,"I did this in class last year, but I've forgotten how to come to the solution:

&gt; Given a set S of n integers, are there elements a, b, c in S such that a + b + c = 0?

I don't want the answer, I just want some hints please :) 

First, I wonder, if I were asked this question in a phone interview, do you think the interviewer would mind if I sorted the list first?

I vaguely remember that in class we sorted the list, and I think we started with numbers on each end of the list, but I can't really remember much else.  ",,False,,t5_2qj1c,False,,,True,t3_ffft7,http://www.reddit.com/r/algorithms/comments/ffft7/can_anyone_walk_me_through_the_3sum_problem/,
1373387839.0,6,self.algorithms,1hxz2e,Shuffle/Permutation with local restrictions,8,2,14,http://www.reddit.com/r/algorithms/comments/1hxz2e/shufflepermutation_with_local_restrictions/,"Basically I want to shuffle array = {0, ... , n-1}, *but* I don't want array[i] - i to get larger than some constant. I have tried to alter the [Fisher-Yates shuffle](http://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle), but I can't manage to get a descent distribution of the elements.

The question is: what distribution is desirable in this case? For the usual shuffle, a uniform distribution over all permutations results in a uniform distribution of values in all positions of the array. However, this simple example shows that this is far from the case for a restricted shuffle.

Lets take array = {0, 1, 2} and restrict array[i] - i &lt;= 1. This results in three possible permutations:

{0, 1, 2}

{0, 2, 1}

{1, 0, 2}

Obviously the values/positions are not uniformly distributed. Does anyone know a way to generate permutations of this kind that results in a justifiable distribution?

EDIT: Sorry, I meant abs(array[i] - i) &lt;= C. I don't know if ppl understood it that way or not.",,False,,t5_2qj1c,1373459778.0,,,True,t3_1hxz2e,http://www.reddit.com/r/algorithms/comments/1hxz2e/shufflepermutation_with_local_restrictions/,
1372641439.0,6,self.algorithms,1hebqg,Closest Pair Algorithms for Streaming Data.,7,1,6,http://www.reddit.com/r/algorithms/comments/1hebqg/closest_pair_algorithms_for_streaming_data/,"This is in the context of Dynamic Clustering for Streaming data wherein we wish to find the closest cluster centroid for an arbitrary cluster centroid. Can anyone suggest suitable closest pair algorithms in that context ?

In fact, as a start point, what kind of typical structure would you use to store the nearest point for an arbitrary point in the streaming context, wherein points (cluster centroids and hence clusters) can be added or deleted depending upon a user-defined parameter to merge/delete clusters for such streaming data ?",,False,,t5_2qj1c,False,,,True,t3_1hebqg,http://www.reddit.com/r/algorithms/comments/1hebqg/closest_pair_algorithms_for_streaming_data/,
1371398142.0,7,self.algorithms,1ggj1p,"Count of the number requests in the last second, minute and hour.",12,5,5,http://www.reddit.com/r/algorithms/comments/1ggj1p/count_of_the_number_requests_in_the_last_second/,"Given a server that has requests coming in. Design a data structure such that you can fetch the count of the number requests in the last second, minute and hour.

Looks like common task, what is the best approach?",,False,,t5_2qj1c,False,,,True,t3_1ggj1p,http://www.reddit.com/r/algorithms/comments/1ggj1p/count_of_the_number_requests_in_the_last_second/,
1365818354.0,8,self.algorithms,1c8w7d,Guidance for Independent Project on Genetic Algorithms?,12,4,3,http://www.reddit.com/r/algorithms/comments/1c8w7d/guidance_for_independent_project_on_genetic/,"Hi everyone, I'm a high school junior looking to do a project on genetic algorithms. I'm planning on creating one that can be applied in the financial world and in the science world. Does anyone have some advice for potential topics of exploration in either field? Could anyone guide me to some sources that could show me the math involved in the process of creating the algorithm itself? Thanks!",,False,,t5_2qj1c,False,,,True,t3_1c8w7d,http://www.reddit.com/r/algorithms/comments/1c8w7d/guidance_for_independent_project_on_genetic/,
1364820297.0,8,self.algorithms,1bf2uu,Optimization Problem in a 2D grid,10,2,7,http://www.reddit.com/r/algorithms/comments/1bf2uu/optimization_problem_in_a_2d_grid/,"I have a grid that is, say, 200x20, as well as *n* points on that grid. Each of these *n* points has associated with it a number *c*, let's call it *c^i* for point *r^i*. I also have a function f(dist) = d * 0.5^(5*dist/range), where *d* and *range* are constant. What I want to find is a sequence of points of **minimum** length, let's call them *p^1* to *p^k*, so that for each *r^i* (i=1..n), the sum of all f(distance(p^j, r^i )) (j=1..k) is at least *c^i*.

Currently I have a not-so-great approximation where I evaluate for each point *p* on the grid the sum of f(distance(p, r^i )) (i=1..n) and choose the one for which this value is maximal. One run of this takes me ~3 seconds.

I'd be grateful for ideas how to do this!",,False,,t5_2qj1c,False,,,True,t3_1bf2uu,http://www.reddit.com/r/algorithms/comments/1bf2uu/optimization_problem_in_a_2d_grid/,
1359501942.0,6,self.algorithms,17iyed,How do I go about creating a probabilistic/statistical model?,9,3,4,http://www.reddit.com/r/algorithms/comments/17iyed/how_do_i_go_about_creating_a/,"I tried posting this to r/learnprogramming but it got downvoted and no one saw it.

I want to make an AI that will play, and hopefully win, Clue.

The idea I have is for the algorithm to track who has guessed what and how many times. I want to be able to ""draw conclusions"" that a card guessed multiple times is statistically more likely to be the answer but I don't know how to mathematically represent that.

In other words, if the computer has 2 of the 6 suspect cards, the remaining 4 cards have a 25% probability of being the culprit. But how would those percentages change as the other players guess them.

Along the same lines I also want to create a model of what cards each player might have. So if player 1 guesses ""Mr Green, with the knife in the billiard room"" and player 2 reveals a card to player 1, how would I mathematically represent the likelihood player 2 has each of those cards compared to the other players. Or say I know player 2 has the knife, how would I model the probability that he may or may not have shown the knife but instead one of the other 2 cards.

I appreciate the help.
",,False,,t5_2qj1c,False,,,True,t3_17iyed,http://www.reddit.com/r/algorithms/comments/17iyed/how_do_i_go_about_creating_a/,
1358811231.0,8,self.algorithms,170q10,Finding total amount of permutations between edges and nodes in a cycle,10,2,5,http://www.reddit.com/r/algorithms/comments/170q10/finding_total_amount_of_permutations_between/,"I am interested in the graph theory problem

if you have a cycle, how many ways can you rearrange the edges and nodes such that you still only have one cycle?

any discussion is welcome",,False,,t5_2qj1c,False,,,True,t3_170q10,http://www.reddit.com/r/algorithms/comments/170q10/finding_total_amount_of_permutations_between/,
1355863784.0,7,self.algorithms,152isa,Minimum Number Of Checks Between Debtors and Creditors,11,4,19,http://www.reddit.com/r/algorithms/comments/152isa/minimum_number_of_checks_between_debtors_and/,"A set of N people owe money/are owed money. The sum of the balances of all debtor and creditor accounts is zero. Some individuals may not owe or be owed anything. These people wish to pay each other in the minimum number of checks/balance transfers. What is the most efficient process for determining a minimal set of (V,D,C) (Value, Debtor Identifier, Creditor Identifier) triples required to zero the balances of all of the people involved?

Backstory for the interested:
This was a question that came up at work today. A group of 4 roommates were paying into a pool whose values depend upon some conditions they've established. Some will be owed money each week and some will owe money. For this subset we decided that there are 4 cases worth looking at:

* Case 1: No one owes anyone. Yay! 0 Checks.
* Case 2: Two individuals owe nothing and are owed nothing. Of the other two, one owes the other a value. 1 Check.
* Case 3: The values owed by two individuals match up with the values owed to the other two individuals. The individuals pay the values they owe to their match. 2 Checks.
* Case 4: Each individual owes a different amount summing to 0, but none with a match to another. The person who owes the most pays the person who owes the second most. That person pays the person who owes the third, and that person pays who owes the most. The cost of sorting is is about 3 steps. 3 Checks.

I'm sure I'm over complicating it but I thought it was a fun problem!",,False,,t5_2qj1c,False,,,True,t3_152isa,http://www.reddit.com/r/algorithms/comments/152isa/minimum_number_of_checks_between_debtors_and/,
1352470766.0,7,self.algorithms,12ww0x,does someone know what noise removal algorithm could be used here?,7,0,2,http://www.reddit.com/r/algorithms/comments/12ww0x/does_someone_know_what_noise_removal_algorithm/,"Hello,

I'm not sure if this is the right subreddit (also posted this is /math), but i couldn't think of a better one.

anyway i have 2 datasets. One raw set, and one which has been cleaned up quite a bit. see here:

http://imgur.com/a/gJWO3 

first i thought that they used some strange clipping method. so i decided to make a plot with color values in the raw data pic on x axis, color values from cleaned up pic on the y axis. it came out like this:

http://imgur.com/RPXb3 

So in that plot, the x value of a point is the color value of a pixel in the raw data, and the y value of every point is the color of the same pixel in the clean pic. i don't understand this. because this means that a color value of 0.5 in the raw data would sometimes be 0.05, sometimes 0.15, sometimes 0.25 in the clean pic, etc.

So i wonder if someone here has any idea's on the technique they could have used?",,False,,t5_2qj1c,False,,,True,t3_12ww0x,http://www.reddit.com/r/algorithms/comments/12ww0x/does_someone_know_what_noise_removal_algorithm/,
1345494575.0,7,self.algorithms,yji8x,[Question] ARIMA Coefficient Estimation Algorithms?,7,0,3,http://www.reddit.com/r/algorithms/comments/yji8x/question_arima_coefficient_estimation_algorithms/,"I am trying to make an ARIMA tool that you just specify p, q, and d and it calculates the coefficients for the ""best fit"" of some time series. An obvious first step is to get an ARIMA(p,0,q) model working, which is an ARMA model.

So far the order I am going here is AR -&gt; ARMA -&gt; ARIMA in my development of this. My AR model uses gradient descent to determine the coefficients and works quite well. I have also made a separate MA model as well using gradient descent and it works, but the minute it doesn't work is when I apply gradient descent to the combined ARMA model.

I am sure I am doing something wrong here, but I have little exposure to statistics and its literature so I am trying to find some good resources I can review to catch my mistake or to find a better algorithm. My background is in mathematics so I understand the language, but its been awhile so I need to review.

So far I have code that iterates forward on a time series. At each iteration it updates the model coefficients based on gradient descent. It then stores the error in the current ""prediction"" and then uses it for the future calculation. The time series has data coming in piece by piece hence the reason I used gradient descent. From the start as the series feeds in, I want the model to ideally stabilize to some set of coefficients and then not change these when the learning rate become insignificant or 0. It seems to be working as expected with just an AR model currently using ""toy"" stationary series, getting pretty good predictions overall with stable coefficients.

For the ARMA model, it breaks down. It may be as simple as not determining my learning rate correctly or poor initialization, or some other stupid mistake. I am a little stumped at the moment and want to take a step back to review literature for a bit before chugging forward.

Does anyone know of any good pseudo-code or some text that actually outlines procedures for determining coefficients in an ARMA model? So far I can only find items on using R or pre-existing packages for constructing these models but I am trying to code the under-the-hood items myself in C#. I don't need model order selection or assumption validation algorithms yet, as I am just writing a tool where you specify an ARIMA(p,d,q) model, then it determines a ""best"" fit to some arbitrary time series. I am using stationary series at the moment just to get an ARMA model to work but the ultimate goal is to have an ARIMA model and use it on non-stationary series.",,False,,t5_2qj1c,1345495514.0,,,True,t3_yji8x,http://www.reddit.com/r/algorithms/comments/yji8x/question_arima_coefficient_estimation_algorithms/,
1344348255.0,8,self.algorithms,xtn6h,Looking for an algorithm that can analyze overlaps and gaps in a set of N-dimensional intervals,11,3,8,http://www.reddit.com/r/algorithms/comments/xtn6h/looking_for_an_algorithm_that_can_analyze/,"Let's say I have an N-dimensional Euclidean space and M N-dimensional intervals. I want to answer two questions:

1. Are there any overlaps?
2. Do the intervals fill the whole space? (= are there any gaps?)

Since these intervals can be multidimensional, I'm basically talking about N-arity tuples of standard mathematical intervals. For example:
    
    N = 1     x=[0, 100]
    N = 2     x=(0, 100), y=[0, ∞)
    ...

The whole thing easiest to explain with N = 1, M = 2. For example, let's say we have these intervals:

    x=(-∞, 0)
    x=[0, ∞)

In this case there are no gaps or overlap, because each possible x value exists in one, and only one interval.

This one has a gap at x=0:

    x=(-∞, 0)
    x=(0, ∞)

This one overlaps at x=0.

    x=(-∞, 0]
    x=[0, ∞)

My intuition tells me that the algorithm should somehow ""merge"" intervals and if there are no gaps, the end result should be one N-dimensional interval that equals to the complete N-dimensional space.

For example, these (N=1, M=3):

    x=(-∞, 0)
    x=[0, 100)
    x=[100, ∞)

could be merged in a pair-wise manner to x=(-∞, ∞) which has no gaps. The algorithm can fail immediately during a merge if an overlap is detected.

The curse of dimensionality will probably destroy me once N gets large, but I'm hoping that there's some kind of algorithm that would help me as long as N is small! Sorry about the terminology. I'm not really a compsci or a math guy, so I don't really know the correct words for these things.

**Edit**

I'd like to point out that the algorithm must support arbitrary N values, so building versions manually for different N values is not acceptable.

So, basically I'm looking for something like this (in Scala):

    // None denotes infinity
    case class IntervalPart(leftOpen: Boolean, left: Option[Double], right: Option[Double], rightOpen: Boolean)
    // N-dimensional interval
    case class Interval(parts: IndexedSeq[IntervalPart])
   
    def hasOverlapsOrGaps(intervals: IndexedSeq[Interval]): Boolean = ...",,False,,t5_2qj1c,1344356155.0,,,True,t3_xtn6h,http://www.reddit.com/r/algorithms/comments/xtn6h/looking_for_an_algorithm_that_can_analyze/,
1343392254.0,8,self.algorithms,x8suf,Help in understanding/optimizing Aho Corasick pattern matching algorithm,9,1,11,http://www.reddit.com/r/algorithms/comments/x8suf/help_in_understandingoptimizing_aho_corasick/,"Hey Redditors; I know this maybe a big difficult, but I posted it here, hoping someone would have the time/desire to help me/others regarding this algorithm;

After a year or so from seeing it first time, I finally decided to go and implement Aho Corasick.

Its a multi pattern, single string matching algorithm: http://en.wikipedia.org/wiki/Aho%E2%80%93Corasick_string_matching_algorithm

I implemented it in C++, and I am pretty confident its correct, passed a sample UVA problem here: http://uva.onlinejudge.org/index.php?option=com_onlinejudge&amp;Itemid=8&amp;category=24&amp;page=show_problem&amp;problem=1620

However, my implementation seems to be pretty slow, and memory consuming. When I tried another problem here: http://acm.timus.ru/problem.aspx?space=1&amp;num=1269

My solution memory limited at test 7.

Basically what I am doing is constructing a trie which will hold the automaton.

Each node has pointers to every possible alphabet can come out of it. First I did a pointer for each node (node * e[255+1]) then switched to map&lt;char,node*&gt; e but the performance almost did not differ at all (unordered_map [hash table in C++] even gave worse performance).

Nodes include also the failure links [f], character on that node, and the pattern number it represents (-1 if no pattern).

I build the trie normally by inserting each keyword, then calculate the failure links by BFSing, for each node, I check if its parent failure link has that character, keep going all the way until I reach the root.

Here is my full code (for the solution of the first problem): http://ideone.com/zkDol

Apologies for the coding style, however I think the general approach itself is what needs to be optimized.

The best I got so far, was a paper in some chinese university, recommending to use a structure called double array trie, which would not need 256 [alpha size] elements per node, here: http://security.riit.tsinghua.edu.cn/mediawiki/images/d/d7/Stringmatch.pdf

[pages 7 and 19]

However, I feel that I do not truly get the idea behind it, and how to use it to solve Aho-Corasick [if even that is the correct way to optimize Aho-Corasick].

I am feeling sort of miserable\bulldozered because of this algorithm and the time it took from me, yet still failed to implement it ""professionally"".

I am sure any helpful and simple replies would be really appreciated by me and by all people seeking better understanding for that sort of obsecure field of string algorithms.

I am not an expert in string\bioinformatics algorithms by any means.

I understood the basic notation used, and the algorithm which said that we shift the pattern by the length of the largest suffix which is also a prefix, the same one used in KMP, and the basic idea and concepts behind an automaton.

But for the rest of the ""strings magic"" I am still far from an expert in it, so the simpler the explanation, the way more helpful it would be :)

Any advice for books/articles/courses would be as helpful as well of course.",,False,,t5_2qj1c,False,,,True,t3_x8suf,http://www.reddit.com/r/algorithms/comments/x8suf/help_in_understandingoptimizing_aho_corasick/,
1341519496.0,9,youtube.com,w3cs4,Bresenham's Line Drawing Algorithm Implemented in Minecraft,14,5,2,http://www.reddit.com/r/algorithms/comments/w3cs4/bresenhams_line_drawing_algorithm_implemented_in/,,,False,,t5_2qj1c,False,,,False,t3_w3cs4,http://www.youtube.com/watch?v=H7uclAqUmDw,
1335910974.0,6,self.algorithms,t288c,"Is there such a thing as dynamic programming that doesn't utilize memoization? If so, what does it consist of? If not, are they just the same thing?",10,4,7,http://www.reddit.com/r/algorithms/comments/t288c/is_there_such_a_thing_as_dynamic_programming_that/,"I took a whole algorithms course and I'm still a little fuzzy on exactly what differentiates dynamic programming in general from simple memoization. Do you only use memoization in ""top-down"" dynamic programming and not in ""bottom-up""? I'm still confused as to what the differences between top-down and bottom-up even are. Are these referring to the trees we're exploring? In top-down, we would start at the top of the tree, bottom-up at the bottom? (not even sure what it would mean to start at the bottom tbh) Any clarification is appreciated.",,False,,t5_2qj1c,False,,,True,t3_t288c,http://www.reddit.com/r/algorithms/comments/t288c/is_there_such_a_thing_as_dynamic_programming_that/,
1335302079.0,5,self.algorithms,sqld9,Would anyone like to work on Project Euler problems with me?,9,4,11,http://www.reddit.com/r/algorithms/comments/sqld9/would_anyone_like_to_work_on_project_euler/,"I know there is a r/projecteuler subreddit, but it is a ghost town so I'm posting this here. I am a senior in college so I have a lot of free time, most of which I spend solving Euler problems. I'm getting tired of not being able to discuss the problems with anybody. My usual friend is too busy writing his undergrad thesis. Is anyone interested in working on some of the more challenging problems with me? PM me if you're interested. Here are some example problems that I've had in the back of my mind but haven't gotten around to really trying to solve yet.

http://projecteuler.net/problem=361  
http://projecteuler.net/problem=369  
http://projecteuler.net/problem=339",,False,,t5_2qj1c,False,,,True,t3_sqld9,http://www.reddit.com/r/algorithms/comments/sqld9/would_anyone_like_to_work_on_project_euler/,
1332363225.0,9,self.algorithms,r7avw,What is the least number of coins to make any change from 1 to 99 cents,10,1,13,http://www.reddit.com/r/algorithms/comments/r7avw/what_is_the_least_number_of_coins_to_make_any/,"This has always bugged me, and I do not personally have the mathematical capabilities to figure this out on my own.

Edit:  for example lets say the answer is fifteen coins (for reference) not necessarily  using all coins at the same time can i make 87 cents 15 cents 24 cents 99 cents

You would need at least four pennies and one nickel i think

Thanks guys, i guess it really wasn't that hard after all haha",,False,,t5_2qj1c,True,,,True,t3_r7avw,http://www.reddit.com/r/algorithms/comments/r7avw/what_is_the_least_number_of_coins_to_make_any/,
1330877514.0,7,self.algorithms,qh8uj,Algorithm for anonymity in P2P networks,7,0,17,http://www.reddit.com/r/algorithms/comments/qh8uj/algorithm_for_anonymity_in_p2p_networks/,"Is there an algorithm that would combine M blocks of codified data to reproduce the original file (N blocks long, where N&lt;M) such that one cannot know which of the M blocks contributed to the final data and which were dummies? 

Some kind of convolution of the data blocks would mix their contents in such a way that the original data is recovered. However, some of the encoded blocks should be dummies - not really part of the content, and knowing which was which should be impossible or exponentially hard to deduct.

Having such an algo would help in the deniability of P2P downloads. One peer would ask for blocks pertaining to a desired file. However, some of the blocks received should be legal blocks of dummy data. Being impossible to decide which of the blocks were the content and which were the dummies, it would cast a shadow of doubt over the status of guilt of the peers one downloaded from.",,False,,t5_2qj1c,True,,,True,t3_qh8uj,http://www.reddit.com/r/algorithms/comments/qh8uj/algorithm_for_anonymity_in_p2p_networks/,
1320701681.0,6,self.algorithms,m3z7p,looking for an algorithm to identify contiguous / separate regions on a regular 3-D grid,7,1,8,http://www.reddit.com/r/algorithms/comments/m3z7p/looking_for_an_algorithm_to_identify_contiguous/,"I have sets of points on a 3-D regular grid.  Those points that are nearest neighbors to each other form contiguous regions, but I need an algorithm for identifying individual disconnected continuous regions.    This is frequently done in geo-image analysis to identify lakes, roads, etc.   Just curious what I should be reading to help me with this task.
  ",,False,,t5_2qj1c,False,,,True,t3_m3z7p,http://www.reddit.com/r/algorithms/comments/m3z7p/looking_for_an_algorithm_to_identify_contiguous/,
1304162382.0,6,newscientist.com,h0s69,A system for recognising a double entendre,10,4,1,http://www.reddit.com/r/algorithms/comments/h0s69/a_system_for_recognising_a_double_entendre/,,,False,,t5_2qj1c,False,,,False,t3_h0s69,http://www.newscientist.com/blogs/onepercent/2011/04/software-works-out-whether-tha.html,
1285943495.0,6,self.algorithms,dli86,Large Data Visualization/Compression,7,1,2,http://www.reddit.com/r/algorithms/comments/dli86/large_data_visualizationcompression/,"Back in the 80's I was working on compression algorithms for large (80's scale) data set (historical census data) - one approach that fascinated me was conversion of data to bitmap storage which then lead me to explore low-bit image embedding of data.  

Believing I stumbled upon something that could be exploited for nefarious purposes, I dropped my research in that area.  Time passed and I learned some years back that ""Steganography"" was something done in multiple variations in various mediums - one of which was data embedding.

Due to my background in GIS and interest in the cognitive sciences, I have leaned towards thematic/cloropleth style guides to disseminate records and their field values in order to provide spatial cues and peripheral relationships between the data being represented.

Not having kept up with various veins of data visualization over the past few years - what posts, papers and examples are out their today that demonstrate advances in data visualization for humans?  

Any ideas/examples/links would be appreciated.

TIA

edit: yeah, I am a Tufte fan but I like to see the symbolism AND the data ",,False,,t5_2qj1c,True,,,True,t3_dli86,http://www.reddit.com/r/algorithms/comments/dli86/large_data_visualizationcompression/,
1279818027.0,7,self.algorithms,csj5e,How does a search engine do spelling correction?,9,2,4,http://www.reddit.com/r/algorithms/comments/csj5e/how_does_a_search_engine_do_spelling_correction/,Do they have a graph for all the words possible with each letter being a node? Or do they just have multiple indexes for the dictionary? Does it differ if the application is Openoffice or Word?,,False,,t5_2qj1c,False,,,True,t3_csj5e,http://www.reddit.com/r/algorithms/comments/csj5e/how_does_a_search_engine_do_spelling_correction/,
1375751326.0,6,self.algorithms,1js3ko,Algorithm used GPS to read -30 dB signal?,8,2,8,http://www.reddit.com/r/algorithms/comments/1js3ko/algorithm_used_gps_to_read_30_db_signal/,"I had a short discussion about this on hacker news but nobody seems to know the answer. Apparently GPS units can receive a signal  -30 dB below the noise floor, in order to receive satellite signals from space. I haven't been able to find any information on the principles of this algorithm other than Wikipedia and such that say it exists in GPS systems. 

I found some journal papers that outlined several specific algorithms, with the Google search terms ""gps -30db signal algorithm"" (Without quotes) But I'm still curious what the mathematical concept or basis is for these algorithms that are able to extract the signal below the noise floor.

Perhaps this is the wrong subreddit, maybe /r/math?",,False,,t5_2qj1c,False,,,True,t3_1js3ko,http://www.reddit.com/r/algorithms/comments/1js3ko/algorithm_used_gps_to_read_30_db_signal/,
1374162729.0,5,self.algorithms,1ikcwp,"I am a Psychologist and want to get into Algorithms, where do I start?",10,5,22,http://www.reddit.com/r/algorithms/comments/1ikcwp/i_am_a_psychologist_and_want_to_get_into/,"So I am taking a new job that will concern itself, to a degree, with the analysis of data from social media sites and similar sources. I am a psychologist by training, and I want to get into Algorithms. I found the [""algorithm design manual""](http://www.amazon.de/Algorithm-Design-Manual-Steven-Skiena/dp/1848000693/ref=sr_1_4?ie=UTF8&amp;qid=1374161611&amp;sr=8-4&amp;keywords=algorithms) , has anyone heard of it, is it any good?

what i basically need to know is how one goes about designing algorithms, especially for computing behavioral data. The aim will be to make certain predictions from the data.

Any help is appreciated!


EDIT: Just to clarify, I will not do any hands-on programming. I am familiar with statistics on a graduate level of behavioral science. I am looking for conceptual information about how algorithms work, and what way best to think when helping to make one. I do know object pascal, so I have some basic understanding of how a program is set up. I am open to learning another programming language, as long as its not to time consuming.",,False,,t5_2qj1c,1374180703.0,,,True,t3_1ikcwp,http://www.reddit.com/r/algorithms/comments/1ikcwp/i_am_a_psychologist_and_want_to_get_into/,
1372372556.0,5,self.algorithms,1h7kao,Combinatorics with the octuply-linked list (the word search),7,2,8,http://www.reddit.com/r/algorithms/comments/1h7kao/combinatorics_with_the_octuplylinked_list_the/,"I have hacked up a solution to the common word search problem that is backed by an octuply-linked list of characters (each character has another character to its top, bottom, left, right, top-left, etc.).  I'm unfamiliar with time complexity, and would like to know if anyone could assist with the time complexity of this search algorithm. I will provide the search algorithm in a pastebin, and link the GitHub repo that contains the rest of the API calls I'm making (only 2 significant classes -- don't panic here).  Hopefully someone can help me. Cheers!

  Without further ado:

[search function pastebin](http://pastebin.com/547D6JUv)

[solution repository (github)](https://github.com/cannonpalms/Character-Maze)
 ",,False,,t5_2qj1c,False,,,True,t3_1h7kao,http://www.reddit.com/r/algorithms/comments/1h7kao/combinatorics_with_the_octuplylinked_list_the/,
1371009217.0,5,self.algorithms,1g69rx,Finding the bit position that most nearly splits an array of unsigned integers in half,10,5,27,http://www.reddit.com/r/algorithms/comments/1g69rx/finding_the_bit_position_that_most_nearly_splits/,"I have an array, call it&amp;nbsp;`A`, of 64-bit unsigned integers that I am treating as bitfields. I need to partition&amp;nbsp;`A` into two subarrays, called `low` and `high`, according to the bit at some position&amp;nbsp;`k`: all of the integers having a&amp;nbsp;0 at position&amp;nbsp;`k` go into `low`, and all of the integers having a&amp;nbsp;1 at position&amp;nbsp;`k` go into `high`. All of this I can easily do, given a value of&amp;nbsp;`k`.

What I want is to determine the position&amp;nbsp;`k` that will split&amp;nbsp;`A` as evenly as possible; I would like `low` and `high` to have nearly the same size.

Currently I am taking a very direct approach: I initialize an array called `count`, holding 64&amp;nbsp;integers, to&amp;nbsp;0. Then I loop through&amp;nbsp;`A`, and for each bit in this unsigned integer, if the bit is&amp;nbsp;1, I&amp;nbsp;increment the corresponding entry of `count`. Afterward I loop through `count` and see which position is closest to half the size of&amp;nbsp;`A`, and that's the value I use for&amp;nbsp;`k`.

I need to do this a lot, and my program runs too slow. Is there some slick bit-twiddling technique I could use to speed this up, so that I'm not looping over each unsigned integer 64&amp;nbsp;times?

===

EDIT: If it helps, I know that the elements of&amp;nbsp;`A` are distinct, but they are not sorted.",,False,,t5_2qj1c,1371021441.0,,,True,t3_1g69rx,http://www.reddit.com/r/algorithms/comments/1g69rx/finding_the_bit_position_that_most_nearly_splits/,
1370904797.0,6,self.algorithms,1g2u6b,Partial match on a dictionary of strings?,6,0,4,http://www.reddit.com/r/algorithms/comments/1g2u6b/partial_match_on_a_dictionary_of_strings/,"Say I have a dictionary with the words {'shot': 1, 'shots': 2, 'hot': 10, 'hotdogs': 14, 'hogs': 17}.

When I query with the word 'hot', I want to return 'shot', 'shots', 'hot', and 'hotdogs' along with the integer associated with each. Is there an algorithm for this that does not involve doing a substring match on each word or regex?",,False,,t5_2qj1c,False,,,True,t3_1g2u6b,http://www.reddit.com/r/algorithms/comments/1g2u6b/partial_match_on_a_dictionary_of_strings/,
1368712721.0,6,self.algorithms,1eg82q,Sorting right triangles. Does this algorithm have a name?,11,5,3,http://www.reddit.com/r/algorithms/comments/1eg82q/sorting_right_triangles_does_this_algorithm_have/,"We are given the 2D coordinates of a set of points, [; \mathbf{x}_i = (a_i, b_i), i=1 \dots n. ;]

Each pair of points produces a right triangle like in [this figure](http://i.imgur.com/D8x5uVi.jpg) (here for illustration I only chose pairs with (a_i,b_i)).

The aim is to find the minimum (or better, sort) angles opposite the vertical side of the right triangles, i.e.

[; \underset{i,j}{\textrm{min}} ~ \tan(\phi_{ij}) = \underset{i,j}{\textrm{min}} ~ \frac{b_i - b_j}{a_i - a_j} . ;]

A naive approach is to compute all n^2 angles and return the smallest one.

An [; \mathcal{O}(n + n \log n) ;] approach is to

* sort the b-coordinates, thus inducing a ""b""-*order* on the points. This takes [; \mathcal{O}(n \log n) ;] time.

* for every point i in the b-*order* compute *only* the angles [; \phi _{i,i-1} ;] and [; \phi _{i,i+1} ;]. So in total there are n-1 angles to compute.

I claim that this simple sweep yields the minimum desired angle. This relies on the (maybe not so obvious) statement:

If [;b_i &lt; b_j &lt; b_k ~ ;]  then  [; ~ \textrm{min}(\phi _{ij}, \phi _{jk}) &lt; \phi _{ik} ~ ;] , where [; \phi \in \[0, \tfrac{\pi}{2}\] ;] .

**Proof:**

The possible arrangements of a triplet (i,j,k) such that [;~ b_i &lt; b_j &lt; b_k;], correspond to the three cases:

a) [;~ a_i &lt; a_k &lt; a_j ;]

b) [;~ a_i &lt; a_j &lt; a_k ;]

c) [;~ a_j &lt; a_i &lt; a_k ;] ,

also visualised [here](http://i.imgur.com/KJC0Fm3.jpg). It can be easily checked that each of these cases satisfies the above statement. The cases are exhaustive, up to reflection wrt to the a or b axis, in which case the order of the angles within the triplet is preserved . □

Does this algorithm already exist, or is this a special case of a more general problem? I am not familiar with computational geometric methods. Thank you in advance!
",,False,,t5_2qj1c,1368784979.0,,,True,t3_1eg82q,http://www.reddit.com/r/algorithms/comments/1eg82q/sorting_right_triangles_does_this_algorithm_have/,
1366541890.0,6,self.algorithms,1csm1f,Gas station problem,10,4,6,http://www.reddit.com/r/algorithms/comments/1csm1f/gas_station_problem/,"I'm trying to solve the following question:


Given a list of gas stations on a single very long road, where each gas station in the list has only two pieces of info: distance from starting point and the amount of gas that it has for sale. You start with an initial amount of gas, G, and assume that your car can hold infinite gasoline. One unit of gasoline allows you to travel one unit of distance. When you refuel, you lose all previously held gasoline (cannot ""stack"" gas). Determine if you can make it to the last gas station on the list, if so find the minimum number of gas stops needed.

Example:

List: {11,31,100}
G = 10
Closest gas station from origin at distance 11 -&gt; no path possible



Attempt:

From your original limit G, calculate for each gas station, S, you can reach in G distance, distance(S) + amount(S) (*amount meaning how much gas you can buy from S). Choose the station with the greatest result and repeat. If no S is found, no path exists.


I'm not really sure if this is a valid solution. It seems to work for all test cases I can think of, though. How would I prove this correct?
",,False,,t5_2qj1c,1366544523.0,,,True,t3_1csm1f,http://www.reddit.com/r/algorithms/comments/1csm1f/gas_station_problem/,
1362419569.0,8,self.algorithms,19ndft,Line Arrangement and its Vertices,9,1,15,http://www.reddit.com/r/algorithms/comments/19ndft/line_arrangement_and_its_vertices/,"Hi! I've come here because I haven't found any answers anywhere else on Google.

My question comes from the Computational Geometry textbook, third edition, section 8.6, question 8.4.

&gt;Let L be a set of n lines in the plane. Give an O(n log n) time algorithm to compute an axis-parallel rectangle that contains all the vertices of A(L) in its interior.

I figured, technically, you could make an infinite rectangle and answer the question in O(1) time, but I'm pretty sure that's not the answer my prof is looking for. :P

I've considered turning the lines into dual points (we've been talking about dual points and line arrangements in class), but that doesn't seem to work any better for finding vertices than just comparing each line to every other line (O(n^2 ) time). Google hasn't found me anything better than O(n^2 ) time. I can't find an answer key for this book anywhere either.

A line sweep algorithm doesn't seem to work because that relies on the lines being segments with endpoints, which isn't a distinction ever made in the question. 

I can't think of anything else to consider. Can anyone else?",,False,,t5_2qj1c,False,,,True,t3_19ndft,http://www.reddit.com/r/algorithms/comments/19ndft/line_arrangement_and_its_vertices/,
1362348509.0,4,self.algorithms,19lkja,Target sum of lists algorithm,8,4,3,http://www.reddit.com/r/algorithms/comments/19lkja/target_sum_of_lists_algorithm/,"Hi. Can anyone help me with an algorithm that chooses predefined lists and adds them together to a target sum? So for instance I have N number of lists that are all of the same integer format:

    [15, 38, 72, 14, 3]
    [42, 12, 70, 30, 6]
    [32, 27, 14, 60, 15] 
    #you get the idea

I want to write a program that selects n number of N lists where each item in the list sums to a target item in a new list, [target0, target1, target2, target3, target4] within X degree of accuracy.

    list1[0] + list2[0] + ... listn[0] = target0
    list1[1] + list2[1] + ... listn[1] = target1
    #etc.

So let's say my goal is [315, 124, 326, 240, 96], but maybe the algorithm selects a certain number of lists that add up to [320, 124, 336, 243, 105], that's fine.

How do I efficiently implement selecting which lists to add together to reach the target list?

Any help is much appreciated!",,False,,t5_2qj1c,False,,,True,t3_19lkja,http://www.reddit.com/r/algorithms/comments/19lkja/target_sum_of_lists_algorithm/,
1362278335.0,4,self.algorithms,19k1cv,Question about writing a brute force closest pair algorithm ,8,4,6,http://www.reddit.com/r/algorithms/comments/19k1cv/question_about_writing_a_brute_force_closest_pair/,"So this is the assignment, 

'Extend the closest pair algoirthm to handle k-dimensional points. Write down pseudocode of the algorithm and estimate the time complexity, Big Oh, of your algorithm. You have N k-dimensional points and your algorithm will return the indices (index1, index2) of the closest pair. All the points are held in 'pts', which is a 2D array, with pts[i] representing the i th point and pts[i][j], representing the j th coordinate of the point (j goes from 0..k-1). Use the following prototype.'

**void ClosestPairKD(Points pts, int N, int index1, int index2){**

I really have no idea where to start on this, aside from maybe adding another for loop to the closest pair algorithm. Any ideas?
",,False,,t5_2qj1c,1362763093.0,,,True,t3_19k1cv,http://www.reddit.com/r/algorithms/comments/19k1cv/question_about_writing_a_brute_force_closest_pair/,
1360824696.0,8,self.algorithms,18i2sa,Question: How is it possible to analyze big data in sublinear time?,11,3,9,http://www.reddit.com/r/algorithms/comments/18i2sa/question_how_is_it_possible_to_analyze_big_data/,I saw that a course is being offered at MIT on this. I'm now curious about the algorithms.,,False,,t5_2qj1c,False,,,True,t3_18i2sa,http://www.reddit.com/r/algorithms/comments/18i2sa/question_how_is_it_possible_to_analyze_big_data/,
1360194305.0,7,self.algorithms,1814hv,Implementation of Binomial Cumulative Distribution Function,9,2,4,http://www.reddit.com/r/algorithms/comments/1814hv/implementation_of_binomial_cumulative/,"I was toying around on my TI-nSpire during Stats class and for fun wrote out the formula for a cumulative binomial like so:

x

∑     ( nCr(n, k) * p^k * (1-p)^n-k )

k=0

Where n is the number of trials, k is the max number of successes, p is the probability of success, and n is the max number of successes. Pretty standard.  I used this with fairly large values of n and x (about 500 and 250 respectively) and took my calculator about 1~2 seconds to spew out an answer.  However, when i just plugged in binCdf(500, .5, 0, 250), the same answer came immediately.  My question is this - what is the evidently more efficient algorithm that the calculator used?

**tl;dr** How do calculators do binomial cumulative distributions so efficiently?

*Edit: Formatting",,False,,t5_2qj1c,False,,,True,t3_1814hv,http://www.reddit.com/r/algorithms/comments/1814hv/implementation_of_binomial_cumulative/,
1356570436.0,6,self.algorithms,15ht3d,Trying to put students in groups in a class,7,1,3,http://www.reddit.com/r/algorithms/comments/15ht3d/trying_to_put_students_in_groups_in_a_class/,"So I put this in the Excel subreddit, but I have my doubts that's the tool I should be using. I'm an educator, and I have a class with twelve students in it. I want to put them in groups of three for each class, and I want to go as many classes as possible without them having the same groupmates. Furthermore, since each student has eleven classmates, I'd love it if, at the end of twenty two class meetings, they could have had each classmate as a group member four and only four times. If you know a way to accomplish this, I'd love a pointer, and if you know what subreddit would be a better place for this request, that would help me too.",,False,,t5_2qj1c,False,,,True,t3_15ht3d,http://www.reddit.com/r/algorithms/comments/15ht3d/trying_to_put_students_in_groups_in_a_class/,
1355730059.0,7,self.algorithms,14zgdg,Data structure to hold a list of rectangles on a discrete grid?,8,1,14,http://www.reddit.com/r/algorithms/comments/14zgdg/data_structure_to_hold_a_list_of_rectangles_on_a/,"I have a list of non-overlapping rectangles that are in a discrete space. (Each rectangle is made up of unit length squares that are aligned with one another. Thus a rectangle could be represented by integer x, y, width, and height.) I want an efficent data structure to hold them and to tell if a given integer x, y coordinate is contained in a rectangle. 

It would be easy to store the rectangles, I could just hash based on the lower left coordinates and store a width and height value. The problem is the hash lookup. If I look up a coordinate in the middle of a rectangle it will get an empty space. 

One naive solution is to just make a hash table of unit squares to cover the entire area of each rectangle, but for a large rectangle, say 100 by 100, this creates too many needless entries into the hash table.

Any thoughts?",,False,,t5_2qj1c,False,,,True,t3_14zgdg,http://www.reddit.com/r/algorithms/comments/14zgdg/data_structure_to_hold_a_list_of_rectangles_on_a/,
1354269955.0,7,self.algorithms,141oh7,Valid paths to visit all nodes in a random graph,11,4,10,http://www.reddit.com/r/algorithms/comments/141oh7/valid_paths_to_visit_all_nodes_in_a_random_graph/,"I've been looking into doing some procedural creation for quite some time now, and I came to realize that the only way for it to work was to calculate all the paths in a graph to find invalid ones.
For this to work, I need a fast permutation algorithm, and I can't find anything suitable.
For example, for the graph :

    A -- B
    |
    C -- D


What I am looking for is something that would find all the valid paths to visit all the nodes from A :

    ABCD
    ACBD
    ACDB


ABDC is invalid because there is no link between B and D without going through C.
ACBD is valid because C was already visited when we got to B, so D is a valid node to visit.
I am looking into something that can output the results for a 50 node graph with random connections...

And yes, I know there is a bajillion combinations for 50 nodes. I'd still want to be able to do it, and maybe optimize it for early rejection (based on some rules).",,False,,t5_2qj1c,False,,,True,t3_141oh7,http://www.reddit.com/r/algorithms/comments/141oh7/valid_paths_to_visit_all_nodes_in_a_random_graph/,
1353729773.0,8,self.algorithms,13p77p,Stuck in trying to prove a theorem about graphs.,9,1,7,http://www.reddit.com/r/algorithms/comments/13p77p/stuck_in_trying_to_prove_a_theorem_about_graphs/,"I was reading about randomized algorithms, and came across a randomized algorithm to find a subset of k nodes in a graph of n nodes, such that the number of edges in this subset is at least `[; m\frac{k(k-1)}{n(n-1)} ;]`, i.e. `[; m\frac{k \choose 2}{n \choose 2} ;]`, where m=number of edges in the graph. (An edge is said to be in the subset if it connects two nodes within the subset). However, that begs the question - how do we know such a subset always exists? I tried proving the claim using induction, but was stuck. Any suggestions?",,False,,t5_2qj1c,1353734572.0,,,True,t3_13p77p,http://www.reddit.com/r/algorithms/comments/13p77p/stuck_in_trying_to_prove_a_theorem_about_graphs/,
1351813041.0,6,self.algorithms,12hhxl,[Q] Why is this false? (Big O related),10,4,15,http://www.reddit.com/r/algorithms/comments/12hhxl/q_why_is_this_false_big_o_related/,"Hey everyone! I'm having a bit of trouble understanding why this is false. It was a question on my mid-term, I answered it right, but I couldn't justify it correctly, can someone elaborate for me? Here's the question.  
&gt; Consider f(n) = (log(n))^log(n) and g(n) = n^100^100, then f(n) is O(g(n))  

Thanks!",,False,,t5_2qj1c,False,,,True,t3_12hhxl,http://www.reddit.com/r/algorithms/comments/12hhxl/q_why_is_this_false_big_o_related/,
1349050831.0,7,arxiv.org,10qhij,[1209.5818] Fast Algorithms for the Maximum Clique Problem on Massive Sparse Graphs,8,1,0,http://www.reddit.com/r/algorithms/comments/10qhij/12095818_fast_algorithms_for_the_maximum_clique/,,,False,,t5_2qj1c,False,,,False,t3_10qhij,http://arxiv.org/abs/1209.5818,
1345918450.0,4,self.algorithms,ytc36,sports scheduling algorithm?,6,2,5,http://www.reddit.com/r/algorithms/comments/ytc36/sports_scheduling_algorithm/,"I play in a local sports league and I think it would be a fun project to write a program to make it easier to schedule the games.  It's a social league, so there is a wide variety of skills (not all teams are equal).  Also there is variety in what teams can play at what time of the night.  

I basically want to be able to define what team can play at each starting time, what each team's average score is, and who they have played before.  Then the program would do it's best to maximize the number of teams that get scheduled to play, minimize the avg point differentials between each set of playing teams (so that the good teams are more likely to play the good teams and the bad teams are more likely to play each other), and favor teams playing each other for the first time this season (to minimize the chances that you play the same team twice).  

I've tried to search for algorithms or examples of how to solve this and am having a very hard time finding reference material to solving this problem.  Can someone please help point me in the right direction in terms of what I should search for and where I can find some reference material to work off of?  ",,False,,t5_2qj1c,False,,,True,t3_ytc36,http://www.reddit.com/r/algorithms/comments/ytc36/sports_scheduling_algorithm/,
1344881514.0,7,self.algorithms,y5m4x,Placing objects into a minimum number of categories ,10,3,11,http://www.reddit.com/r/algorithms/comments/y5m4x/placing_objects_into_a_minimum_number_of/,"For a project I'm working on at my new job: suppose I have a set of objects, and a list if categories. For each object, I know whether it belongs to a particular category or not. What I need to be able to do is find the smallest subset of categories that encompasses every one of the objects. For example, suppose each object has a color and a shape. The naive way of going about this would be to find the biggest category, subtract it from the set and then repeat. This approach wouldn't work if 90% of the objects were square, but the remainder were many different shapes and colors and had to be represented by another three categories if I could have just grouped them into 33% red, blue and green from the start. I'm sure this problem has been solved already (or at least has an efficient algorithm for finding approximate solutions) but I'm note sure what it is called so I haven't been able to search for it. Anyone have any ideas? ",,False,,t5_2qj1c,False,,,True,t3_y5m4x,http://www.reddit.com/r/algorithms/comments/y5m4x/placing_objects_into_a_minimum_number_of/,
1339104961.0,6,self.algorithms,uqgsa,Efficient (Functional?) Dictionary/Set Representation,8,2,6,http://www.reddit.com/r/algorithms/comments/uqgsa/efficient_functional_dictionaryset_representation/,"I'm implementing dataflow analyses for my Ph.D. thesis (I work in compilers) and these require updating dictionaries and sets of values, as well as keeping versions of these dictionaries and sets for multiple points in the programs (basic blocks). I'm running into some performance issues because my current set representation is not very efficient.

Currently, I use a hash map representation. This allows fast O(1) insertion and deletion, but requires O(n) time for copying and equality testing (very problematic). It also means that my dictionaries and sets don't share any data, which can lead to large space usage as well. I got to thinking that there must be a better way to do this. Perhaps by representing sets as binary trees. Perhaps by sharing nodes between the trees in a functional manner (nodes are never mutated).

Dear r/algorithms, do you know of a way of representing sets/dictionaries that could give me say, O(log n) set union, comparison, as well as insertion and deletion?",,False,,t5_2qj1c,1339105664.0,,,True,t3_uqgsa,http://www.reddit.com/r/algorithms/comments/uqgsa/efficient_functional_dictionaryset_representation/,
1338379592.0,6,self.algorithms,ubzn3,Name for a kind of algorithm? (dealing with small changes to a graph or other dataset),7,1,5,http://www.reddit.com/r/algorithms/comments/ubzn3/name_for_a_kind_of_algorithm_dealing_with_small/,"I'm looking for the name for a kind of algorithm, one that deals with deltas to a set of data, such as a graph.  

For example, consider a large graph with sets of N nodes and M edges; I might compute the minimum spanning tree T on that graph.  Now, assume the sets of nodes and edges changes a little, N -&gt; N' and M -&gt; M'.   I might have an algorithm that can efficiently compute the new minimum spanning tree T' given T, N, N', M, and M'.   You can easily imagine all kinds of situations where this kind of algorithm would be useful with real-world changing data.

Do these kinds of algorithms have a common name?   I apologize if this is a stupid question, and thanks in advance to anybody who can point me to a good reference about them.",,False,,t5_2qj1c,False,,,True,t3_ubzn3,http://www.reddit.com/r/algorithms/comments/ubzn3/name_for_a_kind_of_algorithm_dealing_with_small/,
1334701631.0,8,self.algorithms,seyed,100 Matches,8,0,12,http://www.reddit.com/r/algorithms/comments/seyed/100_matches/,"On an expedition to the south pole, an explorer has to set out a sled from a base camp to a destined hut 70 miles away. When he gets there, he needs matches to light up the stove so as not to freeze.
The explorer is given a box of 100 matches by the manager of supplies. the matches are actually guaranteed from the manufacturer and will never fail. However, the manager of supplies is a mortal enemy of the explorer and the explorer is afraid that the manager has spoiled the matches in a manner undetectable except by trying to light them. All the explorer needs is one good match in the whole box. How does he test the matches before leaving so that his probability of dying is very small? (If the explorer finds the box defective, he can keep asking for new boxes until he receives one that passes his test) How small can you make the probability of error? (error = death)",,False,,t5_2qj1c,False,,,True,t3_seyed,http://www.reddit.com/r/algorithms/comments/seyed/100_matches/,
1330743944.0,4,self.algorithms,qff82,Can anyone explain what an algorithm is exactly to a layman?,11,7,10,http://www.reddit.com/r/algorithms/comments/qff82/can_anyone_explain_what_an_algorithm_is_exactly/,"I have a simple math background (no higher than algebra) but I am just curious. I tried wikipedia but still kind of hazy.

Anyone?",,False,,t5_2qj1c,False,,,True,t3_qff82,http://www.reddit.com/r/algorithms/comments/qff82/can_anyone_explain_what_an_algorithm_is_exactly/,
1322938959.0,5,self.algorithms,myx7c,Ask: algorithm to build one high-resolution image from many low-resolution images,7,2,10,http://www.reddit.com/r/algorithms/comments/myx7c/ask_algorithm_to_build_one_highresolution_image/,"If I take a low-resolution (say 320x240) video of a static scene, I end up with many low resolution images. Is there an algorithm and/or software that lets me build a single high-resolution image of the scene ? Let's ignore video compression artifact and sensor noise for now.


Here's my initial thought: if the camera didn't move at all, and is 100% noise free, then I get the same information in each video frame, so this become an image upscaling task.


But what if the cameras moves a little so the information in each video frame is slightly different, is there an algorithm to take advantage of this to build one high-resolution image of the scene ?",,False,,t5_2qj1c,False,,,True,t3_myx7c,http://www.reddit.com/r/algorithms/comments/myx7c/ask_algorithm_to_build_one_highresolution_image/,
1318341384.0,6,self.algorithms,l89r7,Sorting movies with multiple scores,6,0,5,http://www.reddit.com/r/algorithms/comments/l89r7/sorting_movies_with_multiple_scores/,"Hey, I'm looking for a algorithm for sorting a list of movies against each others scores. 

A movie can have a score reference to IMDb, Metacritic and Rottentomatoes. But some movies doesn't have all the references.

For example

* First movie: IMDb score (80%) and a Metacritic score (%80)
* Second movie: Just has a IMDb score (90%)
* Third movie: IMDb score (50%), Metacritic score (50%), and a Rottentomatoes score (50%)

The first movie might sort higher because it has two references that score 80% and second movie just has one reference that score 90%. The third movie sorts last because it has three bad scores. Etc.

Does anyone have an example of a sorting algorithm for this kind of scenario?",,False,,t5_2qj1c,True,,,True,t3_l89r7,http://www.reddit.com/r/algorithms/comments/l89r7/sorting_movies_with_multiple_scores/,
1268114026.0,6,reddit.com,bazod,Recursive call.,13,7,1,http://www.reddit.com/r/algorithms/comments/bazod/recursive_call/,,,False,,t5_2qj1c,False,,,False,t3_bazod,http://www.reddit.com,
1256201116.0,6,en.wikipedia.org,9wkr3,Pagerank - the key to Google's success,7,1,0,http://www.reddit.com/r/algorithms/comments/9wkr3/pagerank_the_key_to_googles_success/,,,False,,t5_2qj1c,False,,,False,t3_9wkr3,http://en.wikipedia.org/wiki/PageRank,
1371573612.0,5,self.algorithms,1gld51,I need some help with designing a search algorithm.,8,3,26,http://www.reddit.com/r/algorithms/comments/1gld51/i_need_some_help_with_designing_a_search_algorithm/,"I need a bit of help getting an algorithm into a better complexity. Im currently doing an iterative search, traversing two lists one item at a time (basically a nested loop). I think there might be a way to do this using trees, enabling a better bigO complexity and faster run time. However, I am having a hard time visualizing it.


I have a list of words to search for:

    a = [""foo"",""bar"",""baz"",""foobar"",""foobaz""]

And I have a list of sentences to search.

    b = [""the quick brown fox"", ""ran over barthe"", ""little brown dog"", ""foobaz is good""]


My current algorithm is looping over all the elements in a, and checking if that element exists in each element of b. If it exists, then it returns True and breaks, else it returns False and keeps checking. 

For this example, my output would be a list of booleans:

    output = [False, True, False, True]

Is there an algorithm with better complexity that can do this kind of search without using a nested loop? Can anyone point me in the right direction?


edit: By the way, I am using this algorithm on a very large set of sentences (more than 50 million unique sentences) with a list of about 100 words. My current runtime is around 90 minutes.",,False,,t5_2qj1c,1371574862.0,,,True,t3_1gld51,http://www.reddit.com/r/algorithms/comments/1gld51/i_need_some_help_with_designing_a_search_algorithm/,
1370561875.0,5,self.algorithms,1ftsca,Looking for an algorithm designer for work on a project. Any help?,12,7,7,http://www.reddit.com/r/algorithms/comments/1ftsca/looking_for_an_algorithm_designer_for_work_on_a/,"Hello /r/algorithms readers! I'm working on a mobile project where I need to have someone create a ranking algorithm as a part of the app.

The challenge is that I can't seem to easily find programmers who also have very deep backgrounds in mathematics - I've spoken with a few different groups who assure me they can all create awesome algorithms, but none of them can supply any specific details.

That said, I'm looking for anyone here who has actual experience in creating algorithms and is looking for side work, or knows of the right direction to look in. I've already tried a few different avenues, and after no luck scraping the bottom of the barrel at elance I figured I'd try here.

PM for details.

Thanks!",,False,,t5_2qj1c,False,,,True,t3_1ftsca,http://www.reddit.com/r/algorithms/comments/1ftsca/looking_for_an_algorithm_designer_for_work_on_a/,
1369842604.0,5,self.algorithms,1f9vht,Calculate the Quartiles of an Unordered List of Integers Iteratively (without sorting)?,6,1,8,http://www.reddit.com/r/algorithms/comments/1f9vht/calculate_the_quartiles_of_an_unordered_list_of/,"Is there an algorithm to do this? If there is, how does it compare in terms of efficiency to sorting? Obviously once it's sorted, it's just calling the appropriate indexed values and pulling your values (interpolating if necessary).

I'm sorting right now and I was just curious if this is the best/only way to do it! It would be really neat if there was a single-pass way to calculate the quartiles without sorting.",,False,,t5_2qj1c,False,,,True,t3_1f9vht,http://www.reddit.com/r/algorithms/comments/1f9vht/calculate_the_quartiles_of_an_unordered_list_of/,
1369353886.0,3,self.algorithms,1extcc,Ranking algorithms for nodes with subnodes?,8,5,4,http://www.reddit.com/r/algorithms/comments/1extcc/ranking_algorithms_for_nodes_with_subnodes/,"Hi, I am working on a site where there are nodes that users can vote on (upvotes/downvotes). Each node has a list of subnodes. Users can vote on each of these subnodes as well. Think of the relationship between posts and comments on reddit.

What ranking algorithms are there that will help me sort nodes based on their own score as well as the score of their subnodes? I've looked at the reddit ranking algorithm for ""hot"" but unfortunately I don't see how i would factor in subnode ranking.",,False,,t5_2qj1c,False,,,True,t3_1extcc,http://www.reddit.com/r/algorithms/comments/1extcc/ranking_algorithms_for_nodes_with_subnodes/,
1368870897.0,6,self.algorithms,1ekjnr,Minimum cost to select at least k nodes of a tree.,9,3,11,http://www.reddit.com/r/algorithms/comments/1ekjnr/minimum_cost_to_select_at_least_k_nodes_of_a_tree/,"You've got a tree with *n* nodes. Each node has a cost associated with it. You can select a node, in which case you incur that node's cost, but all of its descendants get automatically selected for free. Find the minimum cost to select at least *k* nodes, *k* &lt; *n*.

I got this in a contest today and couldn't think of a solution. If the tree is binary, I have an O(n^3 ) DP solution where the subproblem is ""what's the minimum cost to select *j* nodes in the subtree rooted at *m*"", but it doesn't translate nicely to a general tree. I also had the vague notion for a knapsack-y idea across the children of each node (same subproblem as above but a much trickier recurrence), but I didn't explore that.",,False,,t5_2qj1c,False,,,True,t3_1ekjnr,http://www.reddit.com/r/algorithms/comments/1ekjnr/minimum_cost_to_select_at_least_k_nodes_of_a_tree/,
1368711323.0,4,self.algorithms,1eg6pk,"calculate ""best"" price among list of prices",7,3,6,http://www.reddit.com/r/algorithms/comments/1eg6pk/calculate_best_price_among_list_of_prices/,"Hey folks,

I'm a software developer and my current goal is to find a neat way to calculate the best price for a product among a list of different prices available for that specific product. I thought about how to do that and I **could** find a way to solve this with a lot of if's and else's and so on, but maybe there's a better solution by using some mathematics (I'm not good at that, unfortunately).

Scenario: Let's say I offer some kind of product for sale. I have competitors, who sell this product as well, but for different prices than I do. Every seller offers the same pre-defined sets of amounts for this product (100 packs, 500 packs, etc.).

I gathered all the data I need (all prices), now I want to find out what would be the best price for me to offer this product for.

There are several rules that apply for the calculation though: I do not necessarily want to be the cheapest seller everytime, I want to find the most profitable price for my product. In other words:

* if 1 or more of the competitors are **too** cheap, I don't want to go lower than them, but instead look for the next cheapest ones (this can be the 2nd or 3rd or even 4th cheapest of them).

* if I'm the cheapest among all of them, I want to increase my prices, but still stay cheapest (1 cent cheaper than 2nd cheapest).

* if there are 6 sellers for 1 product, and 1 is very cheap, while the 5 others (including me) offer for pretty similar prices, I only want to beat the other 4 so that I can become 2nd cheapest without going down with the price too much. It's like a ""how much positions can I go up and how much does that cost me?""-calculation. I need an algorithm that calculates the best position for the best price.

[Here's a table in Google docs with examples](https://docs.google.com/spreadsheet/ccc?key=0AmYCWqNdQEBmdFJzVEhWdlNiWUlZa25odUEwbXlweGc#gid=0)

The ""best price"" column contains the price I want to sell this product for (calculated manually), so this is the value I want to get in the end.

All I'm actually asking for is if this can be done relatively easy with some math calculations, or if I have to stick with my ""by foot""-solution.",,False,,t5_2qj1c,False,,,True,t3_1eg6pk,http://www.reddit.com/r/algorithms/comments/1eg6pk/calculate_best_price_among_list_of_prices/,
1366352926.0,3,self.algorithms,1cnyj3,Need help finding a generating function for permutations of a set of nonunique elements,6,3,4,http://www.reddit.com/r/algorithms/comments/1cnyj3/need_help_finding_a_generating_function_for/,"I'm looking for a bijective function from {1,2,...,n} to the set of permutations of an array with nonunique elements. The array is a multiset consisting of x zeros and y ones. The number of permutations is n=(x+y)!/x!y!. I need the function to be in closed form from {1,2,...,n} to the permutations, but I don't need it to be closed the other way. Any help would be appreciated. ",,False,,t5_2qj1c,False,,,True,t3_1cnyj3,http://www.reddit.com/r/algorithms/comments/1cnyj3/need_help_finding_a_generating_function_for/,
1364578331.0,5,self.algorithms,1b93yh,Understanding recursive calls on paper,10,5,12,http://www.reddit.com/r/algorithms/comments/1b93yh/understanding_recursive_calls_on_paper/,"I'm having a bit of trouble visualizing recursive function calls on paper. For example the following code prints all combinations of an input string:

    void combination(String inputString, StringBuilder output, int index) {
        for(int i = index; i &lt; inputString.length(); i++) {
            output.append(inputString.charAt(i));
            System.out.println(output);
            // combination(inputString, output, index + 1);
            combination(inputString, output, i + 1);
            output.deleteCharAt(output.length() - 1);
        }
    }

if I call:

    combination(""abc"", new StringBuilder(), 0);

I get the following output:

    a
    ab
    abc
    ac
    b
    bc
    c

I'm trying to write down the function call stack on paper to understand how this recursion works. But I always forget where the last recursive call was, what the values of the parameters were, and where the function goes back on the return statement.  

I need some way to run through recursive calls on paper that will help me keep track of the function calls, parameter values, and returns.  

For example, for the following function:

    int sumValues(int[] array) {
        int sum = 0;
        for(int i = 0; i &lt; array.length; i++) {
            sum += array[i];
        }
        return sum;
    }

To understand how it works, I would write it on paper like this:

    array = {1, 3, 5, 7}

|i       | array[i] | old sum     | new sum|
|:------:|:----------:|:---------------:|:------------:|
| 0     |          1|     0           |   1
| 1     |          3|  1              | 4   
| 2     |        5  |   4             | 9
| 3     | 7         |      9          | 16  

    return sum = 16  

How do I do this for recursive functions?  

**Edit:** Added output of combination function.  
**Edit2:** Fixed bug in combination function.",,False,,t5_2qj1c,1364603369.0,,,True,t3_1b93yh,http://www.reddit.com/r/algorithms/comments/1b93yh/understanding_recursive_calls_on_paper/,
1363061458.0,6,self.algorithms,1a4nnj,"More of a data structure question, really...",9,3,8,http://www.reddit.com/r/algorithms/comments/1a4nnj/more_of_a_data_structure_question_really/,"I have a project in mind that essentially creates a round robin tournament. Each person in the array needs to have an intersection with all the other persons. At the intersection, I can have a pointer or something like it that has the details of the relationship.

Being able to add people to the list would be essential, removing people from the list would be nice.

Web Based would add additional convenience, but I can work around that.

So, on to the real question: Is there an elegant way to do this? A database relationship or an oddly shaped linked 'list' mesh? I'm willing to experiment with different languages and the like, but I'm not sure I have the best coding background to see the simplest way.

If worst comes to worst, I'll over-caffinate and get a bit woozy from too many dry erase markers on one board. It's worked before, but its rarely as efficent as some learned scholar who already did something similar... 
",,False,,t5_2qj1c,False,,,True,t3_1a4nnj,http://www.reddit.com/r/algorithms/comments/1a4nnj/more_of_a_data_structure_question_really/,
1362426821.0,5,self.algorithms,19nmpp,Representing multiple paths between a pair of vertices as a graph with minimal space,7,2,4,http://www.reddit.com/r/algorithms/comments/19nmpp/representing_multiple_paths_between_a_pair_of/,"I have an algorithm for large graphs which finds all shortest paths from a source node to the rest of the graph G (assuming G is connected). The diameter of the graph is small, usually less than 10. I compute the shortest paths using BFS because the graphs I currently work on are non-weighted. Now here is my question:

Assume the source node is A and the target node is G and I computed the following shortest paths between A and G:

    A --&gt; B --&gt; D --&gt; F --&gt; G

    A --&gt; C --&gt; D --&gt; F --&gt; G

    A --&gt; C --&gt; D --&gt; E --&gt; G

    A --&gt; B --&gt; D --&gt; E --&gt; G


If we make a union of all these paths, here is how the induced sub-graph looks like:

            A
          /    \
        B       C
         \     /
            D
          /    \
        E       F
         \    /
           G

I would like to represent this graph using as small space as I could. Initially I thought about using the adjacency list representation and compressing the neighbors of a node using some known algorithms but then I came up with the idea of representing it using paths again. For example, the above sub-graph can be represented by only two of paths as:

    A --&gt; B --&gt; D --&gt; F --&gt; G    and
    A --&gt; C --&gt; D --&gt; E --&gt; G

which requires keeping only 10 vertices. On the contrary, without compressing the neighbors, the adjacency list representation would look like:

    A:    B,C
    B:    D
    C:    D
    .
    .
    etc

and would require 14 vertices. 


So without compression, representing the induced sub-graph using the paths themselves may require keeping less vertices (though I haven't done any analysis yet). 


I have been looking at algorithms books to see a similar problem and potential solutions but so far all I found is related to representing graphs in general. I have a feeling that this special type of induced sub-graph starting and ending with the same pair of vertices and having paths of the same length with intermediate vertices in common can be exploited in some way to reduce the space. My path union idea is just one and I am wondering if anyone has seen anything similar to this. 


I'd really appreciate any input. I have been stuck for a few days, going through algorithms books and papers with not much luck so far.",,False,,t5_2qj1c,1362427184.0,,,True,t3_19nmpp,http://www.reddit.com/r/algorithms/comments/19nmpp/representing_multiple_paths_between_a_pair_of/,
1358261541.0,5,self.algorithms,16mb65,Help with an algorithm to return ranks of an array (using average ranks for ties),7,2,6,http://www.reddit.com/r/algorithms/comments/16mb65/help_with_an_algorithm_to_return_ranks_of_an/,"I've been trying to write an algorithm (or find one online) that will take an array of floats and return an array of the ranks corresponding to each element of that array. I'd like it to return the average of the appropriate rank in the case of ties, such that:

rank([2, 5, 19, 3, 9, 3]) = [1, 4, 6, 2.5, 5, 2.5]

It doesn't matter if they are ranked ascending (like the example) or descending. 


I know that R has a function to do this, but it is internal and I can't find the source code for it. Anyway, I'd like to do this in C, so I won't have access to R's sort function either. 

Alternatively, if there already exists such functionality in C, I'd be very happy to hear that, too!

Any help out there? 

",,False,,t5_2qj1c,False,,,True,t3_16mb65,http://www.reddit.com/r/algorithms/comments/16mb65/help_with_an_algorithm_to_return_ranks_of_an/,
1354966159.0,6,self.algorithms,14htgi,"Shortest path that travels along every edge of a grid at least once, starting from a corner",7,1,7,http://www.reddit.com/r/algorithms/comments/14htgi/shortest_path_that_travels_along_every_edge_of_a/,"So I have a grid of variable width and height (both &gt;= 1). For example, here's a 3x2 one.

     ____ ____ ____ 
    |    |    |    |
    |____|____|____|
    |    |    |    |
    |____|____|____|

Starting from any corner, I wish to find the shortest path that travels along every edge at least once. It does not have to end anywhere in particular, it just needs to have travelled every edge.

I've spent a while reading about these sort of optimisation problems but I can't find one applicable to a problem like this; the closest I've found is Hamiltonian paths which hit every *vertex* of a graph rather than edge, and they're hit *exactly* once rather than *at least* once. Also, this problem has the additional conditions of always being a grid and always starting at a corner, which I hope might make it easier to solve.

I'm not sure where else to go from here, does anyone know where I should be looking to come up with an algorithm to find this path for a variable sized grid? Even if I can't find the absolute shortest path in a reasonable amount of time, being able to come up as close to that as possible would suffice.",,False,,t5_2qj1c,False,,,True,t3_14htgi,http://www.reddit.com/r/algorithms/comments/14htgi/shortest_path_that_travels_along_every_edge_of_a/,
1345428833.0,4,self.algorithms,yi2qi,"Selection without replacement, with weights. or, Questions on probabilistic algorithms performance.",5,1,11,http://www.reddit.com/r/algorithms/comments/yi2qi/selection_without_replacement_with_weights_or/,"*The problem:*

I have a set of things, size n. Each one has an associated weight, or probability of being picked. I have a fixed number of things I'm going to pull, m. m is typically a lot smaller than n [like, 1/10th]. FWIW, this is Java. [for interest, m is actually the sum of the weights]

*Solution 1:*
[This is the ""obvious, correct"" one]

Put everything into a list. I used an ArrayList. Run across the list and sum the weights into a ""totalVal"". Roll the dice to pick a number in the range 0..totalVal. Run across the set with an accumulator [O(n)] and remove the one that falls on the number [O(n)]. Total time, O(m*(n^2)).

*Solution 2:*
[This is a performance improvement, but I'm unsure the clarity of code was worth the gain]

Do the same thing as before, but modify ""remove"" to be ""swap with the one at the end of the list"". Time O(m*n), since ""removal"" just became O(1).

*Solution 3:*

This one is probabilistic in performance, so I don't know how to analyze if it's actually better. First, in the same pass as I previously calculated totalVal, I store an accumulator on the set items themselves. Now it's easy to do a O(log(n)) algorithm to find the thing I'm looking for each time I roll a dice. Obviously naive removal is going to be O(n) as I have to iterate across the entire list to fix the iterator. O(m*n*log(n)), not as good as the one before.

So, the real difference is that I now do accept/reject. Rather than actually remove an item from the list, I just tag it as having previously been selected. The performance of this is O(m * log(n)) assuming I get no rejections. If I have selected an item that has previously been drawn, then I reject the roll and try again.

Solution 3 is faster in practice by wallclock, when I try it. But I don't know how to analyze this to figure out what point it's better or worse. For example, if n==m, that's gonna be obviously some awful performance. If m is 1, it'll be zippyfast.

*TL;DR:* If an algorithm is O(m*n), is that better or worse than O(m*log(n)) if there's some probability of rejection? Should I put a branch in my code based on the relative size of m and n?",,False,,t5_2qj1c,1345434177.0,,,True,t3_yi2qi,http://www.reddit.com/r/algorithms/comments/yi2qi/selection_without_replacement_with_weights_or/,
1343800601.0,5,self.algorithms,xhrjp,"For NP problems, what does it mean if an algorithm is ""verifiable""?",7,2,5,http://www.reddit.com/r/algorithms/comments/xhrjp/for_np_problems_what_does_it_mean_if_an_algorithm/,"Does verifiable mean it works? But if it's already polynomial, doesn't the algorithm already have to work to get that far?",,False,,t5_2qj1c,1343801065.0,,,True,t3_xhrjp,http://www.reddit.com/r/algorithms/comments/xhrjp/for_np_problems_what_does_it_mean_if_an_algorithm/,
1342546462.0,6,self.algorithms,wpltp,Is there a good site out there that teaches/explains how to find the time efficiency of sorting functions/algorithms?,8,2,7,http://www.reddit.com/r/algorithms/comments/wpltp/is_there_a_good_site_out_there_that/,,,False,,t5_2qj1c,False,,,True,t3_wpltp,http://www.reddit.com/r/algorithms/comments/wpltp/is_there_a_good_site_out_there_that/,
1342144210.0,5,self.algorithms,wh5cq,Rete Algorithm,9,4,2,http://www.reddit.com/r/algorithms/comments/wh5cq/rete_algorithm/,"I'm a little confused at this, so bear with me.

As a high level concept, it essentially breaks down the facts into classes or types, say countries and species, then evaluates this sub facts to determine the possible outcomes of input per type, and then joins the types back together for possible outcomes. 

Any explanations on this would be appreciated... I'm still reading a lot about it, but need to just think...

Basically, I need a BRE for a future project, which can evaluate possibly thousands of rules at a time, efficiently. Any other algorithms I should be aware of?",,False,,t5_2qj1c,False,,,True,t3_wh5cq,http://www.reddit.com/r/algorithms/comments/wh5cq/rete_algorithm/,
1339677159.0,4,math.mit.edu,v1jzl,Set Cover Problem,8,4,1,http://www.reddit.com/r/algorithms/comments/v1jzl/set_cover_problem/,,,False,,t5_2qj1c,False,,,False,t3_v1jzl,http://math.mit.edu/~goemans/18434S06/setcover-tamara.pdf,
1338939628.0,6,self.algorithms,umyng,Good know of a good site with algorithm questions and answers?,9,3,1,http://www.reddit.com/r/algorithms/comments/umyng/good_know_of_a_good_site_with_algorithm_questions/,"Those I've found have been mostly in the form of interview and not been relevant to what I'm looking for. I'm interested in questions regarding running time of algorithms, various sorting methods, data structures like heaps and binary trees ( but not anything about their implementation ) and dynamic programming. Essentially basic algorithm theory. ",,False,,t5_2qj1c,False,,,True,t3_umyng,http://www.reddit.com/r/algorithms/comments/umyng/good_know_of_a_good_site_with_algorithm_questions/,
1319344064.0,5,homebrewcode.blogspot.com,llq5k,Simple algorithms to solve linear equations systems with two and three variables (Near the middle of the post).,13,8,15,http://www.reddit.com/r/algorithms/comments/llq5k/simple_algorithms_to_solve_linear_equations/,,,False,,t5_2qj1c,False,,,False,t3_llq5k,http://homebrewcode.blogspot.com/2011/10/iphone.html,
1317228966.0,5,self.algorithms,ku8o0,FFTW3 - What does the the 'imaginary' part mean of fftw_complex?,6,1,13,http://www.reddit.com/r/algorithms/comments/ku8o0/fftw3_what_does_the_the_imaginary_part_mean_of/,"I am using FFTW3 to convert my mic input to frequencies real time. I want to recognize the notes that are being played by my piano connected to my mic mic input. 
So far so good, I'm not there yet but it coming along. I can't help but wondering what the imaginary part means of FFTW3. This is what it says in the [documentation](http://www.fftw.org/doc/Complex-numbers.html): 
&gt; The default FFTW interface uses double precision for all floating-point numbers, and defines a fftw_complex type to hold complex numbers as:
     typedef double fftw_complex[2];
Here, the [0] element holds the real part and the [1] element holds the imaginary part.   

So, why an imaginary part? 
I am also wondering: What is the scale of the real part, is there a max? What is my reference for loud or soft in this case? Help is greatly appreciated!",,False,,t5_2qj1c,False,,,True,t3_ku8o0,http://www.reddit.com/r/algorithms/comments/ku8o0/fftw3_what_does_the_the_imaginary_part_mean_of/,
1295895717.0,6,self.algorithms,f882q,Geographic Information Interpolation?,6,0,5,http://www.reddit.com/r/algorithms/comments/f882q/geographic_information_interpolation/,"I have been investigating interpolation algorithms and the descriptions and algorithms all seem to be oriented around the unit square. 

This is great if you're resizing an image, but my application is for GIS data, in which my data points won't be provided in an even grid. I may have a rectangular region for which I have (say) 17 randomly distributed data points.  What would be the recommended approach for interpolating using the given data? ",,False,,t5_2qj1c,False,,,True,t3_f882q,http://www.reddit.com/r/algorithms/comments/f882q/geographic_information_interpolation/,
1284548872.0,4,csinsider.homeip.net,de4n6,Algorithms and Data Structures: A general description and code,7,3,0,http://www.reddit.com/r/algorithms/comments/de4n6/algorithms_and_data_structures_a_general/,,,False,,t5_2qj1c,False,,,False,t3_de4n6,http://csinsider.homeip.net/index.php/CSCI115,
1374656902.0,3,self.algorithms,1iy2jp,How do I quickly show and reason over the complexity of an algorithm in an exam?,7,4,6,http://www.reddit.com/r/algorithms/comments/1iy2jp/how_do_i_quickly_show_and_reason_over_the/,My problem is not that I don't understand it. Its more that I don't know how to picture how I came to the conclusion that for example binary search is O(log n). There is a piece of code given.,,False,,t5_2qj1c,False,,,True,t3_1iy2jp,http://www.reddit.com/r/algorithms/comments/1iy2jp/how_do_i_quickly_show_and_reason_over_the/,
1373914007.0,3,reddit.com,1icunn,Where can I find an implementation of the Kameda-Weiner algorithm for NFA reduction? [x-post from /r/compsci],6,3,0,http://www.reddit.com/r/algorithms/comments/1icunn/where_can_i_find_an_implementation_of_the/,,,False,,t5_2qj1c,False,,,False,t3_1icunn,http://www.reddit.com/r/compsci/comments/1icumb/where_can_i_find_an_implementation_of_the/,
1371273073.0,5,rerun.me,1gdwcf,Quicksorting - 3-way and Dual Pivot,5,0,0,http://www.reddit.com/r/algorithms/comments/1gdwcf/quicksorting_3way_and_dual_pivot/,,,False,,t5_2qj1c,False,,,False,t3_1gdwcf,http://rerun.me/blog/2013/06/13/quicksorting-3-way-and-dual-pivot/,
1370388921.0,4,self.algorithms,1fopdh,Efficiently partition a set of rectangles into subsets each of which consists of disjoint rectangles.,6,2,12,http://www.reddit.com/r/algorithms/comments/1fopdh/efficiently_partition_a_set_of_rectangles_into/,"I have a set R of axis-aligned rectangles in the plane, and I want to partition this set R into subsets R1, ..., Rk such that each individual set Ri contains non-overlapping rectangles.

My notion of ""partition"" here is slightly weaker than normal; I require that every rectangle r in R occurs in some Ri, but I do not require the sets R1, ..., Rk themselves to be pairwise disjoint.

I'm looking for something better than brute-forcing it. The approach I currently have is inefficient. I exhaustively build a table which maps each rectangle r in R onto a list of all other rectangles in R which it overlaps. I prune from this list those rectangles which do not overlap any other rectangles.

Now I make a pass over the list. If there are any conflicts within the list, I create a new list and move the offenders to that list. I recursively process the new list in this manner until no conflicts are found. This ultimately produces such a partition as desired above.",,False,,t5_2qj1c,False,,,True,t3_1fopdh,http://www.reddit.com/r/algorithms/comments/1fopdh/efficiently_partition_a_set_of_rectangles_into/,
1369711870.0,4,self.algorithms,1f6ft9,"Can I start learning about algorithms, or should I review discrete math first?",10,6,6,http://www.reddit.com/r/algorithms/comments/1f6ft9/can_i_start_learning_about_algorithms_or_should_i/,"I took a Discrete Mathematics course this semester and struggled through the material. I actually did great on exams covering propositional logic, number theory, and mathematical induction. But I did horrible on the exams covering set theory, functions, and graph theory. I admit that I could have studied more, but the exams were also very difficult.

I'd like to learn algorithm design and analysis this summer, specifically by working through ""Introduction to Algorithms"" and watching the MIT OCW lecture videos. I'd like to know if I should go back and review discrete math topics in which I was weak in, or if I can start learning about algorithms. A lot of people say algorithm design and analysis requires a mastery of math, so I'm a bit intimidated to start.",,False,,t5_2qj1c,False,,,True,t3_1f6ft9,http://www.reddit.com/r/algorithms/comments/1f6ft9/can_i_start_learning_about_algorithms_or_should_i/,
1364948262.0,5,scribegriff.com,1bjxl4,Collections in Dart: The Directed Graph,7,2,0,http://www.reddit.com/r/algorithms/comments/1bjxl4/collections_in_dart_the_directed_graph/,,,False,,t5_2qj1c,False,,,False,t3_1bjxl4,http://www.scribegriff.com/studios/index.php?post/2013/02/19/Collections-in-Dart-The-Directed-Graph,
1363716672.0,4,nytimes.com,1aluma,Algorithms Get a Human Hand in Steering Web,8,4,1,http://www.reddit.com/r/algorithms/comments/1aluma/algorithms_get_a_human_hand_in_steering_web/,,,False,,t5_2qj1c,False,,,False,t3_1aluma,http://www.nytimes.com/2013/03/11/technology/computer-algorithms-rely-increasingly-on-human-helpers.html?smid=re-share,
1359142710.0,4,self.algorithms,179svv,Best collection type for most efficient way to determine k nearest neighbours.,5,1,8,http://www.reddit.com/r/algorithms/comments/179svv/best_collection_type_for_most_efficient_way_to/,"So I was reading machine learning introduction article and it explained about k-nearest neighbours algorithm, which depends on finding (surprise!) k amount of nearest neighbours on a graph. Obviously it's very inefficient if I have to go through all the elements and compare their position to point given to find out which points are nearest to it. My intuition says that there are probably some collection types or algorithms to make it more efficient. Any suggestions would be appreciated.",,False,,t5_2qj1c,False,,,True,t3_179svv,http://www.reddit.com/r/algorithms/comments/179svv/best_collection_type_for_most_efficient_way_to/,
1358804340.0,5,blog.databigbang.com,170hae,Stream oriented Knuth Morris Pratt in Haxe,7,2,0,http://www.reddit.com/r/algorithms/comments/170hae/stream_oriented_knuth_morris_pratt_in_haxe/,,,False,,t5_2qj1c,False,,,False,t3_170hae,http://blog.databigbang.com/searching-for-substrings-in-streams-a-slight-modification-of-the-knuth-morris-pratt-algorithm-in-haxe/,
1357238222.0,3,letuskode.blogspot.in,15wf1o,"2

Segment Trees: description + examples + excercises",6,3,0,http://www.reddit.com/r/algorithms/comments/15wf1o/2_segment_trees_description_examples_excercises/,,,False,,t5_2qj1c,False,,,False,t3_15wf1o,http://letuskode.blogspot.in/2013/01/segtrees.html,
1354914623.0,5,self.algorithms,14gpus,Polynomial random number?,7,2,8,http://www.reddit.com/r/algorithms/comments/14gpus/polynomial_random_number/,"Hi all,
Firstly, please forgive my improper use of mathematical terms - my grey matter is way too rusty!

I'm trying to come up with an algorithm that converts input X (between 1 and 1000 (inclusive)) to output Y (same range). 

X inputs have an even distribution between 1-1000, but the Y outputs  are ""pulled"" towards 500. The further X is from 500, the bigger/smaller Y is.

For example;
X = 1 then Y = 1,
X = 100 then Y = 110,
X = 200 then Y = 230,
X = 500 then Y = 500,
X = 800 then Y = 770,
X = 900 then Y = 890,
X = 1000 then Y = 1000

For the inputs 1, 500, and 1000 above, these are the outputs I want.
For 100, 200, 800, and 900 I've just made a guess - I'm simply trying to show the ""pull"" towards 500.

Can anyone please help me with the algorithm? Ideally in a form where I can tinker with the terms to get different output results, so that I can plot it and get the result that ""looks best""?

thanks in advance",,False,,t5_2qj1c,False,,,True,t3_14gpus,http://www.reddit.com/r/algorithms/comments/14gpus/polynomial_random_number/,
1354589262.0,2,self.algorithms,148ms3,"Proof of Transistivity of polynominal reduction. What does the term ""alphabet"" mean in this context. (Link provided to the specific use I am speaking of)",5,3,5,http://www.reddit.com/r/algorithms/comments/148ms3/proof_of_transistivity_of_polynominal_reduction/,"What does the word alphabet mean in the context of the answer for question #1 in the link below? 

VERBATIM: 
Recall: for a polynomial-time reduction ≤p, L ≤p M means that there is a computable
function f: alphabet of L→alphabet of M such that x∈L iff f(x)∈M.
Since L1≤p L2 and L2≤p L3, let g, h be functions such that a∈ L1 iff g(a) ∈ L2, and b∈
L2 iff h(b) ∈ L3, respectly. The composition of g and h, h⋅g is function such that for x∈
L1 iff h(g(x)) ∈ L3. If g and h are computable, so is h⋅g. Then the existence of a
polynomial-time reduction from L1 to L3 is proved.

LINK: 

http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=5&amp;ved=0CEwQFjAE&amp;url=http%3A%2F%2Fwww2.ee.ntu.edu.tw%2F~yen%2Fcourses%2Fal-03%2FHW3Sol.pdf&amp;ei=mlu9UImENY7W0gGHyoGoAw&amp;usg=AFQjCNEQmKyUFHNVppQ9o0rHDzwQkFHUzA",,False,,t5_2qj1c,False,,,True,t3_148ms3,http://www.reddit.com/r/algorithms/comments/148ms3/proof_of_transistivity_of_polynominal_reduction/,
1352659591.0,4,self.algorithms,130pld,[Q]Karatsuba algorithm for polynomial multiplication,5,1,1,http://www.reddit.com/r/algorithms/comments/130pld/qkaratsuba_algorithm_for_polynomial_multiplication/,"Hi, I have task for university to create program that does polynomial multiplication (up to degree-10^6). There are bonus points for speed, so I decided to use Karatsuba algorithm. I read couple of examples and got the general idea of how to multiply two numbers.

So I kept searching and found paper that explains how to do polynomial multiplication. Here is link: http://www.ijcse.com/docs/INDJCSE12-03-01-082.pdf

The important part is section 6, Karatsuba algorithm for polynomials of arbitrary degree

In that section, they calculate Di by simply doing Ai*Bi. Then they calculate Dp,q and here is where I'm lost. I don't know how to get p,q. 

After that comes part where they calculate C0 and Cn-2, that is no problem, but Ci is. If someone would be so kind and explain how to get Dp,q and Ci, I would be very glad.",,False,,t5_2qj1c,False,,,True,t3_130pld,http://www.reddit.com/r/algorithms/comments/130pld/qkaratsuba_algorithm_for_polynomial_multiplication/,
1349352319.0,4,self.algorithms,10xjvg,Calculate average over non uniform ranges,5,1,3,http://www.reddit.com/r/algorithms/comments/10xjvg/calculate_average_over_non_uniform_ranges/,"I'm trying to come up with an algorithm that calculates the average price of a range of widgets. 

In this scenario, sellers sell widgets at a fixed price for a range of widgets.

Seller A:

* 1-5 widgets: $10

* 6-15 widgets: $25

Seller B:

* 1-3 widgets: $7

* 4-10 widgets: $15
* 11-20 widgets: $30


There would be many sellers, each choosing their own min/max/price for each range of widgets. 

I want to be able to calculate the average price of any range I choose. For example I want to calculate the average price of widgets if I wanted to sell them in the range of 5-9 widgets. 

What's a sound way of doing this? 

My initial thought was to calculate the average price for each widget in the range I want to calculate and then average those together:

ie: (avg(rates inc. 5) + avg(rates inc. 6) + avg(rates inc. 7) + avg(rates inc. 8) + avg(rates inc. 9))/(count of range (5 in this case))

Does my algorithm make sense? Plugging in some test data the numbers make sense to me, but I wasn't sure if there were other ways to calculate this kind of average. 
",,False,,t5_2qj1c,False,,,True,t3_10xjvg,http://www.reddit.com/r/algorithms/comments/10xjvg/calculate_average_over_non_uniform_ranges/,
1348634966.0,3,self.algorithms,10hqme,Unsure about a run time,5,2,10,http://www.reddit.com/r/algorithms/comments/10hqme/unsure_about_a_run_time/,"I was analyzing an algorithm that has a loop n times, which can sometimes insert into an AVL tree, but always searches the AVL tree.

If I know the fact that only O(1) items of these n things will insert into the AVL tree can I say that searching/inserting into the AVL tree will take O(1) time with respect to the rest of the algorithm?",,False,,t5_2qj1c,False,,,True,t3_10hqme,http://www.reddit.com/r/algorithms/comments/10hqme/unsure_about_a_run_time/,
1344630957.0,2,self.algorithms,y0k0a,Algorithm for predicting multiple output values based on input values? (supervised learning),5,3,8,http://www.reddit.com/r/algorithms/comments/y0k0a/algorithm_for_predicting_multiple_output_values/,"I'm working with time series data and would like to train a prediction model. I'm thinking a neural network might work for this, but my only experience with them is via Coursera's Machine Learning course. In that course they were used only for classification; the output of the NN was a vector of [0 0 0 1 0] indicating the 4th class is the prediction for the given input.

What I'm wondering is if a NN can be used to predict continuous values? That is, have an output vector of something like [1.1 2.45 20.97]. Is there any reason I can't/shouldn't train a NN using training data that has multiple output values that are continuous in nature? Is there a better algorithm for this type of prediction?

Hopefully this is understandable, but please let me know if there is anything I can add to help clarify.

",,False,,t5_2qj1c,False,,,True,t3_y0k0a,http://www.reddit.com/r/algorithms/comments/y0k0a/algorithm_for_predicting_multiple_output_values/,
1343981320.0,4,self.algorithms,xm12z,Polynomial factorization over finite fields,6,2,1,http://www.reddit.com/r/algorithms/comments/xm12z/polynomial_factorization_over_finite_fields/,"I have a problem where I have to factorize a polynomial over a finite field. The degree of the polynomial may be arbitrarily large. The finite field size may also be arbitrarily large.

1) What is the most efficient way to do this (practically and asymptotically)? 
2) Are there any algorithms for special cases (e.g. when the irreducible factors are all guaranteed to be of degree either 1 or 2)?
3)For finding degree one factors, is there a more efficient way than evaluating the polynomial for all field elements? ",,False,,t5_2qj1c,False,,,True,t3_xm12z,http://www.reddit.com/r/algorithms/comments/xm12z/polynomial_factorization_over_finite_fields/,
1343266634.0,5,self.algorithms,x5yj9,Random Polyomino Generator Algorithm,6,1,9,http://www.reddit.com/r/algorithms/comments/x5yj9/random_polyomino_generator_algorithm/,"In a game I'm making I want to have random dungeon layouts. A dungeon similar to The Legend of Zelda [NES] Or The Binding Of Isaac [PC].

Would anyone be able to help me with an algorithm that lets me input a number and it would output a series of coordinates of a random Polyomino with a given number of blocks.

At this point any input would be much appreciated.



-Thanks


http://en.wikipedia.org/wiki/Polyomino
",,False,,t5_2qj1c,False,,,True,t3_x5yj9,http://www.reddit.com/r/algorithms/comments/x5yj9/random_polyomino_generator_algorithm/,
1342540226.0,4,self.algorithms,wpf6h,Filtering / Routing Algorithm?,4,0,6,http://www.reddit.com/r/algorithms/comments/wpf6h/filtering_routing_algorithm/,"I just joined the monitoring team at a healthcare company. Currently we have a file that routes all generated alerts (essentially SNMP) to their correct group in the company – well that’s what it’s supposed to do, it’s a work in progress. Recently we have been inundated with more requests for more rules and the file is getting out of hand.  I’m wondering what are some best practices when trying to filter these alerts? 

Here’s a quick scenario:
An alert comes in that says the D drive is filling up on the box exampleServ01. This alert needs to go to Level 2 Example Group Admin.
 
The problem is that the C drive on the same box might have to go to another group, so I have to be pretty granular and not override any other alert either. 

Does anyone have a good way to keep everything organized and easy to add to?
Currently it’s just a bunch of IF statements

I'm not looking for code, I'm looking for best practices. 
",,False,,t5_2qj1c,False,,,True,t3_wpf6h,http://www.reddit.com/r/algorithms/comments/wpf6h/filtering_routing_algorithm/,
1341031712.0,2,131002.net,vtvzo,"SipHash pseudorandom functions optimized for short inputs, meant to be DoS-resistant; code in erlang, haskell, C#, JS",5,3,0,http://www.reddit.com/r/algorithms/comments/vtvzo/siphash_pseudorandom_functions_optimized_for/,,,False,,t5_2qj1c,False,,,False,t3_vtvzo,http://131002.net/siphash/,
1331608099.0,2,self.algorithms,qtz6c,"Hey, does anybody know of any algorithms for finding the vertices of something like this?",7,5,3,http://www.reddit.com/r/algorithms/comments/qtz6c/hey_does_anybody_know_of_any_algorithms_for/,"Ok, so I'm trying to find at least the vertices for the bigger line segments.  So far the only thing I can think of doing is some kind of best fit analysis for groups of points.  But I don't know how to choose which points to group together for the line of best fit.  The only thing I can think of is to brute force every possible combination of points for the best fit test.  Is there any more efficient way to find the vertices of [this](http://imgur.com/BySBt)?",,False,,t5_2qj1c,False,,,True,t3_qtz6c,http://www.reddit.com/r/algorithms/comments/qtz6c/hey_does_anybody_know_of_any_algorithms_for/,
1331573922.0,3,self.algorithms,qt5po,Dynamic Solution vs Transportation Problem Simplex Method,4,1,0,http://www.reddit.com/r/algorithms/comments/qt5po/dynamic_solution_vs_transportation_problem/,"Hi algorithms,

At work I have to solve something equivalent to the transportation problem in C++.  My scale however is very small, something smaller than 10 destinations and 20 sources.  
In such a simple case will the Transportation Problem's modified simplex actually be better than a simple dynamic solution?  This will be repeated millions of times a day, but even then I suspect it won't be a big cost relative to other elements of the program.
Also, is there a good C++ library for the transportation problem, assignment problem, and branch-and-bound techniques?",,False,,t5_2qj1c,False,,,True,t3_qt5po,http://www.reddit.com/r/algorithms/comments/qt5po/dynamic_solution_vs_transportation_problem/,
1330625383.0,3,self.algorithms,qd70z,3-SAT Recursive Algorithm,4,1,6,http://www.reddit.com/r/algorithms/comments/qd70z/3sat_recursive_algorithm/,"First: Boolean 3-satisfiability :http://en.wikipedia.org/wiki/3SAT#3-satisfiability 

I have to design an algorithm for a college class that gives a model for a 3-SAT (if it exists).

So far I have designed a strategy of backtracking recursion. A variable is chosen, and then it's assigned to true or false and the recursion goes on to choose the next one. If a contradiction is found, the algorithm goes back to the last known possible point and tries with another value. 

The key here is how to choose the next variable everytime the recursive function is called. I have designed an heuristic that gives full probability to those variables which are alone in a clause (that is, the other two variables are 0). When only two variables are left to decide they get some ""points"" (in this case 5) and when all of the 3 variables are yet to be assigned, all variables get one point. After adding up all these ""points"" I choose the variable with the highest value and continue with the recursive strategy.

When the size of the problem is small (&lt;100 variables) my algorithm solves it in less than a second. But as things get bigger (&gt;250 variables) it takes up to 1 minute or more.

Is there any way to improve my algorithm? Any thoughts would be apreciated.

Sorry if my explanation was not too clear, feel free to ask anything.

PS: Pure literal elimination doesn't help as the formulas I have to solve don't have any.",,False,,t5_2qj1c,False,,,True,t3_qd70z,http://www.reddit.com/r/algorithms/comments/qd70z/3sat_recursive_algorithm/,
1326580085.0,4,self.algorithms,oh92q,Can someone explain to me how a Proportional Integral Derivative algorithm control works?,7,3,3,http://www.reddit.com/r/algorithms/comments/oh92q/can_someone_explain_to_me_how_a_proportional/,"I understand that there has to be a loop to continuously check/correct the error; I guess I'm mostly confused on how exactly does inputing coefficient values effect the input of the process? for example, on a P only algorithm control, if I put in some value for the p coefficent how does that value tell the process input what to do?  
  
Also, what would happen if I have a system (say a heater I want to heat water from 20 degrees to 60 degrees) and I set all the PID values to zero? ",,False,,t5_2qj1c,False,,,True,t3_oh92q,http://www.reddit.com/r/algorithms/comments/oh92q/can_someone_explain_to_me_how_a_proportional/,
1319234771.0,4,self.algorithms,lkf2m,Need a little help designing a 3D parallel projection algorithm (simple as possible+language agnostic) ,6,2,3,http://www.reddit.com/r/algorithms/comments/lkf2m/need_a_little_help_designing_a_3d_parallel/,"Hopefully r/algorithms is a good place for this question, if not I can go elsewhere.

I'm offhandedly interested in programming a low-res vector- or voxel-based game, but I'm not very good at 3D code of any complexity. Ideally, what I'm hoping for is an easy way to do an ""isometric"" view that can rotate around the vertical axis.

I already know a simple pseudo-algorithm that works for perspective projection...

    screenX = objX / objZ
    screenY = objY / objZ

...plus camera transforms, so I'm hopefully looking for something similar that can produce pixel values where the vertical lines stay vertical, but the camera can translate around the vertical axis. Does that make sense? Additionally, for a really simple voxel-based scene, would raytracing be best, instead of pixel placement?

Hope I'm explaining this properly and not like a total noob.",,False,,t5_2qj1c,False,,,True,t3_lkf2m,http://www.reddit.com/r/algorithms/comments/lkf2m/need_a_little_help_designing_a_3d_parallel/,
1292444285.0,4,self.algorithms,emeff,crossword dictionary/wordlist,4,0,1,http://www.reddit.com/r/algorithms/comments/emeff/crossword_dictionarywordlist/,does anyone know of a (free) ascii wordlist that's more extensive than the linux dictionary?  preferably aimed towards crossword puzzles.,,False,,t5_2qj1c,False,,,True,t3_emeff,http://www.reddit.com/r/algorithms/comments/emeff/crossword_dictionarywordlist/,
1286333458.0,5,self.algorithms,dndwm,What's the state of the art for n-body force algorithms?,5,0,2,http://www.reddit.com/r/algorithms/comments/dndwm/whats_the_state_of_the_art_for_nbody_force/,"Does anyone know what algorithms they use now for this problem? For example, if you have n bodies, you need to calculate each body's repulsion to each n other bodies -- leading to an o(n^2) complexity for each round of calculations.

What's the state of the art for this kind of stuff? Or do people just use GPUs to speed this up these days?",,False,,t5_2qj1c,False,,,True,t3_dndwm,http://www.reddit.com/r/algorithms/comments/dndwm/whats_the_state_of_the_art_for_nbody_force/,
1256200514.0,3,biomedcentral.com,9wknp,An algorithm to determine if an emergency call is a actually an emergency,4,1,0,http://www.reddit.com/r/algorithms/comments/9wknp/an_algorithm_to_determine_if_an_emergency_call_is/,,,False,,t5_2qj1c,False,,,False,t3_9wknp,http://www.biomedcentral.com/1471-227X/9/21/abstract,
1374908841.0,3,self.algorithms,1j5eov,Spectral clustering question.,3,0,3,http://www.reddit.com/r/algorithms/comments/1j5eov/spectral_clustering_question/,"Hey guys,

Not sure if this is the best place to ask, but...

I'm reading up on spectral clustering (http://books.nips.cc/papers/files/nips14/AA35.pdf), and I need help clearing up a small detail.

Referring to steps 5 and 6 of the algorithm, I'm having trouble understanding why the i-th row of the eigenvector matrix Y corresponds to the i-th point s_i.

Any help would be great. Thanks!",,False,,t5_2qj1c,False,,,True,t3_1j5eov,http://www.reddit.com/r/algorithms/comments/1j5eov/spectral_clustering_question/,
1374880423.0,3,reddit.com,1j4noh,What is the complexity of the emptiness problem for 2-way DFAs? [x-post from /r/compsci],4,1,0,http://www.reddit.com/r/algorithms/comments/1j4noh/what_is_the_complexity_of_the_emptiness_problem/,,,False,,t5_2qj1c,False,,,False,t3_1j4noh,http://www.reddit.com/r/compsci/comments/1j4lun/what_is_the_complexity_of_the_emptiness_problem/,
1367951899.0,2,self.algorithms,1dvlh2,Initializing Random Stacks,5,3,16,http://www.reddit.com/r/algorithms/comments/1dvlh2/initializing_random_stacks/,"Hi all,

I'm working with a depth first search and there is more than one solution for the set of data that I'm working with. Every time I run the search I would like one of the answers (not always the same one).

I was thinking that the best way to do this would be to randomize the initial stack since I only want one answer returned at a time.

What would be the best way to do this? Any help is much appreciated!",,False,,t5_2qj1c,False,,,True,t3_1dvlh2,http://www.reddit.com/r/algorithms/comments/1dvlh2/initializing_random_stacks/,
1364963658.0,4,self.algorithms,1bkhdp,"How to infer ""prerequisite"" relationships between documents?",7,3,8,http://www.reddit.com/r/algorithms/comments/1bkhdp/how_to_infer_prerequisite_relationships_between/,"Humans learn best when they read a document if they already know whatever knowledge is prerequisite to understanding that document.  A forward reference (to a concept the learner doesn't know yet and is not explained in the text) taxes the learner's brain. 

Let's say I have a set of documents (ordered lists of words).  What are ways we can attempt (and yes, I know this is a fuzzy problem with no ""right"" answer) to order the documents to minimize the number of forward references between documents?

(This isn't intended to be an abstract problem statement.  I am literally attempting to sort documents for learners, so other channels of information we can take advantage of are ok).

-----------

EDIT: Of course, once we know what the prerequisite relationships are between documents, we can perform a topological sort to get the ordering.  But the actual interesting problem is inferring the prerequisite relationships from the documents.  Hence the question title.

EDIT 2: When I say ""Forward references"" I mean concepts, not necessarily (and not even in most cases) explicit hyperlinks.  The documents are not assumed to have been produced together by any single party as a set; they could have been assembled from a variety of sources without any explicit reference to one another.",,False,,t5_2qj1c,1364971313.0,,,True,t3_1bkhdp,http://www.reddit.com/r/algorithms/comments/1bkhdp/how_to_infer_prerequisite_relationships_between/,
1363645732.0,3,self.algorithms,1ajxhr,Any insights on study of expected outcome vs. worst-case outcome?,4,1,3,http://www.reddit.com/r/algorithms/comments/1ajxhr/any_insights_on_study_of_expected_outcome_vs/,"Hi r/Algorithms. I was sent from r/math to r/AskComputerScience and here in hope of finding help for my problem! I'm sorry I'm crossposting but I need help! I am currently doing some tests on the use of a Genetic Algorithm, Simulated Annealing and (hopefully) Lenstra's Algorithm for solving the Bin Packing Problem against the First-Fit Decreasing (FFD) Algorithm.

Some background in the BPP if you want to know what I'm talking about: http://en.wikipedia.org/wiki/Bin_packing_problem it is NP-hard, NPO, it has none approximation scheme, but it does have an assymptotic approximation scheme.

The thing is there is a boundary for the output given by the FFD algorithm in the worst-case scenario: 11/9*Opt(a) + 4. But this is a worst-case boundary and apparently my solutions don't usually perform much better than the FFD, even when using Lenstra's Algorithm for LIP which is precise (and useful in some particular cases). So my question is... Is there any literature on the ""expected"" outcome, or even the ""probability of being optimal"" of an algorithm?

In my work it seems that when there are not many articles and they are not ""pathologic"" (some very small, some very big), FFD tends to give the best solution around 80% of times, but I can't really find a way to prove something like that, I don't even know where to begin with!! (Well I have an idea and I am trying, but I would appreciate some indications :) ).

Thank you very much for all the help!
",,False,,t5_2qj1c,False,,,True,t3_1ajxhr,http://www.reddit.com/r/algorithms/comments/1ajxhr/any_insights_on_study_of_expected_outcome_vs/,
1362115964.0,3,self.algorithms,19g4e0,Algorithm,12,9,12,http://www.reddit.com/r/algorithms/comments/19g4e0/algorithm/,"I would appreciate help with a problem. I thought it up by imagining how a community would try to get rid of unpopular residents. The community accomplishes it by holding an anonymous vote, and everyone in the community is given a ballot for them to name residents that they like and those that they dislike. The administers of the vote then try to make the most people happy.

I modeled the input as an array of tuples. The tuples contain two arrays: one to express likes and the other to express dislikes.
([Likes], [Dislikes])

I want to find a set in which the conditions of the most tuples are fulfilled. This can better be explained through an example.

Given this sample input:
(		([E],     [C]),
		([D],     [B, A]),
		([E],     [D]),
		([B, C], [D]),
		([A],     [D]),
		([C, E], [A]),
		([B],     [C, D])
)

the result should be:
[A, B, E], in which the conditions of four tuples are met:
[E], [C],
[E], [D],
[A], [D],
[B], [C, D]

Note that every element in the likes are included in the set and none from the dislikes.

I keep modeling it as a maximum clique problem, which leaves me with crappy exponential complexity. I tried simplifying the problem where voters could express 0* elements, and I still have no clue where to start.

I'm fairly new to this, so forgive me if my terminology is off. Thanks",,False,,t5_2qj1c,False,,,True,t3_19g4e0,http://www.reddit.com/r/algorithms/comments/19g4e0/algorithm/,
1360588920.0,2,self.algorithms,18b247,How to query number of unique integers in an array range in constant time and O(n) or O(nlogn) precomputation time ?,5,3,24,http://www.reddit.com/r/algorithms/comments/18b247/how_to_query_number_of_unique_integers_in_an/,"Where the array is not sorted and the elements are in the range 1...10^5.

Is there a specific approach or algorithm for doing this ?

Edit:

For example, the array can be: 1,0,0,5,4

[1-indexed]

A query could be: r(1,3) should be 2 [1 and 0].",,False,,t5_2qj1c,1360590681.0,,,True,t3_18b247,http://www.reddit.com/r/algorithms/comments/18b247/how_to_query_number_of_unique_integers_in_an/,
1357771114.0,4,self.algorithms,169y6e,Resource Allocation Problem,5,1,1,http://www.reddit.com/r/algorithms/comments/169y6e/resource_allocation_problem/,"Hi guys, I was hoping you could help me with a resource allocation problem I've not been having much luck with.  Algos aren't my strong suit.

I've posted a latex-formatted version of my problem here: http://mathb.in/1545

The real-world application of this is that I'm occasionally receiving lump subscription payments from customers, without any way of tying those payments to specific invoices (it's a domain problem); I need to divide and allocate each lump payment to a small set of products that we offer, but the catch is that the payment may include money for 5 of widget **a** and 10 of widget **b**, or 1 of **a b** and **c**, etc, and I'd like to do this more elegantly than brute-force.

Which I understand sounds like a terrible way of doing business given just this incredibly-simplified version :) 

Thanks!",,False,,t5_2qj1c,False,,,True,t3_169y6e,http://www.reddit.com/r/algorithms/comments/169y6e/resource_allocation_problem/,
1356635798.0,3,self.algorithms,15j52g,Generating lower bounds on traveling salesman problem?,6,3,4,http://www.reddit.com/r/algorithms/comments/15j52g/generating_lower_bounds_on_traveling_salesman/,"I recently posted a gif of a near-optimal solution to a **massive** (1.9 million cities) traveling salesman problem over at /r/visualization, and was wondering how they determine near-optimality without knowing the optimal solution?

For example, in the case of the specific post I made, [the website](http://www.tsp.gatech.edu/world/pictures.html) states that ""this tour is at most 0.076% longer than an optimal tour."" How did they come up with that percentage?",,False,,t5_2qj1c,False,,,True,t3_15j52g,http://www.reddit.com/r/algorithms/comments/15j52g/generating_lower_bounds_on_traveling_salesman/,
1353884512.0,4,self.algorithms,13s4c1,Q: Dynamic Programming; Longest Uncommon Substring,6,2,7,http://www.reddit.com/r/algorithms/comments/13s4c1/q_dynamic_programming_longest_uncommon_substring/,"Im working through a series of questions that is NOT homework related, which involve dynamic programming and trying to find the longest UNCOMMON substring. I found a recurrance but I would like to chat/talk it out to see if it holds. I will be doing bottom up approach.
Runtime I have is O(n^2) and space is also O(n^2)

Given S='Analysis' and T='Algorithms' let L[i,j] be the length of our longest substring where i and j are pointers to the ends of S,T. 

Let i and j be pointers to the end of each string, we decrement along to move them. 

Base Case : 
We reach the end of our string; s[0] and t[0] where i and j are both 0. Return length[i,j]


    L[i,j] = L(i-1,j-1) + 1   //we have un-common values so increment our length and move our pointers along


Here's where I'm stuck. I'm not sure how to express the recurrance for when i and j have found equal characters. I believe they should just move along and not increment our length. If that's it then im good. 

Skeleton Code
    len[0,0] = 0;
    max = 0;

    if(i==0 || j==0) return len[i,j]; //base case
   
    if(s[i] == t[j]) // equal characters, save length and reset length to 0
        max = l[i,j]
        len = 0;

    else
        i--; j--;
        max ++
        len[i,j]=max


thoughts?
",,False,,t5_2qj1c,False,,,True,t3_13s4c1,http://www.reddit.com/r/algorithms/comments/13s4c1/q_dynamic_programming_longest_uncommon_substring/,
1353859091.0,3,yuzhikov.com,13rgeu,Restoration of defocused and blurred images (part 2) - practical aspects overview,4,1,1,http://www.reddit.com/r/algorithms/comments/13rgeu/restoration_of_defocused_and_blurred_images_part/,,,False,,t5_2qj1c,False,,,False,t3_13rgeu,http://yuzhikov.com/articles/BlurredImagesRestoration2.htm,
1351296468.0,3,self.algorithms,125gta,"(xpost - /r/math) Is there a name for this type of problem? I've tried googling, but I can't seem to find the right terms...",4,1,6,http://www.reddit.com/r/algorithms/comments/125gta/xpost_rmath_is_there_a_name_for_this_type_of/,"So to explain, I'm working on balancing out some components for a project I'm working on for their final assembly. I have three parts:

* (alpha) A part with 4 ""ports"". One is taken at reference of 0, and the other three are differences between reference and that.
* (tau) A 'tee' of kinds where I have an input, and two outputs with values for each of the outputs
* (gamma) The summing junction of my parts, where you have two inputs and one output.

The idea is that for each assembly I build I have one alpha-&gt; two taus -&gt; a gamma (although the order probably isn't important for the overall math); and I want to have it so all their ""imperfections"" balance each other out to zero, or as close as possible.

The way I've been doing it (and already gotten sick of) is by manually eyeing out the differences and doing a ""that'll do"" at the end. I'd like to automate this with MATLAB or something, but because I don't know the name of the type of problem I don't know of any other pre-made solutions. My ideas so far were:

* Write a for-loop inception to brute-force the best combinations by attempting each connection, making a weight, the trying for better/worse. This seems incredibly inefficient
* Don't write a program, sort all the parts from least deltas to most, and just have the last few be wildly off-center (may not be acceptable)

Does anyone have any ideas on where I should start looking for information on how to solve this? ",,False,,t5_2qj1c,False,,,True,t3_125gta,http://www.reddit.com/r/algorithms/comments/125gta/xpost_rmath_is_there_a_name_for_this_type_of/,
1349942721.0,4,self.algorithms,11atq4,does anyone know the Big-Theta proof from Big-O and Big-Omega? ,10,6,6,http://www.reddit.com/r/algorithms/comments/11atq4/does_anyone_know_the_bigtheta_proof_from_bigo_and/,"f(n) = big-thea(g(n)) if and only if f(n) = O(g(n)) and f(n) = Big_Omega(g(n))...I feel it is relatively straight forward. 
For proving the latter two from f(n) = big-theta(g(n)) we would set c for O(g(n)) to the lower bound c_1 for big-theta, and the c for Omega to c_2. 
Then, pretty much do it the same way to prove f(n) = big-theta(g(n)) from the latter two?

Is this right? ",,False,,t5_2qj1c,False,,,True,t3_11atq4,http://www.reddit.com/r/algorithms/comments/11atq4/does_anyone_know_the_bigtheta_proof_from_bigo_and/,
1347090254.0,2,self.algorithms,zjr4c,IOI training,8,6,11,http://www.reddit.com/r/algorithms/comments/zjr4c/ioi_training/,"I am representing my country in the IOI this month but we haven't been given any training :( so I'm looking for any advice, links, information, topics, anything really to help me out.",,False,,t5_2qj1c,False,,,True,t3_zjr4c,http://www.reddit.com/r/algorithms/comments/zjr4c/ioi_training/,
1345341989.0,3,self.algorithms,ygdpd,algorithms related to hilbert's tenth problem.,4,1,4,http://www.reddit.com/r/algorithms/comments/ygdpd/algorithms_related_to_hilberts_tenth_problem/,"to put it in short, i'm looking to devise an algorithm that proves that diophantine sets are recursively enumerable. i know nothing about computer science. i understand that the MRPD theorem outlines the solution, but i'm writing an essay over this and would prefer to discover it on my own for the sake of making the explanation of the process easier; that is to say i would prefer a nudge in the right direction instead of a plain solution. 

thank you r/algorithms.
",,False,,t5_2qj1c,False,,,True,t3_ygdpd,http://www.reddit.com/r/algorithms/comments/ygdpd/algorithms_related_to_hilberts_tenth_problem/,
1339253736.0,3,fiber-space.de,ut7ei,Kites on a zebra crossing: an algorithmic challenge,5,2,1,http://www.reddit.com/r/algorithms/comments/ut7ei/kites_on_a_zebra_crossing_an_algorithmic_challenge/,,,False,,t5_2qj1c,False,,,False,t3_ut7ei,http://fiber-space.de/wordpress/2012/06/09/kites-on-a-zebra-crossing-an-algorithmic-challenge/,
1337719125.0,2,reddit.com,tztmr,"very tiny cluster algorithm for n-dimensional data [ruby, ~13 loc][/r/tinycode x-post]",4,2,0,http://www.reddit.com/r/algorithms/comments/tztmr/very_tiny_cluster_algorithm_for_ndimensional_data/,,,False,,t5_2qj1c,False,,,False,t3_tztmr,http://www.reddit.com/r/tinycode/comments/tzsl7/very_tiny_cluster_algorithm_for_ndimensional_data/,
1334174990.0,3,self.algorithms,s4w7d,Variation on knapsack problem?,3,0,4,http://www.reddit.com/r/algorithms/comments/s4w7d/variation_on_knapsack_problem/,"I think this might be a variation of the multiple knapsack problem (or maybe even could be reduced to it) but I'm not sure. Here's the problem:



You have a set of items with known values and weights. You also have a set of knapsacks, and each knapsack can hold a fixed number of items (different knapsacks might be able to hold different numbers of items). Maximize total value of items in knapsacks while staying under a given weight.



Note that the individual knapsacks don't have a weight restriction. Each knapsack only has a ""number of items it can contain"" restriction. The only other restriction is the total weight of the items.

Any ideas?? (other than brute force of course). Thanks in advance! :)


EDIT: one important restriction I forgot to include:

Items can't necessarily be put into any bag. Essentially their value becomes zero if they are put into a bag they aren't compatible with. You can imagine a general case where each item has a value dependent on its bag, but for my case, its value will either be 0 or it's normal value, depending on the bag.",,False,,t5_2qj1c,True,,,True,t3_s4w7d,http://www.reddit.com/r/algorithms/comments/s4w7d/variation_on_knapsack_problem/,
1333683124.0,3,self.algorithms,rvrac,Big-Oh of Change-Making Algorithm,3,0,9,http://www.reddit.com/r/algorithms/comments/rvrac/bigoh_of_changemaking_algorithm/,"I'm aware that greedy algorithms for the change-making problem is sub-optimal (and sometimes actually incorrect) for currencies (US currency seems to be an exception here).  Without resorting to dynamic programming, I have this simple pseudocode.  

    MakeChange(total, coins)
        C &lt;- empty set
        for i &lt;- 1 to |coins|
            while total &gt;= coins_i
                C &lt;- C U {coins_i}
                total &lt;- total - coins_i
            end
        end
    end

But I'm having trouble trying to find the running time of this (the bounds of the while-loop is throwing me off, and I'm not actually sure how to express the input in this case).  I need the asymptotic runtime in terms of US denominations of coins, such as {.25, .10, .05, .01} and I don't need it for the general case.  

How do you analyze the inner loop when the bounds are uncertain for the input?  ",,False,,t5_2qj1c,False,,,True,t3_rvrac,http://www.reddit.com/r/algorithms/comments/rvrac/bigoh_of_changemaking_algorithm/,
1331427008.0,3,self.algorithms,qqxh9,maximizing utility functions,3,0,8,http://www.reddit.com/r/algorithms/comments/qqxh9/maximizing_utility_functions/,"I have developed an equipment database for a roleplaying game I'm involved with.  I would like to be able to use it to create a web page that does the following:

a) allows the user to specify a utility set for a desired combination of items (ie, hp = 100 utils, mana = 0 utils, strength = 80 utils, etc).  There are quite a few (in excess of 10) members of this set.
b) attempts to optimize the set based on the resulting utility function

Even with a relatively small database (several thousand records) I am guessing this will be a rather difficult problem.  Can anyone point me to possible algorithms that I can implement in the solution here?  I would like to see if it is even feasible to implement given the computing power I have available/am willing to pay for (not much).
",,False,,t5_2qj1c,False,,,True,t3_qqxh9,http://www.reddit.com/r/algorithms/comments/qqxh9/maximizing_utility_functions/,
1321975645.0,4,self.algorithms,mlimr,Need Some Numeric Algorithms,5,1,8,http://www.reddit.com/r/algorithms/comments/mlimr/need_some_numeric_algorithms/,"I've been trying to put together a [statistical library for PHP](https://github.com/mcordingley/PHPStats), and I need help with implementing a few functions.  These are special functions and so do not have an analytic solution, but a numeric one.  So, I am very much out of my depth in terms of coming up with algorithms to solve them.  If I can just get pseudocode implementations of these, I can finish off the first release of the code and get it out into people's hands.  

The ones that I'm missing are the digamma function, the inverse gamma function, and the inverse lower gamma function (not the regularized one!)  I do have an implementation of the inverse regularized incomplete gamma, but I haven't yet tracked down some flaw in my implementation or understanding of it.  Many thanks!",,False,,t5_2qj1c,False,,,True,t3_mlimr,http://www.reddit.com/r/algorithms/comments/mlimr/need_some_numeric_algorithms/,
1321901135.0,3,self.algorithms,mkf1u,Help: Interior Reflective Method - language problems,3,0,2,http://www.reddit.com/r/algorithms/comments/mkf1u/help_interior_reflective_method_language_problems/,"Hey guys,
i'm currently writing my bachelor thesis and one of the tasks is to implement a Trust-Region optimizer, which uses the Interior Reflective Method to solve the trust-region subproblem. It's a very little part of my work and the only one giving me problems right now, after spending too much time on it i decided to ask here.

.

The only public paper about it is from 1991, a higher-quality text part is also found at: [http://www.faculty.jacobs-university.de/poswald/teaching/MathLab3/previous/OptimMatlab.pdf](http://www.faculty.jacobs-university.de/poswald/teaching/MathLab3/previous/OptimMatlab.pdf) (p. 19ff.).
On page 23, the reflective line search is described (RP).

.

I have several problems understanding this method, partly because of the language (i'm not a native english speaker). 

.

What is a boundary-point (Step 2). Does it have a special meaning?

.

Step 3 (b): For each j such that (b_i)_j = u_j
What does this mean exactly? i describes the current step, what is the additional index j for? 
Should i change (b_i)_j to u_j or apply the following substeps to all (b_i)_j which happen to be u_j?

.

The last problem: When is the line search finished? Do i only need to do two steps (i and i-1), where is the criteria to cancel?

.

Thank you guys! Also how do i do linebreaks in Reddit? ;)",,False,,t5_2qj1c,False,,,True,t3_mkf1u,http://www.reddit.com/r/algorithms/comments/mkf1u/help_interior_reflective_method_language_problems/,
1291486135.0,1,self.algorithms,eg6vk,Algorithmic problems,5,4,4,http://www.reddit.com/r/algorithms/comments/eg6vk/algorithmic_problems/,I was wondering if anyone would be interested in a subreddit dedicated to algorithmic problems and solutions to them? Something like [this](http://www.careercup.com/page?pid=algorithm-interview-questions&amp;company=google-interview-questions&amp;job=software-engineer-developer-interview-questions). I don't know if algorithms subreddit can be used for that or if it's better to create a new one. What do you think?,,False,,t5_2qj1c,False,,,True,t3_eg6vk,http://www.reddit.com/r/algorithms/comments/eg6vk/algorithmic_problems/,
1285331257.0,3,google.com,diak3,"My research was based on this: pLSA Algorithm[ppt]
",3,0,0,http://www.reddit.com/r/algorithms/comments/diak3/my_research_was_based_on_this_plsa_algorithmppt/,,,False,,t5_2qj1c,False,,,False,t3_diak3,http://www.google.com/url?sa=t&amp;source=web&amp;cd=1&amp;sqi=2&amp;ved=0CBMQFjAA&amp;url=http%3A%2F%2Frakaposhi.eas.asu.edu%2Fcse494%2Fnotes%2Fs07-plsa.ppt&amp;rct=j&amp;q=pLSA%20algorithm&amp;ei=3ZicTOz4H4qmsQP81p3WAQ&amp;usg=AFQjCNGQp8lv9tArXgn6kFnlcWPN3XRSNQ&amp;cad=rja,
1374688107.0,2,self.algorithms,1iywpq,"Find all sets that don't have ""conflicts"" in the smallest time complexity",5,3,6,http://www.reddit.com/r/algorithms/comments/1iywpq/find_all_sets_that_dont_have_conflicts_in_the/,"Lets say you have an initial set of numbers.

You also have a set of pairs of numbers which are ""conflicts"".

You want to get every combination of numbers from the initial set that does not have a pair of numbers that are in the set of conflicts, except for subsets of other combinations already found.

I'm able to solve it for O(2^n) time, where n = pairs of numbers unique in the list of conflicts, but I'm curious if it can be solved with smaller time complexity.",,False,,t5_2qj1c,1374690321.0,,,True,t3_1iywpq,http://www.reddit.com/r/algorithms/comments/1iywpq/find_all_sets_that_dont_have_conflicts_in_the/,
1369156217.0,2,self.algorithms,1ervo5,Trying to work out an algorithm pertaining to collision resolution for AABBs.,4,2,10,http://www.reddit.com/r/algorithms/comments/1ervo5/trying_to_work_out_an_algorithm_pertaining_to/,"**The problem:**

Let there be two axis-aligned rectangles of arbitrary size and position, A and B. Assume that A and B overlap. Let ray AB be a ray which begins at the center of rectangle B; the direction of the ray is arbitrary. Let there be a third axis-aligned rectangle, C, and assume that it possesses the same width and height as rectangle B.

Find the point on ray AB closest to the center of rectangle B where the center of rectangle C could be placed such that rectangle A and rectangle C do not overlap.

**The application:**

I have two moving rectangular objects, and when there's a collision I need to be able to make them not overlap anymore in addition to making the proper adjustments to velocity. I'm currently using an iterative method, but that's slow and impractical. I don't see why there shouldn't be an algebraic way to solve it quickly and precisely.",,False,,t5_2qj1c,1369158430.0,,,True,t3_1ervo5,http://www.reddit.com/r/algorithms/comments/1ervo5/trying_to_work_out_an_algorithm_pertaining_to/,
1365115838.0,2,self.algorithms,1bp076,Need help in understand Richard M. Karp on NP.,5,3,12,http://www.reddit.com/r/algorithms/comments/1bp076/need_help_in_understand_richard_m_karp_on_np/,"I am taking Analysis of Algorithms course in Queens College, and having a hard time understand the prof. on Karp paper about NP-hard and NP-Complete.

Does anyone know any useful and well explain links or books on  NP-hard and NP-complete?",,False,,t5_2qj1c,False,,,True,t3_1bp076,http://www.reddit.com/r/algorithms/comments/1bp076/need_help_in_understand_richard_m_karp_on_np/,
1364303977.0,2,self.algorithms,1b1ff4,Looking for an algorithm to find best assortment of food to meet USDA's Dietary Reference Intakes (DRI),5,3,7,http://www.reddit.com/r/algorithms/comments/1b1ff4/looking_for_an_algorithm_to_find_best_assortment/,"I am looking for an algorithm. I want to take the USDA dietary recommended intake (DRI) and find the optimum/minimum assortment of foods that, when combined, meet the DRI as closely as possible. Basically I want to create this guy's [soylent](http://robrhinehart.com/?p=424). He creates it using each isolated nutrient, so he can easily measure out the exact dosages. But to create this with regular foods would be more difficult. It would be the PERFECT food! But it might taste nasty...

normally I google this my self, but I really don't know where to start. The closest thing I can think of is packing algorithms. 

any help would be appreciated! thanks,",,False,,t5_2qj1c,False,,,True,t3_1b1ff4,http://www.reddit.com/r/algorithms/comments/1b1ff4/looking_for_an_algorithm_to_find_best_assortment/,
1364244055.0,2,self.algorithms,1azv3e,Help creating algorithm for poker-like game,5,3,5,http://www.reddit.com/r/algorithms/comments/1azv3e/help_creating_algorithm_for_pokerlike_game/,"I'm not sure if this is the best place to post this or not, but it's very probability based so hopefully someone here can help. 

I'm trying to create a poker-like game which uses a deck of 90 cards, containing 6 6's, 7 7's, 8 8's, 9 9's, 10 10's, 11 11's, 12 12's, 13 13's, and 14 14's. The possible hands would be High Card, Pair, 2 Pairs, 3 of a Kind, and 4 of a Kind. 

After doing some work on it, I began to notice that hands are not exactly linear. In other words, not all pairs beat all high cards, and not all 3 of a kinds beat all 2 pairs, etc; they're all just kind of mixed together. 

So, what I'm hoping to do, with your help, is assign a point value for each single, pair, triple, and quadruple so that no matter what combination of cards you have you can add the individual point values together and compare your value with the value of your opponents hands and determine a winner. 

For example, say my hand is (6 6 13 14) and your hand is (8 8 10 11), I want to add the point value of 2 6's, 1 13, and 1 14 and compare it to your point value of 2 8's, 1 10, and 1 11 to figure out the winner of the hand. 

Is it possible to make a system like this that is 100% accurate according to probabilities or is this just a lost cause?",,False,,t5_2qj1c,False,,,True,t3_1azv3e,http://www.reddit.com/r/algorithms/comments/1azv3e/help_creating_algorithm_for_pokerlike_game/,
1362994206.0,2,self.algorithms,1a2o6w,Question about Carmichael number detection.,4,2,2,http://www.reddit.com/r/algorithms/comments/1a2o6w/question_about_carmichael_number_detection/,"I'm having a bit of trouble understanding the motivation behind a particular algorithm presented in my textbook.  The algorithm is an improvement to the fermat test for prime number detection, and goes like this (Testing whether N is prime):


express N -1 as u*2^t where u is odd.  For each randomly chosen a, compute a^u, a^2u, a^4u, ... , a^N-1 .  The normal fermat test just checks whether a^N-1 is equal to 1, but this modified test also looks for the smallest a^k that equals 1, and checks if a^k/2 equals -1.  If not, a^k/2 is a nontrivial square root of 1 which is only possible modulo a composite number.  Thus the modified test fails in more cases than the fermat test and as it turns out, fails for Carmichael numbers.  


Now my question is: why bother looking at a^k/2? It seems to me that if you find a k &lt; N-1 such that a^k = 1, you can stop there and conclude that N is not prime.  This is my reasoning: if N is prime then the multiplicative group of integers mod N has order N, so the subgroup formed by powers of a must have order dividing N which is prime.  Therefore, a must have order N and there cannot exist k &lt; N-1 satisfying a^k = 1.  I cannot figure out how you could find such a k and not immediately conclude that N is not prime.  Why do you have to check a^k/2?  Am I missing something here?",,False,,t5_2qj1c,False,,,True,t3_1a2o6w,http://www.reddit.com/r/algorithms/comments/1a2o6w/question_about_carmichael_number_detection/,
1361812599.0,2,self.algorithms,19787d,Algorithm for constructing adjacency matrix for a hexagonal tessellation? ,5,3,3,http://www.reddit.com/r/algorithms/comments/19787d/algorithm_for_constructing_adjacency_matrix_for_a/,"Can someone point me to a solution? 

EDIT: adjacency is fine instead of adjacency matrix if you prefer",,False,,t5_2qj1c,1361813357.0,,,True,t3_19787d,http://www.reddit.com/r/algorithms/comments/19787d/algorithm_for_constructing_adjacency_matrix_for_a/,
1360701005.0,2,self.algorithms,18eb88,Refined Graph Problem,3,1,14,http://www.reddit.com/r/algorithms/comments/18eb88/refined_graph_problem/,"Hi everybody, I figured it would be better to start a new thread rather than appending to the old one, since I have finally refined what the problem I want to solve is.

I want to solve a(the?) directed Steiner tree problem.  Given an edge weighted graph G = G(V,E,w), and a subset of vertices S exists in V, find the minimum spanning tree for S in G.  I want this to be  a bidirectional graph, so that every edge E has a parallel edge E' pointed in the opposite direction who has a different weight.  Thus, the path from A-&gt;B is not the optimal path from B-&gt;A.

I think that I can also reformulate the problem as looking for the subgraph S in an undirected graph, but with 0 weight edges in some cases.  I think this case is more what I want, and so should have a simpler solution.  Thoughts?",,False,,t5_2qj1c,False,,,True,t3_18eb88,http://www.reddit.com/r/algorithms/comments/18eb88/refined_graph_problem/,
1349877193.0,2,self.algorithms,11923m,Multivariate correlation algorithm [Machine Learning],3,1,5,http://www.reddit.com/r/algorithms/comments/11923m/multivariate_correlation_algorithm_machine/,"Hello,
I am faced with the problem of trying to collapse variables together and not sure what the best way to start is.

I have a data set of 300 variables and 600 data sets. I am looking to create data pairs using the 600 data sets, where a single variable is chosen as the metric. so an input vector of 299 variables [x] and an output variable [y].

My goal is to create an algorithm where a number [z] is specified that corresponds to the number of 'clusters' desired. Such that the algorithm then attempts to create z number of variables based on the fluctuations of x with y. Ideally indicating which variables and the degree to which of the input variables (contained in [x]) affect the value of the clustered variable z.

Can anyone point me in the right direction?

I hope this has made sense, if not questions are obviously welcomed.

Thanks a lot.",,False,,t5_2qj1c,False,,,True,t3_11923m,http://www.reddit.com/r/algorithms/comments/11923m/multivariate_correlation_algorithm_machine/,
1347460254.0,2,self.algorithms,zrm8c,Comparing Stochastic Algorithms,3,1,3,http://www.reddit.com/r/algorithms/comments/zrm8c/comparing_stochastic_algorithms/,"Hello. I have what I'm sure is common problem.

I'm comparing the results of 3 stochastic algorithms, they each run 30 times and at the end of each run, they return a ""score"" which is the effectiveness of the solution found. I need to rank the three algorithms.

I am new to R but I used it to run one-way ANOVA and rejected the null hypothesis and concluded that the three algorithms are not all equally effective. Good, but I still need to rank them (ie Are algorithm A and B not statistically different from eachother, but different from C?) However, I read that I can't just do pair-wise comparison with t-tests or ANOVA because the degrees of freedom are too low.

So I read into Duncan multiple range tests and that seemed suited, but everywhere I look there are harsh criticisms of this method. What else should I use?

Or am I going about this the wrong way altogether?

Thanks in advance!
",,False,,t5_2qj1c,False,,,True,t3_zrm8c,http://www.reddit.com/r/algorithms/comments/zrm8c/comparing_stochastic_algorithms/,
1342772161.0,2,self.algorithms,wv4yk,Looking for help with developing an algorithm,8,6,8,http://www.reddit.com/r/algorithms/comments/wv4yk/looking_for_help_with_developing_an_algorithm/,"I'm developing an app that will fetch traffic times. I want an algorithm that will refresh my traffic times relative to the last data fetch. Since traffic time can vary so much, I'm trying to figure out a way that will fetch and update traffic times relative to my first time and update accordingly. I was thinking something along the lines of an exponential growth tacked to my first fetch, so most of my data fetching comes closer to the end of the process. Can anyone help, give feedback please?",,False,,t5_2qj1c,False,,,True,t3_wv4yk,http://www.reddit.com/r/algorithms/comments/wv4yk/looking_for_help_with_developing_an_algorithm/,
1335336128.0,2,travel.stackexchange.com,sresc,What is the fastest theoretical route for the London “Tube Challenge”?,5,3,3,http://www.reddit.com/r/algorithms/comments/sresc/what_is_the_fastest_theoretical_route_for_the/,,,False,,t5_2qj1c,False,,,False,t3_sresc,http://travel.stackexchange.com/q/6729/101,
1334709626.0,2,self.algorithms,sf5qo,Interested in number theory? Please help me understand an algorithm (or critique my code).,2,0,0,http://www.reddit.com/r/algorithms/comments/sf5qo/interested_in_number_theory_please_help_me/,"A while ago I ran across [Pollock's Conjecture](http://mathworld.wolfram.com/PollocksConjecture.html) in [Skiena's Algorithms book](http://www.amazon.com/Algorithm-Design-Manual-Steven-Skiena/dp/1848000693/ref=dp_ob_title_bk) and thought that it would be a fun problem to play around with. After some initial experiments in Python I moved to C for control and speed and created [this project](https://github.com/rheyns/pollock-conjecture-stats) which can calculate coverage for the first billion integers in 5 minutes on a Core 2-based laptop. (About 30000x faster than on Skienna's machine.)

After reviewing the literature I found a [paper](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.140.7839&amp;rep=rep1&amp;type=pdf) that claims to be able to check n integers in O(n) time. Currently my algorithm has the same complexity as Skienna's* namely O(n^(4/3)). In particular they claim to generate the 3-numbers - integers generated by the sum of three pyramidal numbers - in ""large constant"" time but I can't seem to find a description of how they do it.

I would also appreciate any comments on code style, documentation or any other ideas related to public code since my eventual goal is to use this project and others as sample code to make a career change to software engineering.

Thanks!

* okay, so I make O(m^2) function calls at one point but these mostly short-circuit and besides, m = n/10^9 so this asymptotic is unlikely to be seen for reasonable input sizes.",,False,,t5_2qj1c,False,,,True,t3_sf5qo,http://www.reddit.com/r/algorithms/comments/sf5qo/interested_in_number_theory_please_help_me/,
1331090870.0,2,self.algorithms,ql6i1,Help: determining if a subset is unique,2,0,1,http://www.reddit.com/r/algorithms/comments/ql6i1/help_determining_if_a_subset_is_unique/,"Basically we’re given an array A[0 … n-1] of n elements.  Given an index i where 0 &lt;= i &lt;= n-2
and index j where i &lt; j &lt;=n-1, we need to see if the subset of A[i … j] holds no duplicate values.
We call this out ""range uniqueness query.""  It returns a boolean whether or not the set holds unique values.

Beginner’s approach: we can see a very easy to implement algorithm that requires no preprocessing simply checks each element in A[i … j].  This requires |A[i … j]|2 comparisons.  This is also very bad.   Conclusion: Θ(n) space, Θ(k pow2) RUQ run-time (given k = |A[i … j]|). 

Beginner’s approach 2: we can see multiple redundant comparisons are made when checling the array A[i … j].  First off, we needn’t compare it to itself.  Also, one we check a pair of elements that pair is done.  This requires ceiling((|A[i … j]| -1)2/2) comparisons.  This is still very bad.
Θ(n) space, O(k pow2) RUQ run-time (given k = |A[i … j]|).

We want to reduce the number of comparisons by constructing a datastructure to compute some of it beforehand.  Then, the algorithm run on it takes care of the rest.  Note that we only care about… 
A)	The space of the resultant data structure
B)	The run-time of the RUQ

We can take as long as we want to construct the data structure, as long as it doesn’t take up too much space.

We could compute all values of all ranges before hand in a lookup table, but that would take Θ(n pow2) space, even though we get O(1) runtime.

Our prof gave us a hint saying it could be done looking at range minimum queries.

I was thinking, we could compute the uniqueness of subsets in the form of a segment tree, but if the elements of the subset do not form a whole branch of the tree, computations can get a bit out of hand.
  
Any ideas?  Anyone have any links that could help me out?  ",,False,,t5_2qj1c,False,,,True,t3_ql6i1,http://www.reddit.com/r/algorithms/comments/ql6i1/help_determining_if_a_subset_is_unique/,
1329712339.0,2,self.algorithms,pxcud,Identifying the algorithm to use to solve a Spotify Puzzle,2,0,3,http://www.reddit.com/r/algorithms/comments/pxcud/identifying_the_algorithm_to_use_to_solve_a/,"I have been trying for a few weeks to read this [Algorithm book](http://sist.sysu.edu.cn/~isslxm/DSA/textbook/Skiena.-.TheAlgorithmDesignManual.pdf) by Steven Skiena to brush up on long forgotten CS concepts from college. Today I came across this [Programming Puzzle](http://www.spotify.com/se/jobs/tech/bilateral-projects/) on Spotify and thought I'd take a shot at identifying the algorithm that could be used to solve this problem. So I dug into the Catalog which is the second part of the book and felt like I narrowed it down to Set cover/Set packing problem. But after an hour of digging into them, I realized that neither of the algorithms fit the problem.

So I have 2 questions:
1) Am I doing it right? Is this the correct way to solve problems like these? i.e., Try and identify the underlying algorithm that would solve the problem and then use that as the starting point. Or should I just try and solve the puzzle using my logical abilities and forget about trying to apply algorithms altogether.

2) I feel like I've abstracted the problem to something that would already have a standard algorithm for:

 Given a Universal Set U = {A, B, C...Z} and a bunch of subsets S1 ={A,B}, S2 ={B, C}, S3 = {A, C} ...etc. Find a subset S with the smallest number of items that would include at least one item from each of the subsets.

Ideas?
",,False,,t5_2qj1c,False,,,True,t3_pxcud,http://www.reddit.com/r/algorithms/comments/pxcud/identifying_the_algorithm_to_use_to_solve_a/,
1319750277.0,2,codeartisan.tumblr.com,lrf7j,Traveling Salesman solved with Ant Colony Optimization (code in Python),2,0,1,http://www.reddit.com/r/algorithms/comments/lrf7j/traveling_salesman_solved_with_ant_colony/,,,False,,t5_2qj1c,False,,,False,t3_lrf7j,http://codeartisan.tumblr.com/post/11944892293/solving-tsp-with-ant-colony-optimization-python,
1318838035.0,2,self.algorithms,lex8s,Help needed in geometry...,2,0,3,http://www.reddit.com/r/algorithms/comments/lex8s/help_needed_in_geometry/,"Hey everyone! 

Does anyone know of an algorithm with which I can find the greatest number of circular regions of a certain radius on a sphere that are not overlapping? The position doesn't matter. They only need to be disjoint and I need to know the position of the regions not only the total number.

If there is no such algorithm for the greatest number of circles is there one for constructing a reasonablt large number? Any  ideas?
Thanks a lot!",,False,,t5_2qj1c,False,,,True,t3_lex8s,http://www.reddit.com/r/algorithms/comments/lex8s/help_needed_in_geometry/,
1314696779.0,2,self.algorithms,jywqi,Question regarding 'Wall street algorithms' ,2,0,1,http://www.reddit.com/r/algorithms/comments/jywqi/question_regarding_wall_street_algorithms/,"I'm wondering about the algorithms Kevin Slavin talkins in [his TED talk!](http://www.ted.com/talks/lang/eng/kevin_slavin_how_algorithms_shape_our_world.html). 

When he says algorithm does he means like a pattern in the stock market? If so, can these algorithms help predict the market?",,False,,t5_2qj1c,False,,,True,t3_jywqi,http://www.reddit.com/r/algorithms/comments/jywqi/question_regarding_wall_street_algorithms/,
1284755769.0,2,ic.sunysb.edu,dfdh5,"Visualization of Delaunay diagram algorithm that 
computes it via lift a to paraboloid",2,0,1,http://www.reddit.com/r/algorithms/comments/dfdh5/visualization_of_delaunay_diagram_algorithm_that/,,,False,,t5_2qj1c,False,,,False,t3_dfdh5,http://www.ic.sunysb.edu/Stu/rkogan/delaunay_applet/,
1228636937.0,2,catonmat.net,7hw7e,"MIT's Introduction to Algorithms, Lectures 4 and 5: Sorting",7,5,0,http://www.reddit.com/r/algorithms/comments/7hw7e/mits_introduction_to_algorithms_lectures_4_and_5/,,,False,,t5_2qj1c,False,,,False,t3_7hw7e,http://www.catonmat.net/blog/mit-introduction-to-algorithms-part-three/,
1215902146.0,2,catonmat.net,6rhro,Three Beautiful Quicksorts,3,1,0,http://www.reddit.com/r/algorithms/comments/6rhro/three_beautiful_quicksorts/,,,False,,t5_2qj1c,False,,,False,t3_6rhro,http://www.catonmat.net/blog/three-beautiful-quicksorts/,
1372570998.0,1,self.algorithms,1hcotn,Help with multivariate clustering,4,3,4,http://www.reddit.com/r/algorithms/comments/1hcotn/help_with_multivariate_clustering/,"I've been stuck on this clustering problem I'm having trouble resolving. I've done clustering before when having to find clusters from the results of an experiment. The trouble I'm having now is that I want to create clusters from attributes of the experiment results. For example, the following would be the attributes of the experiment results:


Experiment 1: (att0:true), (att1, false), (att2, true), (att3, true), (att4, true), (att5, true), etc

Experiment 2: (att0:true), (att1, false), (att2, false), (att3, true), (att4, false), (att5, true), etc

Experiment 3: (att0:true), (att1, true), (att2, true), (att3, true), (att4, false), (att5, true), etc

Experiment 4: (att0:false), (att1, true), (att2, true), (att3, false), (att4, false), (att5, false), etc


I would like to be able to cluster together (att0, att3, att5) as a cluster that is always present together (if one attribute is present, all of the attributes in the cluster are present). I do not care about any other clusters that do not have this property. My current approach is to find mutual pairwise attributes that have this property, and then checking all such pairs against each other to determine clusters. The number of attributes can get up to a couple of hundred, and the number of experiments can get up to tens of thousands. My approach just doesn't cut it. 


What is the relevant family of algorithms that I should be looking at? Since I've done clustering before, I've tried it but haven't been able to formulate the data in a suitable manner. I've also given data mining a quick glance but haven't gotten anywhere yet.",,False,,t5_2qj1c,False,,,True,t3_1hcotn,http://www.reddit.com/r/algorithms/comments/1hcotn/help_with_multivariate_clustering/,
1371526292.0,1,reddit.com,1gka3e,Any suggestions for optimising this solution to the programming problem? : AskComputerScience,3,2,0,http://www.reddit.com/r/algorithms/comments/1gka3e/any_suggestions_for_optimising_this_solution_to/,,,False,,t5_2qj1c,False,,,False,t3_1gka3e,http://www.reddit.com/r/AskComputerScience/comments/1gj3uq/any_suggestions_for_optimising_this_solution_to/,
1365900704.0,1,self.algorithms,1catjm,Stable-Marriage Problem applied to teacher-teaching assistant pairing.,3,2,5,http://www.reddit.com/r/algorithms/comments/1catjm/stablemarriage_problem_applied_to_teacherteaching/,"Say you've got 83 teachers and 157 student teaching assistants.

Every application of the gale-shapley algorithm I find shows matching of even numbers.  

Is there an implementation where there are uneven matching pairs?  Or an implementation where it is unreasonable to ask someone to rank every student?  For example, a teacher picks their favorite 10 kids, and they'll be assigned two of them.  And a student picks their favorite five teachers?

I'm not looking for a coded solution -- just a direction to point my search.

Thanks.",,False,,t5_2qj1c,False,,,True,t3_1catjm,http://www.reddit.com/r/algorithms/comments/1catjm/stablemarriage_problem_applied_to_teacherteaching/,
1363311329.0,1,self.algorithms,1abnzv,Creating an Algorithm to select/optimize from a list of resources,4,3,4,http://www.reddit.com/r/algorithms/comments/1abnzv/creating_an_algorithm_to_selectoptimize_from_a/,"I've been assigned my first algorithm intensive task and need some guidance on how to start to build a reasonable algorithm. It goes like this - If a web visitor comes to a page and requests a widget, I need to select the best vendor to get the widget from. The selection criteria maybe one of two, or a combination: 
(1) We guarantee a minimum of downloads per day per vendor, some vendors will not...but need to be fair (for example fill Vendor A's completely without giving Vendor B, C anything until it's filled)
(2) Maximizing revenue..some vendor may offer higher amounts than others and we need to optimize for revenue, but we need to be fair to vendors offering less (they will get some downloads but at a trickle)

I don't know what class of problem this is, but it seems similar to what Google does with Adwords (but I maybe mistaken) except only the highest vendor on the list gets anything.  Any guidance or thoughts would be most appreciated...or even pointers to papers.",,False,,t5_2qj1c,False,,,True,t3_1abnzv,http://www.reddit.com/r/algorithms/comments/1abnzv/creating_an_algorithm_to_selectoptimize_from_a/,
1362113505.0,1,self.algorithms,19g1sa,Lempel-Ziv 78 Compression with HashMap,2,1,2,http://www.reddit.com/r/algorithms/comments/19g1sa/lempelziv_78_compression_with_hashmap/,"Hi, I have been tasked with the assignment of writing a program that takes in a binary string and outputs the compressed version under LZ78 compression. In the assignment, our professor asked us to do it in two different ways, once with a trie, and once with an implementation of Java's HashMap.

The compression with the dictionary backed by a trie data structure was easy enough for me to understand (0 goes to left, 1 goes to right). However, with the HashMap version, I'm having trouble envisioning how to start (what should be the types for keys and values for the hashmap). 

In the trie based implementation I used a node class that contained the last read bit of that phrase and the index of that phrase.",,False,,t5_2qj1c,False,,,True,t3_19g1sa,http://www.reddit.com/r/algorithms/comments/19g1sa/lempelziv_78_compression_with_hashmap/,
1354682167.0,1,self.algorithms,14b0kn,"Another polynominal reduction question. Proving if A is polynominally reducicble to B and B in in P then A is also in P, how to prove?",4,3,4,http://www.reddit.com/r/algorithms/comments/14b0kn/another_polynominal_reduction_question_proving_if/,"If A is polynominally reducicble to B and B in in P then A is also in P.

Is this proved by stating, that because there is a function F such that if x belongs to A and F(x) belongs to B then by the fact of polynominal reduction that computations of the x must be done in polynominal time and the number of calls to F is polynominal and the amount of work done by F is polynominal. A polynominal of a polynominal is still a polynominal, thus A can be solved in polynominal time and is also in P. ",,False,,t5_2qj1c,False,,,True,t3_14b0kn,http://www.reddit.com/r/algorithms/comments/14b0kn/another_polynominal_reduction_question_proving_if/,
1351255872.0,1,self.algorithms,124d3c,Is there a solution/formula for this?,2,1,2,http://www.reddit.com/r/algorithms/comments/124d3c/is_there_a_solutionformula_for_this/,"A staff of employees are rewarded for productivity (individually measured by a number P). The total amount to be distributed to the staff is R.

Each employee is supposed to get a productivity bonus calculated as:  

* bonus = R * P / (sum of P for the staff)

That is, each employee gets a share of R according to his percentage of the overall productivity (sum of P for the staff).

But for an employee to get the productivity bonus, this bonus has to be above what he would normally be paid (salary S).
Let's call an employee E1 and his salary S1 and his productivity measure P1.

That is, E1 receives the bonus only if:

* S1 &lt; R * P1 / (sum of P for the staff)

When an employee's productivity bonus is below his salary S, his P is taken from the overall productivity and his salary is taken from R.
So after E1 is removed, the bonus is recalculated for the remaining employees as:

* bonus after E1 is removed = (R - S1) * P / (sum of P for the staff - P1)

This process repeats until no employee is removed or until all of them are removed.

When someone's salary is too high with low productivity, the bonus for the remaining employees will be reduced and different people will be removed from the calculation in the next iteration.

Is there a formula or an optimized algorithm to find out sooner who receives and who doesn't receive the bonus?
I am looking for any ideas to improve this and, if possible, eliminate the iterations. Any indications of what to research are welcome!",,False,,t5_2qj1c,False,,,True,t3_124d3c,http://www.reddit.com/r/algorithms/comments/124d3c/is_there_a_solutionformula_for_this/,
1350658181.0,2,github.com,11qz0t,Been teaching myself algorithms. How did I do?,8,6,0,http://www.reddit.com/r/algorithms/comments/11qz0t/been_teaching_myself_algorithms_how_did_i_do/,,,False,,t5_2qj1c,False,,,False,t3_11qz0t,https://github.com/AeroNotix/algostructure,
1340758963.0,1,self.algorithms,vns93,A very novice algorithm problem,2,1,4,http://www.reddit.com/r/algorithms/comments/vns93/a_very_novice_algorithm_problem/,"FULL DISCLAIMER: I am not an algorithm user/creator/anything else. I am very much a newb here, briefly visiting your fine subreddit with the humblest of genuflects. 


OK, I have a variable in a data set in which all the values range between 1 and 5. Long story short, it would make my life easier if the values instead ranged between 1 and 100, such that 1=1, 3=50, and 5=100. 

First question: is there an algorithm solution? And more importantly,

Second question: how would you come up with such a solution? I've been racking my brain a bit and can't seem to come up with anything substantial.

Thanks all!",,False,,t5_2qj1c,False,,,True,t3_vns93,http://www.reddit.com/r/algorithms/comments/vns93/a_very_novice_algorithm_problem/,
1338261179.0,1,self.algorithms,u9qn2,naive rod cutting proof help,2,1,5,http://www.reddit.com/r/algorithms/comments/u9qn2/naive_rod_cutting_proof_help/,"This should be an easy substitution method, but I can't seem to get it. Ok, so I'm given that the recurrence relation for a non-memoized rod cutting algorithm is T(n) = 1 + { sum from j==0 to n-1 of T(j) }, and I'm asked to show that T(n) = 2^n . I also know that the number of problems that this algorithm has to solve is the sum of our number of items choose the number of subproblems less then n that haven't been solved yet. When tackling the recurrence tree, Its obvious that it grows at 2^n, but how do I prove this using substitution or induction. I won't lie, this is a homework problem (although it won't ever be graded...) so avoid feeding me the answer, I would like to be able to solve recurrences like this when it actually matters (like my algo test next week) Thanks for any help or advice! ",,False,,t5_2qj1c,False,,,True,t3_u9qn2,http://www.reddit.com/r/algorithms/comments/u9qn2/naive_rod_cutting_proof_help/,
1332616910.0,1,self.algorithms,rbppu,"Working out the ""best"" score based on quantity and ratio",2,1,4,http://www.reddit.com/r/algorithms/comments/rbppu/working_out_the_best_score_based_on_quantity_and/,"Hope I'm posting in the right place!

I've got a lot of products rated good, bad and OK.
What I'm having trouble with is finding which is rated the ""best""- similar to Amazon's sort by rating.

Getting the average rating won't work as I want a product with 99 good ratings and 1 bad rating to rank higher than a product with just 2 good ratings.

Any ideas on what type of formula to use?",,False,,t5_2qj1c,False,,,True,t3_rbppu,http://www.reddit.com/r/algorithms/comments/rbppu/working_out_the_best_score_based_on_quantity_and/,
1328909659.0,1,self.algorithms,pjx0y,Looking for an algorithm.,1,0,1,http://www.reddit.com/r/algorithms/comments/pjx0y/looking_for_an_algorithm/,"I have a grid of 10x10 tiles.
Lets say I have a field looking like this:

    000000000000
    011111100000
    001111000000
    000000000000

Let 0 be a free space and 1 be a tile.
I want to find the vertices of the polygon created with those tiles. For this example it would give us an array of vertices:
10,10; 70,10; 70,20; 60,20; 60,30; 20,30; 20,20; 10,20.

Just need to know is there a name for this algorithm and what it is.",,False,,t5_2qj1c,False,,,True,t3_pjx0y,http://www.reddit.com/r/algorithms/comments/pjx0y/looking_for_an_algorithm/,
1326175493.0,1,self.algorithms,oai6e,Ask: What is the difference between an eigenvalue and a Ritz value?,1,0,0,http://www.reddit.com/r/algorithms/comments/oai6e/ask_what_is_the_difference_between_an_eigenvalue/,"Specifically, we're trying to use ARPACK to find eigenmodes for a fluid dynamics problem and can't seem to make any sense of even the simplest example.",,False,,t5_2qj1c,False,,,True,t3_oai6e,http://www.reddit.com/r/algorithms/comments/oai6e/ask_what_is_the_difference_between_an_eigenvalue/,
1322590841.0,1,stackoverflow.com,mtl1e,AskReddit: I have posted a question in Stackoverflow. Please see if you can answer it.,1,0,0,http://www.reddit.com/r/algorithms/comments/mtl1e/askreddit_i_have_posted_a_question_in/,,,False,,t5_2qj1c,False,,,False,t3_mtl1e,http://stackoverflow.com/questions/8314746/voronoi-tessalation-in-python,
1318814439.0,1,self.algorithms,lem19,Efficient matrix multiplication in commercial and open source software,1,0,0,http://www.reddit.com/r/algorithms/comments/lem19/efficient_matrix_multiplication_in_commercial_and/,"Hi,

I am trying to find some real world cases that involves efficient matrix multiplication and as such requires finding the best order for the multiplication of some matrices.

Do you know any software applications that depend on finding the most efficient order for multiplication of a number of given matrices?",,False,,t5_2qj1c,False,,,True,t3_lem19,http://www.reddit.com/r/algorithms/comments/lem19/efficient_matrix_multiplication_in_commercial_and/,
1317451501.0,1,self.algorithms,kxauy,Graph pattern matching,2,1,0,http://www.reddit.com/r/algorithms/comments/kxauy/graph_pattern_matching/,"Algorithmic friends!

I'm writing a [pattern matcher](http://docs.neo4j.org/chunked/snapshot/cypher-query-lang.html) for a graph database, and I find myself in unknown territory.

I'd like to learn much more about this topic, but I don't know where to look. Any and all recommendations for accessible book on the subject would be very appreciated.

Thank you!",,False,,t5_2qj1c,False,,,True,t3_kxauy,http://www.reddit.com/r/algorithms/comments/kxauy/graph_pattern_matching/,
1313297338.0,1,self.algorithms,ji8ng,"Identify a problem, maybe even suggest an algorithm?",1,0,0,http://www.reddit.com/r/algorithms/comments/ji8ng/identify_a_problem_maybe_even_suggest_an_algorithm/,"I have a problem; I hope it is a problem someone has solved before!

Description:  Suppose that a directed graph is given, in which each edge is weighted by a (strictly positive) number, and each vertex has been assigned a color from the set {C1,..,CN}.

A finite sequence of colors is given, X1,X2,...,XM.  The problem is to find a sequence of vertices x1,...,xM such that:

* each vertex in the sequence is adjacent to the previous vertex in the sequence (except the first vertex, of course)

* vertex xk must have color Xk (so the kth vertex must have the kth given color)

* the weight of the resulting path is minimal.  (Weight is computed in the usual way, summing the weights of the edges traversed.)

Two important notes.  First, vertex x1 may be any vertex with appropriate color X1 (i.e. there is no particular starting location given, only a required starting color).  Second, a vertex may be repeated in the chosen sequence.  (In the application I have in mind, not only are vertices repeated, they are often repeated.)

It is straightforward to code up a brute-force attack (tree out all of the vertex sequences satisfying the given sequence of colors, choose the one of minimal weight).  I am wondering if this is a problem that has been studied before, and if there is a more elegant approach to solving the problem.  (A modification to Dijkstra's algorithm came to mind first.)

Any help is appreciated!",,False,,t5_2qj1c,False,,,True,t3_ji8ng,http://www.reddit.com/r/algorithms/comments/ji8ng/identify_a_problem_maybe_even_suggest_an_algorithm/,
1304406559.0,1,iq-games.blogspot.com,h2z52,"All about Towers of Hanoi. Algorithm of all variations of problems, generic case and java code too! ",2,1,0,http://www.reddit.com/r/algorithms/comments/h2z52/all_about_towers_of_hanoi_algorithm_of_all/,,,False,,t5_2qj1c,False,,,False,t3_h2z52,http://iq-games.blogspot.com/2011/02/bringing-down-towers-of-hanoi-part1.html,
1303975389.0,1,forums.nvidia.com,gz4za,Request for OpenCL LU decomposition library,1,0,1,http://www.reddit.com/r/algorithms/comments/gz4za/request_for_opencl_lu_decomposition_library/,,,False,,t5_2qj1c,False,,,False,t3_gz4za,http://forums.nvidia.com/index.php?showtopic=45909,
1303578391.0,1,www-igm.univ-mlv.fr,gvt2x,String Matching Algorithms Visualized,1,0,0,http://www.reddit.com/r/algorithms/comments/gvt2x/string_matching_algorithms_visualized/,,,False,,t5_2qj1c,False,,,False,t3_gvt2x,http://www-igm.univ-mlv.fr/~lecroq/string/,
1303577367.0,1,laplacian.wordpress.com,gvssu,How Shazam Works: ID-ing Music,1,0,0,http://www.reddit.com/r/algorithms/comments/gvssu/how_shazam_works_iding_music/,,,False,,t5_2qj1c,False,,,False,t3_gvssu,http://laplacian.wordpress.com/2009/01/10/how-shazam-works/,
1302428072.0,1,self.algorithms,gmn4w,Best Book/paper for developing intuition for network flow algorithms ? ,1,0,0,http://www.reddit.com/r/algorithms/comments/gmn4w/best_bookpaper_for_developing_intuition_for/,,,False,,t5_2qj1c,False,,,True,t3_gmn4w,http://www.reddit.com/r/algorithms/comments/gmn4w/best_bookpaper_for_developing_intuition_for/,
1298933709.0,1,self.algorithms,fummd,New computer vision algorithm for computer aided diagnosis of medical images or general pattern matching,1,0,0,http://www.reddit.com/r/algorithms/comments/fummd/new_computer_vision_algorithm_for_computer_aided/,"Dr. Balis and his colleagues have produced a new Spatially-Invariant Vector Quantization (SIVQ) algorithm for locating similar areas within a digital image. This has huge implications in medicine and specifically pathology since diagnosing physician pathologists review human biopsy tissue on glass slides using a microscope, and a single tissue slide when scanned at 400x may result in an image up to 30 Gigapixels in size. A single physician pathologist after 3 to 6 years of specialized training usually reviews 50 to 300 glass slides with tissue per day from different patients to diagnose cancer and other diseases. See the images in the paper: [Hipp JD, Cheng JY, Toner M, Tompkins RG, Balis UJ. Spatially Invariant Vector Quantization: A pattern matching algorithm for multiple classes of image subject matter including pathology. J Pathol Inform 2011;2:13](http://www.jpathinformatics.org/article.asp?issn=2153-3539;year=2011;volume=2;issue=1;spage=13;epage=13;aulast=Hipp)",,False,,t5_2qj1c,False,,,True,t3_fummd,http://www.reddit.com/r/algorithms/comments/fummd/new_computer_vision_algorithm_for_computer_aided/,
1219423889.0,1,catonmat.net,6xjb2,"Review of MIT's ""Introduction to Algorithms"" course. Part two: Divide and Conquer",2,1,0,http://www.reddit.com/r/algorithms/comments/6xjb2/review_of_mits_introduction_to_algorithms_course/,,,False,,t5_2qj1c,False,,,False,t3_6xjb2,http://www.catonmat.net/blog/mit-introduction-to-algorithms-part-two/,
1219339296.0,1,catonmat.net,6xe5x,"Detailed review of MIT's ""Introduction to Algorithms"" course. Part one: Analysis of Algorithms and Asymptotic Notation",2,1,0,http://www.reddit.com/r/algorithms/comments/6xe5x/detailed_review_of_mits_introduction_to/,,,False,,t5_2qj1c,False,,,False,t3_6xe5x,http://www.catonmat.net/blog/mit-introduction-to-algorithms-part-one/,
1372737812.0,0,self.algorithms,1hh4wm,Clustering on non-numeric (categorical) data,2,2,4,http://www.reddit.com/r/algorithms/comments/1hh4wm/clustering_on_nonnumeric_categorical_data/,"Hi all!

I am researching clustering algorithms for data that is not numeric. I am not at liberty to discuss exactly on what data I'm clustering (it's proprietary information), but I can give you an idea of the kind of data I have. Also, I am somewhat new to this area of study. Please let me know if my understanding is off and I should be trying different things.

So, pretty much all of the clustering algorithms I've come across so far use some notion of distance to find clusters. This is fine if your data is numeric and it has some intrinsic *value* that we find meaningful. For example, we would consider the value of a housing price meaningful because we could compare two instances of it in a helpful way: $200k - $150k = $50k lets us know that the value of the first price is more than the second. A distance measure would thus be helpful in this case. This is not so for categorical data. Categorical data is where the instances of the feature all fall into a set with no natural ordering. Car makes, for example, would be considered categorical data. We would find no meaning in comparing the names of two manufacturers in the same way we did the housing prices: Ford - Toyota = ??? is not very helpful. Even if we assigned numbers to the categories, the distances we would find would be arbitrary and hence meaningless.

My data is a mix of these two things. I have numeric, categorical, and boolean features in my data sets (I consider boolean data a subset of categorical data, although we *might* find boolean distances meaningful with proper scaling). My research so far has turned up these two promising-ish papers:

* [Clustering Mixed Numeric and Categorical Data: A Cluster Ensemble Approach](http://arxiv.org/ftp/cs/papers/0509/0509011.pdf)

* [Rock: A Robust Categorical Algorithm for Clustering Attributes](http://www.cis.upenn.edu/~sudipto/mypapers/categorical.pdf)

I don't know if these are quite what I'm looking for. They seem a bit hand-wavey about certain things (especially the first), but the other papers I found were much worse. Is there anyone on here who has experience with trying to cluster this type of data? If so, could you point me in the direction of some decent papers to read up on?

Thanks in advance!

**tl;dr** - I need to cluster mixed categorical and numeric data. Know of any good papers?",,False,,t5_2qj1c,False,,,True,t3_1hh4wm,http://www.reddit.com/r/algorithms/comments/1hh4wm/clustering_on_nonnumeric_categorical_data/,
1372335463.0,0,self.algorithms,1h69sx,Looking for a really good and detailed description for: loop invariant and time/computational complexity.,2,2,1,http://www.reddit.com/r/algorithms/comments/1h69sx/looking_for_a_really_good_and_detailed/,"Hello /r/algorithms,

First of all: english is not my first language. I took those names from google translate.

So to make things clear:

* loop invariant - proof that *some specific condition* is true at the end of the code/pseudocode. For example - I have this piece of code: http://i.imgur.com/v80yybe.png , and I have to prove that: value of variable suma is equal to sum numbers from 0 to (i-1) and is loop invariant. I really don't know how to even start solving this kind of thing.

* Time/computational complexity - calculate how much time specific algorithm will take and what is his computantional complexity (notation O(..)). The problem here is that I don't know many times specific instruction will performe/execute. What I am talking about: http://i.imgur.com/dEsE73S.png. Now, how to do simmilar thing to this: http://i.imgur.com/o0NVimN.png. I am able to do the rest of equations and calculations, I just have the problem to specify n's.

I would appreciate any help. If I am asking for too much or I am in the wrong place, just tell me.

That's it.",,False,,t5_2qj1c,False,,,True,t3_1h69sx,http://www.reddit.com/r/algorithms/comments/1h69sx/looking_for_a_really_good_and_detailed/,
1371840095.0,0,self.algorithms,1gt6et,Technology for email to make it hard to spy.,3,3,3,http://www.reddit.com/r/algorithms/comments/1gt6et/technology_for_email_to_make_it_hard_to_spy/,"What if the email (and text chat) protocol changed to following -
Each email address is associated with public and private key and all the public key for every email address is stored in a server, which has to be queried by sender before sending mail to a recipient. For sending mail to multiple people, the mail will be encrypted for each recipient with their public key and multiple copy has to be kept at server.
Mail sending - 
* Foreach recipient, get their public key
* Foreach recipient, send Encrypt(email data,  recipient key) to mail server

Mail reading -
* Get my encrypted email and decode using my private key

What I am focusing on with this protocol is -
* The middleman must not be allowed to view the email content
* CPU intensive task for encrypting and decrypting happen at client computer, so the cost of maintaining mail server is minimal.
* Can be amalgamated into existing email protocol. User will have to use special client to send AND read encrypted email.
What this protocol doesn't do -
* still doesn't solve the problem of encrypted header 
* mail sent to this address from outside domain will be unencrypted.

I would be glad to hear more expert opinion on this. And since I am not a lawyer so any comment on legality of such service is welcome.",,False,,t5_2qj1c,False,,,True,t3_1gt6et,http://www.reddit.com/r/algorithms/comments/1gt6et/technology_for_email_to_make_it_hard_to_spy/,
1371030681.0,0,self.algorithms,1g6qm7,"help designing algorithms, suggested programs.",1,1,0,http://www.reddit.com/r/algorithms/comments/1g6qm7/help_designing_algorithms_suggested_programs/,"I am currently an athletic training student and I am working on an emergency protocol algorithm for my university on what to do in result of different athletic injuries. I can come up with the algorithms fairly decent at least I think so. the problem I am having is visually mapping them out. Since this will be implemented I cannot do just drawings (unfortunately) so i would need this typed out or mapped out on some sort of computer program.

I am trying to map it out on microsoft word but that is a pain in the butt. Doing that for 10+ different injuries will take entirely too long and will be too stressful. The flow charts on microsoft word (that i tried) weren't able to do much if yes/if no scenarios. Does anyone know of any software or website or tip/trick in microsoft word to make the designing of an algorithm that much easier.I am currently working on an apple computer (if that helps).

Any help would be much appreciated! thanks!",,False,,t5_2qj1c,False,,,True,t3_1g6qm7,http://www.reddit.com/r/algorithms/comments/1g6qm7/help_designing_algorithms_suggested_programs/,
1370937832.0,0,self.algorithms,1g3xkv,extending a partial order to an optimal linear order,2,2,0,http://www.reddit.com/r/algorithms/comments/1g3xkv/extending_a_partial_order_to_an_optimal_linear/,"I have a big set of elements, where every element has a set of attributes. This attributes can be clustered into two groups such that the attributes of the elements are reduced to one binary attribute (0 for one group and 1 for the other) where attribute 1 is considered better then 0.
On this set of elements a partial order is given. With this order around 5% of the elements are comparable and also several elements with attribute 0 are better than elements with attribute 1.
The goal is now to find the optimal linear extension such that the number of 0/1 inversions is minimized, or in other words the elements with attribute 1 are ranked as high as possible.
The problem sounds easy, but at least for me it is not. i came up with two heuristics which provide approximations of the optimal ordering but there are always some parts of the ordering which are not optimal. My last idea would be a linear programm, but maybe there already exists an algorithm i am not aware of, or somebody of you has any idea.
",,False,,t5_2qj1c,False,,,True,t3_1g3xkv,http://www.reddit.com/r/algorithms/comments/1g3xkv/extending_a_partial_order_to_an_optimal_linear/,
1370575017.0,0,informit.com,1fu81y,"A fresh perspective on iteration (Alexandrescu, 2009)",2,2,0,http://www.reddit.com/r/algorithms/comments/1fu81y/a_fresh_perspective_on_iteration_alexandrescu_2009/,,,False,,t5_2qj1c,False,,,False,t3_1fu81y,http://www.informit.com/articles/printerfriendly.aspx?p=1407357,
1370066059.0,0,reddit.com,1fgaj2,Checking if guesses==valid for Mastermind game (x-post from LearnProgramming),5,5,0,http://www.reddit.com/r/algorithms/comments/1fgaj2/checking_if_guessesvalid_for_mastermind_game/,,,False,,t5_2qj1c,False,,,False,t3_1fgaj2,http://www.reddit.com/r/learnprogramming/comments/1fg7c3/checking_if_guessesvalid_for_mastermind_game/,
1369359202.0,0,self.algorithms,1exz5q,Time Efficiency Analysis,4,4,3,http://www.reddit.com/r/algorithms/comments/1exz5q/time_efficiency_analysis/,"Hey first time posting to this subreddit but im having some trouble doing the time efficiency analysis for basic algorithms. For the first one I dont believe that all the answers are n but idk what else they would be. For the second problem im not sure how to compute the C(n). Could someone explain this to me and let me know if i am doing this right?
Thanks for reading everyone!

//input: integer n&gt;0

S=0

for i = 1 to n 

   S = S+i*i

return S

Input Size: n
Basic operation: +, *
Worst: n
Average: n
Best: n
C(n): n
Cannot be simplified

//input: nxn matrix A of real numbers

for i = 0 to n-2{
 
   for j = i+1 to n-1{ 

   if A[i,j]≠A[j,i]

  return false

}}

return true
",,False,,t5_2qj1c,False,,,True,t3_1exz5q,http://www.reddit.com/r/algorithms/comments/1exz5q/time_efficiency_analysis/,
1369289106.0,0,self.algorithms,1ew0ih,"""Magic Square""-esque problem.",1,1,3,http://www.reddit.com/r/algorithms/comments/1ew0ih/magic_squareesque_problem/,"So I'm writing a program to solve ""magic square""-esque type problem for personal use (aka cheating MAG grab in SMT: Soul Hackers), but I'm having trouble breaking down the solution process.

http://imgur.com/1cWjNrI 

Always Given:

1. Value of the center square

2. Hints for each column and row

Rules:

1. Each square holds a number 1 through 9
2. Each number is used only once.
3. Each row and column added and modulus-ed by ten must be equal to the hint provided for the row/column. (EG. (a+b+c) % 10 = 5 and (a+d+g) % 10 = 8 in the above example.

Anyone know what the most efficient (or at least working) algorithm is for solving this problem?

I figure you start by figuring out all possible pairs of numbers for the center row or column, but not sure how to proceed...",,False,,t5_2qj1c,False,,,True,t3_1ew0ih,http://www.reddit.com/r/algorithms/comments/1ew0ih/magic_squareesque_problem/,
1368747379.0,1,self.algorithms,1ehfug,Optimality Rant,5,4,12,http://www.reddit.com/r/algorithms/comments/1ehfug/optimality_rant/,"This might be slightly unrelated to algorithms, but I didn't know where else to ask.

I've been programming for about 6 years now. I started in college (majoring in CSE) and immediately after that, I decided to join graduate school. I have absolutely no industry experience (I don't know if that matters or not), but I will be starting my first full time job (SDE) in a big company this fall.  

So here's my problem: When I'm trying to come up with an algorithm for something, I always try to optimize my algorithm as much as possible in my first attempt. I always aim for perfection in my first attempt. What that does is that it distracts me from the actual problem at hand to the point where I'm not thinking about the actual problem, rather trying to come up with the optimal way to solve the incomplete problem.  

I noticed this during my interviews too. Whenever I was asked a coding question, I'd try to come up with the best solution in the first attempt. Effectively, not thinking about the actual problem at all.  

I have the same problem in practice (while I'm actually coding). For example, in Java, I try to avoid using Lists and always see if there's a way to work around them and use arrays instead. In my brain, I'm thinking, ""Arrays are more *native*. Lists have overhead. The array solution will be more efficient."" And it doesn't stop there. If I come to the conclusion that I cannot do without Lists, then after I've got the List and have to return it, I'll convert the list to an array and return an array instead because, ""It will be more efficient.""  

Sometimes, I even try to reuse variables/objects.

/rant

So here's what I wanted to ask:

1. Does anyone else do this? How do I get out of this mindset of always aiming for the best solution?
2. In practice, how much more efficient is it really, if I use an array instead of a list? Are there any numbers?
",,False,,t5_2qj1c,False,,,True,t3_1ehfug,http://www.reddit.com/r/algorithms/comments/1ehfug/optimality_rant/,
1348004833.0,0,self.algorithms,103o2y,how do i come up with an algorithm - not even sure how to ask my question,2,2,1,http://www.reddit.com/r/algorithms/comments/103o2y/how_do_i_come_up_with_an_algorithm_not_even_sure/,"So it is worth mentioning that this problem is already solved, I am not asking for the answer.  What I am after is how to come up with the answer i.e. what would one need to know in order to develop an algorithm to solve the following problem, probably formatted very poorly.

x = list of arbitrary length
n = a given number of sublists

if x modulo n = 0:
     then divide x into n sublists such that each sublist is of the same length
else
     then divide x into n-1 sublists such that each sublist is of the same length and put the remaining items into an additional final sublist.  the length of the last sublist should be as close to the length of the other sublists as possible without being greater
	 
example:

if i have a list x of length 11 and n is 4

name1
name2
name3

name4
name5
name6

name7
name8
name9

name10
name11

if i have a list x of length 11 and n is 3

name1
name2
name3
name4

name5
name6
name7
name8

name9
name10
name11

",,False,,t5_2qj1c,False,,,True,t3_103o2y,http://www.reddit.com/r/algorithms/comments/103o2y/how_do_i_come_up_with_an_algorithm_not_even_sure/,
1346061648.0,0,self.algorithms,ywb6j,The % of Histoy Lost,2,2,2,http://www.reddit.com/r/algorithms/comments/ywb6j/the_of_histoy_lost/,Is there an algorithm that calculates the ~amount of recorded history that has been lost? Assuming each year back we go in history we retain a smaller proportion of recorded history that the last. ,,False,,t5_2qj1c,False,,,True,t3_ywb6j,http://www.reddit.com/r/algorithms/comments/ywb6j/the_of_histoy_lost/,
1344911038.0,0,self.algorithms,y6i1p,Use the digit n exactly k times to make the number M. You may use any mathematical symbols you would like.,2,2,4,http://www.reddit.com/r/algorithms/comments/y6i1p/use_the_digit_n_exactly_k_times_to_make_the/,"I came across the following problem:

Use 8 exactly eight times to make 1000.  You may use any mathematical symbols you would like.

Let's assume you can also concatenate digits (e.g. 888).

Given generic digit n, integer k, and solution M, how would you design an algorithm to solve this problem as quickly as possible?",,False,,t5_2qj1c,False,,,True,t3_y6i1p,http://www.reddit.com/r/algorithms/comments/y6i1p/use_the_digit_n_exactly_k_times_to_make_the/,
1336881233.0,0,self.algorithms,tkjpc,How to prove load balancing is NP-complete,1,1,0,http://www.reddit.com/r/algorithms/comments/tkjpc/how_to_prove_load_balancing_is_npcomplete/,"Load balancing is when you have n jobs where each job takes some time t and you have k processors. You want to split the jobs across the processors so that the last processor to finish finishes at the earliest possible.

So I have this homework problem to prove that load balancing with 2 processors is NP-complete by doing a reduction from subset sum. I've been stuck on this for a while and I'm getting nowhere. 

The closest thing I can see is that there are 2^n ways to assign jobs to processors. So you can think of one processor as being items in a subset, and the other processor as items not in that subset, with the union being the entire set. The trick then is to pick the right numbers such that when you run the load balancing algorithm you get jobs that correspond to numbers in the subset sum in one processor and the jobs that correspond to items not in it in the other processor. But I'm at a loss at how to pick the right numbers so that happens.",,False,,t5_2qj1c,False,,,True,t3_tkjpc,http://www.reddit.com/r/algorithms/comments/tkjpc/how_to_prove_load_balancing_is_npcomplete/,
1336272172.0,0,self.algorithms,t971v,ELI5: Why is the Collatz Conjecture algorithmically undecidable?,4,4,4,http://www.reddit.com/r/algorithms/comments/t971v/eli5_why_is_the_collatz_conjecture/,Don't explain it like I'm five. Explain it like I'm a potential math-major in her second year of undergraduate study.,,False,,t5_2qj1c,False,,,True,t3_t971v,http://www.reddit.com/r/algorithms/comments/t971v/eli5_why_is_the_collatz_conjecture/,
1335583642.0,0,i.imgur.com,swcdy,"The result of 3 hours of generating with a Diamond Square algorithm in java, 8192x8192 pixels.",4,4,4,http://www.reddit.com/r/algorithms/comments/swcdy/the_result_of_3_hours_of_generating_with_a/,,,False,,t5_2qj1c,False,,,False,t3_swcdy,http://i.imgur.com/iTClW.png,
1335052336.0,0,recursiveuniver.se,slxo9,Cafe au Life - Annotated Hashlife source code in Coffeescript,3,3,0,http://www.reddit.com/r/algorithms/comments/slxo9/cafe_au_life_annotated_hashlife_source_code_in/,,,False,,t5_2qj1c,False,,,False,t3_slxo9,http://recursiveuniver.se/docs/cafeaulife.html,
1334177364.0,0,self.algorithms,s4yll,RMST Algorithm for task scheduling,3,3,2,http://www.reddit.com/r/algorithms/comments/s4yll/rmst_algorithm_for_task_scheduling/,"The schedulability condition: max(ln2,1-xi*ln2), can someone explain what this means? I'm not familiar with the notation ln2,1 nor do I know what max means here.",,False,,t5_2qj1c,False,,,True,t3_s4yll,http://www.reddit.com/r/algorithms/comments/s4yll/rmst_algorithm_for_task_scheduling/,
1332455557.0,0,self.algorithms,r91vh,Hi there.  Does anyone know how to find rotation between to similar images?,1,1,1,http://www.reddit.com/r/algorithms/comments/r91vh/hi_there_does_anyone_know_how_to_find_rotation/,I'm wondering if there is an algorithm that can look at these [two pictures](http://imgur.com/a/dtCpF) of the same car and find calculate a transformation matrix to turn one picture into the other.,,False,,t5_2qj1c,False,,,True,t3_r91vh,http://www.reddit.com/r/algorithms/comments/r91vh/hi_there_does_anyone_know_how_to_find_rotation/,
1332345565.0,0,self.algorithms,r6vgj,Adjacency list from a set of rules? ,1,1,6,http://www.reddit.com/r/algorithms/comments/r6vgj/adjacency_list_from_a_set_of_rules/,"Lets say you have have to generate the adjacency list for a graph of N dials. D1,D2.. to DN. 

D1,D2.. DN can have values 0-9, and can each be increased, or decreased by 1, but only one at a time.

You are given N, as well as a subset of combinations for the dials that are not valid.

Of course, this is just an example, but the idea is that each combination of dials would represent a vertex in a graph, and each edge would be a valid way of getting from one combination to the next.

A similar example would be generating valid moves for a game board.

In either case, you could use the graph to find the shortest path from an initial state, to a target state.

My question is, what is the fastest way to generate the adjacency list? The naive solution, I would think, would be to generate each combination, and check to see if it were valid. And then, for each solution, create all possible neighbors, and check to see if those are in the valid combination list. 

It seems this solution would take at least O(10^N). Is there an existing algorithm that speeds this up a bit?",,False,,t5_2qj1c,False,,,True,t3_r6vgj,http://www.reddit.com/r/algorithms/comments/r6vgj/adjacency_list_from_a_set_of_rules/,
1331295559.0,0,reddit.com,qossv,Wondering about Sports League Scheduling Algorithm? Really don't know how I could implement it. [X-post from /r/learnprogramming],2,2,0,http://www.reddit.com/r/algorithms/comments/qossv/wondering_about_sports_league_scheduling/,,,False,,t5_2qj1c,False,,,False,t3_qossv,http://www.reddit.com/r/learnprogramming/comments/qofse/wondering_about_sports_league_scheduling/,
1331064279.0,0,self.algorithms,qkkz1,I need an algorithm!,3,3,9,http://www.reddit.com/r/algorithms/comments/qkkz1/i_need_an_algorithm/,"I'm cross-posting this from r/math:

I am developing a search engine for an upcoming web venture, and desperately need some help.

This search engine will return a list of user profiles. Each profile is assigned a score based off how much content they have added - 50 points for profile pictures, 10 pts for high priority content, 5 pts for medium, and 2 pts for low. Each profile also has a 0-5 star rating, and an integer value which represents the amount of times that the profile's owner has made a sprocket.
The problem is that I need an algorithm which orders by profiles with high ratings and content scores but low sprocket counts.
From my limited mathematical knowledge, I think that the ""baseline"" would be 3 sub-scores:

    priority = (sprockets / total sprockets) + (rating / 5) + (score / max score)

I have the feeling like it shouldn't be so simple, though. Are there any obvious consequences of this lay formula? Is there a better way to do this? What about curving each sub-score, perhaps with an adjustable constant (don't kill me) to change each sub-score's importance?
Any help would be much appreciated. I'm also not just looking for an answer, but also a learning opportunity.

**edit**: I am aware that in my equation the number of sprockets a profile has increases priority, which is not what I want. This is an obvious example of why I need help.

**edit 2**: Here's the one response I got on r/math from **jeffrey_negrea**, and it looks good (at least from the perspective of a person who is mathematically blind; moi). Any thoughts?

    base = (rating / 5) + (score / max score)  
    spro = (sprockets / total sprockets)
  
&gt; If you want priority to decrease when sprockets increase, one option is to ""discount"" base at a rate proportional to the number of sprockets. Let e be your favourite positive real value. Let our ""nominal interest rate convertible k times per year"" be i = (e)(spro). Define priority to be the present value of $base received in 1 year.

    priority = base / [1 + i/k]k = [(rating / 5) + (score / max score)] / [1 + (sprockets / total sprockets)(e/k)]k

&gt; The highest score possible is 2 occurring iff rating=5, score = max score and sprockets = 0  
The lowest score possible is 0 occurring iff rating = score = 0.  As the number of compounding intervals per unit time goes to infinity, we get the limiting priority function

    priority = (base)exp{-i} = base / [1 + i / k] k = [(rating / 5) + (score / max score)] exp{-(sprockets / total sprockets) e}

**edit 3**: Now is the time on Sprockets when we dance!",,False,,t5_2qj1c,True,,,True,t3_qkkz1,http://www.reddit.com/r/algorithms/comments/qkkz1/i_need_an_algorithm/,
1322668842.0,0,self.algorithms,mutmn,interesting puzzle,4,4,0,http://www.reddit.com/r/algorithms/comments/mutmn/interesting_puzzle/,"say you are given two things:
1) a list of words
2) a big block of text

your goal is to find the words from the list in the big block of text and replace them with &lt;FOUND&gt;.

what do you do? what DO you do?",,False,,t5_2qj1c,False,,,True,t3_mutmn,http://www.reddit.com/r/algorithms/comments/mutmn/interesting_puzzle/,
1317828000.0,2,self.algorithms,l1s03,Are all algorithms solvable using the Top Down approach?,8,6,7,http://www.reddit.com/r/algorithms/comments/l1s03/are_all_algorithms_solvable_using_the_top_down/,"As you know, in the top down approach we decompose a problem into smaller problems that can be solved and proven correct easily, and then we combine the solution to these small problems to find the answer to the original problem.

The question is: are all algorithms solvable using this approach? Or are there times where ""ad hoc"" solutions is inevitable?

For example, considering the following problem:

&gt; Given an integer x and a list of integers, find out if there are two numbers in the list that add up to x.

One O(nlogn) solution is to:

    sort the list
    for i = 0 to len of list
    using binary search, find an element with the value of (x - list[i]) that is not the i'th element
        if found return true
    return false

This doesn't look like an algorithm that's designed in a top-down approach, or is it and am I missing something here? If it's not, is there a top-down and efficient algorithm available for solving this problem?",,False,,t5_2qj1c,False,,,True,t3_l1s03,http://www.reddit.com/r/algorithms/comments/l1s03/are_all_algorithms_solvable_using_the_top_down/,
1316578496.0,0,self.algorithms,kme19,A simple way to understand lower bounds for algorithms,2,2,2,http://www.reddit.com/r/algorithms/comments/kme19/a_simple_way_to_understand_lower_bounds_for/,"(I would like someone to validate if this conversation is accurate)

Definition (for this discussion): 
Lower Bound : Minimum number of steps a algorithm needs to perform a task T to achieve a desired result Z.

Conversation between two machines A and B to perform task T (and produce
a desired result):

A: I need atleast X steps to peform this task. Mind you, that is atleast X,
meaning I may need lot more than X steps, but alteast X.

B : Ok, so X is your lower bound. I have an algorithm, but my algorithm needs
at least Y steps. and Y &gt; X. So, looks like your algorithm may be better for some
instances of the problem, where you may just need X or a little over X steps.

A: Y is your lower bound and my lower bound is better than yours. Also, I
believe any machine in the world will need at least X steps to perform task T.

Case 1:

Machine C walks in

C: Hold it A. I have an instance of the problem and an algorithm which will need
only Z steps for that instance and more than Z steps for all other instances.
Also, Z &lt; X. So, I have the best lower bound.

(Here C, just disproved A's claim about A's lower bound being best among ALL algorithms for task T).

Case 2:

Machine C walks in

C: Hold it A. Let me say something. You claim you need atleast X
steps to perform task T. But, I have a proof that any algorithm always needs W ( where W &gt; X ) steps to perform task T ( for all different instances of task T). So, I am tightening your lower bound. Needing atleast X steps is a valid statement since W&gt;X, but still was not tight. 
",,False,,t5_2qj1c,False,,,True,t3_kme19,http://www.reddit.com/r/algorithms/comments/kme19/a_simple_way_to_understand_lower_bounds_for/,
1292605257.0,0,self.algorithms,enhea,determine properties to split data in to groups,1,1,0,http://www.reddit.com/r/algorithms/comments/enhea/determine_properties_to_split_data_in_to_groups/,"i have a sample set of data which i have manually divided in n groups.
which possibilities do i have to find out which properties define a group membership?",,False,,t5_2qj1c,False,,,True,t3_enhea,http://www.reddit.com/r/algorithms/comments/enhea/determine_properties_to_split_data_in_to_groups/,
1284442031.0,0,newscientist.com,ddjil,Bayes's probability puzzle,6,6,2,http://www.reddit.com/r/algorithms/comments/ddjil/bayess_probability_puzzle/,,,False,,t5_2qj1c,False,,,False,t3_ddjil,http://www.newscientist.com/article/mg20727771.200-zeros-to-heroes-bayess-probability-puzzle.html,
1373604038.0,0,self.algorithms,1i4tml,Hoping some bright person here can help me out with this,1,2,3,http://www.reddit.com/r/algorithms/comments/1i4tml/hoping_some_bright_person_here_can_help_me_out/,"So I'm coming from over at /r/fantasyfootball, and have an interesting problem for you guys. I'm actually studying computer science, but am just getting into it, and therefore don't quite have the knowledge or experience be able to come up with a solution to this (though I'm looking forward to learning something during this process, hopefully).

So here's the problem.

I'm not sure how familiar many of you are with fantasy football, (or any fantasy sport really, it doesn't matter which) but the beginning of each season starts with a draft. You and your friends (usually 10, 12, or 14 people total) take turns choosing real-life players to be on your imaginary team, filling spots on your roster based on football position. Once a player is chosen, he's taken, and can't be selected by anyone else.

What I'm looking to do is to create a program or algorithm that will select the best team possible given the number of players that should be selected at each position. I've already broken the players into rounds, and have assigned values to each of them. A brief, simplified example:

Say my draft is much smaller. There are only 4 people playing in the league, drafting 5 total rounds, and I want 2 running backs (RB), one quarterback (QB), and two wide receivers (WR). The rounds look as follows.

**Round 1**

QB A (87 points)
QB B (80 points)
RB A (79 points)
WR A (75 points)

**Round 2**

RB B (70 points)
WR B (68 points)
WR C (67 points)
RB C (65 points)

**Round 3**

QB C (62 points)
RB D (60 points)
WR D (58 points)
QB D (56 points)

**Round 4**

QB E (55 points)
WR E (53 points)
WR F (52 points)
QB F (51 points)

**Round 5**

RB E (49 points)
WR G (46 points)
WR H (45 points)
QB G (42 points)

Being able to pick one player from each round, I want to garner the highest point total possible ending with a roster of 1 QB, 2 RB's, and 2 WR's. While this is fairly simple reduced down to this size, it's much more complicated (with there being literally millions of possible paths) when you have a group of 14 people selecting for 15 rounds.

Can anyone suggest how to go about doing this, or is anyone able to think of a set of steps to accomplish this? I haven't the faintest idea where to start, so I'd really appreciate any help anyone might be able to give.

Thanks very much!",,False,,t5_2qj1c,1373604542.0,,,True,t3_1i4tml,http://www.reddit.com/r/algorithms/comments/1i4tml/hoping_some_bright_person_here_can_help_me_out/,
1370563401.0,0,self.algorithms,1ftu76,Crucial Algorithms that everybody should know,1,2,0,http://www.reddit.com/r/algorithms/comments/1ftu76/crucial_algorithms_that_everybody_should_know/,"Do you guys have any algorithms that everybody should know? It can go from basic all the way to advanced. I'll start off with a few basics:

Binary Search

Quicksort

Heapsort",,False,,t5_2qj1c,1370564139.0,,,True,t3_1ftu76,http://www.reddit.com/r/algorithms/comments/1ftu76/crucial_algorithms_that_everybody_should_know/,
1369863870.0,0,self.algorithms,1fanfr,On the practice of calculating the probability of rolling exactly A black-dice successes and exactly B white-dice successes when drawing Z dice from a bag containing X black dice and Y white dice,1,2,1,http://www.reddit.com/r/algorithms/comments/1fanfr/on_the_practice_of_calculating_the_probability_of/,"For creating a game, I am creating a statistical model for the practice of placing X black six-sided dice and Y white six-sided dice into a bag, drawing Z of these dice and then rolling them, with a success on a black die being 4 through 6 and success on a white die being 5 or 6. I am wanting to create a different probability matrix for each combination of X, Y and Z. This matrix will have values 0 through Z on both axes, with one axis indication the number of successes on the black dice rolled and one axis indicating the number of successes on the white dice rolled. The end result is a chart that allows me to reference corresponding cells to determine my chances of rolling exactly A black-dice successes and exactly B white-dice successes when drawing Z dice from a bag containing X black dice and Y white dice.

The method I am using to model these probabilities is as follows: For each possible combination of A black-dice successes and B white-dice successes (with proposed values A and B ranging from 0 to the sample size Z), I go through each set of possible values for the number of black dice (P) and the number of white dice (Q) drawn Z at a time and calculate the probabilities that each particular combination would produce exactly A black-dice successes and B white-dice success. I do this by finding the product of:

* the probability of rolling A black-dice successes (0.5 ^ A)

* the probability of rolling black-dice failures on the remaining black dice (0.5 ^ (Z - (A+Q)))

* the probability of rolling B white-dice successes (0.333 ^ B)

* the probability of rolling white-dice failures on the remaining white dice (0.667 ^ (Z - (B+P)))

I then use the hypergeometric distribution for a population size X+Y with X possible successes and a sample size of Z to determine the probability that exactly P black dice would be drawn in the first place and multiply the above product by that number. This gives me the probability that I will draw exactly P black dice and Q white dice when drawing Z dice from a bag of X black dice and Y white dice, and then subsequently roll A black-dice successes and B white-dice successes. The summation of all values of P+Q=Z gives me a single cell in my matrix offering the probability of rolling exactly A black-dice successes and exactly B white-dice successes when drawing Z dice from a bag containing X black dice and Y white dice.

I have written a Java program to run these numbers for me because ain't nobody trying to do all that on paper, amirite? (Also, I recognize that there are values of A and B that are not possible for some combinations of XYZ. The program detects these and sets those probabilities to zero before the point of summation.)

My problem: my algorithm should produce values for all possible combinations but when I run the program and add up all of the values in the completed matrix, I come up with a value that is less than zero. Now, computer programs are complex and finicky things. . .I know this. It is entirely possible that I bullocks up the code somewhere and that is the issue. However, what I am trying to determine is this: **is the method described above correct or have I messed up my algorithm?**
",,False,,t5_2qj1c,False,,,True,t3_1fanfr,http://www.reddit.com/r/algorithms/comments/1fanfr/on_the_practice_of_calculating_the_probability_of/,
1367391311.0,0,self.algorithms,1dgw1l,Asymptotic analysis: O(n) vs. O(n log n),2,3,15,http://www.reddit.com/r/algorithms/comments/1dgw1l/asymptotic_analysis_on_vs_on_log_n/,"Seems pretty basic, but can someone explain why we differentiate between those two? Obviously n log n is bigger than n, but given the definition of O(.), aren't the sets O(n) and O(n log n) the same? Is the difference tantamount to the one between O(n) and O(cn) for some constant c? That is, for c&gt;1, cn&gt;n, but O(cn)=O(n).",,False,,t5_2qj1c,False,,,True,t3_1dgw1l,http://www.reddit.com/r/algorithms/comments/1dgw1l/asymptotic_analysis_on_vs_on_log_n/,
1367294311.0,0,self.algorithms,1de1lh,Scheduling Genetic Algorithm,1,2,2,http://www.reddit.com/r/algorithms/comments/1de1lh/scheduling_genetic_algorithm/,"Hello Everyone,
I am an 11th grader that just started calculus and limits (so my knowledge of calculus is not extensive). I was thinking about doing a project over the summer in which I would create a genetic algorithm with the aim of solving a scheduling problem. I think it would be really cool if I could create an algorithm and then offer it to the administration to use instead of their manual way of making students' schedules. Anyone have any advice? How much math would this project entail? Or is it more about the coding?",,False,,t5_2qj1c,False,,,True,t3_1de1lh,http://www.reddit.com/r/algorithms/comments/1de1lh/scheduling_genetic_algorithm/,
1366152099.0,0,en.wikipedia.org,1chqv8,Algorithm of the day:Master Theorem,1,2,0,http://www.reddit.com/r/algorithms/comments/1chqv8/algorithm_of_the_daymaster_theorem/,,,False,,t5_2qj1c,False,,,False,t3_1chqv8,http://en.wikipedia.org/wiki/Master_theorem,
1366071767.0,0,self.algorithms,1cfdwu,good ole' TSP (traveling salesman problem)..,1,2,0,http://www.reddit.com/r/algorithms/comments/1cfdwu/good_ole_tsp_traveling_salesman_problem/,Anybody know of a good chunk of psuedo-code for TSP using dynamic programming?,,False,,t5_2qj1c,False,,,True,t3_1cfdwu,http://www.reddit.com/r/algorithms/comments/1cfdwu/good_ole_tsp_traveling_salesman_problem/,
1365793932.0,0,en.wikipedia.org,1c834r,Algorithm of the day: Huffman coding,4,5,0,http://www.reddit.com/r/algorithms/comments/1c834r/algorithm_of_the_day_huffman_coding/,,,False,,t5_2qj1c,False,,,False,t3_1c834r,http://en.wikipedia.org/wiki/Huffman_coding,
1364513244.0,0,self.algorithms,1b7iwl,Getting started with algorithms?,3,4,5,http://www.reddit.com/r/algorithms/comments/1b7iwl/getting_started_with_algorithms/,"I'm a (relatively) good programmer. I can solve most problems I run into; however, when I go to codechef, I find that I'm *very* lacking when it comes to constructing algorithms. If anyone can suggest some reading material that will teach me the basics, I feel I can learn more from there.",,False,,t5_2qj1c,False,,,True,t3_1b7iwl,http://www.reddit.com/r/algorithms/comments/1b7iwl/getting_started_with_algorithms/,
1363352388.0,0,self.algorithms,1acipf,Help with Algorithms,4,5,10,http://www.reddit.com/r/algorithms/comments/1acipf/help_with_algorithms/,"Hey all, 
I've become stuck on my assessment on the last two questions regarding pseudocode,
&gt;
&gt;Write the pseudocode for an iterative algorithm which takes as input a list of numbers and also returns as output a list of numbers. This algorithm leaves the first entry in the input list unchanged, but divides each next element in the list by its preceding element. For example, the input list [5, 4, 2, −6] should be returned as [5, 0.8, 0.5, −3].
&gt;
&gt;Trace your pseudocode for the input list [5, 4, 2, –6].
&gt;
I've been told that it's only 3 lines with an input of something roughly like 
b_n = a_n/a_(n-1) and b_0 = a_0,

If someone can help explain that would be really nice.
Also
&gt;
    Consider the following pseudocode segment.
    1. input y {y is a three-digit hexadecimal number}
    2. d ← 0
    3. for i = 1 to 3
    3.1. char ← i^th character of y, reading y from right to left
    3.2. if char = ‘A or B or C or D or E or F’
    3.2.1. Convert char to its decimal equivalent
    3.3. end if
    3.4. d ← d + 16^i-1 x char
    4. end for
    5. output d

Trace the pseudocode for the input y=A2E

Briefly explain in words what this pseudocode does (i.e. its purpose) and how it achieves that purpose. You only need to write two or three short sentences to answer this question.

I've solved every other issue but stuck on these, now I don't just want the answer if someone can explain how it works as well to help me understand them then I would be happy. As I was only introduced to this stuff a few days ago and am expected to full understand it and I'm having real trouble with the whole logic thing. ",,False,,t5_2qj1c,1363381694.0,,,True,t3_1acipf,http://www.reddit.com/r/algorithms/comments/1acipf/help_with_algorithms/,
1362849415.0,0,self.algorithms,19z70a,interview call - Help with Algorithms and Data Structures needed.,2,3,3,http://www.reddit.com/r/algorithms/comments/19z70a/interview_call_help_with_algorithms_and_data/,"Hi, I got a tech interview call from this amazing company(don't ask name) and they are looking for programmers with stress on Algorithms and Data structers, searching, sorting, trees, sets, arrays etc and O(n). Hashing is very important obviously. I have studied those sometime ago but now have become rusty and i am looking for sources to brush up quick and in depth and detail- with big O(n). also, which language should i go for. C, C++ or Java? I am into all of those.
Apologies if im getting this on the wrong subreddit but this could be a life changer for me. Thanks again. ",,False,,t5_2qj1c,False,,,True,t3_19z70a,http://www.reddit.com/r/algorithms/comments/19z70a/interview_call_help_with_algorithms_and_data/,
1361960401.0,0,self.algorithms,19bjrc,Why Algorithms are Important,3,4,0,http://www.reddit.com/r/algorithms/comments/19bjrc/why_algorithms_are_important/,"When we started looking at algs, my professor used this example to show why algorithms matter:

The age of the universe in Planck time (sometimes considered the smallest unit of time) 

- age of universe in Planck time ≈ 10^61.

The number of atoms in the observable universe 

- number of cores ≈ 10^80.

Therefore, the 

- max number of cpu cores × max clock ticks ≈ 10^141 steps

In the last five years, this becomes

- max cpu cores × max clock ticks in five years ≈ 10^100 steps.

Reasonably, the most steps a person could run a program for is 

- 500 cores × 4 GHz × 5 years ≈ 10^20 steps.

Say you wanted to sort 100 items. If we try to do this by brute force, i.e. by putting them in random order until we get the right one, we get

- number of permutations = 100! ≈ 10^158.

Meaning that, without algorithms, there is no way we could have sorted 100 items, even if we used each atom in the universe as a core, running at the fastest speed theoretically possible, for the entire duration of the universe.

Edit for formatting",,False,,t5_2qj1c,1361960912.0,,,True,t3_19bjrc,http://www.reddit.com/r/algorithms/comments/19bjrc/why_algorithms_are_important/,
1360188279.0,0,self.algorithms,180wmy,Building a Restricted Towers of Hanoi Algorithm (Restriction inside),8,8,2,http://www.reddit.com/r/algorithms/comments/180wmy/building_a_restricted_towers_of_hanoi_algorithm/,"So I'm messing with the towers of Hanoi algorithm, which is a very standard example of recursive programming but for anyone that hasn't seen it, it looks like this:

&gt;FUNCTION MoveTower(disk, source, dest, spare):


&gt;IF disk == 0, THEN:
  

&gt; move disk from source to dest


&gt;ELSE:
    

&gt;  MoveTower(disk - 1, source, spare, dest)   
    

&gt;  move disk from source to dest    //(My idea is make this two moves, but seems too easy)
    

&gt;  MoveTower(disk - 1, spare, dest, source)  


&gt;END IF

I want to impose a restriction on this though. You cannot go from source right to dest, or from A to C (if you label each tower A,B,C from left to right). So for one disk, you'd move A-&gt;B-&gt;C rather than just A-&gt;B. (Same to move back: C-&gt;B-&gt;A)

I know that the complexity moves from 2^n to 3^n, but I'm having trouble with the actual pseudocode.

Ideas?",,False,,t5_2qj1c,1360193016.0,,,True,t3_180wmy,http://www.reddit.com/r/algorithms/comments/180wmy/building_a_restricted_towers_of_hanoi_algorithm/,
1359806305.0,0,reddit.com,17r0t6,SubReddit for programming contests (algorithmic style contests very welcome),1,2,0,http://www.reddit.com/r/algorithms/comments/17r0t6/subreddit_for_programming_contests_algorithmic/,,,False,,t5_2qj1c,False,,,False,t3_17r0t6,http://www.reddit.com/r/pcontests/,
1359516709.0,0,self.algorithms,17jg6n,Counting iterations of a while loop,5,6,4,http://www.reddit.com/r/algorithms/comments/17jg6n/counting_iterations_of_a_while_loop/,"If given a loop:
while n&gt;1
   n=n-b
endwhile

Is it possible to express the number of iterations in terms of n and b alone? or do I need to introduce a constant k?

If this subreddit isn't for such basic questions please point me in the right direction.",,False,,t5_2qj1c,False,,,True,t3_17jg6n,http://www.reddit.com/r/algorithms/comments/17jg6n/counting_iterations_of_a_while_loop/,
1354440600.0,0,github.com,145973,PowerShell Algorithm Module,1,2,0,http://www.reddit.com/r/algorithms/comments/145973/powershell_algorithm_module/,,,False,,t5_2qj1c,False,,,False,t3_145973,https://github.com/taylorgibb/algorithms/,
1352839934.0,0,self.algorithms,1353xq,"AVL Trees, Rotations, and Me",3,4,3,http://www.reddit.com/r/algorithms/comments/1353xq/avl_trees_rotations_and_me/,"So I was sick at school and missed about three lectures, all centered on AVL trees. Through personal reading, I get the general gist of them, but the process of doing rotations just isn't clicking. I'm probably just misinterpreting or missing a key point, hence why I came here. Can anyone give me the idiot's guide to rotating a tree?",,False,,t5_2qj1c,False,,,True,t3_1353xq,http://www.reddit.com/r/algorithms/comments/1353xq/avl_trees_rotations_and_me/,
1343941692.0,0,self.algorithms,xl1ld,Algorithm for Scaling an Object Relative to Another Object.,1,2,1,http://www.reddit.com/r/algorithms/comments/xl1ld/algorithm_for_scaling_an_object_relative_to/,"I'm trying to figure out an algorithm for doing this:  [http://i.imgur.com/8WsAV.png!](http://i.imgur.com/8WsAV.png).  My objects have the following  geometric properties:  

*  X
*  Y
*  Width
*  Height
*  CenterX
*  CenterY
*  SkewX
*  SkewY

These objects can contain other objects as shown in the picture.  It's pretty easy to determine the scaled dimensions of the outer objects, but I can't figure out the correct algorithm to compute the scaled dimensions of its inner objects.  Does anyone know an algorithm for this?  This seems like a fairly common problem for graphical programs but I'm having a hard time looking for a solution online.
",,False,,t5_2qj1c,False,,,True,t3_xl1ld,http://www.reddit.com/r/algorithms/comments/xl1ld/algorithm_for_scaling_an_object_relative_to/,
1340913846.0,0,mostafa-abedi.com,vramw,"My takes &amp; notes | Coursera | Algorithms: Design and Analysis , part 1 | Introduction | Mostafa Abedi's Learning Blog",8,9,0,http://www.reddit.com/r/algorithms/comments/vramw/my_takes_notes_coursera_algorithms_design_and/,,,False,,t5_2qj1c,False,,,False,t3_vramw,http://mostafa-abedi.com/2012/06/takes-notes-coursera-algorithms-design-analysis-part-1-introduction/,
1340771601.0,0,self.algorithms,vo4bi,Need Help: Algorithm for matching numbers.,2,3,20,http://www.reddit.com/r/algorithms/comments/vo4bi/need_help_algorithm_for_matching_numbers/,"~~What algorithm generates a paring of all numbers 1..n in all possible ways of pairing?~~

Edit: A better question:  There are n students in a classroom, numbered 1..n. A teacher needs to be able to print a list floor(n/2) long showing partners for a project. Stragglers will be printed last. A different pairing needs to be printed every day. How can this list be generated? Can we ensure all possible ways of pairing are exhausted?",,False,,t5_2qj1c,1340778502.0,,,True,t3_vo4bi,http://www.reddit.com/r/algorithms/comments/vo4bi/need_help_algorithm_for_matching_numbers/,
1363371895.0,0,sorting-algorithms.com,1ad3hs,Algoritmos de ordenação,3,5,0,http://www.reddit.com/r/algorithms/comments/1ad3hs/algoritmos_de_ordenação/,,,False,,t5_2qj1c,False,,,False,t3_1ad3hs,http://www.sorting-algorithms.com/,
1362091664.0,0,self.algorithms,19fb8e,Why didn't OP google the question before asking it on Reddit?,2,4,0,http://www.reddit.com/r/algorithms/comments/19fb8e/why_didnt_op_google_the_question_before_asking_it/,"Apologies but this is a general purpose comment regarding the ""why didn't the OP google question before asking reddit"" situation.  (A) If you see one of these situations, how about simply sharing the keywords YOU used to find a solution and let OP take it from there; if there are more questions, we're always open. (B) If you're the OP, tell us what keywords you used to do your search.  DETAILS: I agree that people should use the resources at hand before coming to reddit, including but not limited to google.  I consider myself pretty resourceful when doing a search but I know I've come up dry on google before -- only to have someone (usually rudely but whatever) point out web resources they found.  Don't know what I missed but it was probably a word or phrase I hadn't thought of -- which I'd like to know about for next time.  Soap box is now being vacated...",,False,,t5_2qj1c,False,,,True,t3_19fb8e,http://www.reddit.com/r/algorithms/comments/19fb8e/why_didnt_op_google_the_question_before_asking_it/,
1360560015.0,0,self.algorithms,18ajqy,Help !,3,4,2,http://www.reddit.com/r/algorithms/comments/18ajqy/help/,"I'm a new Computer Science student and kinda new to writing algorithms
Here's the problem I'm trying to solve:
Design an algorithm that is given a positive integer N and determines whether N is a prime number,
that is, not evenly divisible by any value other than 1 and itself. The output of your algorithm is
either the message ‘not prime,’ along with the given number N, or the message ‘prime’.
I know that I have to test the opposite and have a loop, but I can't seem to figure it out
Please help a rookie !",,False,,t5_2qj1c,False,,,True,t3_18ajqy,http://www.reddit.com/r/algorithms/comments/18ajqy/help/,
1355320860.0,0,en.wikipedia.org,14q3w6,"Knight's tour - Wikipedia, the free encyclopedia",2,4,0,http://www.reddit.com/r/algorithms/comments/14q3w6/knights_tour_wikipedia_the_free_encyclopedia/,,,False,,t5_2qj1c,False,,,False,t3_14q3w6,http://en.wikipedia.org/wiki/Knight's_tour,
1353790486.0,0,programmers.stackexchange.com,13q805,Help with algorithmic complexity in custom merge sort implementation,1,3,0,http://www.reddit.com/r/algorithms/comments/13q805/help_with_algorithmic_complexity_in_custom_merge/,,,False,,t5_2qj1c,False,,,False,t3_13q805,http://programmers.stackexchange.com/q/177069/42062,
1353454230.0,0,self.algorithms,13jbb8,What algorithm does an operating system use to choose the frame of a video to display as it's icon? And can I play around with it in Linux(Ubuntu)?,1,3,3,http://www.reddit.com/r/algorithms/comments/13jbb8/what_algorithm_does_an_operating_system_use_to/,,,False,,t5_2qj1c,False,,,True,t3_13jbb8,http://www.reddit.com/r/algorithms/comments/13jbb8/what_algorithm_does_an_operating_system_use_to/,
1353299579.0,0,self.algorithms,13fnwv,What is your favorite Algorithm?,1,3,4,http://www.reddit.com/r/algorithms/comments/13fnwv/what_is_your_favorite_algorithm/,"There are countless algorithms, what are some that you find truly brilliant or simply just find yourself in awe at their beauty?

I personally love the Fitch maximum parsimony algorithm developed by Walter Fitch for its eloquence. One of my favorite algorithms for it's sheer brilliance is fortunes.

What's your favorite /r/algorithms?",,False,,t5_2qj1c,1353301770.0,,,True,t3_13fnwv,http://www.reddit.com/r/algorithms/comments/13fnwv/what_is_your_favorite_algorithm/,
1334453956.0,0,self.algorithms,sa9a7,Are there any commonly used algorithms in video gaming?,3,5,6,http://www.reddit.com/r/algorithms/comments/sa9a7/are_there_any_commonly_used_algorithms_in_video/,"I'm just learning about algorithms and have a research assignment. Hit me with some interesting knowledge, please and thank you :)",,False,,t5_2qj1c,False,,,True,t3_sa9a7,http://www.reddit.com/r/algorithms/comments/sa9a7/are_there_any_commonly_used_algorithms_in_video/,
1268160323.0,0,digg.com,bb90g,Buggy recursive call.,2,5,0,http://www.reddit.com/r/algorithms/comments/bb90g/buggy_recursive_call/,,,False,,t5_2qj1c,False,,,False,t3_bb90g,http://digg.com,
